I0526 17:04:51.508635 24213 caffe.cpp:185] Using GPUs 0
I0526 17:04:51.534660 24213 caffe.cpp:190] GPU 0: GeForce GTX TITAN X
I0526 17:04:51.868120 24213 solver.cpp:48] Initializing solver from parameters: 
test_iter: 11
test_interval: 30
base_lr: 1e-05
display: 10
max_iter: 8000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 1000
snapshot: 1000
snapshot_prefix: "snapshot2/caffe_CAM_finetuneMIT"
solver_mode: GPU
device_id: 0
net: "train_val.prototxt"
I0526 17:04:51.868299 24213 solver.cpp:91] Creating training net from net file: train_val.prototxt
I0526 17:04:51.869626 24213 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0526 17:04:51.869693 24213 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0526 17:04:51.870038 24213 net.cpp:49] Initializing net from parameters: 
name: "placesCNNobjectdiscoveryAverageSumFinedtunedMITindoor"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  image_data_param {
    source: "train.txt"
    batch_size: 128
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "conv6"
  type: "Convolution"
  bottom: "pool5"
  top: "conv6"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "conv6"
  top: "conv6"
}
layer {
  name: "conv7"
  type: "Convolution"
  bottom: "conv6"
  top: "conv7"
  param {
    lr_mult: 5
    decay_mult: 1
  }
  param {
    lr_mult: 10
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "conv7"
  top: "conv7"
}
layer {
  name: "pool8_global"
  type: "Pooling"
  bottom: "conv7"
  top: "pool8_global"
  pooling_param {
    pool: AVE
    kernel_size: 11
    stride: 11
  }
}
layer {
  name: "mitindoor_fc9"
  type: "InnerProduct"
  bottom: "pool8_global"
  top: "mitindoor_fc9"
  param {
    lr_mult: 10
    decay_mult: 1
  }
  param {
    lr_mult: 20
    decay_mult: 0
  }
  inner_product_param {
    num_output: 67
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "mitindoor_fc9"
  bottom: "label"
  top: "loss"
}
I0526 17:04:51.870251 24213 layer_factory.hpp:77] Creating layer data
I0526 17:04:51.870314 24213 net.cpp:91] Creating Layer data
I0526 17:04:51.870327 24213 net.cpp:399] data -> data
I0526 17:04:51.870362 24213 net.cpp:399] data -> label
I0526 17:04:51.870906 24213 image_data_layer.cpp:38] Opening file train.txt
I0526 17:04:51.871332 24213 image_data_layer.cpp:53] A total of 405 images.
I0526 17:04:51.887533 24213 image_data_layer.cpp:80] output data size: 128,3,227,227
I0526 17:04:52.045938 24213 net.cpp:141] Setting up data
I0526 17:04:52.046044 24213 net.cpp:148] Top shape: 128 3 227 227 (19787136)
I0526 17:04:52.046087 24213 net.cpp:148] Top shape: 128 (128)
I0526 17:04:52.046113 24213 net.cpp:156] Memory required for data: 79149056
I0526 17:04:52.046144 24213 layer_factory.hpp:77] Creating layer conv1
I0526 17:04:52.046188 24213 net.cpp:91] Creating Layer conv1
I0526 17:04:52.046217 24213 net.cpp:425] conv1 <- data
I0526 17:04:52.046252 24213 net.cpp:399] conv1 -> conv1
I0526 17:04:52.049409 24213 net.cpp:141] Setting up conv1
I0526 17:04:52.049474 24213 net.cpp:148] Top shape: 128 96 55 55 (37171200)
I0526 17:04:52.049504 24213 net.cpp:156] Memory required for data: 227833856
I0526 17:04:52.049545 24213 layer_factory.hpp:77] Creating layer relu1
I0526 17:04:52.049579 24213 net.cpp:91] Creating Layer relu1
I0526 17:04:52.049607 24213 net.cpp:425] relu1 <- conv1
I0526 17:04:52.049633 24213 net.cpp:386] relu1 -> conv1 (in-place)
I0526 17:04:52.049671 24213 net.cpp:141] Setting up relu1
I0526 17:04:52.049700 24213 net.cpp:148] Top shape: 128 96 55 55 (37171200)
I0526 17:04:52.049726 24213 net.cpp:156] Memory required for data: 376518656
I0526 17:04:52.049747 24213 layer_factory.hpp:77] Creating layer pool1
I0526 17:04:52.049774 24213 net.cpp:91] Creating Layer pool1
I0526 17:04:52.049798 24213 net.cpp:425] pool1 <- conv1
I0526 17:04:52.049823 24213 net.cpp:399] pool1 -> pool1
I0526 17:04:52.049918 24213 net.cpp:141] Setting up pool1
I0526 17:04:52.049958 24213 net.cpp:148] Top shape: 128 96 27 27 (8957952)
I0526 17:04:52.049988 24213 net.cpp:156] Memory required for data: 412350464
I0526 17:04:52.050011 24213 layer_factory.hpp:77] Creating layer norm1
I0526 17:04:52.050056 24213 net.cpp:91] Creating Layer norm1
I0526 17:04:52.050086 24213 net.cpp:425] norm1 <- pool1
I0526 17:04:52.050124 24213 net.cpp:399] norm1 -> norm1
I0526 17:04:52.056438 24213 net.cpp:141] Setting up norm1
I0526 17:04:52.056499 24213 net.cpp:148] Top shape: 128 96 27 27 (8957952)
I0526 17:04:52.056531 24213 net.cpp:156] Memory required for data: 448182272
I0526 17:04:52.056557 24213 layer_factory.hpp:77] Creating layer conv2
I0526 17:04:52.056592 24213 net.cpp:91] Creating Layer conv2
I0526 17:04:52.056618 24213 net.cpp:425] conv2 <- norm1
I0526 17:04:52.056645 24213 net.cpp:399] conv2 -> conv2
I0526 17:04:52.072438 24213 net.cpp:141] Setting up conv2
I0526 17:04:52.072530 24213 net.cpp:148] Top shape: 128 256 27 27 (23887872)
I0526 17:04:52.072561 24213 net.cpp:156] Memory required for data: 543733760
I0526 17:04:52.072600 24213 layer_factory.hpp:77] Creating layer relu2
I0526 17:04:52.072633 24213 net.cpp:91] Creating Layer relu2
I0526 17:04:52.072656 24213 net.cpp:425] relu2 <- conv2
I0526 17:04:52.072686 24213 net.cpp:386] relu2 -> conv2 (in-place)
I0526 17:04:52.072717 24213 net.cpp:141] Setting up relu2
I0526 17:04:52.072747 24213 net.cpp:148] Top shape: 128 256 27 27 (23887872)
I0526 17:04:52.072772 24213 net.cpp:156] Memory required for data: 639285248
I0526 17:04:52.072795 24213 layer_factory.hpp:77] Creating layer pool2
I0526 17:04:52.072821 24213 net.cpp:91] Creating Layer pool2
I0526 17:04:52.072846 24213 net.cpp:425] pool2 <- conv2
I0526 17:04:52.072873 24213 net.cpp:399] pool2 -> pool2
I0526 17:04:52.072962 24213 net.cpp:141] Setting up pool2
I0526 17:04:52.072994 24213 net.cpp:148] Top shape: 128 256 13 13 (5537792)
I0526 17:04:52.073019 24213 net.cpp:156] Memory required for data: 661436416
I0526 17:04:52.073043 24213 layer_factory.hpp:77] Creating layer norm2
I0526 17:04:52.073076 24213 net.cpp:91] Creating Layer norm2
I0526 17:04:52.073101 24213 net.cpp:425] norm2 <- pool2
I0526 17:04:52.073127 24213 net.cpp:399] norm2 -> norm2
I0526 17:04:52.073196 24213 net.cpp:141] Setting up norm2
I0526 17:04:52.073228 24213 net.cpp:148] Top shape: 128 256 13 13 (5537792)
I0526 17:04:52.073252 24213 net.cpp:156] Memory required for data: 683587584
I0526 17:04:52.073274 24213 layer_factory.hpp:77] Creating layer conv3
I0526 17:04:52.073307 24213 net.cpp:91] Creating Layer conv3
I0526 17:04:52.073333 24213 net.cpp:425] conv3 <- norm2
I0526 17:04:52.073362 24213 net.cpp:399] conv3 -> conv3
I0526 17:04:52.116436 24213 net.cpp:141] Setting up conv3
I0526 17:04:52.116525 24213 net.cpp:148] Top shape: 128 384 13 13 (8306688)
I0526 17:04:52.116555 24213 net.cpp:156] Memory required for data: 716814336
I0526 17:04:52.116596 24213 layer_factory.hpp:77] Creating layer relu3
I0526 17:04:52.116631 24213 net.cpp:91] Creating Layer relu3
I0526 17:04:52.116657 24213 net.cpp:425] relu3 <- conv3
I0526 17:04:52.116694 24213 net.cpp:386] relu3 -> conv3 (in-place)
I0526 17:04:52.116731 24213 net.cpp:141] Setting up relu3
I0526 17:04:52.116760 24213 net.cpp:148] Top shape: 128 384 13 13 (8306688)
I0526 17:04:52.116785 24213 net.cpp:156] Memory required for data: 750041088
I0526 17:04:52.116811 24213 layer_factory.hpp:77] Creating layer conv4
I0526 17:04:52.116847 24213 net.cpp:91] Creating Layer conv4
I0526 17:04:52.116873 24213 net.cpp:425] conv4 <- conv3
I0526 17:04:52.116901 24213 net.cpp:399] conv4 -> conv4
I0526 17:04:52.148829 24213 net.cpp:141] Setting up conv4
I0526 17:04:52.148910 24213 net.cpp:148] Top shape: 128 384 13 13 (8306688)
I0526 17:04:52.148938 24213 net.cpp:156] Memory required for data: 783267840
I0526 17:04:52.148972 24213 layer_factory.hpp:77] Creating layer relu4
I0526 17:04:52.149003 24213 net.cpp:91] Creating Layer relu4
I0526 17:04:52.149027 24213 net.cpp:425] relu4 <- conv4
I0526 17:04:52.149057 24213 net.cpp:386] relu4 -> conv4 (in-place)
I0526 17:04:52.149087 24213 net.cpp:141] Setting up relu4
I0526 17:04:52.149116 24213 net.cpp:148] Top shape: 128 384 13 13 (8306688)
I0526 17:04:52.149140 24213 net.cpp:156] Memory required for data: 816494592
I0526 17:04:52.149163 24213 layer_factory.hpp:77] Creating layer conv5
I0526 17:04:52.149194 24213 net.cpp:91] Creating Layer conv5
I0526 17:04:52.149230 24213 net.cpp:425] conv5 <- conv4
I0526 17:04:52.149273 24213 net.cpp:399] conv5 -> conv5
I0526 17:04:52.181145 24213 net.cpp:141] Setting up conv5
I0526 17:04:52.181229 24213 net.cpp:148] Top shape: 128 384 13 13 (8306688)
I0526 17:04:52.181260 24213 net.cpp:156] Memory required for data: 849721344
I0526 17:04:52.181298 24213 layer_factory.hpp:77] Creating layer relu5
I0526 17:04:52.181334 24213 net.cpp:91] Creating Layer relu5
I0526 17:04:52.181361 24213 net.cpp:425] relu5 <- conv5
I0526 17:04:52.181394 24213 net.cpp:386] relu5 -> conv5 (in-place)
I0526 17:04:52.181426 24213 net.cpp:141] Setting up relu5
I0526 17:04:52.181455 24213 net.cpp:148] Top shape: 128 384 13 13 (8306688)
I0526 17:04:52.181479 24213 net.cpp:156] Memory required for data: 882948096
I0526 17:04:52.181506 24213 layer_factory.hpp:77] Creating layer pool5
I0526 17:04:52.181535 24213 net.cpp:91] Creating Layer pool5
I0526 17:04:52.181560 24213 net.cpp:425] pool5 <- conv5
I0526 17:04:52.181589 24213 net.cpp:399] pool5 -> pool5
I0526 17:04:52.181675 24213 net.cpp:141] Setting up pool5
I0526 17:04:52.181709 24213 net.cpp:148] Top shape: 128 384 11 11 (5947392)
I0526 17:04:52.181732 24213 net.cpp:156] Memory required for data: 906737664
I0526 17:04:52.181756 24213 layer_factory.hpp:77] Creating layer conv6
I0526 17:04:52.181799 24213 net.cpp:91] Creating Layer conv6
I0526 17:04:52.181825 24213 net.cpp:425] conv6 <- pool5
I0526 17:04:52.181864 24213 net.cpp:399] conv6 -> conv6
I0526 17:04:52.223999 24213 net.cpp:141] Setting up conv6
I0526 17:04:52.224092 24213 net.cpp:148] Top shape: 128 512 11 11 (7929856)
I0526 17:04:52.224119 24213 net.cpp:156] Memory required for data: 938457088
I0526 17:04:52.224151 24213 layer_factory.hpp:77] Creating layer relu6
I0526 17:04:52.224182 24213 net.cpp:91] Creating Layer relu6
I0526 17:04:52.224207 24213 net.cpp:425] relu6 <- conv6
I0526 17:04:52.224234 24213 net.cpp:386] relu6 -> conv6 (in-place)
I0526 17:04:52.224266 24213 net.cpp:141] Setting up relu6
I0526 17:04:52.224292 24213 net.cpp:148] Top shape: 128 512 11 11 (7929856)
I0526 17:04:52.224314 24213 net.cpp:156] Memory required for data: 970176512
I0526 17:04:52.224336 24213 layer_factory.hpp:77] Creating layer conv7
I0526 17:04:52.224370 24213 net.cpp:91] Creating Layer conv7
I0526 17:04:52.224392 24213 net.cpp:425] conv7 <- conv6
I0526 17:04:52.224421 24213 net.cpp:399] conv7 -> conv7
I0526 17:04:52.280982 24213 net.cpp:141] Setting up conv7
I0526 17:04:52.281119 24213 net.cpp:148] Top shape: 128 512 11 11 (7929856)
I0526 17:04:52.281148 24213 net.cpp:156] Memory required for data: 1001895936
I0526 17:04:52.281183 24213 layer_factory.hpp:77] Creating layer relu7
I0526 17:04:52.281218 24213 net.cpp:91] Creating Layer relu7
I0526 17:04:52.281244 24213 net.cpp:425] relu7 <- conv7
I0526 17:04:52.281275 24213 net.cpp:386] relu7 -> conv7 (in-place)
I0526 17:04:52.281309 24213 net.cpp:141] Setting up relu7
I0526 17:04:52.281337 24213 net.cpp:148] Top shape: 128 512 11 11 (7929856)
I0526 17:04:52.281359 24213 net.cpp:156] Memory required for data: 1033615360
I0526 17:04:52.281381 24213 layer_factory.hpp:77] Creating layer pool8_global
I0526 17:04:52.281407 24213 net.cpp:91] Creating Layer pool8_global
I0526 17:04:52.281433 24213 net.cpp:425] pool8_global <- conv7
I0526 17:04:52.281461 24213 net.cpp:399] pool8_global -> pool8_global
I0526 17:04:52.281522 24213 net.cpp:141] Setting up pool8_global
I0526 17:04:52.281555 24213 net.cpp:148] Top shape: 128 512 1 1 (65536)
I0526 17:04:52.281580 24213 net.cpp:156] Memory required for data: 1033877504
I0526 17:04:52.281604 24213 layer_factory.hpp:77] Creating layer mitindoor_fc9
I0526 17:04:52.281631 24213 net.cpp:91] Creating Layer mitindoor_fc9
I0526 17:04:52.281654 24213 net.cpp:425] mitindoor_fc9 <- pool8_global
I0526 17:04:52.281682 24213 net.cpp:399] mitindoor_fc9 -> mitindoor_fc9
I0526 17:04:52.283496 24213 net.cpp:141] Setting up mitindoor_fc9
I0526 17:04:52.283573 24213 net.cpp:148] Top shape: 128 67 (8576)
I0526 17:04:52.283599 24213 net.cpp:156] Memory required for data: 1033911808
I0526 17:04:52.283646 24213 layer_factory.hpp:77] Creating layer loss
I0526 17:04:52.283696 24213 net.cpp:91] Creating Layer loss
I0526 17:04:52.283722 24213 net.cpp:425] loss <- mitindoor_fc9
I0526 17:04:52.283747 24213 net.cpp:425] loss <- label
I0526 17:04:52.283776 24213 net.cpp:399] loss -> loss
I0526 17:04:52.283824 24213 layer_factory.hpp:77] Creating layer loss
I0526 17:04:52.284747 24213 net.cpp:141] Setting up loss
I0526 17:04:52.284806 24213 net.cpp:148] Top shape: (1)
I0526 17:04:52.284833 24213 net.cpp:151]     with loss weight 1
I0526 17:04:52.284881 24213 net.cpp:156] Memory required for data: 1033911812
I0526 17:04:52.284909 24213 net.cpp:217] loss needs backward computation.
I0526 17:04:52.284934 24213 net.cpp:217] mitindoor_fc9 needs backward computation.
I0526 17:04:52.284957 24213 net.cpp:217] pool8_global needs backward computation.
I0526 17:04:52.284982 24213 net.cpp:217] relu7 needs backward computation.
I0526 17:04:52.285004 24213 net.cpp:217] conv7 needs backward computation.
I0526 17:04:52.285027 24213 net.cpp:217] relu6 needs backward computation.
I0526 17:04:52.285048 24213 net.cpp:217] conv6 needs backward computation.
I0526 17:04:52.285070 24213 net.cpp:217] pool5 needs backward computation.
I0526 17:04:52.285095 24213 net.cpp:217] relu5 needs backward computation.
I0526 17:04:52.285117 24213 net.cpp:217] conv5 needs backward computation.
I0526 17:04:52.285140 24213 net.cpp:217] relu4 needs backward computation.
I0526 17:04:52.285161 24213 net.cpp:217] conv4 needs backward computation.
I0526 17:04:52.285187 24213 net.cpp:217] relu3 needs backward computation.
I0526 17:04:52.285207 24213 net.cpp:217] conv3 needs backward computation.
I0526 17:04:52.285230 24213 net.cpp:217] norm2 needs backward computation.
I0526 17:04:52.285253 24213 net.cpp:217] pool2 needs backward computation.
I0526 17:04:52.285277 24213 net.cpp:217] relu2 needs backward computation.
I0526 17:04:52.285300 24213 net.cpp:217] conv2 needs backward computation.
I0526 17:04:52.285321 24213 net.cpp:217] norm1 needs backward computation.
I0526 17:04:52.285343 24213 net.cpp:217] pool1 needs backward computation.
I0526 17:04:52.285368 24213 net.cpp:217] relu1 needs backward computation.
I0526 17:04:52.285389 24213 net.cpp:217] conv1 needs backward computation.
I0526 17:04:52.285413 24213 net.cpp:219] data does not need backward computation.
I0526 17:04:52.285434 24213 net.cpp:261] This network produces output loss
I0526 17:04:52.285476 24213 net.cpp:274] Network initialization done.
I0526 17:04:52.286912 24213 solver.cpp:181] Creating test net (#0) specified by net file: train_val.prototxt
I0526 17:04:52.287039 24213 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0526 17:04:52.287423 24213 net.cpp:49] Initializing net from parameters: 
name: "placesCNNobjectdiscoveryAverageSumFinedtunedMITindoor"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  image_data_param {
    source: "val.txt"
    batch_size: 50
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "conv6"
  type: "Convolution"
  bottom: "pool5"
  top: "conv6"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "conv6"
  top: "conv6"
}
layer {
  name: "conv7"
  type: "Convolution"
  bottom: "conv6"
  top: "conv7"
  param {
    lr_mult: 5
    decay_mult: 1
  }
  param {
    lr_mult: 10
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "conv7"
  top: "conv7"
}
layer {
  name: "pool8_global"
  type: "Pooling"
  bottom: "conv7"
  top: "pool8_global"
  pooling_param {
    pool: AVE
    kernel_size: 11
    stride: 11
  }
}
layer {
  name: "mitindoor_fc9"
  type: "InnerProduct"
  bottom: "pool8_global"
  top: "mitindoor_fc9"
  param {
    lr_mult: 10
    decay_mult: 1
  }
  param {
    lr_mult: 20
    decay_mult: 0
  }
  inner_product_param {
    num_output: 67
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "mitindoor_fc9"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "mitindoor_fc9"
  bottom: "label"
  top: "loss"
}
I0526 17:04:52.289082 24213 layer_factory.hpp:77] Creating layer data
I0526 17:04:52.289139 24213 net.cpp:91] Creating Layer data
I0526 17:04:52.289170 24213 net.cpp:399] data -> data
I0526 17:04:52.289211 24213 net.cpp:399] data -> label
I0526 17:04:52.289253 24213 image_data_layer.cpp:38] Opening file val.txt
I0526 17:04:52.289816 24213 image_data_layer.cpp:53] A total of 533 images.
I0526 17:04:52.293505 24213 image_data_layer.cpp:80] output data size: 50,3,227,227
I0526 17:04:52.347142 24213 net.cpp:141] Setting up data
I0526 17:04:52.347229 24213 net.cpp:148] Top shape: 50 3 227 227 (7729350)
I0526 17:04:52.347259 24213 net.cpp:148] Top shape: 50 (50)
I0526 17:04:52.347285 24213 net.cpp:156] Memory required for data: 30917600
I0526 17:04:52.347311 24213 layer_factory.hpp:77] Creating layer label_data_1_split
I0526 17:04:52.347342 24213 net.cpp:91] Creating Layer label_data_1_split
I0526 17:04:52.347367 24213 net.cpp:425] label_data_1_split <- label
I0526 17:04:52.347393 24213 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0526 17:04:52.347425 24213 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0526 17:04:52.347524 24213 net.cpp:141] Setting up label_data_1_split
I0526 17:04:52.347558 24213 net.cpp:148] Top shape: 50 (50)
I0526 17:04:52.347586 24213 net.cpp:148] Top shape: 50 (50)
I0526 17:04:52.347609 24213 net.cpp:156] Memory required for data: 30918000
I0526 17:04:52.347635 24213 layer_factory.hpp:77] Creating layer conv1
I0526 17:04:52.347671 24213 net.cpp:91] Creating Layer conv1
I0526 17:04:52.347695 24213 net.cpp:425] conv1 <- data
I0526 17:04:52.347723 24213 net.cpp:399] conv1 -> conv1
I0526 17:04:52.349691 24213 net.cpp:141] Setting up conv1
I0526 17:04:52.349736 24213 net.cpp:148] Top shape: 50 96 55 55 (14520000)
I0526 17:04:52.349764 24213 net.cpp:156] Memory required for data: 88998000
I0526 17:04:52.349798 24213 layer_factory.hpp:77] Creating layer relu1
I0526 17:04:52.349829 24213 net.cpp:91] Creating Layer relu1
I0526 17:04:52.349853 24213 net.cpp:425] relu1 <- conv1
I0526 17:04:52.349879 24213 net.cpp:386] relu1 -> conv1 (in-place)
I0526 17:04:52.349907 24213 net.cpp:141] Setting up relu1
I0526 17:04:52.349933 24213 net.cpp:148] Top shape: 50 96 55 55 (14520000)
I0526 17:04:52.349958 24213 net.cpp:156] Memory required for data: 147078000
I0526 17:04:52.349980 24213 layer_factory.hpp:77] Creating layer pool1
I0526 17:04:52.350008 24213 net.cpp:91] Creating Layer pool1
I0526 17:04:52.350041 24213 net.cpp:425] pool1 <- conv1
I0526 17:04:52.350069 24213 net.cpp:399] pool1 -> pool1
I0526 17:04:52.350149 24213 net.cpp:141] Setting up pool1
I0526 17:04:52.350183 24213 net.cpp:148] Top shape: 50 96 27 27 (3499200)
I0526 17:04:52.350208 24213 net.cpp:156] Memory required for data: 161074800
I0526 17:04:52.350229 24213 layer_factory.hpp:77] Creating layer norm1
I0526 17:04:52.350255 24213 net.cpp:91] Creating Layer norm1
I0526 17:04:52.350281 24213 net.cpp:425] norm1 <- pool1
I0526 17:04:52.350306 24213 net.cpp:399] norm1 -> norm1
I0526 17:04:52.350378 24213 net.cpp:141] Setting up norm1
I0526 17:04:52.350409 24213 net.cpp:148] Top shape: 50 96 27 27 (3499200)
I0526 17:04:52.350432 24213 net.cpp:156] Memory required for data: 175071600
I0526 17:04:52.350455 24213 layer_factory.hpp:77] Creating layer conv2
I0526 17:04:52.350484 24213 net.cpp:91] Creating Layer conv2
I0526 17:04:52.350509 24213 net.cpp:425] conv2 <- norm1
I0526 17:04:52.350538 24213 net.cpp:399] conv2 -> conv2
I0526 17:04:52.365660 24213 net.cpp:141] Setting up conv2
I0526 17:04:52.365747 24213 net.cpp:148] Top shape: 50 256 27 27 (9331200)
I0526 17:04:52.365774 24213 net.cpp:156] Memory required for data: 212396400
I0526 17:04:52.365811 24213 layer_factory.hpp:77] Creating layer relu2
I0526 17:04:52.365846 24213 net.cpp:91] Creating Layer relu2
I0526 17:04:52.365871 24213 net.cpp:425] relu2 <- conv2
I0526 17:04:52.365898 24213 net.cpp:386] relu2 -> conv2 (in-place)
I0526 17:04:52.365928 24213 net.cpp:141] Setting up relu2
I0526 17:04:52.365958 24213 net.cpp:148] Top shape: 50 256 27 27 (9331200)
I0526 17:04:52.365980 24213 net.cpp:156] Memory required for data: 249721200
I0526 17:04:52.366003 24213 layer_factory.hpp:77] Creating layer pool2
I0526 17:04:52.366039 24213 net.cpp:91] Creating Layer pool2
I0526 17:04:52.366067 24213 net.cpp:425] pool2 <- conv2
I0526 17:04:52.366106 24213 net.cpp:399] pool2 -> pool2
I0526 17:04:52.366204 24213 net.cpp:141] Setting up pool2
I0526 17:04:52.366237 24213 net.cpp:148] Top shape: 50 256 13 13 (2163200)
I0526 17:04:52.366263 24213 net.cpp:156] Memory required for data: 258374000
I0526 17:04:52.366286 24213 layer_factory.hpp:77] Creating layer norm2
I0526 17:04:52.366313 24213 net.cpp:91] Creating Layer norm2
I0526 17:04:52.366335 24213 net.cpp:425] norm2 <- pool2
I0526 17:04:52.366364 24213 net.cpp:399] norm2 -> norm2
I0526 17:04:52.366433 24213 net.cpp:141] Setting up norm2
I0526 17:04:52.366466 24213 net.cpp:148] Top shape: 50 256 13 13 (2163200)
I0526 17:04:52.366490 24213 net.cpp:156] Memory required for data: 267026800
I0526 17:04:52.366513 24213 layer_factory.hpp:77] Creating layer conv3
I0526 17:04:52.366544 24213 net.cpp:91] Creating Layer conv3
I0526 17:04:52.366570 24213 net.cpp:425] conv3 <- norm2
I0526 17:04:52.366600 24213 net.cpp:399] conv3 -> conv3
I0526 17:04:52.409693 24213 net.cpp:141] Setting up conv3
I0526 17:04:52.409741 24213 net.cpp:148] Top shape: 50 384 13 13 (3244800)
I0526 17:04:52.409750 24213 net.cpp:156] Memory required for data: 280006000
I0526 17:04:52.409771 24213 layer_factory.hpp:77] Creating layer relu3
I0526 17:04:52.409790 24213 net.cpp:91] Creating Layer relu3
I0526 17:04:52.409800 24213 net.cpp:425] relu3 <- conv3
I0526 17:04:52.409814 24213 net.cpp:386] relu3 -> conv3 (in-place)
I0526 17:04:52.409832 24213 net.cpp:141] Setting up relu3
I0526 17:04:52.409843 24213 net.cpp:148] Top shape: 50 384 13 13 (3244800)
I0526 17:04:52.409852 24213 net.cpp:156] Memory required for data: 292985200
I0526 17:04:52.409860 24213 layer_factory.hpp:77] Creating layer conv4
I0526 17:04:52.409880 24213 net.cpp:91] Creating Layer conv4
I0526 17:04:52.409889 24213 net.cpp:425] conv4 <- conv3
I0526 17:04:52.409901 24213 net.cpp:399] conv4 -> conv4
I0526 17:04:52.441567 24213 net.cpp:141] Setting up conv4
I0526 17:04:52.441597 24213 net.cpp:148] Top shape: 50 384 13 13 (3244800)
I0526 17:04:52.441606 24213 net.cpp:156] Memory required for data: 305964400
I0526 17:04:52.441620 24213 layer_factory.hpp:77] Creating layer relu4
I0526 17:04:52.441638 24213 net.cpp:91] Creating Layer relu4
I0526 17:04:52.441649 24213 net.cpp:425] relu4 <- conv4
I0526 17:04:52.441663 24213 net.cpp:386] relu4 -> conv4 (in-place)
I0526 17:04:52.441679 24213 net.cpp:141] Setting up relu4
I0526 17:04:52.441690 24213 net.cpp:148] Top shape: 50 384 13 13 (3244800)
I0526 17:04:52.441699 24213 net.cpp:156] Memory required for data: 318943600
I0526 17:04:52.441705 24213 layer_factory.hpp:77] Creating layer conv5
I0526 17:04:52.441723 24213 net.cpp:91] Creating Layer conv5
I0526 17:04:52.441732 24213 net.cpp:425] conv5 <- conv4
I0526 17:04:52.441747 24213 net.cpp:399] conv5 -> conv5
I0526 17:04:52.471709 24213 net.cpp:141] Setting up conv5
I0526 17:04:52.471818 24213 net.cpp:148] Top shape: 50 384 13 13 (3244800)
I0526 17:04:52.471848 24213 net.cpp:156] Memory required for data: 331922800
I0526 17:04:52.471890 24213 layer_factory.hpp:77] Creating layer relu5
I0526 17:04:52.471930 24213 net.cpp:91] Creating Layer relu5
I0526 17:04:52.471961 24213 net.cpp:425] relu5 <- conv5
I0526 17:04:52.471999 24213 net.cpp:386] relu5 -> conv5 (in-place)
I0526 17:04:52.472038 24213 net.cpp:141] Setting up relu5
I0526 17:04:52.472065 24213 net.cpp:148] Top shape: 50 384 13 13 (3244800)
I0526 17:04:52.472090 24213 net.cpp:156] Memory required for data: 344902000
I0526 17:04:52.472111 24213 layer_factory.hpp:77] Creating layer pool5
I0526 17:04:52.472152 24213 net.cpp:91] Creating Layer pool5
I0526 17:04:52.472177 24213 net.cpp:425] pool5 <- conv5
I0526 17:04:52.472203 24213 net.cpp:399] pool5 -> pool5
I0526 17:04:52.472285 24213 net.cpp:141] Setting up pool5
I0526 17:04:52.472317 24213 net.cpp:148] Top shape: 50 384 11 11 (2323200)
I0526 17:04:52.472342 24213 net.cpp:156] Memory required for data: 354194800
I0526 17:04:52.472364 24213 layer_factory.hpp:77] Creating layer conv6
I0526 17:04:52.472401 24213 net.cpp:91] Creating Layer conv6
I0526 17:04:52.472427 24213 net.cpp:425] conv6 <- pool5
I0526 17:04:52.472466 24213 net.cpp:399] conv6 -> conv6
I0526 17:04:52.515018 24213 net.cpp:141] Setting up conv6
I0526 17:04:52.515101 24213 net.cpp:148] Top shape: 50 512 11 11 (3097600)
I0526 17:04:52.515128 24213 net.cpp:156] Memory required for data: 366585200
I0526 17:04:52.515161 24213 layer_factory.hpp:77] Creating layer relu6
I0526 17:04:52.515199 24213 net.cpp:91] Creating Layer relu6
I0526 17:04:52.515223 24213 net.cpp:425] relu6 <- conv6
I0526 17:04:52.515250 24213 net.cpp:386] relu6 -> conv6 (in-place)
I0526 17:04:52.515282 24213 net.cpp:141] Setting up relu6
I0526 17:04:52.515308 24213 net.cpp:148] Top shape: 50 512 11 11 (3097600)
I0526 17:04:52.515331 24213 net.cpp:156] Memory required for data: 378975600
I0526 17:04:52.515353 24213 layer_factory.hpp:77] Creating layer conv7
I0526 17:04:52.515385 24213 net.cpp:91] Creating Layer conv7
I0526 17:04:52.515408 24213 net.cpp:425] conv7 <- conv6
I0526 17:04:52.515436 24213 net.cpp:399] conv7 -> conv7
I0526 17:04:52.571765 24213 net.cpp:141] Setting up conv7
I0526 17:04:52.571846 24213 net.cpp:148] Top shape: 50 512 11 11 (3097600)
I0526 17:04:52.571872 24213 net.cpp:156] Memory required for data: 391366000
I0526 17:04:52.571903 24213 layer_factory.hpp:77] Creating layer relu7
I0526 17:04:52.571938 24213 net.cpp:91] Creating Layer relu7
I0526 17:04:52.571964 24213 net.cpp:425] relu7 <- conv7
I0526 17:04:52.571993 24213 net.cpp:386] relu7 -> conv7 (in-place)
I0526 17:04:52.572027 24213 net.cpp:141] Setting up relu7
I0526 17:04:52.572057 24213 net.cpp:148] Top shape: 50 512 11 11 (3097600)
I0526 17:04:52.572082 24213 net.cpp:156] Memory required for data: 403756400
I0526 17:04:52.572104 24213 layer_factory.hpp:77] Creating layer pool8_global
I0526 17:04:52.572132 24213 net.cpp:91] Creating Layer pool8_global
I0526 17:04:52.572157 24213 net.cpp:425] pool8_global <- conv7
I0526 17:04:52.572187 24213 net.cpp:399] pool8_global -> pool8_global
I0526 17:04:52.572252 24213 net.cpp:141] Setting up pool8_global
I0526 17:04:52.572288 24213 net.cpp:148] Top shape: 50 512 1 1 (25600)
I0526 17:04:52.572311 24213 net.cpp:156] Memory required for data: 403858800
I0526 17:04:52.572335 24213 layer_factory.hpp:77] Creating layer mitindoor_fc9
I0526 17:04:52.572362 24213 net.cpp:91] Creating Layer mitindoor_fc9
I0526 17:04:52.572386 24213 net.cpp:425] mitindoor_fc9 <- pool8_global
I0526 17:04:52.572414 24213 net.cpp:399] mitindoor_fc9 -> mitindoor_fc9
I0526 17:04:52.574196 24213 net.cpp:141] Setting up mitindoor_fc9
I0526 17:04:52.574247 24213 net.cpp:148] Top shape: 50 67 (3350)
I0526 17:04:52.574276 24213 net.cpp:156] Memory required for data: 403872200
I0526 17:04:52.574306 24213 layer_factory.hpp:77] Creating layer mitindoor_fc9_mitindoor_fc9_0_split
I0526 17:04:52.574333 24213 net.cpp:91] Creating Layer mitindoor_fc9_mitindoor_fc9_0_split
I0526 17:04:52.574364 24213 net.cpp:425] mitindoor_fc9_mitindoor_fc9_0_split <- mitindoor_fc9
I0526 17:04:52.574391 24213 net.cpp:399] mitindoor_fc9_mitindoor_fc9_0_split -> mitindoor_fc9_mitindoor_fc9_0_split_0
I0526 17:04:52.574424 24213 net.cpp:399] mitindoor_fc9_mitindoor_fc9_0_split -> mitindoor_fc9_mitindoor_fc9_0_split_1
I0526 17:04:52.574506 24213 net.cpp:141] Setting up mitindoor_fc9_mitindoor_fc9_0_split
I0526 17:04:52.574545 24213 net.cpp:148] Top shape: 50 67 (3350)
I0526 17:04:52.574571 24213 net.cpp:148] Top shape: 50 67 (3350)
I0526 17:04:52.574594 24213 net.cpp:156] Memory required for data: 403899000
I0526 17:04:52.574620 24213 layer_factory.hpp:77] Creating layer accuracy
I0526 17:04:52.574645 24213 net.cpp:91] Creating Layer accuracy
I0526 17:04:52.574668 24213 net.cpp:425] accuracy <- mitindoor_fc9_mitindoor_fc9_0_split_0
I0526 17:04:52.574695 24213 net.cpp:425] accuracy <- label_data_1_split_0
I0526 17:04:52.574722 24213 net.cpp:399] accuracy -> accuracy
I0526 17:04:52.574753 24213 net.cpp:141] Setting up accuracy
I0526 17:04:52.574781 24213 net.cpp:148] Top shape: (1)
I0526 17:04:52.574803 24213 net.cpp:156] Memory required for data: 403899004
I0526 17:04:52.574827 24213 layer_factory.hpp:77] Creating layer loss
I0526 17:04:52.574863 24213 net.cpp:91] Creating Layer loss
I0526 17:04:52.574903 24213 net.cpp:425] loss <- mitindoor_fc9_mitindoor_fc9_0_split_1
I0526 17:04:52.574930 24213 net.cpp:425] loss <- label_data_1_split_1
I0526 17:04:52.574956 24213 net.cpp:399] loss -> loss
I0526 17:04:52.574988 24213 layer_factory.hpp:77] Creating layer loss
I0526 17:04:52.575148 24213 net.cpp:141] Setting up loss
I0526 17:04:52.575182 24213 net.cpp:148] Top shape: (1)
I0526 17:04:52.575207 24213 net.cpp:151]     with loss weight 1
I0526 17:04:52.575242 24213 net.cpp:156] Memory required for data: 403899008
I0526 17:04:52.575263 24213 net.cpp:217] loss needs backward computation.
I0526 17:04:52.575289 24213 net.cpp:219] accuracy does not need backward computation.
I0526 17:04:52.575312 24213 net.cpp:217] mitindoor_fc9_mitindoor_fc9_0_split needs backward computation.
I0526 17:04:52.575335 24213 net.cpp:217] mitindoor_fc9 needs backward computation.
I0526 17:04:52.575356 24213 net.cpp:217] pool8_global needs backward computation.
I0526 17:04:52.575377 24213 net.cpp:217] relu7 needs backward computation.
I0526 17:04:52.575398 24213 net.cpp:217] conv7 needs backward computation.
I0526 17:04:52.575419 24213 net.cpp:217] relu6 needs backward computation.
I0526 17:04:52.575441 24213 net.cpp:217] conv6 needs backward computation.
I0526 17:04:52.575464 24213 net.cpp:217] pool5 needs backward computation.
I0526 17:04:52.575487 24213 net.cpp:217] relu5 needs backward computation.
I0526 17:04:52.575508 24213 net.cpp:217] conv5 needs backward computation.
I0526 17:04:52.575530 24213 net.cpp:217] relu4 needs backward computation.
I0526 17:04:52.575551 24213 net.cpp:217] conv4 needs backward computation.
I0526 17:04:52.575572 24213 net.cpp:217] relu3 needs backward computation.
I0526 17:04:52.575598 24213 net.cpp:217] conv3 needs backward computation.
I0526 17:04:52.575618 24213 net.cpp:217] norm2 needs backward computation.
I0526 17:04:52.575640 24213 net.cpp:217] pool2 needs backward computation.
I0526 17:04:52.575662 24213 net.cpp:217] relu2 needs backward computation.
I0526 17:04:52.575682 24213 net.cpp:217] conv2 needs backward computation.
I0526 17:04:52.575705 24213 net.cpp:217] norm1 needs backward computation.
I0526 17:04:52.575729 24213 net.cpp:217] pool1 needs backward computation.
I0526 17:04:52.575752 24213 net.cpp:217] relu1 needs backward computation.
I0526 17:04:52.575774 24213 net.cpp:217] conv1 needs backward computation.
I0526 17:04:52.575796 24213 net.cpp:219] label_data_1_split does not need backward computation.
I0526 17:04:52.575819 24213 net.cpp:219] data does not need backward computation.
I0526 17:04:52.575840 24213 net.cpp:261] This network produces output accuracy
I0526 17:04:52.575862 24213 net.cpp:261] This network produces output loss
I0526 17:04:52.575906 24213 net.cpp:274] Network initialization done.
I0526 17:04:52.576112 24213 solver.cpp:60] Solver scaffolding done.
I0526 17:04:52.576918 24213 caffe.cpp:129] Finetuning from /data2/hrishikesh16/CAM/models/alexnetplusCAM_places205.caffemodel
I0526 17:04:52.633673 24213 net.cpp:753] Ignoring source layer fc9
I0526 17:04:52.688846 24213 net.cpp:753] Ignoring source layer fc9
I0526 17:04:52.689766 24213 caffe.cpp:219] Starting Optimization
I0526 17:04:52.689807 24213 solver.cpp:279] Solving placesCNNobjectdiscoveryAverageSumFinedtunedMITindoor
I0526 17:04:52.689834 24213 solver.cpp:280] Learning Rate Policy: step
I0526 17:04:52.691591 24213 solver.cpp:337] Iteration 0, Testing net (#0)
I0526 17:04:52.696434 24213 blocking_queue.cpp:50] Data layer prefetch queue empty
I0526 17:04:55.875072 24213 solver.cpp:404]     Test net output #0: accuracy = 0.0109091
I0526 17:04:55.875196 24213 solver.cpp:404]     Test net output #1: loss = 4.37107 (* 1 = 4.37107 loss)
I0526 17:04:56.998797 24213 solver.cpp:228] Iteration 0, loss = 4.41123
I0526 17:04:56.998858 24213 solver.cpp:244]     Train net output #0: loss = 4.41123 (* 1 = 4.41123 loss)
I0526 17:04:56.998896 24213 sgd_solver.cpp:106] Iteration 0, lr = 1e-05
I0526 17:05:09.372637 24213 solver.cpp:228] Iteration 10, loss = 4.35434
I0526 17:05:09.372679 24213 solver.cpp:244]     Train net output #0: loss = 4.35434 (* 1 = 4.35434 loss)
I0526 17:05:09.372714 24213 sgd_solver.cpp:106] Iteration 10, lr = 1e-05
I0526 17:05:21.728369 24213 solver.cpp:228] Iteration 20, loss = 4.21382
I0526 17:05:21.728536 24213 solver.cpp:244]     Train net output #0: loss = 4.21382 (* 1 = 4.21382 loss)
I0526 17:05:21.728550 24213 sgd_solver.cpp:106] Iteration 20, lr = 1e-05
I0526 17:05:32.308897 24213 solver.cpp:337] Iteration 30, Testing net (#0)
I0526 17:05:35.281335 24213 solver.cpp:404]     Test net output #0: accuracy = 0.0290909
I0526 17:05:35.281394 24213 solver.cpp:404]     Test net output #1: loss = 4.21673 (* 1 = 4.21673 loss)
I0526 17:05:36.395298 24213 solver.cpp:228] Iteration 30, loss = 4.07792
I0526 17:05:36.395406 24213 solver.cpp:244]     Train net output #0: loss = 4.07792 (* 1 = 4.07792 loss)
I0526 17:05:36.395442 24213 sgd_solver.cpp:106] Iteration 30, lr = 1e-05
I0526 17:05:48.764503 24213 solver.cpp:228] Iteration 40, loss = 3.95774
I0526 17:05:48.764550 24213 solver.cpp:244]     Train net output #0: loss = 3.95774 (* 1 = 3.95774 loss)
I0526 17:05:48.764564 24213 sgd_solver.cpp:106] Iteration 40, lr = 1e-05
I0526 17:06:01.138774 24213 solver.cpp:228] Iteration 50, loss = 3.85138
I0526 17:06:01.138998 24213 solver.cpp:244]     Train net output #0: loss = 3.85138 (* 1 = 3.85138 loss)
I0526 17:06:01.139039 24213 sgd_solver.cpp:106] Iteration 50, lr = 1e-05
I0526 17:06:12.173837 24213 solver.cpp:337] Iteration 60, Testing net (#0)
I0526 17:06:15.309936 24213 solver.cpp:404]     Test net output #0: accuracy = 0.0672727
I0526 17:06:15.309986 24213 solver.cpp:404]     Test net output #1: loss = 4.0804 (* 1 = 4.0804 loss)
I0526 17:06:16.423629 24213 solver.cpp:228] Iteration 60, loss = 3.7922
I0526 17:06:16.423743 24213 solver.cpp:244]     Train net output #0: loss = 3.7922 (* 1 = 3.7922 loss)
I0526 17:06:16.423785 24213 sgd_solver.cpp:106] Iteration 60, lr = 1e-05
I0526 17:06:28.772367 24213 solver.cpp:228] Iteration 70, loss = 3.7002
I0526 17:06:28.772480 24213 solver.cpp:244]     Train net output #0: loss = 3.7002 (* 1 = 3.7002 loss)
I0526 17:06:28.772517 24213 sgd_solver.cpp:106] Iteration 70, lr = 1e-05
I0526 17:06:41.136361 24213 solver.cpp:228] Iteration 80, loss = 3.63267
I0526 17:06:41.136462 24213 solver.cpp:244]     Train net output #0: loss = 3.63267 (* 1 = 3.63267 loss)
I0526 17:06:41.136479 24213 sgd_solver.cpp:106] Iteration 80, lr = 1e-05
I0526 17:06:51.711139 24213 solver.cpp:337] Iteration 90, Testing net (#0)
I0526 17:06:54.910080 24213 solver.cpp:404]     Test net output #0: accuracy = 0.103636
I0526 17:06:54.910132 24213 solver.cpp:404]     Test net output #1: loss = 3.97542 (* 1 = 3.97542 loss)
I0526 17:06:56.023710 24213 solver.cpp:228] Iteration 90, loss = 3.60135
I0526 17:06:56.023753 24213 solver.cpp:244]     Train net output #0: loss = 3.60135 (* 1 = 3.60135 loss)
I0526 17:06:56.023767 24213 sgd_solver.cpp:106] Iteration 90, lr = 1e-05
I0526 17:07:08.398624 24213 solver.cpp:228] Iteration 100, loss = 3.4539
I0526 17:07:08.398674 24213 solver.cpp:244]     Train net output #0: loss = 3.4539 (* 1 = 3.4539 loss)
I0526 17:07:08.398689 24213 sgd_solver.cpp:106] Iteration 100, lr = 1e-05
I0526 17:07:20.744851 24213 solver.cpp:228] Iteration 110, loss = 3.39163
I0526 17:07:20.744953 24213 solver.cpp:244]     Train net output #0: loss = 3.39163 (* 1 = 3.39163 loss)
I0526 17:07:20.744971 24213 sgd_solver.cpp:106] Iteration 110, lr = 1e-05
I0526 17:07:31.556074 24213 solver.cpp:337] Iteration 120, Testing net (#0)
I0526 17:07:34.521545 24213 solver.cpp:404]     Test net output #0: accuracy = 0.149091
I0526 17:07:34.521615 24213 solver.cpp:404]     Test net output #1: loss = 3.85869 (* 1 = 3.85869 loss)
I0526 17:07:35.639824 24213 solver.cpp:228] Iteration 120, loss = 3.30918
I0526 17:07:35.639937 24213 solver.cpp:244]     Train net output #0: loss = 3.30918 (* 1 = 3.30918 loss)
I0526 17:07:35.639974 24213 sgd_solver.cpp:106] Iteration 120, lr = 1e-05
I0526 17:07:47.991140 24213 solver.cpp:228] Iteration 130, loss = 3.29123
I0526 17:07:47.991189 24213 solver.cpp:244]     Train net output #0: loss = 3.29123 (* 1 = 3.29123 loss)
I0526 17:07:47.991204 24213 sgd_solver.cpp:106] Iteration 130, lr = 1e-05
I0526 17:08:00.362923 24213 solver.cpp:228] Iteration 140, loss = 3.2281
I0526 17:08:00.363051 24213 solver.cpp:244]     Train net output #0: loss = 3.2281 (* 1 = 3.2281 loss)
I0526 17:08:00.363064 24213 sgd_solver.cpp:106] Iteration 140, lr = 1e-05
I0526 17:08:11.037902 24213 solver.cpp:337] Iteration 150, Testing net (#0)
I0526 17:08:14.225667 24213 solver.cpp:404]     Test net output #0: accuracy = 0.178182
I0526 17:08:14.225966 24213 solver.cpp:404]     Test net output #1: loss = 3.73438 (* 1 = 3.73438 loss)
I0526 17:08:15.335901 24213 solver.cpp:228] Iteration 150, loss = 3.15144
I0526 17:08:15.335954 24213 solver.cpp:244]     Train net output #0: loss = 3.15144 (* 1 = 3.15144 loss)
I0526 17:08:15.335969 24213 sgd_solver.cpp:106] Iteration 150, lr = 1e-05
I0526 17:08:27.695091 24213 solver.cpp:228] Iteration 160, loss = 3.06635
I0526 17:08:27.695143 24213 solver.cpp:244]     Train net output #0: loss = 3.06635 (* 1 = 3.06635 loss)
I0526 17:08:27.695158 24213 sgd_solver.cpp:106] Iteration 160, lr = 1e-05
I0526 17:08:40.066182 24213 solver.cpp:228] Iteration 170, loss = 2.9898
I0526 17:08:40.066268 24213 solver.cpp:244]     Train net output #0: loss = 2.9898 (* 1 = 2.9898 loss)
I0526 17:08:40.066278 24213 sgd_solver.cpp:106] Iteration 170, lr = 1e-05
I0526 17:08:51.098546 24213 solver.cpp:337] Iteration 180, Testing net (#0)
I0526 17:08:53.606592 24213 solver.cpp:404]     Test net output #0: accuracy = 0.196364
I0526 17:08:53.606700 24213 solver.cpp:404]     Test net output #1: loss = 3.62219 (* 1 = 3.62219 loss)
I0526 17:08:54.717901 24213 solver.cpp:228] Iteration 180, loss = 2.96609
I0526 17:08:54.717954 24213 solver.cpp:244]     Train net output #0: loss = 2.96609 (* 1 = 2.96609 loss)
I0526 17:08:54.717964 24213 sgd_solver.cpp:106] Iteration 180, lr = 1e-05
I0526 17:09:07.090685 24213 solver.cpp:228] Iteration 190, loss = 2.85516
I0526 17:09:07.090729 24213 solver.cpp:244]     Train net output #0: loss = 2.85516 (* 1 = 2.85516 loss)
I0526 17:09:07.090739 24213 sgd_solver.cpp:106] Iteration 190, lr = 1e-05
I0526 17:09:19.459251 24213 solver.cpp:228] Iteration 200, loss = 2.81621
I0526 17:09:19.459367 24213 solver.cpp:244]     Train net output #0: loss = 2.81621 (* 1 = 2.81621 loss)
I0526 17:09:19.459385 24213 sgd_solver.cpp:106] Iteration 200, lr = 1e-05
I0526 17:09:30.133939 24213 solver.cpp:337] Iteration 210, Testing net (#0)
I0526 17:09:32.888384 24213 solver.cpp:404]     Test net output #0: accuracy = 0.218182
I0526 17:09:32.888445 24213 solver.cpp:404]     Test net output #1: loss = 3.51513 (* 1 = 3.51513 loss)
I0526 17:09:33.992904 24213 solver.cpp:228] Iteration 210, loss = 2.84113
I0526 17:09:33.992960 24213 solver.cpp:244]     Train net output #0: loss = 2.84113 (* 1 = 2.84113 loss)
I0526 17:09:33.992971 24213 sgd_solver.cpp:106] Iteration 210, lr = 1e-05
I0526 17:09:46.364429 24213 solver.cpp:228] Iteration 220, loss = 2.72302
I0526 17:09:46.364485 24213 solver.cpp:244]     Train net output #0: loss = 2.72302 (* 1 = 2.72302 loss)
I0526 17:09:46.364500 24213 sgd_solver.cpp:106] Iteration 220, lr = 1e-05
I0526 17:09:58.741446 24213 solver.cpp:228] Iteration 230, loss = 2.58078
I0526 17:09:58.741559 24213 solver.cpp:244]     Train net output #0: loss = 2.58078 (* 1 = 2.58078 loss)
I0526 17:09:58.741576 24213 sgd_solver.cpp:106] Iteration 230, lr = 1e-05
I0526 17:10:09.590904 24213 solver.cpp:337] Iteration 240, Testing net (#0)
I0526 17:10:12.318437 24213 solver.cpp:404]     Test net output #0: accuracy = 0.234545
I0526 17:10:12.318538 24213 solver.cpp:404]     Test net output #1: loss = 3.41533 (* 1 = 3.41533 loss)
I0526 17:10:13.427541 24213 solver.cpp:228] Iteration 240, loss = 2.58969
I0526 17:10:13.427585 24213 solver.cpp:244]     Train net output #0: loss = 2.58969 (* 1 = 2.58969 loss)
I0526 17:10:13.427600 24213 sgd_solver.cpp:106] Iteration 240, lr = 1e-05
I0526 17:10:25.813235 24213 solver.cpp:228] Iteration 250, loss = 2.52231
I0526 17:10:25.813278 24213 solver.cpp:244]     Train net output #0: loss = 2.52231 (* 1 = 2.52231 loss)
I0526 17:10:25.813293 24213 sgd_solver.cpp:106] Iteration 250, lr = 1e-05
I0526 17:10:38.203245 24213 solver.cpp:228] Iteration 260, loss = 2.47901
I0526 17:10:38.203373 24213 solver.cpp:244]     Train net output #0: loss = 2.47901 (* 1 = 2.47901 loss)
I0526 17:10:38.203390 24213 sgd_solver.cpp:106] Iteration 260, lr = 1e-05
I0526 17:10:48.773315 24213 solver.cpp:337] Iteration 270, Testing net (#0)
I0526 17:10:51.433320 24213 solver.cpp:404]     Test net output #0: accuracy = 0.241818
I0526 17:10:51.433374 24213 solver.cpp:404]     Test net output #1: loss = 3.32318 (* 1 = 3.32318 loss)
I0526 17:10:52.541813 24213 solver.cpp:228] Iteration 270, loss = 2.48464
I0526 17:10:52.541862 24213 solver.cpp:244]     Train net output #0: loss = 2.48464 (* 1 = 2.48464 loss)
I0526 17:10:52.541875 24213 sgd_solver.cpp:106] Iteration 270, lr = 1e-05
I0526 17:11:04.903825 24213 solver.cpp:228] Iteration 280, loss = 2.43879
I0526 17:11:04.903882 24213 solver.cpp:244]     Train net output #0: loss = 2.43879 (* 1 = 2.43879 loss)
I0526 17:11:04.903892 24213 sgd_solver.cpp:106] Iteration 280, lr = 1e-05
I0526 17:11:17.260391 24213 solver.cpp:228] Iteration 290, loss = 2.36213
I0526 17:11:17.260488 24213 solver.cpp:244]     Train net output #0: loss = 2.36213 (* 1 = 2.36213 loss)
I0526 17:11:17.260499 24213 sgd_solver.cpp:106] Iteration 290, lr = 1e-05
I0526 17:11:27.843821 24213 solver.cpp:337] Iteration 300, Testing net (#0)
I0526 17:11:30.554744 24213 solver.cpp:404]     Test net output #0: accuracy = 0.261818
I0526 17:11:30.554787 24213 solver.cpp:404]     Test net output #1: loss = 3.22399 (* 1 = 3.22399 loss)
I0526 17:11:31.666560 24213 solver.cpp:228] Iteration 300, loss = 2.24467
I0526 17:11:31.666610 24213 solver.cpp:244]     Train net output #0: loss = 2.24467 (* 1 = 2.24467 loss)
I0526 17:11:31.666621 24213 sgd_solver.cpp:106] Iteration 300, lr = 1e-05
I0526 17:11:44.030424 24213 solver.cpp:228] Iteration 310, loss = 2.24845
I0526 17:11:44.030468 24213 solver.cpp:244]     Train net output #0: loss = 2.24845 (* 1 = 2.24845 loss)
I0526 17:11:44.030483 24213 sgd_solver.cpp:106] Iteration 310, lr = 1e-05
I0526 17:11:56.393846 24213 solver.cpp:228] Iteration 320, loss = 2.23853
I0526 17:11:56.393952 24213 solver.cpp:244]     Train net output #0: loss = 2.23853 (* 1 = 2.23853 loss)
I0526 17:11:56.393965 24213 sgd_solver.cpp:106] Iteration 320, lr = 1e-05
I0526 17:12:07.094096 24213 solver.cpp:337] Iteration 330, Testing net (#0)
I0526 17:12:09.694176 24213 solver.cpp:404]     Test net output #0: accuracy = 0.261818
I0526 17:12:09.694217 24213 solver.cpp:404]     Test net output #1: loss = 3.16954 (* 1 = 3.16954 loss)
I0526 17:12:10.802274 24213 solver.cpp:228] Iteration 330, loss = 2.22423
I0526 17:12:10.802323 24213 solver.cpp:244]     Train net output #0: loss = 2.22423 (* 1 = 2.22423 loss)
I0526 17:12:10.802338 24213 sgd_solver.cpp:106] Iteration 330, lr = 1e-05
I0526 17:12:23.176759 24213 solver.cpp:228] Iteration 340, loss = 2.09988
I0526 17:12:23.176810 24213 solver.cpp:244]     Train net output #0: loss = 2.09988 (* 1 = 2.09988 loss)
I0526 17:12:23.176820 24213 sgd_solver.cpp:106] Iteration 340, lr = 1e-05
I0526 17:12:35.543846 24213 solver.cpp:228] Iteration 350, loss = 2.0667
I0526 17:12:35.543932 24213 solver.cpp:244]     Train net output #0: loss = 2.0667 (* 1 = 2.0667 loss)
I0526 17:12:35.543944 24213 sgd_solver.cpp:106] Iteration 350, lr = 1e-05
I0526 17:12:46.074543 24213 solver.cpp:337] Iteration 360, Testing net (#0)
I0526 17:12:48.757936 24213 solver.cpp:404]     Test net output #0: accuracy = 0.278182
I0526 17:12:48.757977 24213 solver.cpp:404]     Test net output #1: loss = 3.08548 (* 1 = 3.08548 loss)
I0526 17:12:49.872278 24213 solver.cpp:228] Iteration 360, loss = 2.02709
I0526 17:12:49.872324 24213 solver.cpp:244]     Train net output #0: loss = 2.02709 (* 1 = 2.02709 loss)
I0526 17:12:49.872337 24213 sgd_solver.cpp:106] Iteration 360, lr = 1e-05
I0526 17:13:02.259891 24213 solver.cpp:228] Iteration 370, loss = 1.95358
I0526 17:13:02.259939 24213 solver.cpp:244]     Train net output #0: loss = 1.95358 (* 1 = 1.95358 loss)
I0526 17:13:02.259953 24213 sgd_solver.cpp:106] Iteration 370, lr = 1e-05
I0526 17:13:14.644099 24213 solver.cpp:228] Iteration 380, loss = 1.82789
I0526 17:13:14.644243 24213 solver.cpp:244]     Train net output #0: loss = 1.82789 (* 1 = 1.82789 loss)
I0526 17:13:14.644255 24213 sgd_solver.cpp:106] Iteration 380, lr = 1e-05
I0526 17:13:25.184883 24213 solver.cpp:337] Iteration 390, Testing net (#0)
I0526 17:13:28.058285 24213 solver.cpp:404]     Test net output #0: accuracy = 0.283636
I0526 17:13:28.058387 24213 solver.cpp:404]     Test net output #1: loss = 3.02481 (* 1 = 3.02481 loss)
I0526 17:13:29.168413 24213 solver.cpp:228] Iteration 390, loss = 1.96063
I0526 17:13:29.168473 24213 solver.cpp:244]     Train net output #0: loss = 1.96063 (* 1 = 1.96063 loss)
I0526 17:13:29.168488 24213 sgd_solver.cpp:106] Iteration 390, lr = 1e-05
I0526 17:13:41.545727 24213 solver.cpp:228] Iteration 400, loss = 1.93871
I0526 17:13:41.545770 24213 solver.cpp:244]     Train net output #0: loss = 1.93871 (* 1 = 1.93871 loss)
I0526 17:13:41.545783 24213 sgd_solver.cpp:106] Iteration 400, lr = 1e-05
I0526 17:13:53.912729 24213 solver.cpp:228] Iteration 410, loss = 1.78897
I0526 17:13:53.912837 24213 solver.cpp:244]     Train net output #0: loss = 1.78897 (* 1 = 1.78897 loss)
I0526 17:13:53.912855 24213 sgd_solver.cpp:106] Iteration 410, lr = 1e-05
I0526 17:14:04.712530 24213 solver.cpp:337] Iteration 420, Testing net (#0)
I0526 17:14:07.407300 24213 solver.cpp:404]     Test net output #0: accuracy = 0.289091
I0526 17:14:07.407351 24213 solver.cpp:404]     Test net output #1: loss = 2.95831 (* 1 = 2.95831 loss)
I0526 17:14:08.516067 24213 solver.cpp:228] Iteration 420, loss = 1.70435
I0526 17:14:08.516124 24213 solver.cpp:244]     Train net output #0: loss = 1.70435 (* 1 = 1.70435 loss)
I0526 17:14:08.516134 24213 sgd_solver.cpp:106] Iteration 420, lr = 1e-05
I0526 17:14:20.885205 24213 solver.cpp:228] Iteration 430, loss = 1.68092
I0526 17:14:20.885311 24213 solver.cpp:244]     Train net output #0: loss = 1.68092 (* 1 = 1.68092 loss)
I0526 17:14:20.885334 24213 sgd_solver.cpp:106] Iteration 430, lr = 1e-05
I0526 17:14:33.258880 24213 solver.cpp:228] Iteration 440, loss = 1.79906
I0526 17:14:33.259001 24213 solver.cpp:244]     Train net output #0: loss = 1.79906 (* 1 = 1.79906 loss)
I0526 17:14:33.259013 24213 sgd_solver.cpp:106] Iteration 440, lr = 1e-05
I0526 17:14:44.034742 24213 solver.cpp:337] Iteration 450, Testing net (#0)
I0526 17:14:47.457305 24213 solver.cpp:404]     Test net output #0: accuracy = 0.287273
I0526 17:14:47.457391 24213 solver.cpp:404]     Test net output #1: loss = 2.92021 (* 1 = 2.92021 loss)
I0526 17:14:48.567720 24213 solver.cpp:228] Iteration 450, loss = 1.64044
I0526 17:14:48.567793 24213 solver.cpp:244]     Train net output #0: loss = 1.64044 (* 1 = 1.64044 loss)
I0526 17:14:48.567809 24213 sgd_solver.cpp:106] Iteration 450, lr = 1e-05
I0526 17:15:00.944249 24213 solver.cpp:228] Iteration 460, loss = 1.71165
I0526 17:15:00.944308 24213 solver.cpp:244]     Train net output #0: loss = 1.71165 (* 1 = 1.71165 loss)
I0526 17:15:00.944319 24213 sgd_solver.cpp:106] Iteration 460, lr = 1e-05
I0526 17:15:13.313971 24213 solver.cpp:228] Iteration 470, loss = 1.62011
I0526 17:15:13.314072 24213 solver.cpp:244]     Train net output #0: loss = 1.62011 (* 1 = 1.62011 loss)
I0526 17:15:13.314091 24213 sgd_solver.cpp:106] Iteration 470, lr = 1e-05
I0526 17:15:23.903342 24213 solver.cpp:337] Iteration 480, Testing net (#0)
I0526 17:15:26.721231 24213 solver.cpp:404]     Test net output #0: accuracy = 0.3
I0526 17:15:26.721302 24213 solver.cpp:404]     Test net output #1: loss = 2.8553 (* 1 = 2.8553 loss)
I0526 17:15:27.831403 24213 solver.cpp:228] Iteration 480, loss = 1.63039
I0526 17:15:27.831460 24213 solver.cpp:244]     Train net output #0: loss = 1.63039 (* 1 = 1.63039 loss)
I0526 17:15:27.831471 24213 sgd_solver.cpp:106] Iteration 480, lr = 1e-05
I0526 17:15:40.203274 24213 solver.cpp:228] Iteration 490, loss = 1.52446
I0526 17:15:40.203335 24213 solver.cpp:244]     Train net output #0: loss = 1.52446 (* 1 = 1.52446 loss)
I0526 17:15:40.203344 24213 sgd_solver.cpp:106] Iteration 490, lr = 1e-05
I0526 17:15:52.575242 24213 solver.cpp:228] Iteration 500, loss = 1.59098
I0526 17:15:52.575358 24213 solver.cpp:244]     Train net output #0: loss = 1.59098 (* 1 = 1.59098 loss)
I0526 17:15:52.575371 24213 sgd_solver.cpp:106] Iteration 500, lr = 1e-05
I0526 17:16:03.442390 24213 solver.cpp:337] Iteration 510, Testing net (#0)
I0526 17:16:06.062811 24213 solver.cpp:404]     Test net output #0: accuracy = 0.316364
I0526 17:16:06.062865 24213 solver.cpp:404]     Test net output #1: loss = 2.7962 (* 1 = 2.7962 loss)
I0526 17:16:07.173723 24213 solver.cpp:228] Iteration 510, loss = 1.5275
I0526 17:16:07.173764 24213 solver.cpp:244]     Train net output #0: loss = 1.5275 (* 1 = 1.5275 loss)
I0526 17:16:07.173774 24213 sgd_solver.cpp:106] Iteration 510, lr = 1e-05
I0526 17:16:19.528473 24213 solver.cpp:228] Iteration 520, loss = 1.53333
I0526 17:16:19.528517 24213 solver.cpp:244]     Train net output #0: loss = 1.53333 (* 1 = 1.53333 loss)
I0526 17:16:19.528527 24213 sgd_solver.cpp:106] Iteration 520, lr = 1e-05
I0526 17:16:31.899157 24213 solver.cpp:228] Iteration 530, loss = 1.535
I0526 17:16:31.899274 24213 solver.cpp:244]     Train net output #0: loss = 1.535 (* 1 = 1.535 loss)
I0526 17:16:31.899287 24213 sgd_solver.cpp:106] Iteration 530, lr = 1e-05
I0526 17:16:42.667352 24213 solver.cpp:337] Iteration 540, Testing net (#0)
I0526 17:16:45.538434 24213 solver.cpp:404]     Test net output #0: accuracy = 0.327273
I0526 17:16:45.538573 24213 solver.cpp:404]     Test net output #1: loss = 2.75529 (* 1 = 2.75529 loss)
I0526 17:16:46.651885 24213 solver.cpp:228] Iteration 540, loss = 1.38275
I0526 17:16:46.651928 24213 solver.cpp:244]     Train net output #0: loss = 1.38275 (* 1 = 1.38275 loss)
I0526 17:16:46.651943 24213 sgd_solver.cpp:106] Iteration 540, lr = 1e-05
I0526 17:16:59.016417 24213 solver.cpp:228] Iteration 550, loss = 1.31324
I0526 17:16:59.016461 24213 solver.cpp:244]     Train net output #0: loss = 1.31324 (* 1 = 1.31324 loss)
I0526 17:16:59.016476 24213 sgd_solver.cpp:106] Iteration 550, lr = 1e-05
I0526 17:17:11.390298 24213 solver.cpp:228] Iteration 560, loss = 1.48278
I0526 17:17:11.390400 24213 solver.cpp:244]     Train net output #0: loss = 1.48278 (* 1 = 1.48278 loss)
I0526 17:17:11.390419 24213 sgd_solver.cpp:106] Iteration 560, lr = 1e-05
I0526 17:17:22.286164 24213 solver.cpp:337] Iteration 570, Testing net (#0)
I0526 17:17:25.318696 24213 solver.cpp:404]     Test net output #0: accuracy = 0.325455
I0526 17:17:25.318744 24213 solver.cpp:404]     Test net output #1: loss = 2.73357 (* 1 = 2.73357 loss)
I0526 17:17:26.431536 24213 solver.cpp:228] Iteration 570, loss = 1.38731
I0526 17:17:26.431588 24213 solver.cpp:244]     Train net output #0: loss = 1.38731 (* 1 = 1.38731 loss)
I0526 17:17:26.431604 24213 sgd_solver.cpp:106] Iteration 570, lr = 1e-05
I0526 17:17:38.812873 24213 solver.cpp:228] Iteration 580, loss = 1.25751
I0526 17:17:38.812921 24213 solver.cpp:244]     Train net output #0: loss = 1.25751 (* 1 = 1.25751 loss)
I0526 17:17:38.812935 24213 sgd_solver.cpp:106] Iteration 580, lr = 1e-05
I0526 17:17:51.198559 24213 solver.cpp:228] Iteration 590, loss = 1.29898
I0526 17:17:51.198684 24213 solver.cpp:244]     Train net output #0: loss = 1.29898 (* 1 = 1.29898 loss)
I0526 17:17:51.198696 24213 sgd_solver.cpp:106] Iteration 590, lr = 1e-05
I0526 17:18:02.144368 24213 solver.cpp:337] Iteration 600, Testing net (#0)
I0526 17:18:04.899448 24213 solver.cpp:404]     Test net output #0: accuracy = 0.334545
I0526 17:18:04.899549 24213 solver.cpp:404]     Test net output #1: loss = 2.69027 (* 1 = 2.69027 loss)
I0526 17:18:06.011973 24213 solver.cpp:228] Iteration 600, loss = 1.37511
I0526 17:18:06.012028 24213 solver.cpp:244]     Train net output #0: loss = 1.37511 (* 1 = 1.37511 loss)
I0526 17:18:06.012044 24213 sgd_solver.cpp:106] Iteration 600, lr = 1e-05
I0526 17:18:18.381701 24213 solver.cpp:228] Iteration 610, loss = 1.21925
I0526 17:18:18.381744 24213 solver.cpp:244]     Train net output #0: loss = 1.21925 (* 1 = 1.21925 loss)
I0526 17:18:18.381760 24213 sgd_solver.cpp:106] Iteration 610, lr = 1e-05
I0526 17:18:30.743577 24213 solver.cpp:228] Iteration 620, loss = 1.26836
I0526 17:18:30.743705 24213 solver.cpp:244]     Train net output #0: loss = 1.26836 (* 1 = 1.26836 loss)
I0526 17:18:30.743746 24213 sgd_solver.cpp:106] Iteration 620, lr = 1e-05
I0526 17:18:41.452409 24213 solver.cpp:337] Iteration 630, Testing net (#0)
I0526 17:18:44.235687 24213 solver.cpp:404]     Test net output #0: accuracy = 0.34
I0526 17:18:44.235788 24213 solver.cpp:404]     Test net output #1: loss = 2.6648 (* 1 = 2.6648 loss)
I0526 17:18:45.346485 24213 solver.cpp:228] Iteration 630, loss = 1.34161
I0526 17:18:45.346529 24213 solver.cpp:244]     Train net output #0: loss = 1.34161 (* 1 = 1.34161 loss)
I0526 17:18:45.346545 24213 sgd_solver.cpp:106] Iteration 630, lr = 1e-05
I0526 17:18:57.710945 24213 solver.cpp:228] Iteration 640, loss = 1.29422
I0526 17:18:57.710988 24213 solver.cpp:244]     Train net output #0: loss = 1.29422 (* 1 = 1.29422 loss)
I0526 17:18:57.710999 24213 sgd_solver.cpp:106] Iteration 640, lr = 1e-05
I0526 17:19:10.066073 24213 solver.cpp:228] Iteration 650, loss = 1.223
I0526 17:19:10.066169 24213 solver.cpp:244]     Train net output #0: loss = 1.223 (* 1 = 1.223 loss)
I0526 17:19:10.066186 24213 sgd_solver.cpp:106] Iteration 650, lr = 1e-05
I0526 17:19:20.954983 24213 solver.cpp:337] Iteration 660, Testing net (#0)
I0526 17:19:23.564285 24213 solver.cpp:404]     Test net output #0: accuracy = 0.343636
I0526 17:19:23.564326 24213 solver.cpp:404]     Test net output #1: loss = 2.65683 (* 1 = 2.65683 loss)
I0526 17:19:24.676594 24213 solver.cpp:228] Iteration 660, loss = 1.13021
I0526 17:19:24.676635 24213 solver.cpp:244]     Train net output #0: loss = 1.13021 (* 1 = 1.13021 loss)
I0526 17:19:24.676650 24213 sgd_solver.cpp:106] Iteration 660, lr = 1e-05
I0526 17:19:37.039178 24213 solver.cpp:228] Iteration 670, loss = 1.15089
I0526 17:19:37.039233 24213 solver.cpp:244]     Train net output #0: loss = 1.15089 (* 1 = 1.15089 loss)
I0526 17:19:37.039250 24213 sgd_solver.cpp:106] Iteration 670, lr = 1e-05
I0526 17:19:49.404039 24213 solver.cpp:228] Iteration 680, loss = 1.20546
I0526 17:19:49.404145 24213 solver.cpp:244]     Train net output #0: loss = 1.20546 (* 1 = 1.20546 loss)
I0526 17:19:49.404187 24213 sgd_solver.cpp:106] Iteration 680, lr = 1e-05
I0526 17:20:00.429276 24213 solver.cpp:337] Iteration 690, Testing net (#0)
I0526 17:20:03.170485 24213 solver.cpp:404]     Test net output #0: accuracy = 0.356364
I0526 17:20:03.170552 24213 solver.cpp:404]     Test net output #1: loss = 2.63756 (* 1 = 2.63756 loss)
I0526 17:20:04.279520 24213 solver.cpp:228] Iteration 690, loss = 1.01153
I0526 17:20:04.279574 24213 solver.cpp:244]     Train net output #0: loss = 1.01153 (* 1 = 1.01153 loss)
I0526 17:20:04.279585 24213 sgd_solver.cpp:106] Iteration 690, lr = 1e-05
I0526 17:20:16.632947 24213 solver.cpp:228] Iteration 700, loss = 1.13898
I0526 17:20:16.632992 24213 solver.cpp:244]     Train net output #0: loss = 1.13898 (* 1 = 1.13898 loss)
I0526 17:20:16.633002 24213 sgd_solver.cpp:106] Iteration 700, lr = 1e-05
I0526 17:20:29.007473 24213 solver.cpp:228] Iteration 710, loss = 1.13332
I0526 17:20:29.007572 24213 solver.cpp:244]     Train net output #0: loss = 1.13332 (* 1 = 1.13332 loss)
I0526 17:20:29.007586 24213 sgd_solver.cpp:106] Iteration 710, lr = 1e-05
I0526 17:20:39.983633 24213 solver.cpp:337] Iteration 720, Testing net (#0)
I0526 17:20:42.801121 24213 solver.cpp:404]     Test net output #0: accuracy = 0.361818
I0526 17:20:42.801220 24213 solver.cpp:404]     Test net output #1: loss = 2.62442 (* 1 = 2.62442 loss)
I0526 17:20:43.907824 24213 solver.cpp:228] Iteration 720, loss = 1.02249
I0526 17:20:43.907883 24213 solver.cpp:244]     Train net output #0: loss = 1.02249 (* 1 = 1.02249 loss)
I0526 17:20:43.907901 24213 sgd_solver.cpp:106] Iteration 720, lr = 1e-05
I0526 17:20:56.265764 24213 solver.cpp:228] Iteration 730, loss = 1.01622
I0526 17:20:56.265817 24213 solver.cpp:244]     Train net output #0: loss = 1.01622 (* 1 = 1.01622 loss)
I0526 17:20:56.265828 24213 sgd_solver.cpp:106] Iteration 730, lr = 1e-05
I0526 17:21:08.617172 24213 solver.cpp:228] Iteration 740, loss = 1.05609
I0526 17:21:08.617285 24213 solver.cpp:244]     Train net output #0: loss = 1.05609 (* 1 = 1.05609 loss)
I0526 17:21:08.617302 24213 sgd_solver.cpp:106] Iteration 740, lr = 1e-05
I0526 17:21:19.469456 24213 solver.cpp:337] Iteration 750, Testing net (#0)
I0526 17:21:22.709993 24213 solver.cpp:404]     Test net output #0: accuracy = 0.361818
I0526 17:21:22.710115 24213 solver.cpp:404]     Test net output #1: loss = 2.59353 (* 1 = 2.59353 loss)
I0526 17:21:23.828151 24213 solver.cpp:228] Iteration 750, loss = 0.986443
I0526 17:21:23.828191 24213 solver.cpp:244]     Train net output #0: loss = 0.986443 (* 1 = 0.986443 loss)
I0526 17:21:23.828202 24213 sgd_solver.cpp:106] Iteration 750, lr = 1e-05
I0526 17:21:36.187069 24213 solver.cpp:228] Iteration 760, loss = 0.961432
I0526 17:21:36.187116 24213 solver.cpp:244]     Train net output #0: loss = 0.961432 (* 1 = 0.961432 loss)
I0526 17:21:36.187132 24213 sgd_solver.cpp:106] Iteration 760, lr = 1e-05
I0526 17:21:48.423496 24213 solver.cpp:228] Iteration 770, loss = 0.987398
I0526 17:21:48.423651 24213 solver.cpp:244]     Train net output #0: loss = 0.987398 (* 1 = 0.987398 loss)
I0526 17:21:48.423723 24213 sgd_solver.cpp:106] Iteration 770, lr = 1e-05
I0526 17:21:59.112192 24213 solver.cpp:337] Iteration 780, Testing net (#0)
I0526 17:22:01.761690 24213 solver.cpp:404]     Test net output #0: accuracy = 0.361818
I0526 17:22:01.761736 24213 solver.cpp:404]     Test net output #1: loss = 2.57031 (* 1 = 2.57031 loss)
I0526 17:22:02.871104 24213 solver.cpp:228] Iteration 780, loss = 0.991131
I0526 17:22:02.871153 24213 solver.cpp:244]     Train net output #0: loss = 0.991131 (* 1 = 0.991131 loss)
I0526 17:22:02.871170 24213 sgd_solver.cpp:106] Iteration 780, lr = 1e-05
I0526 17:22:15.249099 24213 solver.cpp:228] Iteration 790, loss = 0.879728
I0526 17:22:15.249160 24213 solver.cpp:244]     Train net output #0: loss = 0.879728 (* 1 = 0.879728 loss)
I0526 17:22:15.249171 24213 sgd_solver.cpp:106] Iteration 790, lr = 1e-05
I0526 17:22:27.581697 24213 solver.cpp:228] Iteration 800, loss = 1.02255
I0526 17:22:27.581758 24213 solver.cpp:244]     Train net output #0: loss = 1.02255 (* 1 = 1.02255 loss)
I0526 17:22:27.581768 24213 sgd_solver.cpp:106] Iteration 800, lr = 1e-05
I0526 17:22:38.312541 24213 solver.cpp:337] Iteration 810, Testing net (#0)
I0526 17:22:40.916450 24213 solver.cpp:404]     Test net output #0: accuracy = 0.356364
I0526 17:22:40.916488 24213 solver.cpp:404]     Test net output #1: loss = 2.59371 (* 1 = 2.59371 loss)
I0526 17:22:42.026810 24213 solver.cpp:228] Iteration 810, loss = 0.978283
I0526 17:22:42.026860 24213 solver.cpp:244]     Train net output #0: loss = 0.978283 (* 1 = 0.978283 loss)
I0526 17:22:42.026870 24213 sgd_solver.cpp:106] Iteration 810, lr = 1e-05
I0526 17:22:54.393270 24213 solver.cpp:228] Iteration 820, loss = 0.987729
I0526 17:22:54.393326 24213 solver.cpp:244]     Train net output #0: loss = 0.987729 (* 1 = 0.987729 loss)
I0526 17:22:54.393337 24213 sgd_solver.cpp:106] Iteration 820, lr = 1e-05
I0526 17:23:06.729671 24213 solver.cpp:228] Iteration 830, loss = 0.887067
I0526 17:23:06.729756 24213 solver.cpp:244]     Train net output #0: loss = 0.887067 (* 1 = 0.887067 loss)
I0526 17:23:06.729773 24213 sgd_solver.cpp:106] Iteration 830, lr = 1e-05
I0526 17:23:17.501560 24213 solver.cpp:337] Iteration 840, Testing net (#0)
I0526 17:23:20.056866 24213 solver.cpp:404]     Test net output #0: accuracy = 0.36
I0526 17:23:20.056908 24213 solver.cpp:404]     Test net output #1: loss = 2.55209 (* 1 = 2.55209 loss)
I0526 17:23:21.166193 24213 solver.cpp:228] Iteration 840, loss = 0.822202
I0526 17:23:21.166236 24213 solver.cpp:244]     Train net output #0: loss = 0.822202 (* 1 = 0.822202 loss)
I0526 17:23:21.166251 24213 sgd_solver.cpp:106] Iteration 840, lr = 1e-05
I0526 17:23:33.529911 24213 solver.cpp:228] Iteration 850, loss = 0.858606
I0526 17:23:33.529956 24213 solver.cpp:244]     Train net output #0: loss = 0.858606 (* 1 = 0.858606 loss)
I0526 17:23:33.529971 24213 sgd_solver.cpp:106] Iteration 850, lr = 1e-05
I0526 17:23:45.886173 24213 solver.cpp:228] Iteration 860, loss = 0.812087
I0526 17:23:45.886306 24213 solver.cpp:244]     Train net output #0: loss = 0.812087 (* 1 = 0.812087 loss)
I0526 17:23:45.886322 24213 sgd_solver.cpp:106] Iteration 860, lr = 1e-05
I0526 17:23:56.648887 24213 solver.cpp:337] Iteration 870, Testing net (#0)
I0526 17:23:59.217975 24213 solver.cpp:404]     Test net output #0: accuracy = 0.376364
I0526 17:23:59.218106 24213 solver.cpp:404]     Test net output #1: loss = 2.53583 (* 1 = 2.53583 loss)
I0526 17:24:00.336916 24213 solver.cpp:228] Iteration 870, loss = 0.872602
I0526 17:24:00.336967 24213 solver.cpp:244]     Train net output #0: loss = 0.872602 (* 1 = 0.872602 loss)
I0526 17:24:00.336982 24213 sgd_solver.cpp:106] Iteration 870, lr = 1e-05
I0526 17:24:12.705273 24213 solver.cpp:228] Iteration 880, loss = 0.898475
I0526 17:24:12.705324 24213 solver.cpp:244]     Train net output #0: loss = 0.898475 (* 1 = 0.898475 loss)
I0526 17:24:12.705335 24213 sgd_solver.cpp:106] Iteration 880, lr = 1e-05
I0526 17:24:24.989404 24213 solver.cpp:228] Iteration 890, loss = 0.971735
I0526 17:24:24.989564 24213 solver.cpp:244]     Train net output #0: loss = 0.971735 (* 1 = 0.971735 loss)
I0526 17:24:24.989588 24213 sgd_solver.cpp:106] Iteration 890, lr = 1e-05
I0526 17:24:35.875792 24213 solver.cpp:337] Iteration 900, Testing net (#0)
I0526 17:24:38.732172 24213 solver.cpp:404]     Test net output #0: accuracy = 0.374545
I0526 17:24:38.732271 24213 solver.cpp:404]     Test net output #1: loss = 2.55097 (* 1 = 2.55097 loss)
I0526 17:24:39.848026 24213 solver.cpp:228] Iteration 900, loss = 0.820761
I0526 17:24:39.848070 24213 solver.cpp:244]     Train net output #0: loss = 0.820761 (* 1 = 0.820761 loss)
I0526 17:24:39.848085 24213 sgd_solver.cpp:106] Iteration 900, lr = 1e-05
I0526 17:24:52.204632 24213 solver.cpp:228] Iteration 910, loss = 0.772772
I0526 17:24:52.204676 24213 solver.cpp:244]     Train net output #0: loss = 0.772772 (* 1 = 0.772772 loss)
I0526 17:24:52.204691 24213 sgd_solver.cpp:106] Iteration 910, lr = 1e-05
I0526 17:25:04.552186 24213 solver.cpp:228] Iteration 920, loss = 0.800346
I0526 17:25:04.552284 24213 solver.cpp:244]     Train net output #0: loss = 0.800346 (* 1 = 0.800346 loss)
I0526 17:25:04.552301 24213 sgd_solver.cpp:106] Iteration 920, lr = 1e-05
I0526 17:25:15.297220 24213 solver.cpp:337] Iteration 930, Testing net (#0)
I0526 17:25:17.859069 24213 solver.cpp:404]     Test net output #0: accuracy = 0.38
I0526 17:25:17.859172 24213 solver.cpp:404]     Test net output #1: loss = 2.54581 (* 1 = 2.54581 loss)
I0526 17:25:18.971834 24213 solver.cpp:228] Iteration 930, loss = 0.832868
I0526 17:25:18.971936 24213 solver.cpp:244]     Train net output #0: loss = 0.832868 (* 1 = 0.832868 loss)
I0526 17:25:18.971971 24213 sgd_solver.cpp:106] Iteration 930, lr = 1e-05
I0526 17:25:31.358523 24213 solver.cpp:228] Iteration 940, loss = 0.781281
I0526 17:25:31.358571 24213 solver.cpp:244]     Train net output #0: loss = 0.781281 (* 1 = 0.781281 loss)
I0526 17:25:31.358579 24213 sgd_solver.cpp:106] Iteration 940, lr = 1e-05
I0526 17:25:43.738678 24213 solver.cpp:228] Iteration 950, loss = 0.791405
I0526 17:25:43.738767 24213 solver.cpp:244]     Train net output #0: loss = 0.791405 (* 1 = 0.791405 loss)
I0526 17:25:43.738778 24213 sgd_solver.cpp:106] Iteration 950, lr = 1e-05
I0526 17:25:54.340037 24213 solver.cpp:337] Iteration 960, Testing net (#0)
I0526 17:25:57.297822 24213 solver.cpp:404]     Test net output #0: accuracy = 0.376364
I0526 17:25:57.297960 24213 solver.cpp:404]     Test net output #1: loss = 2.5584 (* 1 = 2.5584 loss)
I0526 17:25:58.406975 24213 solver.cpp:228] Iteration 960, loss = 0.830445
I0526 17:25:58.407040 24213 solver.cpp:244]     Train net output #0: loss = 0.830445 (* 1 = 0.830445 loss)
I0526 17:25:58.407058 24213 sgd_solver.cpp:106] Iteration 960, lr = 1e-05
I0526 17:26:10.784098 24213 solver.cpp:228] Iteration 970, loss = 0.658157
I0526 17:26:10.784142 24213 solver.cpp:244]     Train net output #0: loss = 0.658157 (* 1 = 0.658157 loss)
I0526 17:26:10.784158 24213 sgd_solver.cpp:106] Iteration 970, lr = 1e-05
I0526 17:26:23.149963 24213 solver.cpp:228] Iteration 980, loss = 0.68967
I0526 17:26:23.150151 24213 solver.cpp:244]     Train net output #0: loss = 0.68967 (* 1 = 0.68967 loss)
I0526 17:26:23.150190 24213 sgd_solver.cpp:106] Iteration 980, lr = 1e-05
I0526 17:26:34.084229 24213 solver.cpp:337] Iteration 990, Testing net (#0)
I0526 17:26:36.626966 24213 solver.cpp:404]     Test net output #0: accuracy = 0.38
I0526 17:26:36.627065 24213 solver.cpp:404]     Test net output #1: loss = 2.55694 (* 1 = 2.55694 loss)
I0526 17:26:37.738611 24213 solver.cpp:228] Iteration 990, loss = 0.868207
I0526 17:26:37.738653 24213 solver.cpp:244]     Train net output #0: loss = 0.868207 (* 1 = 0.868207 loss)
I0526 17:26:37.738668 24213 sgd_solver.cpp:106] Iteration 990, lr = 1e-05
I0526 17:26:48.879492 24213 solver.cpp:454] Snapshotting to binary proto file snapshot2/caffe_CAM_finetuneMIT_iter_1000.caffemodel
I0526 17:26:49.139118 24213 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot2/caffe_CAM_finetuneMIT_iter_1000.solverstate
I0526 17:26:50.275187 24213 solver.cpp:228] Iteration 1000, loss = 0.696291
I0526 17:26:50.275231 24213 solver.cpp:244]     Train net output #0: loss = 0.696291 (* 1 = 0.696291 loss)
I0526 17:26:50.275248 24213 sgd_solver.cpp:106] Iteration 1000, lr = 1e-06
I0526 17:27:02.618417 24213 solver.cpp:228] Iteration 1010, loss = 0.761915
I0526 17:27:02.618507 24213 solver.cpp:244]     Train net output #0: loss = 0.761915 (* 1 = 0.761915 loss)
I0526 17:27:02.618525 24213 sgd_solver.cpp:106] Iteration 1010, lr = 1e-06
I0526 17:27:13.502720 24213 solver.cpp:337] Iteration 1020, Testing net (#0)
I0526 17:27:16.092816 24213 solver.cpp:404]     Test net output #0: accuracy = 0.374545
I0526 17:27:16.092933 24213 solver.cpp:404]     Test net output #1: loss = 2.55081 (* 1 = 2.55081 loss)
I0526 17:27:17.208633 24213 solver.cpp:228] Iteration 1020, loss = 0.678572
I0526 17:27:17.208695 24213 solver.cpp:244]     Train net output #0: loss = 0.678572 (* 1 = 0.678572 loss)
I0526 17:27:17.208714 24213 sgd_solver.cpp:106] Iteration 1020, lr = 1e-06
I0526 17:27:29.569011 24213 solver.cpp:228] Iteration 1030, loss = 0.703332
I0526 17:27:29.569057 24213 solver.cpp:244]     Train net output #0: loss = 0.703332 (* 1 = 0.703332 loss)
I0526 17:27:29.569067 24213 sgd_solver.cpp:106] Iteration 1030, lr = 1e-06
I0526 17:27:41.904242 24213 solver.cpp:228] Iteration 1040, loss = 0.702677
I0526 17:27:41.904350 24213 solver.cpp:244]     Train net output #0: loss = 0.702677 (* 1 = 0.702677 loss)
I0526 17:27:41.904369 24213 sgd_solver.cpp:106] Iteration 1040, lr = 1e-06
I0526 17:27:52.639096 24213 solver.cpp:337] Iteration 1050, Testing net (#0)
I0526 17:27:55.614622 24213 solver.cpp:404]     Test net output #0: accuracy = 0.374545
I0526 17:27:55.614696 24213 solver.cpp:404]     Test net output #1: loss = 2.55511 (* 1 = 2.55511 loss)
I0526 17:27:56.722492 24213 solver.cpp:228] Iteration 1050, loss = 0.662005
I0526 17:27:56.722532 24213 solver.cpp:244]     Train net output #0: loss = 0.662005 (* 1 = 0.662005 loss)
I0526 17:27:56.722542 24213 sgd_solver.cpp:106] Iteration 1050, lr = 1e-06
I0526 17:28:09.076302 24213 solver.cpp:228] Iteration 1060, loss = 0.71831
I0526 17:28:09.076349 24213 solver.cpp:244]     Train net output #0: loss = 0.71831 (* 1 = 0.71831 loss)
I0526 17:28:09.076365 24213 sgd_solver.cpp:106] Iteration 1060, lr = 1e-06
I0526 17:28:21.403990 24213 solver.cpp:228] Iteration 1070, loss = 0.768251
I0526 17:28:21.404080 24213 solver.cpp:244]     Train net output #0: loss = 0.768251 (* 1 = 0.768251 loss)
I0526 17:28:21.404098 24213 sgd_solver.cpp:106] Iteration 1070, lr = 1e-06
I0526 17:28:32.067296 24213 solver.cpp:337] Iteration 1080, Testing net (#0)
I0526 17:28:34.980772 24213 solver.cpp:404]     Test net output #0: accuracy = 0.372727
I0526 17:28:34.980841 24213 solver.cpp:404]     Test net output #1: loss = 2.57997 (* 1 = 2.57997 loss)
I0526 17:28:36.085789 24213 solver.cpp:228] Iteration 1080, loss = 0.817563
I0526 17:28:36.085837 24213 solver.cpp:244]     Train net output #0: loss = 0.817563 (* 1 = 0.817563 loss)
I0526 17:28:36.085847 24213 sgd_solver.cpp:106] Iteration 1080, lr = 1e-06
I0526 17:28:48.445639 24213 solver.cpp:228] Iteration 1090, loss = 0.751685
I0526 17:28:48.445684 24213 solver.cpp:244]     Train net output #0: loss = 0.751685 (* 1 = 0.751685 loss)
I0526 17:28:48.445695 24213 sgd_solver.cpp:106] Iteration 1090, lr = 1e-06
I0526 17:29:00.784698 24213 solver.cpp:228] Iteration 1100, loss = 0.657698
I0526 17:29:00.784835 24213 solver.cpp:244]     Train net output #0: loss = 0.657698 (* 1 = 0.657698 loss)
I0526 17:29:00.784879 24213 sgd_solver.cpp:106] Iteration 1100, lr = 1e-06
I0526 17:29:11.701216 24213 solver.cpp:337] Iteration 1110, Testing net (#0)
I0526 17:29:14.425853 24213 solver.cpp:404]     Test net output #0: accuracy = 0.381818
I0526 17:29:14.425889 24213 solver.cpp:404]     Test net output #1: loss = 2.54986 (* 1 = 2.54986 loss)
I0526 17:29:15.543222 24213 solver.cpp:228] Iteration 1110, loss = 0.712127
I0526 17:29:15.543279 24213 solver.cpp:244]     Train net output #0: loss = 0.712127 (* 1 = 0.712127 loss)
I0526 17:29:15.543289 24213 sgd_solver.cpp:106] Iteration 1110, lr = 1e-06
I0526 17:29:27.912596 24213 solver.cpp:228] Iteration 1120, loss = 0.764884
I0526 17:29:27.912655 24213 solver.cpp:244]     Train net output #0: loss = 0.764884 (* 1 = 0.764884 loss)
I0526 17:29:27.912667 24213 sgd_solver.cpp:106] Iteration 1120, lr = 1e-06
I0526 17:29:40.216576 24213 solver.cpp:228] Iteration 1130, loss = 0.860224
I0526 17:29:40.216707 24213 solver.cpp:244]     Train net output #0: loss = 0.860224 (* 1 = 0.860224 loss)
I0526 17:29:40.216723 24213 sgd_solver.cpp:106] Iteration 1130, lr = 1e-06
I0526 17:29:50.890292 24213 solver.cpp:337] Iteration 1140, Testing net (#0)
I0526 17:29:53.751238 24213 solver.cpp:404]     Test net output #0: accuracy = 0.381818
I0526 17:29:53.751335 24213 solver.cpp:404]     Test net output #1: loss = 2.5388 (* 1 = 2.5388 loss)
I0526 17:29:54.873805 24213 solver.cpp:228] Iteration 1140, loss = 0.738444
I0526 17:29:54.873848 24213 solver.cpp:244]     Train net output #0: loss = 0.738444 (* 1 = 0.738444 loss)
I0526 17:29:54.873859 24213 sgd_solver.cpp:106] Iteration 1140, lr = 1e-06
I0526 17:30:07.232630 24213 solver.cpp:228] Iteration 1150, loss = 0.675559
I0526 17:30:07.232671 24213 solver.cpp:244]     Train net output #0: loss = 0.675559 (* 1 = 0.675559 loss)
I0526 17:30:07.232681 24213 sgd_solver.cpp:106] Iteration 1150, lr = 1e-06
I0526 17:30:19.561300 24213 solver.cpp:228] Iteration 1160, loss = 0.701994
I0526 17:30:19.561398 24213 solver.cpp:244]     Train net output #0: loss = 0.701994 (* 1 = 0.701994 loss)
I0526 17:30:19.561415 24213 sgd_solver.cpp:106] Iteration 1160, lr = 1e-06
I0526 17:30:30.445662 24213 solver.cpp:337] Iteration 1170, Testing net (#0)
I0526 17:30:32.960832 24213 solver.cpp:404]     Test net output #0: accuracy = 0.381818
I0526 17:30:32.960937 24213 solver.cpp:404]     Test net output #1: loss = 2.538 (* 1 = 2.538 loss)
I0526 17:30:34.069870 24213 solver.cpp:228] Iteration 1170, loss = 0.69549
I0526 17:30:34.069916 24213 solver.cpp:244]     Train net output #0: loss = 0.69549 (* 1 = 0.69549 loss)
I0526 17:30:34.069931 24213 sgd_solver.cpp:106] Iteration 1170, lr = 1e-06
I0526 17:30:46.437261 24213 solver.cpp:228] Iteration 1180, loss = 0.788248
I0526 17:30:46.437305 24213 solver.cpp:244]     Train net output #0: loss = 0.788248 (* 1 = 0.788248 loss)
I0526 17:30:46.437315 24213 sgd_solver.cpp:106] Iteration 1180, lr = 1e-06
I0526 17:30:58.779361 24213 solver.cpp:228] Iteration 1190, loss = 0.718966
I0526 17:30:58.779445 24213 solver.cpp:244]     Train net output #0: loss = 0.718966 (* 1 = 0.718966 loss)
I0526 17:30:58.779458 24213 sgd_solver.cpp:106] Iteration 1190, lr = 1e-06
I0526 17:31:09.609786 24213 solver.cpp:337] Iteration 1200, Testing net (#0)
I0526 17:31:12.122326 24213 solver.cpp:404]     Test net output #0: accuracy = 0.38
I0526 17:31:12.122401 24213 solver.cpp:404]     Test net output #1: loss = 2.56315 (* 1 = 2.56315 loss)
I0526 17:31:13.235229 24213 solver.cpp:228] Iteration 1200, loss = 0.79272
I0526 17:31:13.235275 24213 solver.cpp:244]     Train net output #0: loss = 0.79272 (* 1 = 0.79272 loss)
I0526 17:31:13.235286 24213 sgd_solver.cpp:106] Iteration 1200, lr = 1e-06
I0526 17:31:25.593495 24213 solver.cpp:228] Iteration 1210, loss = 0.720538
I0526 17:31:25.593540 24213 solver.cpp:244]     Train net output #0: loss = 0.720538 (* 1 = 0.720538 loss)
I0526 17:31:25.593550 24213 sgd_solver.cpp:106] Iteration 1210, lr = 1e-06
I0526 17:31:37.936240 24213 solver.cpp:228] Iteration 1220, loss = 0.638322
I0526 17:31:37.936383 24213 solver.cpp:244]     Train net output #0: loss = 0.638322 (* 1 = 0.638322 loss)
I0526 17:31:37.936395 24213 sgd_solver.cpp:106] Iteration 1220, lr = 1e-06
I0526 17:31:48.627990 24213 solver.cpp:337] Iteration 1230, Testing net (#0)
I0526 17:31:51.575634 24213 solver.cpp:404]     Test net output #0: accuracy = 0.383636
I0526 17:31:51.575673 24213 solver.cpp:404]     Test net output #1: loss = 2.53686 (* 1 = 2.53686 loss)
I0526 17:31:52.684204 24213 solver.cpp:228] Iteration 1230, loss = 0.73698
I0526 17:31:52.684257 24213 solver.cpp:244]     Train net output #0: loss = 0.73698 (* 1 = 0.73698 loss)
I0526 17:31:52.684272 24213 sgd_solver.cpp:106] Iteration 1230, lr = 1e-06
I0526 17:32:05.051318 24213 solver.cpp:228] Iteration 1240, loss = 0.730609
I0526 17:32:05.051368 24213 solver.cpp:244]     Train net output #0: loss = 0.730609 (* 1 = 0.730609 loss)
I0526 17:32:05.051383 24213 sgd_solver.cpp:106] Iteration 1240, lr = 1e-06
I0526 17:32:17.385419 24213 solver.cpp:228] Iteration 1250, loss = 0.749159
I0526 17:32:17.385519 24213 solver.cpp:244]     Train net output #0: loss = 0.749159 (* 1 = 0.749159 loss)
I0526 17:32:17.385537 24213 sgd_solver.cpp:106] Iteration 1250, lr = 1e-06
I0526 17:32:28.135041 24213 solver.cpp:337] Iteration 1260, Testing net (#0)
I0526 17:32:30.652994 24213 solver.cpp:404]     Test net output #0: accuracy = 0.376364
I0526 17:32:30.653123 24213 solver.cpp:404]     Test net output #1: loss = 2.5505 (* 1 = 2.5505 loss)
I0526 17:32:31.764559 24213 solver.cpp:228] Iteration 1260, loss = 0.710763
I0526 17:32:31.764624 24213 solver.cpp:244]     Train net output #0: loss = 0.710763 (* 1 = 0.710763 loss)
I0526 17:32:31.764636 24213 sgd_solver.cpp:106] Iteration 1260, lr = 1e-06
I0526 17:32:44.129825 24213 solver.cpp:228] Iteration 1270, loss = 0.737234
I0526 17:32:44.129873 24213 solver.cpp:244]     Train net output #0: loss = 0.737234 (* 1 = 0.737234 loss)
I0526 17:32:44.129889 24213 sgd_solver.cpp:106] Iteration 1270, lr = 1e-06
I0526 17:32:56.467347 24213 solver.cpp:228] Iteration 1280, loss = 0.690265
I0526 17:32:56.467447 24213 solver.cpp:244]     Train net output #0: loss = 0.690265 (* 1 = 0.690265 loss)
I0526 17:32:56.467459 24213 sgd_solver.cpp:106] Iteration 1280, lr = 1e-06
I0526 17:33:07.206070 24213 solver.cpp:337] Iteration 1290, Testing net (#0)
I0526 17:33:10.072643 24213 solver.cpp:404]     Test net output #0: accuracy = 0.376364
I0526 17:33:10.072742 24213 solver.cpp:404]     Test net output #1: loss = 2.55423 (* 1 = 2.55423 loss)
I0526 17:33:11.182211 24213 solver.cpp:228] Iteration 1290, loss = 0.819763
I0526 17:33:11.182255 24213 solver.cpp:244]     Train net output #0: loss = 0.819763 (* 1 = 0.819763 loss)
I0526 17:33:11.182266 24213 sgd_solver.cpp:106] Iteration 1290, lr = 1e-06
I0526 17:33:23.556510 24213 solver.cpp:228] Iteration 1300, loss = 0.772988
I0526 17:33:23.556558 24213 solver.cpp:244]     Train net output #0: loss = 0.772988 (* 1 = 0.772988 loss)
I0526 17:33:23.556569 24213 sgd_solver.cpp:106] Iteration 1300, lr = 1e-06
I0526 17:33:35.887841 24213 solver.cpp:228] Iteration 1310, loss = 0.707457
I0526 17:33:35.887923 24213 solver.cpp:244]     Train net output #0: loss = 0.707457 (* 1 = 0.707457 loss)
I0526 17:33:35.887935 24213 sgd_solver.cpp:106] Iteration 1310, lr = 1e-06
I0526 17:33:46.746208 24213 solver.cpp:337] Iteration 1320, Testing net (#0)
I0526 17:33:49.327767 24213 solver.cpp:404]     Test net output #0: accuracy = 0.38
I0526 17:33:49.327872 24213 solver.cpp:404]     Test net output #1: loss = 2.55914 (* 1 = 2.55914 loss)
I0526 17:33:50.448956 24213 solver.cpp:228] Iteration 1320, loss = 0.7395
I0526 17:33:50.449003 24213 solver.cpp:244]     Train net output #0: loss = 0.7395 (* 1 = 0.7395 loss)
I0526 17:33:50.449019 24213 sgd_solver.cpp:106] Iteration 1320, lr = 1e-06
I0526 17:34:02.815925 24213 solver.cpp:228] Iteration 1330, loss = 0.755198
I0526 17:34:02.815969 24213 solver.cpp:244]     Train net output #0: loss = 0.755198 (* 1 = 0.755198 loss)
I0526 17:34:02.815984 24213 sgd_solver.cpp:106] Iteration 1330, lr = 1e-06
I0526 17:34:15.158536 24213 solver.cpp:228] Iteration 1340, loss = 0.762219
I0526 17:34:15.158660 24213 solver.cpp:244]     Train net output #0: loss = 0.762219 (* 1 = 0.762219 loss)
I0526 17:34:15.158679 24213 sgd_solver.cpp:106] Iteration 1340, lr = 1e-06
I0526 17:34:25.682481 24213 solver.cpp:337] Iteration 1350, Testing net (#0)
I0526 17:34:28.613708 24213 solver.cpp:404]     Test net output #0: accuracy = 0.38
I0526 17:34:28.613756 24213 solver.cpp:404]     Test net output #1: loss = 2.55305 (* 1 = 2.55305 loss)
I0526 17:34:29.725194 24213 solver.cpp:228] Iteration 1350, loss = 0.629406
I0526 17:34:29.725251 24213 solver.cpp:244]     Train net output #0: loss = 0.629406 (* 1 = 0.629406 loss)
I0526 17:34:29.725262 24213 sgd_solver.cpp:106] Iteration 1350, lr = 1e-06
I0526 17:34:42.082715 24213 solver.cpp:228] Iteration 1360, loss = 0.696767
I0526 17:34:42.082756 24213 solver.cpp:244]     Train net output #0: loss = 0.696767 (* 1 = 0.696767 loss)
I0526 17:34:42.082767 24213 sgd_solver.cpp:106] Iteration 1360, lr = 1e-06
I0526 17:34:54.427657 24213 solver.cpp:228] Iteration 1370, loss = 0.843569
I0526 17:34:54.427743 24213 solver.cpp:244]     Train net output #0: loss = 0.843569 (* 1 = 0.843569 loss)
I0526 17:34:54.427755 24213 sgd_solver.cpp:106] Iteration 1370, lr = 1e-06
I0526 17:35:05.200021 24213 solver.cpp:337] Iteration 1380, Testing net (#0)
I0526 17:35:08.225054 24213 solver.cpp:404]     Test net output #0: accuracy = 0.376364
I0526 17:35:08.225096 24213 solver.cpp:404]     Test net output #1: loss = 2.54885 (* 1 = 2.54885 loss)
I0526 17:35:09.342383 24213 solver.cpp:228] Iteration 1380, loss = 0.762911
I0526 17:35:09.342425 24213 solver.cpp:244]     Train net output #0: loss = 0.762911 (* 1 = 0.762911 loss)
I0526 17:35:09.342435 24213 sgd_solver.cpp:106] Iteration 1380, lr = 1e-06
I0526 17:35:21.719539 24213 solver.cpp:228] Iteration 1390, loss = 0.64923
I0526 17:35:21.719596 24213 solver.cpp:244]     Train net output #0: loss = 0.64923 (* 1 = 0.64923 loss)
I0526 17:35:21.719609 24213 sgd_solver.cpp:106] Iteration 1390, lr = 1e-06
I0526 17:35:34.005055 24213 solver.cpp:228] Iteration 1400, loss = 0.718114
I0526 17:35:34.005154 24213 solver.cpp:244]     Train net output #0: loss = 0.718114 (* 1 = 0.718114 loss)
I0526 17:35:34.005167 24213 sgd_solver.cpp:106] Iteration 1400, lr = 1e-06
I0526 17:35:44.648367 24213 solver.cpp:337] Iteration 1410, Testing net (#0)
I0526 17:35:47.241580 24213 solver.cpp:404]     Test net output #0: accuracy = 0.374545
I0526 17:35:47.241619 24213 solver.cpp:404]     Test net output #1: loss = 2.58758 (* 1 = 2.58758 loss)
I0526 17:35:48.362669 24213 solver.cpp:228] Iteration 1410, loss = 0.689743
I0526 17:35:48.362751 24213 solver.cpp:244]     Train net output #0: loss = 0.689743 (* 1 = 0.689743 loss)
I0526 17:35:48.362772 24213 sgd_solver.cpp:106] Iteration 1410, lr = 1e-06
I0526 17:36:00.722070 24213 solver.cpp:228] Iteration 1420, loss = 0.70019
I0526 17:36:00.722111 24213 solver.cpp:244]     Train net output #0: loss = 0.70019 (* 1 = 0.70019 loss)
I0526 17:36:00.722121 24213 sgd_solver.cpp:106] Iteration 1420, lr = 1e-06
I0526 17:36:13.056325 24213 solver.cpp:228] Iteration 1430, loss = 0.779203
I0526 17:36:13.056412 24213 solver.cpp:244]     Train net output #0: loss = 0.779203 (* 1 = 0.779203 loss)
I0526 17:36:13.056429 24213 sgd_solver.cpp:106] Iteration 1430, lr = 1e-06
I0526 17:36:23.935248 24213 solver.cpp:337] Iteration 1440, Testing net (#0)
I0526 17:36:26.441087 24213 solver.cpp:404]     Test net output #0: accuracy = 0.383636
I0526 17:36:26.441125 24213 solver.cpp:404]     Test net output #1: loss = 2.53651 (* 1 = 2.53651 loss)
I0526 17:36:27.554767 24213 solver.cpp:228] Iteration 1440, loss = 0.692053
I0526 17:36:27.554813 24213 solver.cpp:244]     Train net output #0: loss = 0.692053 (* 1 = 0.692053 loss)
I0526 17:36:27.554828 24213 sgd_solver.cpp:106] Iteration 1440, lr = 1e-06
I0526 17:36:39.921200 24213 solver.cpp:228] Iteration 1450, loss = 0.735059
I0526 17:36:39.921309 24213 solver.cpp:244]     Train net output #0: loss = 0.735059 (* 1 = 0.735059 loss)
I0526 17:36:39.921345 24213 sgd_solver.cpp:106] Iteration 1450, lr = 1e-06
I0526 17:36:52.276532 24213 solver.cpp:228] Iteration 1460, loss = 0.74456
I0526 17:36:52.276667 24213 solver.cpp:244]     Train net output #0: loss = 0.74456 (* 1 = 0.74456 loss)
I0526 17:36:52.276680 24213 sgd_solver.cpp:106] Iteration 1460, lr = 1e-06
I0526 17:37:02.890377 24213 solver.cpp:337] Iteration 1470, Testing net (#0)
I0526 17:37:05.839299 24213 solver.cpp:404]     Test net output #0: accuracy = 0.383636
I0526 17:37:05.839366 24213 solver.cpp:404]     Test net output #1: loss = 2.52783 (* 1 = 2.52783 loss)
I0526 17:37:06.952996 24213 solver.cpp:228] Iteration 1470, loss = 0.670224
I0526 17:37:06.953039 24213 solver.cpp:244]     Train net output #0: loss = 0.670224 (* 1 = 0.670224 loss)
I0526 17:37:06.953053 24213 sgd_solver.cpp:106] Iteration 1470, lr = 1e-06
I0526 17:37:19.317915 24213 solver.cpp:228] Iteration 1480, loss = 0.67178
I0526 17:37:19.317984 24213 solver.cpp:244]     Train net output #0: loss = 0.67178 (* 1 = 0.67178 loss)
I0526 17:37:19.318001 24213 sgd_solver.cpp:106] Iteration 1480, lr = 1e-06
I0526 17:37:31.672726 24213 solver.cpp:228] Iteration 1490, loss = 0.703183
I0526 17:37:31.672850 24213 solver.cpp:244]     Train net output #0: loss = 0.703183 (* 1 = 0.703183 loss)
I0526 17:37:31.672905 24213 sgd_solver.cpp:106] Iteration 1490, lr = 1e-06
I0526 17:37:42.163857 24213 solver.cpp:337] Iteration 1500, Testing net (#0)
I0526 17:37:44.970715 24213 solver.cpp:404]     Test net output #0: accuracy = 0.378182
I0526 17:37:44.970832 24213 solver.cpp:404]     Test net output #1: loss = 2.57157 (* 1 = 2.57157 loss)
I0526 17:37:46.081823 24213 solver.cpp:228] Iteration 1500, loss = 0.640236
I0526 17:37:46.081894 24213 solver.cpp:244]     Train net output #0: loss = 0.640236 (* 1 = 0.640236 loss)
I0526 17:37:46.081912 24213 sgd_solver.cpp:106] Iteration 1500, lr = 1e-06
I0526 17:37:58.459841 24213 solver.cpp:228] Iteration 1510, loss = 0.748938
I0526 17:37:58.459894 24213 solver.cpp:244]     Train net output #0: loss = 0.748938 (* 1 = 0.748938 loss)
I0526 17:37:58.459910 24213 sgd_solver.cpp:106] Iteration 1510, lr = 1e-06
I0526 17:38:10.810485 24213 solver.cpp:228] Iteration 1520, loss = 0.721859
I0526 17:38:10.810616 24213 solver.cpp:244]     Train net output #0: loss = 0.721859 (* 1 = 0.721859 loss)
I0526 17:38:10.810634 24213 sgd_solver.cpp:106] Iteration 1520, lr = 1e-06
I0526 17:38:21.439431 24213 solver.cpp:337] Iteration 1530, Testing net (#0)
I0526 17:38:24.144318 24213 solver.cpp:404]     Test net output #0: accuracy = 0.378182
I0526 17:38:24.144376 24213 solver.cpp:404]     Test net output #1: loss = 2.55916 (* 1 = 2.55916 loss)
I0526 17:38:25.253725 24213 solver.cpp:228] Iteration 1530, loss = 0.703349
I0526 17:38:25.253784 24213 solver.cpp:244]     Train net output #0: loss = 0.703349 (* 1 = 0.703349 loss)
I0526 17:38:25.253800 24213 sgd_solver.cpp:106] Iteration 1530, lr = 1e-06
I0526 17:38:37.608414 24213 solver.cpp:228] Iteration 1540, loss = 0.667902
I0526 17:38:37.608480 24213 solver.cpp:244]     Train net output #0: loss = 0.667902 (* 1 = 0.667902 loss)
I0526 17:38:37.608495 24213 sgd_solver.cpp:106] Iteration 1540, lr = 1e-06
I0526 17:38:49.980924 24213 solver.cpp:228] Iteration 1550, loss = 0.736541
I0526 17:38:49.981101 24213 solver.cpp:244]     Train net output #0: loss = 0.736541 (* 1 = 0.736541 loss)
I0526 17:38:49.981118 24213 sgd_solver.cpp:106] Iteration 1550, lr = 1e-06
I0526 17:39:00.618095 24213 solver.cpp:337] Iteration 1560, Testing net (#0)
I0526 17:39:03.133200 24213 solver.cpp:404]     Test net output #0: accuracy = 0.38
I0526 17:39:03.133266 24213 solver.cpp:404]     Test net output #1: loss = 2.54113 (* 1 = 2.54113 loss)
I0526 17:39:04.249035 24213 solver.cpp:228] Iteration 1560, loss = 0.685644
I0526 17:39:04.249089 24213 solver.cpp:244]     Train net output #0: loss = 0.685644 (* 1 = 0.685644 loss)
I0526 17:39:04.249105 24213 sgd_solver.cpp:106] Iteration 1560, lr = 1e-06
I0526 17:39:16.596436 24213 solver.cpp:228] Iteration 1570, loss = 0.752665
I0526 17:39:16.596500 24213 solver.cpp:244]     Train net output #0: loss = 0.752665 (* 1 = 0.752665 loss)
I0526 17:39:16.596513 24213 sgd_solver.cpp:106] Iteration 1570, lr = 1e-06
I0526 17:39:28.947717 24213 solver.cpp:228] Iteration 1580, loss = 0.741483
I0526 17:39:28.947831 24213 solver.cpp:244]     Train net output #0: loss = 0.741483 (* 1 = 0.741483 loss)
I0526 17:39:28.947844 24213 sgd_solver.cpp:106] Iteration 1580, lr = 1e-06
I0526 17:39:39.508633 24213 solver.cpp:337] Iteration 1590, Testing net (#0)
I0526 17:39:42.033231 24213 solver.cpp:404]     Test net output #0: accuracy = 0.38
I0526 17:39:42.033493 24213 solver.cpp:404]     Test net output #1: loss = 2.56079 (* 1 = 2.56079 loss)
I0526 17:39:43.142498 24213 solver.cpp:228] Iteration 1590, loss = 0.73032
I0526 17:39:43.142566 24213 solver.cpp:244]     Train net output #0: loss = 0.73032 (* 1 = 0.73032 loss)
I0526 17:39:43.142582 24213 sgd_solver.cpp:106] Iteration 1590, lr = 1e-06
I0526 17:39:55.507982 24213 solver.cpp:228] Iteration 1600, loss = 0.653282
I0526 17:39:55.508025 24213 solver.cpp:244]     Train net output #0: loss = 0.653282 (* 1 = 0.653282 loss)
I0526 17:39:55.508035 24213 sgd_solver.cpp:106] Iteration 1600, lr = 1e-06
I0526 17:40:07.867324 24213 solver.cpp:228] Iteration 1610, loss = 0.72988
I0526 17:40:07.867435 24213 solver.cpp:244]     Train net output #0: loss = 0.72988 (* 1 = 0.72988 loss)
I0526 17:40:07.867447 24213 sgd_solver.cpp:106] Iteration 1610, lr = 1e-06
I0526 17:40:18.560685 24213 solver.cpp:337] Iteration 1620, Testing net (#0)
I0526 17:40:21.186152 24213 solver.cpp:404]     Test net output #0: accuracy = 0.378182
I0526 17:40:21.186250 24213 solver.cpp:404]     Test net output #1: loss = 2.56155 (* 1 = 2.56155 loss)
I0526 17:40:22.304683 24213 solver.cpp:228] Iteration 1620, loss = 0.68451
I0526 17:40:22.304733 24213 solver.cpp:244]     Train net output #0: loss = 0.68451 (* 1 = 0.68451 loss)
I0526 17:40:22.304750 24213 sgd_solver.cpp:106] Iteration 1620, lr = 1e-06
I0526 17:40:34.678127 24213 solver.cpp:228] Iteration 1630, loss = 0.748706
I0526 17:40:34.678176 24213 solver.cpp:244]     Train net output #0: loss = 0.748706 (* 1 = 0.748706 loss)
I0526 17:40:34.678187 24213 sgd_solver.cpp:106] Iteration 1630, lr = 1e-06
I0526 17:40:47.052333 24213 solver.cpp:228] Iteration 1640, loss = 0.669354
I0526 17:40:47.052439 24213 solver.cpp:244]     Train net output #0: loss = 0.669354 (* 1 = 0.669354 loss)
I0526 17:40:47.052484 24213 sgd_solver.cpp:106] Iteration 1640, lr = 1e-06
I0526 17:40:57.949991 24213 solver.cpp:337] Iteration 1650, Testing net (#0)
I0526 17:41:00.581830 24213 solver.cpp:404]     Test net output #0: accuracy = 0.38
I0526 17:41:00.581869 24213 solver.cpp:404]     Test net output #1: loss = 2.57412 (* 1 = 2.57412 loss)
I0526 17:41:01.694936 24213 solver.cpp:228] Iteration 1650, loss = 0.720817
I0526 17:41:01.694984 24213 solver.cpp:244]     Train net output #0: loss = 0.720817 (* 1 = 0.720817 loss)
I0526 17:41:01.694995 24213 sgd_solver.cpp:106] Iteration 1650, lr = 1e-06
I0526 17:41:14.064105 24213 solver.cpp:228] Iteration 1660, loss = 0.640963
I0526 17:41:14.064153 24213 solver.cpp:244]     Train net output #0: loss = 0.640963 (* 1 = 0.640963 loss)
I0526 17:41:14.064168 24213 sgd_solver.cpp:106] Iteration 1660, lr = 1e-06
I0526 17:41:26.422943 24213 solver.cpp:228] Iteration 1670, loss = 0.619288
I0526 17:41:26.423087 24213 solver.cpp:244]     Train net output #0: loss = 0.619288 (* 1 = 0.619288 loss)
I0526 17:41:26.423107 24213 sgd_solver.cpp:106] Iteration 1670, lr = 1e-06
I0526 17:41:37.187001 24213 solver.cpp:337] Iteration 1680, Testing net (#0)
I0526 17:41:39.995725 24213 solver.cpp:404]     Test net output #0: accuracy = 0.38
I0526 17:41:39.995784 24213 solver.cpp:404]     Test net output #1: loss = 2.56188 (* 1 = 2.56188 loss)
I0526 17:41:41.107131 24213 solver.cpp:228] Iteration 1680, loss = 0.667401
I0526 17:41:41.107173 24213 solver.cpp:244]     Train net output #0: loss = 0.667401 (* 1 = 0.667401 loss)
I0526 17:41:41.107183 24213 sgd_solver.cpp:106] Iteration 1680, lr = 1e-06
I0526 17:41:53.481986 24213 solver.cpp:228] Iteration 1690, loss = 0.749906
I0526 17:41:53.482054 24213 solver.cpp:244]     Train net output #0: loss = 0.749906 (* 1 = 0.749906 loss)
I0526 17:41:53.482066 24213 sgd_solver.cpp:106] Iteration 1690, lr = 1e-06
I0526 17:42:05.844796 24213 solver.cpp:228] Iteration 1700, loss = 0.714958
I0526 17:42:05.844923 24213 solver.cpp:244]     Train net output #0: loss = 0.714958 (* 1 = 0.714958 loss)
I0526 17:42:05.844935 24213 sgd_solver.cpp:106] Iteration 1700, lr = 1e-06
I0526 17:42:16.563002 24213 solver.cpp:337] Iteration 1710, Testing net (#0)
I0526 17:42:19.278216 24213 solver.cpp:404]     Test net output #0: accuracy = 0.387273
I0526 17:42:19.278267 24213 solver.cpp:404]     Test net output #1: loss = 2.5279 (* 1 = 2.5279 loss)
I0526 17:42:20.386896 24213 solver.cpp:228] Iteration 1710, loss = 0.646999
I0526 17:42:20.386952 24213 solver.cpp:244]     Train net output #0: loss = 0.646999 (* 1 = 0.646999 loss)
I0526 17:42:20.386967 24213 sgd_solver.cpp:106] Iteration 1710, lr = 1e-06
I0526 17:42:32.766774 24213 solver.cpp:228] Iteration 1720, loss = 0.586681
I0526 17:42:32.766821 24213 solver.cpp:244]     Train net output #0: loss = 0.586681 (* 1 = 0.586681 loss)
I0526 17:42:32.766836 24213 sgd_solver.cpp:106] Iteration 1720, lr = 1e-06
I0526 17:42:45.127490 24213 solver.cpp:228] Iteration 1730, loss = 0.679465
I0526 17:42:45.127593 24213 solver.cpp:244]     Train net output #0: loss = 0.679465 (* 1 = 0.679465 loss)
I0526 17:42:45.127604 24213 sgd_solver.cpp:106] Iteration 1730, lr = 1e-06
I0526 17:42:56.095911 24213 solver.cpp:337] Iteration 1740, Testing net (#0)
I0526 17:42:58.947329 24213 solver.cpp:404]     Test net output #0: accuracy = 0.38
I0526 17:42:58.947365 24213 solver.cpp:404]     Test net output #1: loss = 2.57454 (* 1 = 2.57454 loss)
I0526 17:43:00.059342 24213 solver.cpp:228] Iteration 1740, loss = 0.690237
I0526 17:43:00.059386 24213 solver.cpp:244]     Train net output #0: loss = 0.690237 (* 1 = 0.690237 loss)
I0526 17:43:00.059396 24213 sgd_solver.cpp:106] Iteration 1740, lr = 1e-06
I0526 17:43:12.426591 24213 solver.cpp:228] Iteration 1750, loss = 0.747746
I0526 17:43:12.426636 24213 solver.cpp:244]     Train net output #0: loss = 0.747746 (* 1 = 0.747746 loss)
I0526 17:43:12.426652 24213 sgd_solver.cpp:106] Iteration 1750, lr = 1e-06
I0526 17:43:24.792027 24213 solver.cpp:228] Iteration 1760, loss = 0.675396
I0526 17:43:24.792132 24213 solver.cpp:244]     Train net output #0: loss = 0.675396 (* 1 = 0.675396 loss)
I0526 17:43:24.792150 24213 sgd_solver.cpp:106] Iteration 1760, lr = 1e-06
I0526 17:43:35.692128 24213 solver.cpp:337] Iteration 1770, Testing net (#0)
I0526 17:43:38.270730 24213 solver.cpp:404]     Test net output #0: accuracy = 0.378182
I0526 17:43:38.270834 24213 solver.cpp:404]     Test net output #1: loss = 2.54528 (* 1 = 2.54528 loss)
I0526 17:43:39.386198 24213 solver.cpp:228] Iteration 1770, loss = 0.69366
I0526 17:43:39.386245 24213 solver.cpp:244]     Train net output #0: loss = 0.69366 (* 1 = 0.69366 loss)
I0526 17:43:39.386255 24213 sgd_solver.cpp:106] Iteration 1770, lr = 1e-06
I0526 17:43:51.742754 24213 solver.cpp:228] Iteration 1780, loss = 0.563563
I0526 17:43:51.742802 24213 solver.cpp:244]     Train net output #0: loss = 0.563563 (* 1 = 0.563563 loss)
I0526 17:43:51.742818 24213 sgd_solver.cpp:106] Iteration 1780, lr = 1e-06
I0526 17:44:04.097851 24213 solver.cpp:228] Iteration 1790, loss = 0.681288
I0526 17:44:04.097978 24213 solver.cpp:244]     Train net output #0: loss = 0.681288 (* 1 = 0.681288 loss)
I0526 17:44:04.097991 24213 sgd_solver.cpp:106] Iteration 1790, lr = 1e-06
I0526 17:44:14.662339 24213 solver.cpp:337] Iteration 1800, Testing net (#0)
I0526 17:44:17.170114 24213 solver.cpp:404]     Test net output #0: accuracy = 0.387273
I0526 17:44:17.170168 24213 solver.cpp:404]     Test net output #1: loss = 2.5273 (* 1 = 2.5273 loss)
I0526 17:44:18.285441 24213 solver.cpp:228] Iteration 1800, loss = 0.677827
I0526 17:44:18.285503 24213 solver.cpp:244]     Train net output #0: loss = 0.677827 (* 1 = 0.677827 loss)
I0526 17:44:18.285521 24213 sgd_solver.cpp:106] Iteration 1800, lr = 1e-06
I0526 17:44:30.644958 24213 solver.cpp:228] Iteration 1810, loss = 0.693398
I0526 17:44:30.645004 24213 solver.cpp:244]     Train net output #0: loss = 0.693398 (* 1 = 0.693398 loss)
I0526 17:44:30.645020 24213 sgd_solver.cpp:106] Iteration 1810, lr = 1e-06
I0526 17:44:43.012697 24213 solver.cpp:228] Iteration 1820, loss = 0.689725
I0526 17:44:43.012840 24213 solver.cpp:244]     Train net output #0: loss = 0.689725 (* 1 = 0.689725 loss)
I0526 17:44:43.012858 24213 sgd_solver.cpp:106] Iteration 1820, lr = 1e-06
I0526 17:44:53.990378 24213 solver.cpp:337] Iteration 1830, Testing net (#0)
I0526 17:44:56.735471 24213 solver.cpp:404]     Test net output #0: accuracy = 0.390909
I0526 17:44:56.735566 24213 solver.cpp:404]     Test net output #1: loss = 2.53807 (* 1 = 2.53807 loss)
I0526 17:44:57.851999 24213 solver.cpp:228] Iteration 1830, loss = 0.676315
I0526 17:44:57.852056 24213 solver.cpp:244]     Train net output #0: loss = 0.676315 (* 1 = 0.676315 loss)
I0526 17:44:57.852072 24213 sgd_solver.cpp:106] Iteration 1830, lr = 1e-06
I0526 17:45:10.228701 24213 solver.cpp:228] Iteration 1840, loss = 0.633388
I0526 17:45:10.228752 24213 solver.cpp:244]     Train net output #0: loss = 0.633388 (* 1 = 0.633388 loss)
I0526 17:45:10.228768 24213 sgd_solver.cpp:106] Iteration 1840, lr = 1e-06
I0526 17:45:22.610965 24213 solver.cpp:228] Iteration 1850, loss = 0.701677
I0526 17:45:22.611054 24213 solver.cpp:244]     Train net output #0: loss = 0.701677 (* 1 = 0.701677 loss)
I0526 17:45:22.611071 24213 sgd_solver.cpp:106] Iteration 1850, lr = 1e-06
I0526 17:45:33.410735 24213 solver.cpp:337] Iteration 1860, Testing net (#0)
I0526 17:45:36.189968 24213 solver.cpp:404]     Test net output #0: accuracy = 0.38
I0526 17:45:36.190032 24213 solver.cpp:404]     Test net output #1: loss = 2.54789 (* 1 = 2.54789 loss)
I0526 17:45:37.298897 24213 solver.cpp:228] Iteration 1860, loss = 0.719129
I0526 17:45:37.298941 24213 solver.cpp:244]     Train net output #0: loss = 0.719129 (* 1 = 0.719129 loss)
I0526 17:45:37.298956 24213 sgd_solver.cpp:106] Iteration 1860, lr = 1e-06
I0526 17:45:49.665570 24213 solver.cpp:228] Iteration 1870, loss = 0.651632
I0526 17:45:49.665613 24213 solver.cpp:244]     Train net output #0: loss = 0.651632 (* 1 = 0.651632 loss)
I0526 17:45:49.665628 24213 sgd_solver.cpp:106] Iteration 1870, lr = 1e-06
I0526 17:46:02.037808 24213 solver.cpp:228] Iteration 1880, loss = 0.819926
I0526 17:46:02.037993 24213 solver.cpp:244]     Train net output #0: loss = 0.819926 (* 1 = 0.819926 loss)
I0526 17:46:02.038039 24213 sgd_solver.cpp:106] Iteration 1880, lr = 1e-06
I0526 17:46:12.559339 24213 solver.cpp:337] Iteration 1890, Testing net (#0)
I0526 17:46:15.544616 24213 solver.cpp:404]     Test net output #0: accuracy = 0.385455
I0526 17:46:15.544656 24213 solver.cpp:404]     Test net output #1: loss = 2.55936 (* 1 = 2.55936 loss)
I0526 17:46:16.661093 24213 solver.cpp:228] Iteration 1890, loss = 0.68606
I0526 17:46:16.661139 24213 solver.cpp:244]     Train net output #0: loss = 0.68606 (* 1 = 0.68606 loss)
I0526 17:46:16.661152 24213 sgd_solver.cpp:106] Iteration 1890, lr = 1e-06
I0526 17:46:29.025251 24213 solver.cpp:228] Iteration 1900, loss = 0.693614
I0526 17:46:29.025302 24213 solver.cpp:244]     Train net output #0: loss = 0.693614 (* 1 = 0.693614 loss)
I0526 17:46:29.025313 24213 sgd_solver.cpp:106] Iteration 1900, lr = 1e-06
I0526 17:46:41.376294 24213 solver.cpp:228] Iteration 1910, loss = 0.635052
I0526 17:46:41.376453 24213 solver.cpp:244]     Train net output #0: loss = 0.635052 (* 1 = 0.635052 loss)
I0526 17:46:41.376499 24213 sgd_solver.cpp:106] Iteration 1910, lr = 1e-06
I0526 17:46:52.266983 24213 solver.cpp:337] Iteration 1920, Testing net (#0)
I0526 17:46:55.187968 24213 solver.cpp:404]     Test net output #0: accuracy = 0.381818
I0526 17:46:55.188027 24213 solver.cpp:404]     Test net output #1: loss = 2.5386 (* 1 = 2.5386 loss)
I0526 17:46:56.296771 24213 solver.cpp:228] Iteration 1920, loss = 0.684911
I0526 17:46:56.296814 24213 solver.cpp:244]     Train net output #0: loss = 0.684911 (* 1 = 0.684911 loss)
I0526 17:46:56.296824 24213 sgd_solver.cpp:106] Iteration 1920, lr = 1e-06
I0526 17:47:08.663619 24213 solver.cpp:228] Iteration 1930, loss = 0.678632
I0526 17:47:08.663676 24213 solver.cpp:244]     Train net output #0: loss = 0.678632 (* 1 = 0.678632 loss)
I0526 17:47:08.663686 24213 sgd_solver.cpp:106] Iteration 1930, lr = 1e-06
I0526 17:47:21.039222 24213 solver.cpp:228] Iteration 1940, loss = 0.808659
I0526 17:47:21.039326 24213 solver.cpp:244]     Train net output #0: loss = 0.808659 (* 1 = 0.808659 loss)
I0526 17:47:21.039340 24213 sgd_solver.cpp:106] Iteration 1940, lr = 1e-06
I0526 17:47:31.951647 24213 solver.cpp:337] Iteration 1950, Testing net (#0)
I0526 17:47:34.606811 24213 solver.cpp:404]     Test net output #0: accuracy = 0.38
I0526 17:47:34.606860 24213 solver.cpp:404]     Test net output #1: loss = 2.56906 (* 1 = 2.56906 loss)
I0526 17:47:35.716502 24213 solver.cpp:228] Iteration 1950, loss = 0.733399
I0526 17:47:35.716547 24213 solver.cpp:244]     Train net output #0: loss = 0.733399 (* 1 = 0.733399 loss)
I0526 17:47:35.716557 24213 sgd_solver.cpp:106] Iteration 1950, lr = 1e-06
I0526 17:47:48.090529 24213 solver.cpp:228] Iteration 1960, loss = 0.645812
I0526 17:47:48.090595 24213 solver.cpp:244]     Train net output #0: loss = 0.645812 (* 1 = 0.645812 loss)
I0526 17:47:48.090611 24213 sgd_solver.cpp:106] Iteration 1960, lr = 1e-06
I0526 17:48:00.465963 24213 solver.cpp:228] Iteration 1970, loss = 0.60517
I0526 17:48:00.466089 24213 solver.cpp:244]     Train net output #0: loss = 0.60517 (* 1 = 0.60517 loss)
I0526 17:48:00.466138 24213 sgd_solver.cpp:106] Iteration 1970, lr = 1e-06
I0526 17:48:11.233850 24213 solver.cpp:337] Iteration 1980, Testing net (#0)
I0526 17:48:13.930927 24213 solver.cpp:404]     Test net output #0: accuracy = 0.381818
I0526 17:48:13.930974 24213 solver.cpp:404]     Test net output #1: loss = 2.55797 (* 1 = 2.55797 loss)
I0526 17:48:15.045555 24213 solver.cpp:228] Iteration 1980, loss = 0.697297
I0526 17:48:15.045603 24213 solver.cpp:244]     Train net output #0: loss = 0.697297 (* 1 = 0.697297 loss)
I0526 17:48:15.045619 24213 sgd_solver.cpp:106] Iteration 1980, lr = 1e-06
I0526 17:48:27.418462 24213 solver.cpp:228] Iteration 1990, loss = 0.723817
I0526 17:48:27.418521 24213 solver.cpp:244]     Train net output #0: loss = 0.723817 (* 1 = 0.723817 loss)
I0526 17:48:27.418572 24213 sgd_solver.cpp:106] Iteration 1990, lr = 1e-06
I0526 17:48:38.562341 24213 solver.cpp:454] Snapshotting to binary proto file snapshot2/caffe_CAM_finetuneMIT_iter_2000.caffemodel
I0526 17:48:38.735939 24213 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot2/caffe_CAM_finetuneMIT_iter_2000.solverstate
I0526 17:48:39.873945 24213 solver.cpp:228] Iteration 2000, loss = 0.727189
I0526 17:48:39.873988 24213 solver.cpp:244]     Train net output #0: loss = 0.727189 (* 1 = 0.727189 loss)
I0526 17:48:39.873999 24213 sgd_solver.cpp:106] Iteration 2000, lr = 1e-07
I0526 17:48:50.490840 24213 solver.cpp:337] Iteration 2010, Testing net (#0)
I0526 17:48:53.226577 24213 solver.cpp:404]     Test net output #0: accuracy = 0.381818
I0526 17:48:53.226708 24213 solver.cpp:404]     Test net output #1: loss = 2.57174 (* 1 = 2.57174 loss)
I0526 17:48:54.338706 24213 solver.cpp:228] Iteration 2010, loss = 0.696207
I0526 17:48:54.338752 24213 solver.cpp:244]     Train net output #0: loss = 0.696207 (* 1 = 0.696207 loss)
I0526 17:48:54.338767 24213 sgd_solver.cpp:106] Iteration 2010, lr = 1e-07
I0526 17:49:06.699724 24213 solver.cpp:228] Iteration 2020, loss = 0.582961
I0526 17:49:06.699780 24213 solver.cpp:244]     Train net output #0: loss = 0.582961 (* 1 = 0.582961 loss)
I0526 17:49:06.699796 24213 sgd_solver.cpp:106] Iteration 2020, lr = 1e-07
I0526 17:49:19.063212 24213 solver.cpp:228] Iteration 2030, loss = 0.602952
I0526 17:49:19.063366 24213 solver.cpp:244]     Train net output #0: loss = 0.602952 (* 1 = 0.602952 loss)
I0526 17:49:19.063383 24213 sgd_solver.cpp:106] Iteration 2030, lr = 1e-07
I0526 17:49:29.923039 24213 solver.cpp:337] Iteration 2040, Testing net (#0)
I0526 17:49:32.939172 24213 solver.cpp:404]     Test net output #0: accuracy = 0.381818
I0526 17:49:32.939229 24213 solver.cpp:404]     Test net output #1: loss = 2.57472 (* 1 = 2.57472 loss)
I0526 17:49:34.055073 24213 solver.cpp:228] Iteration 2040, loss = 0.612458
I0526 17:49:34.055150 24213 solver.cpp:244]     Train net output #0: loss = 0.612458 (* 1 = 0.612458 loss)
I0526 17:49:34.055161 24213 sgd_solver.cpp:106] Iteration 2040, lr = 1e-07
I0526 17:49:40.255429 24213 solver.cpp:228] Iteration 2050, loss = 0.765701
I0526 17:49:40.255478 24213 solver.cpp:244]     Train net output #0: loss = 0.765701 (* 1 = 0.765701 loss)
I0526 17:49:40.255489 24213 sgd_solver.cpp:106] Iteration 2050, lr = 1e-07
I0526 17:49:46.187250 24213 solver.cpp:228] Iteration 2060, loss = 0.692615
I0526 17:49:46.187295 24213 solver.cpp:244]     Train net output #0: loss = 0.692615 (* 1 = 0.692615 loss)
I0526 17:49:46.187306 24213 sgd_solver.cpp:106] Iteration 2060, lr = 1e-07
I0526 17:49:51.541019 24213 solver.cpp:337] Iteration 2070, Testing net (#0)
I0526 17:49:53.514346 24213 solver.cpp:404]     Test net output #0: accuracy = 0.383636
I0526 17:49:53.514394 24213 solver.cpp:404]     Test net output #1: loss = 2.55282 (* 1 = 2.55282 loss)
I0526 17:49:54.049559 24213 solver.cpp:228] Iteration 2070, loss = 0.706584
I0526 17:49:54.049609 24213 solver.cpp:244]     Train net output #0: loss = 0.706584 (* 1 = 0.706584 loss)
I0526 17:49:54.049620 24213 sgd_solver.cpp:106] Iteration 2070, lr = 1e-07
I0526 17:49:59.991263 24213 solver.cpp:228] Iteration 2080, loss = 0.671866
I0526 17:49:59.991314 24213 solver.cpp:244]     Train net output #0: loss = 0.671866 (* 1 = 0.671866 loss)
I0526 17:49:59.991324 24213 sgd_solver.cpp:106] Iteration 2080, lr = 1e-07
I0526 17:50:05.930071 24213 solver.cpp:228] Iteration 2090, loss = 0.579572
I0526 17:50:05.930124 24213 solver.cpp:244]     Train net output #0: loss = 0.579572 (* 1 = 0.579572 loss)
I0526 17:50:05.930132 24213 sgd_solver.cpp:106] Iteration 2090, lr = 1e-07
I0526 17:50:11.277518 24213 solver.cpp:337] Iteration 2100, Testing net (#0)
I0526 17:50:13.142565 24213 solver.cpp:404]     Test net output #0: accuracy = 0.387273
I0526 17:50:13.142602 24213 solver.cpp:404]     Test net output #1: loss = 2.53199 (* 1 = 2.53199 loss)
I0526 17:50:13.680286 24213 solver.cpp:228] Iteration 2100, loss = 0.675443
I0526 17:50:13.680340 24213 solver.cpp:244]     Train net output #0: loss = 0.675443 (* 1 = 0.675443 loss)
I0526 17:50:13.680351 24213 sgd_solver.cpp:106] Iteration 2100, lr = 1e-07
I0526 17:50:19.619158 24213 solver.cpp:228] Iteration 2110, loss = 0.669756
I0526 17:50:19.619207 24213 solver.cpp:244]     Train net output #0: loss = 0.669756 (* 1 = 0.669756 loss)
I0526 17:50:19.619218 24213 sgd_solver.cpp:106] Iteration 2110, lr = 1e-07
I0526 17:50:25.562693 24213 solver.cpp:228] Iteration 2120, loss = 0.670701
I0526 17:50:25.562808 24213 solver.cpp:244]     Train net output #0: loss = 0.670701 (* 1 = 0.670701 loss)
I0526 17:50:25.562826 24213 sgd_solver.cpp:106] Iteration 2120, lr = 1e-07
I0526 17:50:30.910054 24213 solver.cpp:337] Iteration 2130, Testing net (#0)
I0526 17:50:32.988215 24213 solver.cpp:404]     Test net output #0: accuracy = 0.381818
I0526 17:50:32.988255 24213 solver.cpp:404]     Test net output #1: loss = 2.56711 (* 1 = 2.56711 loss)
I0526 17:50:33.520439 24213 solver.cpp:228] Iteration 2130, loss = 0.736739
I0526 17:50:33.520563 24213 solver.cpp:244]     Train net output #0: loss = 0.736739 (* 1 = 0.736739 loss)
I0526 17:50:33.520602 24213 sgd_solver.cpp:106] Iteration 2130, lr = 1e-07
I0526 17:50:39.457201 24213 solver.cpp:228] Iteration 2140, loss = 0.604678
I0526 17:50:39.457267 24213 solver.cpp:244]     Train net output #0: loss = 0.604678 (* 1 = 0.604678 loss)
I0526 17:50:39.457278 24213 sgd_solver.cpp:106] Iteration 2140, lr = 1e-07
I0526 17:50:45.401651 24213 solver.cpp:228] Iteration 2150, loss = 0.693714
I0526 17:50:45.401695 24213 solver.cpp:244]     Train net output #0: loss = 0.693714 (* 1 = 0.693714 loss)
I0526 17:50:45.401705 24213 sgd_solver.cpp:106] Iteration 2150, lr = 1e-07
I0526 17:50:50.747686 24213 solver.cpp:337] Iteration 2160, Testing net (#0)
I0526 17:50:52.997457 24213 solver.cpp:404]     Test net output #0: accuracy = 0.381818
I0526 17:50:52.997514 24213 solver.cpp:404]     Test net output #1: loss = 2.56179 (* 1 = 2.56179 loss)
I0526 17:50:53.529187 24213 solver.cpp:228] Iteration 2160, loss = 0.63937
I0526 17:50:53.529265 24213 solver.cpp:244]     Train net output #0: loss = 0.63937 (* 1 = 0.63937 loss)
I0526 17:50:53.529281 24213 sgd_solver.cpp:106] Iteration 2160, lr = 1e-07
I0526 17:50:59.466557 24213 solver.cpp:228] Iteration 2170, loss = 0.618677
I0526 17:50:59.466672 24213 solver.cpp:244]     Train net output #0: loss = 0.618677 (* 1 = 0.618677 loss)
I0526 17:50:59.466686 24213 sgd_solver.cpp:106] Iteration 2170, lr = 1e-07
I0526 17:51:05.413233 24213 solver.cpp:228] Iteration 2180, loss = 0.706682
I0526 17:51:05.413288 24213 solver.cpp:244]     Train net output #0: loss = 0.706682 (* 1 = 0.706682 loss)
I0526 17:51:05.413300 24213 sgd_solver.cpp:106] Iteration 2180, lr = 1e-07
I0526 17:51:10.765606 24213 solver.cpp:337] Iteration 2190, Testing net (#0)
I0526 17:51:12.753128 24213 solver.cpp:404]     Test net output #0: accuracy = 0.387273
I0526 17:51:12.753171 24213 solver.cpp:404]     Test net output #1: loss = 2.54247 (* 1 = 2.54247 loss)
I0526 17:51:13.284483 24213 solver.cpp:228] Iteration 2190, loss = 0.7664
I0526 17:51:13.284521 24213 solver.cpp:244]     Train net output #0: loss = 0.7664 (* 1 = 0.7664 loss)
I0526 17:51:13.284533 24213 sgd_solver.cpp:106] Iteration 2190, lr = 1e-07
I0526 17:51:19.225181 24213 solver.cpp:228] Iteration 2200, loss = 0.685411
I0526 17:51:19.225229 24213 solver.cpp:244]     Train net output #0: loss = 0.685411 (* 1 = 0.685411 loss)
I0526 17:51:19.225244 24213 sgd_solver.cpp:106] Iteration 2200, lr = 1e-07
I0526 17:51:25.176054 24213 solver.cpp:228] Iteration 2210, loss = 0.55244
I0526 17:51:25.176105 24213 solver.cpp:244]     Train net output #0: loss = 0.55244 (* 1 = 0.55244 loss)
I0526 17:51:25.176131 24213 sgd_solver.cpp:106] Iteration 2210, lr = 1e-07
I0526 17:51:30.520419 24213 solver.cpp:337] Iteration 2220, Testing net (#0)
I0526 17:51:32.372800 24213 solver.cpp:404]     Test net output #0: accuracy = 0.38
I0526 17:51:32.372848 24213 solver.cpp:404]     Test net output #1: loss = 2.55673 (* 1 = 2.55673 loss)
I0526 17:51:32.908427 24213 solver.cpp:228] Iteration 2220, loss = 0.713922
I0526 17:51:32.908489 24213 solver.cpp:244]     Train net output #0: loss = 0.713922 (* 1 = 0.713922 loss)
I0526 17:51:32.908505 24213 sgd_solver.cpp:106] Iteration 2220, lr = 1e-07
I0526 17:51:38.850159 24213 solver.cpp:228] Iteration 2230, loss = 0.701983
I0526 17:51:38.850203 24213 solver.cpp:244]     Train net output #0: loss = 0.701983 (* 1 = 0.701983 loss)
I0526 17:51:38.850214 24213 sgd_solver.cpp:106] Iteration 2230, lr = 1e-07
I0526 17:51:44.787051 24213 solver.cpp:228] Iteration 2240, loss = 0.6407
I0526 17:51:44.787091 24213 solver.cpp:244]     Train net output #0: loss = 0.6407 (* 1 = 0.6407 loss)
I0526 17:51:44.787101 24213 sgd_solver.cpp:106] Iteration 2240, lr = 1e-07
I0526 17:51:50.135360 24213 solver.cpp:337] Iteration 2250, Testing net (#0)
I0526 17:51:52.012071 24213 solver.cpp:404]     Test net output #0: accuracy = 0.38
I0526 17:51:52.012110 24213 solver.cpp:404]     Test net output #1: loss = 2.55983 (* 1 = 2.55983 loss)
I0526 17:51:52.545095 24213 solver.cpp:228] Iteration 2250, loss = 0.674451
I0526 17:51:52.545146 24213 solver.cpp:244]     Train net output #0: loss = 0.674451 (* 1 = 0.674451 loss)
I0526 17:51:52.545157 24213 sgd_solver.cpp:106] Iteration 2250, lr = 1e-07
I0526 17:51:58.485618 24213 solver.cpp:228] Iteration 2260, loss = 0.726464
I0526 17:51:58.485666 24213 solver.cpp:244]     Train net output #0: loss = 0.726464 (* 1 = 0.726464 loss)
I0526 17:51:58.485677 24213 sgd_solver.cpp:106] Iteration 2260, lr = 1e-07
I0526 17:52:04.430299 24213 solver.cpp:228] Iteration 2270, loss = 0.618365
I0526 17:52:04.430413 24213 solver.cpp:244]     Train net output #0: loss = 0.618365 (* 1 = 0.618365 loss)
I0526 17:52:04.430424 24213 sgd_solver.cpp:106] Iteration 2270, lr = 1e-07
I0526 17:52:09.775805 24213 solver.cpp:337] Iteration 2280, Testing net (#0)
I0526 17:52:11.671068 24213 solver.cpp:404]     Test net output #0: accuracy = 0.385455
I0526 17:52:11.671124 24213 solver.cpp:404]     Test net output #1: loss = 2.55986 (* 1 = 2.55986 loss)
I0526 17:52:12.209213 24213 solver.cpp:228] Iteration 2280, loss = 0.559277
I0526 17:52:12.209269 24213 solver.cpp:244]     Train net output #0: loss = 0.559277 (* 1 = 0.559277 loss)
I0526 17:52:12.209285 24213 sgd_solver.cpp:106] Iteration 2280, lr = 1e-07
I0526 17:52:18.144223 24213 solver.cpp:228] Iteration 2290, loss = 0.611223
I0526 17:52:18.144263 24213 solver.cpp:244]     Train net output #0: loss = 0.611223 (* 1 = 0.611223 loss)
I0526 17:52:18.144273 24213 sgd_solver.cpp:106] Iteration 2290, lr = 1e-07
I0526 17:52:24.086457 24213 solver.cpp:228] Iteration 2300, loss = 0.632588
I0526 17:52:24.086498 24213 solver.cpp:244]     Train net output #0: loss = 0.632588 (* 1 = 0.632588 loss)
I0526 17:52:24.086508 24213 sgd_solver.cpp:106] Iteration 2300, lr = 1e-07
I0526 17:52:29.428483 24213 solver.cpp:337] Iteration 2310, Testing net (#0)
I0526 17:52:31.361271 24213 solver.cpp:404]     Test net output #0: accuracy = 0.378182
I0526 17:52:31.361318 24213 solver.cpp:404]     Test net output #1: loss = 2.56875 (* 1 = 2.56875 loss)
I0526 17:52:31.892459 24213 solver.cpp:228] Iteration 2310, loss = 0.702944
I0526 17:52:31.892503 24213 solver.cpp:244]     Train net output #0: loss = 0.702944 (* 1 = 0.702944 loss)
I0526 17:52:31.892519 24213 sgd_solver.cpp:106] Iteration 2310, lr = 1e-07
I0526 17:52:37.836679 24213 solver.cpp:228] Iteration 2320, loss = 0.666345
I0526 17:52:37.836805 24213 solver.cpp:244]     Train net output #0: loss = 0.666345 (* 1 = 0.666345 loss)
I0526 17:52:37.836825 24213 sgd_solver.cpp:106] Iteration 2320, lr = 1e-07
I0526 17:52:43.782531 24213 solver.cpp:228] Iteration 2330, loss = 0.646836
I0526 17:52:43.782580 24213 solver.cpp:244]     Train net output #0: loss = 0.646836 (* 1 = 0.646836 loss)
I0526 17:52:43.782591 24213 sgd_solver.cpp:106] Iteration 2330, lr = 1e-07
I0526 17:52:49.132261 24213 solver.cpp:337] Iteration 2340, Testing net (#0)
I0526 17:52:51.110121 24213 solver.cpp:404]     Test net output #0: accuracy = 0.374545
I0526 17:52:51.110158 24213 solver.cpp:404]     Test net output #1: loss = 2.58013 (* 1 = 2.58013 loss)
I0526 17:52:51.641535 24213 solver.cpp:228] Iteration 2340, loss = 0.612242
I0526 17:52:51.641602 24213 solver.cpp:244]     Train net output #0: loss = 0.612242 (* 1 = 0.612242 loss)
I0526 17:52:51.641618 24213 sgd_solver.cpp:106] Iteration 2340, lr = 1e-07
I0526 17:52:57.586053 24213 solver.cpp:228] Iteration 2350, loss = 0.617155
I0526 17:52:57.586107 24213 solver.cpp:244]     Train net output #0: loss = 0.617155 (* 1 = 0.617155 loss)
I0526 17:52:57.586118 24213 sgd_solver.cpp:106] Iteration 2350, lr = 1e-07
I0526 17:53:03.523221 24213 solver.cpp:228] Iteration 2360, loss = 0.720386
I0526 17:53:03.523269 24213 solver.cpp:244]     Train net output #0: loss = 0.720386 (* 1 = 0.720386 loss)
I0526 17:53:03.523280 24213 sgd_solver.cpp:106] Iteration 2360, lr = 1e-07
I0526 17:53:08.870923 24213 solver.cpp:337] Iteration 2370, Testing net (#0)
I0526 17:53:10.902921 24213 solver.cpp:404]     Test net output #0: accuracy = 0.383636
I0526 17:53:10.902963 24213 solver.cpp:404]     Test net output #1: loss = 2.55108 (* 1 = 2.55108 loss)
I0526 17:53:11.440743 24213 solver.cpp:228] Iteration 2370, loss = 0.609593
I0526 17:53:11.440790 24213 solver.cpp:244]     Train net output #0: loss = 0.609593 (* 1 = 0.609593 loss)
I0526 17:53:11.440801 24213 sgd_solver.cpp:106] Iteration 2370, lr = 1e-07
I0526 17:53:17.376137 24213 solver.cpp:228] Iteration 2380, loss = 0.616442
I0526 17:53:17.376180 24213 solver.cpp:244]     Train net output #0: loss = 0.616442 (* 1 = 0.616442 loss)
I0526 17:53:17.376191 24213 sgd_solver.cpp:106] Iteration 2380, lr = 1e-07
I0526 17:53:23.323410 24213 solver.cpp:228] Iteration 2390, loss = 0.645981
I0526 17:53:23.323454 24213 solver.cpp:244]     Train net output #0: loss = 0.645981 (* 1 = 0.645981 loss)
I0526 17:53:23.323464 24213 sgd_solver.cpp:106] Iteration 2390, lr = 1e-07
I0526 17:53:28.671201 24213 solver.cpp:337] Iteration 2400, Testing net (#0)
I0526 17:53:30.664988 24213 solver.cpp:404]     Test net output #0: accuracy = 0.383636
I0526 17:53:30.665040 24213 solver.cpp:404]     Test net output #1: loss = 2.54694 (* 1 = 2.54694 loss)
I0526 17:53:31.196105 24213 solver.cpp:228] Iteration 2400, loss = 0.635233
I0526 17:53:31.196169 24213 solver.cpp:244]     Train net output #0: loss = 0.635233 (* 1 = 0.635233 loss)
I0526 17:53:31.196185 24213 sgd_solver.cpp:106] Iteration 2400, lr = 1e-07
I0526 17:53:37.136109 24213 solver.cpp:228] Iteration 2410, loss = 0.565093
I0526 17:53:37.136164 24213 solver.cpp:244]     Train net output #0: loss = 0.565093 (* 1 = 0.565093 loss)
I0526 17:53:37.136174 24213 sgd_solver.cpp:106] Iteration 2410, lr = 1e-07
I0526 17:53:43.080293 24213 solver.cpp:228] Iteration 2420, loss = 0.655434
I0526 17:53:43.080394 24213 solver.cpp:244]     Train net output #0: loss = 0.655434 (* 1 = 0.655434 loss)
I0526 17:53:43.080412 24213 sgd_solver.cpp:106] Iteration 2420, lr = 1e-07
I0526 17:53:48.433806 24213 solver.cpp:337] Iteration 2430, Testing net (#0)
I0526 17:53:50.495959 24213 solver.cpp:404]     Test net output #0: accuracy = 0.381818
I0526 17:53:50.496012 24213 solver.cpp:404]     Test net output #1: loss = 2.56705 (* 1 = 2.56705 loss)
I0526 17:53:51.032346 24213 solver.cpp:228] Iteration 2430, loss = 0.703873
I0526 17:53:51.032402 24213 solver.cpp:244]     Train net output #0: loss = 0.703873 (* 1 = 0.703873 loss)
I0526 17:53:51.032413 24213 sgd_solver.cpp:106] Iteration 2430, lr = 1e-07
I0526 17:53:56.978456 24213 solver.cpp:228] Iteration 2440, loss = 0.715266
I0526 17:53:56.978510 24213 solver.cpp:244]     Train net output #0: loss = 0.715266 (* 1 = 0.715266 loss)
I0526 17:53:56.978521 24213 sgd_solver.cpp:106] Iteration 2440, lr = 1e-07
I0526 17:54:02.914978 24213 solver.cpp:228] Iteration 2450, loss = 0.686675
I0526 17:54:02.915022 24213 solver.cpp:244]     Train net output #0: loss = 0.686675 (* 1 = 0.686675 loss)
I0526 17:54:02.915033 24213 sgd_solver.cpp:106] Iteration 2450, lr = 1e-07
I0526 17:54:08.260656 24213 solver.cpp:337] Iteration 2460, Testing net (#0)
I0526 17:54:10.339666 24213 solver.cpp:404]     Test net output #0: accuracy = 0.381818
I0526 17:54:10.339711 24213 solver.cpp:404]     Test net output #1: loss = 2.56584 (* 1 = 2.56584 loss)
I0526 17:54:10.872620 24213 solver.cpp:228] Iteration 2460, loss = 0.611677
I0526 17:54:10.872731 24213 solver.cpp:244]     Train net output #0: loss = 0.611677 (* 1 = 0.611677 loss)
I0526 17:54:10.872779 24213 sgd_solver.cpp:106] Iteration 2460, lr = 1e-07
I0526 17:54:16.815266 24213 solver.cpp:228] Iteration 2470, loss = 0.731464
I0526 17:54:16.815397 24213 solver.cpp:244]     Train net output #0: loss = 0.731464 (* 1 = 0.731464 loss)
I0526 17:54:16.815410 24213 sgd_solver.cpp:106] Iteration 2470, lr = 1e-07
I0526 17:54:22.757197 24213 solver.cpp:228] Iteration 2480, loss = 0.679461
I0526 17:54:22.757261 24213 solver.cpp:244]     Train net output #0: loss = 0.679461 (* 1 = 0.679461 loss)
I0526 17:54:22.757273 24213 sgd_solver.cpp:106] Iteration 2480, lr = 1e-07
I0526 17:54:28.103507 24213 solver.cpp:337] Iteration 2490, Testing net (#0)
I0526 17:54:30.311676 24213 solver.cpp:404]     Test net output #0: accuracy = 0.383636
I0526 17:54:30.311723 24213 solver.cpp:404]     Test net output #1: loss = 2.54458 (* 1 = 2.54458 loss)
I0526 17:54:30.842334 24213 solver.cpp:228] Iteration 2490, loss = 0.701159
I0526 17:54:30.842392 24213 solver.cpp:244]     Train net output #0: loss = 0.701159 (* 1 = 0.701159 loss)
I0526 17:54:30.842407 24213 sgd_solver.cpp:106] Iteration 2490, lr = 1e-07
I0526 17:54:36.781213 24213 solver.cpp:228] Iteration 2500, loss = 0.671664
I0526 17:54:36.781275 24213 solver.cpp:244]     Train net output #0: loss = 0.671664 (* 1 = 0.671664 loss)
I0526 17:54:36.781291 24213 sgd_solver.cpp:106] Iteration 2500, lr = 1e-07
I0526 17:54:42.726502 24213 solver.cpp:228] Iteration 2510, loss = 0.727179
I0526 17:54:42.726547 24213 solver.cpp:244]     Train net output #0: loss = 0.727179 (* 1 = 0.727179 loss)
I0526 17:54:42.726557 24213 sgd_solver.cpp:106] Iteration 2510, lr = 1e-07
I0526 17:54:48.072453 24213 solver.cpp:337] Iteration 2520, Testing net (#0)
I0526 17:54:50.137313 24213 solver.cpp:404]     Test net output #0: accuracy = 0.383636
I0526 17:54:50.137351 24213 solver.cpp:404]     Test net output #1: loss = 2.54576 (* 1 = 2.54576 loss)
I0526 17:54:50.669214 24213 solver.cpp:228] Iteration 2520, loss = 0.639216
I0526 17:54:50.669265 24213 solver.cpp:244]     Train net output #0: loss = 0.639216 (* 1 = 0.639216 loss)
I0526 17:54:50.669275 24213 sgd_solver.cpp:106] Iteration 2520, lr = 1e-07
I0526 17:54:56.615038 24213 solver.cpp:228] Iteration 2530, loss = 0.599954
I0526 17:54:56.615097 24213 solver.cpp:244]     Train net output #0: loss = 0.599954 (* 1 = 0.599954 loss)
I0526 17:54:56.615124 24213 sgd_solver.cpp:106] Iteration 2530, lr = 1e-07
I0526 17:55:02.559828 24213 solver.cpp:228] Iteration 2540, loss = 0.666249
I0526 17:55:02.559878 24213 solver.cpp:244]     Train net output #0: loss = 0.666249 (* 1 = 0.666249 loss)
I0526 17:55:02.559893 24213 sgd_solver.cpp:106] Iteration 2540, lr = 1e-07
I0526 17:55:07.904844 24213 solver.cpp:337] Iteration 2550, Testing net (#0)
I0526 17:55:09.963954 24213 solver.cpp:404]     Test net output #0: accuracy = 0.38
I0526 17:55:09.964007 24213 solver.cpp:404]     Test net output #1: loss = 2.57421 (* 1 = 2.57421 loss)
I0526 17:55:10.495348 24213 solver.cpp:228] Iteration 2550, loss = 0.683162
I0526 17:55:10.495405 24213 solver.cpp:244]     Train net output #0: loss = 0.683162 (* 1 = 0.683162 loss)
I0526 17:55:10.495419 24213 sgd_solver.cpp:106] Iteration 2550, lr = 1e-07
I0526 17:55:16.442920 24213 solver.cpp:228] Iteration 2560, loss = 0.67608
I0526 17:55:16.442966 24213 solver.cpp:244]     Train net output #0: loss = 0.67608 (* 1 = 0.67608 loss)
I0526 17:55:16.442977 24213 sgd_solver.cpp:106] Iteration 2560, lr = 1e-07
I0526 17:55:22.380890 24213 solver.cpp:228] Iteration 2570, loss = 0.68214
I0526 17:55:22.381008 24213 solver.cpp:244]     Train net output #0: loss = 0.68214 (* 1 = 0.68214 loss)
I0526 17:55:22.381021 24213 sgd_solver.cpp:106] Iteration 2570, lr = 1e-07
I0526 17:55:27.731021 24213 solver.cpp:337] Iteration 2580, Testing net (#0)
I0526 17:55:29.899091 24213 solver.cpp:404]     Test net output #0: accuracy = 0.38
I0526 17:55:29.899134 24213 solver.cpp:404]     Test net output #1: loss = 2.56857 (* 1 = 2.56857 loss)
I0526 17:55:30.430277 24213 solver.cpp:228] Iteration 2580, loss = 0.628345
I0526 17:55:30.430341 24213 solver.cpp:244]     Train net output #0: loss = 0.628345 (* 1 = 0.628345 loss)
I0526 17:55:30.430356 24213 sgd_solver.cpp:106] Iteration 2580, lr = 1e-07
I0526 17:55:36.375661 24213 solver.cpp:228] Iteration 2590, loss = 0.658268
I0526 17:55:36.375715 24213 solver.cpp:244]     Train net output #0: loss = 0.658268 (* 1 = 0.658268 loss)
I0526 17:55:36.375725 24213 sgd_solver.cpp:106] Iteration 2590, lr = 1e-07
I0526 17:55:42.320390 24213 solver.cpp:228] Iteration 2600, loss = 0.626653
I0526 17:55:42.320435 24213 solver.cpp:244]     Train net output #0: loss = 0.626653 (* 1 = 0.626653 loss)
I0526 17:55:42.320444 24213 sgd_solver.cpp:106] Iteration 2600, lr = 1e-07
I0526 17:55:47.674599 24213 solver.cpp:337] Iteration 2610, Testing net (#0)
I0526 17:55:50.009505 24213 solver.cpp:404]     Test net output #0: accuracy = 0.383636
I0526 17:55:50.009562 24213 solver.cpp:404]     Test net output #1: loss = 2.57574 (* 1 = 2.57574 loss)
I0526 17:55:50.542114 24213 solver.cpp:228] Iteration 2610, loss = 0.689609
I0526 17:55:50.542171 24213 solver.cpp:244]     Train net output #0: loss = 0.689609 (* 1 = 0.689609 loss)
I0526 17:55:50.542183 24213 sgd_solver.cpp:106] Iteration 2610, lr = 1e-07
I0526 17:55:56.481324 24213 solver.cpp:228] Iteration 2620, loss = 0.636914
I0526 17:55:56.481452 24213 solver.cpp:244]     Train net output #0: loss = 0.636914 (* 1 = 0.636914 loss)
I0526 17:55:56.481469 24213 sgd_solver.cpp:106] Iteration 2620, lr = 1e-07
I0526 17:56:02.417443 24213 solver.cpp:228] Iteration 2630, loss = 0.642005
I0526 17:56:02.417500 24213 solver.cpp:244]     Train net output #0: loss = 0.642005 (* 1 = 0.642005 loss)
I0526 17:56:02.417513 24213 sgd_solver.cpp:106] Iteration 2630, lr = 1e-07
I0526 17:56:07.951608 24213 solver.cpp:337] Iteration 2640, Testing net (#0)
I0526 17:56:10.033584 24213 solver.cpp:404]     Test net output #0: accuracy = 0.383636
I0526 17:56:10.033629 24213 solver.cpp:404]     Test net output #1: loss = 2.54673 (* 1 = 2.54673 loss)
I0526 17:56:10.565210 24213 solver.cpp:228] Iteration 2640, loss = 0.683088
I0526 17:56:10.565250 24213 solver.cpp:244]     Train net output #0: loss = 0.683088 (* 1 = 0.683088 loss)
I0526 17:56:10.565260 24213 sgd_solver.cpp:106] Iteration 2640, lr = 1e-07
I0526 17:56:16.511824 24213 solver.cpp:228] Iteration 2650, loss = 0.589507
I0526 17:56:16.511881 24213 solver.cpp:244]     Train net output #0: loss = 0.589507 (* 1 = 0.589507 loss)
I0526 17:56:16.511891 24213 sgd_solver.cpp:106] Iteration 2650, lr = 1e-07
I0526 17:56:22.457036 24213 solver.cpp:228] Iteration 2660, loss = 0.639074
I0526 17:56:22.457090 24213 solver.cpp:244]     Train net output #0: loss = 0.639074 (* 1 = 0.639074 loss)
I0526 17:56:22.457100 24213 sgd_solver.cpp:106] Iteration 2660, lr = 1e-07
I0526 17:56:27.809394 24213 solver.cpp:337] Iteration 2670, Testing net (#0)
I0526 17:56:29.964375 24213 solver.cpp:404]     Test net output #0: accuracy = 0.385455
I0526 17:56:29.964422 24213 solver.cpp:404]     Test net output #1: loss = 2.54838 (* 1 = 2.54838 loss)
I0526 17:56:30.501788 24213 solver.cpp:228] Iteration 2670, loss = 0.636716
I0526 17:56:30.501842 24213 solver.cpp:244]     Train net output #0: loss = 0.636716 (* 1 = 0.636716 loss)
I0526 17:56:30.501857 24213 sgd_solver.cpp:106] Iteration 2670, lr = 1e-07
I0526 17:56:36.445328 24213 solver.cpp:228] Iteration 2680, loss = 0.733926
I0526 17:56:36.445375 24213 solver.cpp:244]     Train net output #0: loss = 0.733926 (* 1 = 0.733926 loss)
I0526 17:56:36.445389 24213 sgd_solver.cpp:106] Iteration 2680, lr = 1e-07
I0526 17:56:42.392551 24213 solver.cpp:228] Iteration 2690, loss = 0.773898
I0526 17:56:42.392591 24213 solver.cpp:244]     Train net output #0: loss = 0.773898 (* 1 = 0.773898 loss)
I0526 17:56:42.392602 24213 sgd_solver.cpp:106] Iteration 2690, lr = 1e-07
I0526 17:56:47.745340 24213 solver.cpp:337] Iteration 2700, Testing net (#0)
I0526 17:56:49.720798 24213 solver.cpp:404]     Test net output #0: accuracy = 0.376364
I0526 17:56:49.720840 24213 solver.cpp:404]     Test net output #1: loss = 2.57004 (* 1 = 2.57004 loss)
I0526 17:56:50.252882 24213 solver.cpp:228] Iteration 2700, loss = 0.745683
I0526 17:56:50.252921 24213 solver.cpp:244]     Train net output #0: loss = 0.745683 (* 1 = 0.745683 loss)
I0526 17:56:50.252933 24213 sgd_solver.cpp:106] Iteration 2700, lr = 1e-07
I0526 17:56:56.196050 24213 solver.cpp:228] Iteration 2710, loss = 0.702381
I0526 17:56:56.196111 24213 solver.cpp:244]     Train net output #0: loss = 0.702381 (* 1 = 0.702381 loss)
I0526 17:56:56.196122 24213 sgd_solver.cpp:106] Iteration 2710, lr = 1e-07
I0526 17:57:02.131747 24213 solver.cpp:228] Iteration 2720, loss = 0.649356
I0526 17:57:02.131863 24213 solver.cpp:244]     Train net output #0: loss = 0.649356 (* 1 = 0.649356 loss)
I0526 17:57:02.131876 24213 sgd_solver.cpp:106] Iteration 2720, lr = 1e-07
I0526 17:57:07.483211 24213 solver.cpp:337] Iteration 2730, Testing net (#0)
I0526 17:57:09.718070 24213 solver.cpp:404]     Test net output #0: accuracy = 0.383636
I0526 17:57:09.718127 24213 solver.cpp:404]     Test net output #1: loss = 2.53321 (* 1 = 2.53321 loss)
I0526 17:57:10.248839 24213 solver.cpp:228] Iteration 2730, loss = 0.625877
I0526 17:57:10.248891 24213 solver.cpp:244]     Train net output #0: loss = 0.625877 (* 1 = 0.625877 loss)
I0526 17:57:10.248908 24213 sgd_solver.cpp:106] Iteration 2730, lr = 1e-07
I0526 17:57:16.196295 24213 solver.cpp:228] Iteration 2740, loss = 0.710479
I0526 17:57:16.196333 24213 solver.cpp:244]     Train net output #0: loss = 0.710479 (* 1 = 0.710479 loss)
I0526 17:57:16.196343 24213 sgd_solver.cpp:106] Iteration 2740, lr = 1e-07
I0526 17:57:22.135838 24213 solver.cpp:228] Iteration 2750, loss = 0.711371
I0526 17:57:22.135886 24213 solver.cpp:244]     Train net output #0: loss = 0.711371 (* 1 = 0.711371 loss)
I0526 17:57:22.135903 24213 sgd_solver.cpp:106] Iteration 2750, lr = 1e-07
I0526 17:57:27.485724 24213 solver.cpp:337] Iteration 2760, Testing net (#0)
I0526 17:57:29.441396 24213 solver.cpp:404]     Test net output #0: accuracy = 0.392727
I0526 17:57:29.441444 24213 solver.cpp:404]     Test net output #1: loss = 2.52697 (* 1 = 2.52697 loss)
I0526 17:57:29.980255 24213 solver.cpp:228] Iteration 2760, loss = 0.600887
I0526 17:57:29.980305 24213 solver.cpp:244]     Train net output #0: loss = 0.600887 (* 1 = 0.600887 loss)
I0526 17:57:29.980316 24213 sgd_solver.cpp:106] Iteration 2760, lr = 1e-07
I0526 17:57:35.918184 24213 solver.cpp:228] Iteration 2770, loss = 0.59417
I0526 17:57:35.918339 24213 solver.cpp:244]     Train net output #0: loss = 0.59417 (* 1 = 0.59417 loss)
I0526 17:57:35.918350 24213 sgd_solver.cpp:106] Iteration 2770, lr = 1e-07
I0526 17:57:41.863951 24213 solver.cpp:228] Iteration 2780, loss = 0.617235
I0526 17:57:41.864011 24213 solver.cpp:244]     Train net output #0: loss = 0.617235 (* 1 = 0.617235 loss)
I0526 17:57:41.864022 24213 sgd_solver.cpp:106] Iteration 2780, lr = 1e-07
I0526 17:57:47.214850 24213 solver.cpp:337] Iteration 2790, Testing net (#0)
I0526 17:57:49.367677 24213 solver.cpp:404]     Test net output #0: accuracy = 0.385455
I0526 17:57:49.367723 24213 solver.cpp:404]     Test net output #1: loss = 2.54022 (* 1 = 2.54022 loss)
I0526 17:57:49.900077 24213 solver.cpp:228] Iteration 2790, loss = 0.683585
I0526 17:57:49.900203 24213 solver.cpp:244]     Train net output #0: loss = 0.683585 (* 1 = 0.683585 loss)
I0526 17:57:49.900246 24213 sgd_solver.cpp:106] Iteration 2790, lr = 1e-07
I0526 17:57:55.844280 24213 solver.cpp:228] Iteration 2800, loss = 0.719896
I0526 17:57:55.844318 24213 solver.cpp:244]     Train net output #0: loss = 0.719896 (* 1 = 0.719896 loss)
I0526 17:57:55.844329 24213 sgd_solver.cpp:106] Iteration 2800, lr = 1e-07
I0526 17:58:01.790366 24213 solver.cpp:228] Iteration 2810, loss = 0.682676
I0526 17:58:01.790410 24213 solver.cpp:244]     Train net output #0: loss = 0.682676 (* 1 = 0.682676 loss)
I0526 17:58:01.790419 24213 sgd_solver.cpp:106] Iteration 2810, lr = 1e-07
I0526 17:58:07.138645 24213 solver.cpp:337] Iteration 2820, Testing net (#0)
I0526 17:58:09.129001 24213 solver.cpp:404]     Test net output #0: accuracy = 0.385455
I0526 17:58:09.129053 24213 solver.cpp:404]     Test net output #1: loss = 2.56948 (* 1 = 2.56948 loss)
I0526 17:58:09.666369 24213 solver.cpp:228] Iteration 2820, loss = 0.647992
I0526 17:58:09.666407 24213 solver.cpp:244]     Train net output #0: loss = 0.647992 (* 1 = 0.647992 loss)
I0526 17:58:09.666419 24213 sgd_solver.cpp:106] Iteration 2820, lr = 1e-07
I0526 17:58:15.608835 24213 solver.cpp:228] Iteration 2830, loss = 0.670474
I0526 17:58:15.608878 24213 solver.cpp:244]     Train net output #0: loss = 0.670474 (* 1 = 0.670474 loss)
I0526 17:58:15.608889 24213 sgd_solver.cpp:106] Iteration 2830, lr = 1e-07
I0526 17:58:21.547008 24213 solver.cpp:228] Iteration 2840, loss = 0.597922
I0526 17:58:21.547063 24213 solver.cpp:244]     Train net output #0: loss = 0.597922 (* 1 = 0.597922 loss)
I0526 17:58:21.547075 24213 sgd_solver.cpp:106] Iteration 2840, lr = 1e-07
I0526 17:58:26.895172 24213 solver.cpp:337] Iteration 2850, Testing net (#0)
I0526 17:58:28.842823 24213 solver.cpp:404]     Test net output #0: accuracy = 0.383636
I0526 17:58:28.842871 24213 solver.cpp:404]     Test net output #1: loss = 2.54128 (* 1 = 2.54128 loss)
I0526 17:58:29.375092 24213 solver.cpp:228] Iteration 2850, loss = 0.755341
I0526 17:58:29.375128 24213 solver.cpp:244]     Train net output #0: loss = 0.755341 (* 1 = 0.755341 loss)
I0526 17:58:29.375138 24213 sgd_solver.cpp:106] Iteration 2850, lr = 1e-07
I0526 17:58:35.315922 24213 solver.cpp:228] Iteration 2860, loss = 0.713385
I0526 17:58:35.315963 24213 solver.cpp:244]     Train net output #0: loss = 0.713385 (* 1 = 0.713385 loss)
I0526 17:58:35.315979 24213 sgd_solver.cpp:106] Iteration 2860, lr = 1e-07
I0526 17:58:41.259434 24213 solver.cpp:228] Iteration 2870, loss = 0.669602
I0526 17:58:41.259572 24213 solver.cpp:244]     Train net output #0: loss = 0.669602 (* 1 = 0.669602 loss)
I0526 17:58:41.259593 24213 sgd_solver.cpp:106] Iteration 2870, lr = 1e-07
I0526 17:58:46.608170 24213 solver.cpp:337] Iteration 2880, Testing net (#0)
I0526 17:58:49.017678 24213 solver.cpp:404]     Test net output #0: accuracy = 0.381818
I0526 17:58:49.017722 24213 solver.cpp:404]     Test net output #1: loss = 2.56406 (* 1 = 2.56406 loss)
I0526 17:58:49.549163 24213 solver.cpp:228] Iteration 2880, loss = 0.783555
I0526 17:58:49.549211 24213 solver.cpp:244]     Train net output #0: loss = 0.783555 (* 1 = 0.783555 loss)
I0526 17:58:49.549226 24213 sgd_solver.cpp:106] Iteration 2880, lr = 1e-07
I0526 17:58:55.487666 24213 solver.cpp:228] Iteration 2890, loss = 0.693812
I0526 17:58:55.487710 24213 solver.cpp:244]     Train net output #0: loss = 0.693812 (* 1 = 0.693812 loss)
I0526 17:58:55.487725 24213 sgd_solver.cpp:106] Iteration 2890, lr = 1e-07
I0526 17:59:01.424010 24213 solver.cpp:228] Iteration 2900, loss = 0.650514
I0526 17:59:01.424052 24213 solver.cpp:244]     Train net output #0: loss = 0.650514 (* 1 = 0.650514 loss)
I0526 17:59:01.424062 24213 sgd_solver.cpp:106] Iteration 2900, lr = 1e-07
I0526 17:59:06.779387 24213 solver.cpp:337] Iteration 2910, Testing net (#0)
I0526 17:59:08.804703 24213 solver.cpp:404]     Test net output #0: accuracy = 0.38
I0526 17:59:08.804741 24213 solver.cpp:404]     Test net output #1: loss = 2.5616 (* 1 = 2.5616 loss)
I0526 17:59:09.337801 24213 solver.cpp:228] Iteration 2910, loss = 0.638643
I0526 17:59:09.337851 24213 solver.cpp:244]     Train net output #0: loss = 0.638643 (* 1 = 0.638643 loss)
I0526 17:59:09.337865 24213 sgd_solver.cpp:106] Iteration 2910, lr = 1e-07
I0526 17:59:15.276396 24213 solver.cpp:228] Iteration 2920, loss = 0.684507
I0526 17:59:15.276554 24213 solver.cpp:244]     Train net output #0: loss = 0.684507 (* 1 = 0.684507 loss)
I0526 17:59:15.276567 24213 sgd_solver.cpp:106] Iteration 2920, lr = 1e-07
I0526 17:59:21.213121 24213 solver.cpp:228] Iteration 2930, loss = 0.704651
I0526 17:59:21.213172 24213 solver.cpp:244]     Train net output #0: loss = 0.704651 (* 1 = 0.704651 loss)
I0526 17:59:21.213182 24213 sgd_solver.cpp:106] Iteration 2930, lr = 1e-07
I0526 17:59:26.556911 24213 solver.cpp:337] Iteration 2940, Testing net (#0)
I0526 17:59:28.590817 24213 solver.cpp:404]     Test net output #0: accuracy = 0.383636
I0526 17:59:28.590864 24213 solver.cpp:404]     Test net output #1: loss = 2.56976 (* 1 = 2.56976 loss)
I0526 17:59:29.123466 24213 solver.cpp:228] Iteration 2940, loss = 0.713791
I0526 17:59:29.123524 24213 solver.cpp:244]     Train net output #0: loss = 0.713791 (* 1 = 0.713791 loss)
I0526 17:59:29.123539 24213 sgd_solver.cpp:106] Iteration 2940, lr = 1e-07
I0526 17:59:35.070402 24213 solver.cpp:228] Iteration 2950, loss = 0.635967
I0526 17:59:35.070451 24213 solver.cpp:244]     Train net output #0: loss = 0.635967 (* 1 = 0.635967 loss)
I0526 17:59:35.070464 24213 sgd_solver.cpp:106] Iteration 2950, lr = 1e-07
I0526 17:59:41.005475 24213 solver.cpp:228] Iteration 2960, loss = 0.659673
I0526 17:59:41.005527 24213 solver.cpp:244]     Train net output #0: loss = 0.659673 (* 1 = 0.659673 loss)
I0526 17:59:41.005540 24213 sgd_solver.cpp:106] Iteration 2960, lr = 1e-07
I0526 17:59:46.357285 24213 solver.cpp:337] Iteration 2970, Testing net (#0)
I0526 17:59:48.606431 24213 solver.cpp:404]     Test net output #0: accuracy = 0.378182
I0526 17:59:48.606479 24213 solver.cpp:404]     Test net output #1: loss = 2.57811 (* 1 = 2.57811 loss)
I0526 17:59:49.138763 24213 solver.cpp:228] Iteration 2970, loss = 0.668491
I0526 17:59:49.138813 24213 solver.cpp:244]     Train net output #0: loss = 0.668491 (* 1 = 0.668491 loss)
I0526 17:59:49.138824 24213 sgd_solver.cpp:106] Iteration 2970, lr = 1e-07
I0526 17:59:55.079462 24213 solver.cpp:228] Iteration 2980, loss = 0.609468
I0526 17:59:55.079512 24213 solver.cpp:244]     Train net output #0: loss = 0.609468 (* 1 = 0.609468 loss)
I0526 17:59:55.079522 24213 sgd_solver.cpp:106] Iteration 2980, lr = 1e-07
I0526 18:00:01.022143 24213 solver.cpp:228] Iteration 2990, loss = 0.712736
I0526 18:00:01.022197 24213 solver.cpp:244]     Train net output #0: loss = 0.712736 (* 1 = 0.712736 loss)
I0526 18:00:01.022212 24213 sgd_solver.cpp:106] Iteration 2990, lr = 1e-07
I0526 18:00:06.366556 24213 solver.cpp:454] Snapshotting to binary proto file snapshot2/caffe_CAM_finetuneMIT_iter_3000.caffemodel
I0526 18:00:06.482411 24213 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot2/caffe_CAM_finetuneMIT_iter_3000.solverstate
I0526 18:00:06.506610 24213 solver.cpp:337] Iteration 3000, Testing net (#0)
I0526 18:00:08.434656 24213 solver.cpp:404]     Test net output #0: accuracy = 0.387273
I0526 18:00:08.434703 24213 solver.cpp:404]     Test net output #1: loss = 2.54827 (* 1 = 2.54827 loss)
I0526 18:00:08.968196 24213 solver.cpp:228] Iteration 3000, loss = 0.770497
I0526 18:00:08.968300 24213 solver.cpp:244]     Train net output #0: loss = 0.770497 (* 1 = 0.770497 loss)
I0526 18:00:08.968340 24213 sgd_solver.cpp:106] Iteration 3000, lr = 1e-08
I0526 18:00:14.910845 24213 solver.cpp:228] Iteration 3010, loss = 0.679009
I0526 18:00:14.910912 24213 solver.cpp:244]     Train net output #0: loss = 0.679009 (* 1 = 0.679009 loss)
I0526 18:00:14.910928 24213 sgd_solver.cpp:106] Iteration 3010, lr = 1e-08
I0526 18:00:21.182698 24213 solver.cpp:228] Iteration 3020, loss = 0.629159
I0526 18:00:21.182858 24213 solver.cpp:244]     Train net output #0: loss = 0.629159 (* 1 = 0.629159 loss)
I0526 18:00:21.182878 24213 sgd_solver.cpp:106] Iteration 3020, lr = 1e-08
I0526 18:00:26.869458 24213 solver.cpp:337] Iteration 3030, Testing net (#0)
I0526 18:00:29.006135 24213 solver.cpp:404]     Test net output #0: accuracy = 0.383636
I0526 18:00:29.006176 24213 solver.cpp:404]     Test net output #1: loss = 2.54194 (* 1 = 2.54194 loss)
I0526 18:00:29.538003 24213 solver.cpp:228] Iteration 3030, loss = 0.602085
I0526 18:00:29.538118 24213 solver.cpp:244]     Train net output #0: loss = 0.602085 (* 1 = 0.602085 loss)
I0526 18:00:29.538139 24213 sgd_solver.cpp:106] Iteration 3030, lr = 1e-08
I0526 18:00:35.474895 24213 solver.cpp:228] Iteration 3040, loss = 0.568242
I0526 18:00:35.474947 24213 solver.cpp:244]     Train net output #0: loss = 0.568242 (* 1 = 0.568242 loss)
I0526 18:00:35.474958 24213 sgd_solver.cpp:106] Iteration 3040, lr = 1e-08
I0526 18:00:41.412818 24213 solver.cpp:228] Iteration 3050, loss = 0.672362
I0526 18:00:41.412968 24213 solver.cpp:244]     Train net output #0: loss = 0.672362 (* 1 = 0.672362 loss)
I0526 18:00:41.413033 24213 sgd_solver.cpp:106] Iteration 3050, lr = 1e-08
I0526 18:00:46.853502 24213 solver.cpp:337] Iteration 3060, Testing net (#0)
I0526 18:00:48.836702 24213 solver.cpp:404]     Test net output #0: accuracy = 0.383636
I0526 18:00:48.836746 24213 solver.cpp:404]     Test net output #1: loss = 2.55551 (* 1 = 2.55551 loss)
I0526 18:00:49.367979 24213 solver.cpp:228] Iteration 3060, loss = 0.615882
I0526 18:00:49.368017 24213 solver.cpp:244]     Train net output #0: loss = 0.615882 (* 1 = 0.615882 loss)
I0526 18:00:49.368028 24213 sgd_solver.cpp:106] Iteration 3060, lr = 1e-08
I0526 18:00:55.308094 24213 solver.cpp:228] Iteration 3070, loss = 0.659158
I0526 18:00:55.308538 24213 solver.cpp:244]     Train net output #0: loss = 0.659158 (* 1 = 0.659158 loss)
I0526 18:00:55.308558 24213 sgd_solver.cpp:106] Iteration 3070, lr = 1e-08
I0526 18:01:01.247750 24213 solver.cpp:228] Iteration 3080, loss = 0.558429
I0526 18:01:01.247798 24213 solver.cpp:244]     Train net output #0: loss = 0.558429 (* 1 = 0.558429 loss)
I0526 18:01:01.247826 24213 sgd_solver.cpp:106] Iteration 3080, lr = 1e-08
I0526 18:01:06.599275 24213 solver.cpp:337] Iteration 3090, Testing net (#0)
I0526 18:01:08.818114 24213 solver.cpp:404]     Test net output #0: accuracy = 0.381818
I0526 18:01:08.818169 24213 solver.cpp:404]     Test net output #1: loss = 2.56219 (* 1 = 2.56219 loss)
I0526 18:01:09.350195 24213 solver.cpp:228] Iteration 3090, loss = 0.610617
I0526 18:01:09.350234 24213 solver.cpp:244]     Train net output #0: loss = 0.610617 (* 1 = 0.610617 loss)
I0526 18:01:09.350246 24213 sgd_solver.cpp:106] Iteration 3090, lr = 1e-08
I0526 18:01:15.283658 24213 solver.cpp:228] Iteration 3100, loss = 0.719452
I0526 18:01:15.283700 24213 solver.cpp:244]     Train net output #0: loss = 0.719452 (* 1 = 0.719452 loss)
I0526 18:01:15.283711 24213 sgd_solver.cpp:106] Iteration 3100, lr = 1e-08
I0526 18:01:21.216217 24213 solver.cpp:228] Iteration 3110, loss = 0.687846
I0526 18:01:21.216260 24213 solver.cpp:244]     Train net output #0: loss = 0.687846 (* 1 = 0.687846 loss)
I0526 18:01:21.216276 24213 sgd_solver.cpp:106] Iteration 3110, lr = 1e-08
I0526 18:01:26.558019 24213 solver.cpp:337] Iteration 3120, Testing net (#0)
I0526 18:01:28.806462 24213 solver.cpp:404]     Test net output #0: accuracy = 0.389091
I0526 18:01:28.806520 24213 solver.cpp:404]     Test net output #1: loss = 2.53253 (* 1 = 2.53253 loss)
I0526 18:01:29.338261 24213 solver.cpp:228] Iteration 3120, loss = 0.644023
I0526 18:01:29.338300 24213 solver.cpp:244]     Train net output #0: loss = 0.644023 (* 1 = 0.644023 loss)
I0526 18:01:29.338312 24213 sgd_solver.cpp:106] Iteration 3120, lr = 1e-08
I0526 18:01:35.276674 24213 solver.cpp:228] Iteration 3130, loss = 0.6672
I0526 18:01:35.276721 24213 solver.cpp:244]     Train net output #0: loss = 0.6672 (* 1 = 0.6672 loss)
I0526 18:01:35.276737 24213 sgd_solver.cpp:106] Iteration 3130, lr = 1e-08
I0526 18:01:41.213775 24213 solver.cpp:228] Iteration 3140, loss = 0.735916
I0526 18:01:41.213832 24213 solver.cpp:244]     Train net output #0: loss = 0.735916 (* 1 = 0.735916 loss)
I0526 18:01:41.213845 24213 sgd_solver.cpp:106] Iteration 3140, lr = 1e-08
I0526 18:01:46.557508 24213 solver.cpp:337] Iteration 3150, Testing net (#0)
I0526 18:01:48.431305 24213 solver.cpp:404]     Test net output #0: accuracy = 0.376364
I0526 18:01:48.431347 24213 solver.cpp:404]     Test net output #1: loss = 2.57325 (* 1 = 2.57325 loss)
I0526 18:01:48.962985 24213 solver.cpp:228] Iteration 3150, loss = 0.6045
I0526 18:01:48.963026 24213 solver.cpp:244]     Train net output #0: loss = 0.6045 (* 1 = 0.6045 loss)
I0526 18:01:48.963042 24213 sgd_solver.cpp:106] Iteration 3150, lr = 1e-08
I0526 18:01:54.905480 24213 solver.cpp:228] Iteration 3160, loss = 0.61167
I0526 18:01:54.905532 24213 solver.cpp:244]     Train net output #0: loss = 0.61167 (* 1 = 0.61167 loss)
I0526 18:01:54.905550 24213 sgd_solver.cpp:106] Iteration 3160, lr = 1e-08
I0526 18:02:00.842291 24213 solver.cpp:228] Iteration 3170, loss = 0.746
I0526 18:02:00.842382 24213 solver.cpp:244]     Train net output #0: loss = 0.746 (* 1 = 0.746 loss)
I0526 18:02:00.842401 24213 sgd_solver.cpp:106] Iteration 3170, lr = 1e-08
I0526 18:02:06.192991 24213 solver.cpp:337] Iteration 3180, Testing net (#0)
I0526 18:02:08.241627 24213 solver.cpp:404]     Test net output #0: accuracy = 0.385455
I0526 18:02:08.241696 24213 solver.cpp:404]     Test net output #1: loss = 2.54533 (* 1 = 2.54533 loss)
I0526 18:02:08.773814 24213 solver.cpp:228] Iteration 3180, loss = 0.698436
I0526 18:02:08.773869 24213 solver.cpp:244]     Train net output #0: loss = 0.698436 (* 1 = 0.698436 loss)
I0526 18:02:08.773885 24213 sgd_solver.cpp:106] Iteration 3180, lr = 1e-08
I0526 18:02:14.716464 24213 solver.cpp:228] Iteration 3190, loss = 0.662293
I0526 18:02:14.716539 24213 solver.cpp:244]     Train net output #0: loss = 0.662293 (* 1 = 0.662293 loss)
I0526 18:02:14.716555 24213 sgd_solver.cpp:106] Iteration 3190, lr = 1e-08
I0526 18:02:20.657174 24213 solver.cpp:228] Iteration 3200, loss = 0.658931
I0526 18:02:20.657364 24213 solver.cpp:244]     Train net output #0: loss = 0.658931 (* 1 = 0.658931 loss)
I0526 18:02:20.657412 24213 sgd_solver.cpp:106] Iteration 3200, lr = 1e-08
I0526 18:02:26.291820 24213 solver.cpp:337] Iteration 3210, Testing net (#0)
I0526 18:02:28.388892 24213 solver.cpp:404]     Test net output #0: accuracy = 0.381818
I0526 18:02:28.388942 24213 solver.cpp:404]     Test net output #1: loss = 2.57489 (* 1 = 2.57489 loss)
I0526 18:02:28.920349 24213 solver.cpp:228] Iteration 3210, loss = 0.727047
I0526 18:02:28.920456 24213 solver.cpp:244]     Train net output #0: loss = 0.727047 (* 1 = 0.727047 loss)
I0526 18:02:28.920496 24213 sgd_solver.cpp:106] Iteration 3210, lr = 1e-08
I0526 18:02:35.116390 24213 solver.cpp:228] Iteration 3220, loss = 0.611221
I0526 18:02:35.116586 24213 solver.cpp:244]     Train net output #0: loss = 0.611221 (* 1 = 0.611221 loss)
I0526 18:02:35.116611 24213 sgd_solver.cpp:106] Iteration 3220, lr = 1e-08
I0526 18:02:41.819300 24213 solver.cpp:228] Iteration 3230, loss = 0.604226
I0526 18:02:41.819360 24213 solver.cpp:244]     Train net output #0: loss = 0.604226 (* 1 = 0.604226 loss)
I0526 18:02:41.819375 24213 sgd_solver.cpp:106] Iteration 3230, lr = 1e-08
I0526 18:02:47.473067 24213 solver.cpp:337] Iteration 3240, Testing net (#0)
I0526 18:02:49.888099 24213 solver.cpp:404]     Test net output #0: accuracy = 0.381818
I0526 18:02:49.888149 24213 solver.cpp:404]     Test net output #1: loss = 2.55056 (* 1 = 2.55056 loss)
I0526 18:02:50.419657 24213 solver.cpp:228] Iteration 3240, loss = 0.72445
I0526 18:02:50.419705 24213 solver.cpp:244]     Train net output #0: loss = 0.72445 (* 1 = 0.72445 loss)
I0526 18:02:50.419723 24213 sgd_solver.cpp:106] Iteration 3240, lr = 1e-08
I0526 18:02:56.356569 24213 solver.cpp:228] Iteration 3250, loss = 0.659588
I0526 18:02:56.356623 24213 solver.cpp:244]     Train net output #0: loss = 0.659588 (* 1 = 0.659588 loss)
I0526 18:02:56.356642 24213 sgd_solver.cpp:106] Iteration 3250, lr = 1e-08
I0526 18:03:02.293361 24213 solver.cpp:228] Iteration 3260, loss = 0.672948
I0526 18:03:02.293431 24213 solver.cpp:244]     Train net output #0: loss = 0.672948 (* 1 = 0.672948 loss)
I0526 18:03:02.293448 24213 sgd_solver.cpp:106] Iteration 3260, lr = 1e-08
I0526 18:03:07.643272 24213 solver.cpp:337] Iteration 3270, Testing net (#0)
I0526 18:03:09.935116 24213 solver.cpp:404]     Test net output #0: accuracy = 0.374545
I0526 18:03:09.935174 24213 solver.cpp:404]     Test net output #1: loss = 2.58406 (* 1 = 2.58406 loss)
I0526 18:03:10.466516 24213 solver.cpp:228] Iteration 3270, loss = 0.648491
I0526 18:03:10.466570 24213 solver.cpp:244]     Train net output #0: loss = 0.648491 (* 1 = 0.648491 loss)
I0526 18:03:10.466588 24213 sgd_solver.cpp:106] Iteration 3270, lr = 1e-08
I0526 18:03:16.411303 24213 solver.cpp:228] Iteration 3280, loss = 0.706097
I0526 18:03:16.411375 24213 solver.cpp:244]     Train net output #0: loss = 0.706097 (* 1 = 0.706097 loss)
I0526 18:03:16.411387 24213 sgd_solver.cpp:106] Iteration 3280, lr = 1e-08
I0526 18:03:22.343503 24213 solver.cpp:228] Iteration 3290, loss = 0.608763
I0526 18:03:22.343554 24213 solver.cpp:244]     Train net output #0: loss = 0.608763 (* 1 = 0.608763 loss)
I0526 18:03:22.343566 24213 sgd_solver.cpp:106] Iteration 3290, lr = 1e-08
I0526 18:03:27.687268 24213 solver.cpp:337] Iteration 3300, Testing net (#0)
I0526 18:03:29.829910 24213 solver.cpp:404]     Test net output #0: accuracy = 0.381818
I0526 18:03:29.829967 24213 solver.cpp:404]     Test net output #1: loss = 2.55894 (* 1 = 2.55894 loss)
I0526 18:03:30.361775 24213 solver.cpp:228] Iteration 3300, loss = 0.753317
I0526 18:03:30.361881 24213 solver.cpp:244]     Train net output #0: loss = 0.753317 (* 1 = 0.753317 loss)
I0526 18:03:30.361903 24213 sgd_solver.cpp:106] Iteration 3300, lr = 1e-08
I0526 18:03:36.302913 24213 solver.cpp:228] Iteration 3310, loss = 0.764034
I0526 18:03:36.302973 24213 solver.cpp:244]     Train net output #0: loss = 0.764034 (* 1 = 0.764034 loss)
I0526 18:03:36.302989 24213 sgd_solver.cpp:106] Iteration 3310, lr = 1e-08
I0526 18:03:42.235599 24213 solver.cpp:228] Iteration 3320, loss = 0.723048
I0526 18:03:42.235757 24213 solver.cpp:244]     Train net output #0: loss = 0.723048 (* 1 = 0.723048 loss)
I0526 18:03:42.235772 24213 sgd_solver.cpp:106] Iteration 3320, lr = 1e-08
I0526 18:03:47.590785 24213 solver.cpp:337] Iteration 3330, Testing net (#0)
I0526 18:03:49.963858 24213 solver.cpp:404]     Test net output #0: accuracy = 0.381818
I0526 18:03:49.963912 24213 solver.cpp:404]     Test net output #1: loss = 2.5502 (* 1 = 2.5502 loss)
I0526 18:03:50.497756 24213 solver.cpp:228] Iteration 3330, loss = 0.601649
I0526 18:03:50.497822 24213 solver.cpp:244]     Train net output #0: loss = 0.601649 (* 1 = 0.601649 loss)
I0526 18:03:50.497838 24213 sgd_solver.cpp:106] Iteration 3330, lr = 1e-08
I0526 18:03:56.445876 24213 solver.cpp:228] Iteration 3340, loss = 0.600886
I0526 18:03:56.445932 24213 solver.cpp:244]     Train net output #0: loss = 0.600886 (* 1 = 0.600886 loss)
I0526 18:03:56.445950 24213 sgd_solver.cpp:106] Iteration 3340, lr = 1e-08
I0526 18:04:02.380271 24213 solver.cpp:228] Iteration 3350, loss = 0.658567
I0526 18:04:02.380350 24213 solver.cpp:244]     Train net output #0: loss = 0.658567 (* 1 = 0.658567 loss)
I0526 18:04:02.380367 24213 sgd_solver.cpp:106] Iteration 3350, lr = 1e-08
I0526 18:04:07.731925 24213 solver.cpp:337] Iteration 3360, Testing net (#0)
I0526 18:04:10.312503 24213 solver.cpp:404]     Test net output #0: accuracy = 0.385455
I0526 18:04:10.312631 24213 solver.cpp:404]     Test net output #1: loss = 2.55553 (* 1 = 2.55553 loss)
I0526 18:04:10.843785 24213 solver.cpp:228] Iteration 3360, loss = 0.777576
I0526 18:04:10.843894 24213 solver.cpp:244]     Train net output #0: loss = 0.777576 (* 1 = 0.777576 loss)
I0526 18:04:10.843932 24213 sgd_solver.cpp:106] Iteration 3360, lr = 1e-08
I0526 18:04:16.787125 24213 solver.cpp:228] Iteration 3370, loss = 0.740126
I0526 18:04:16.787235 24213 solver.cpp:244]     Train net output #0: loss = 0.740126 (* 1 = 0.740126 loss)
I0526 18:04:16.787250 24213 sgd_solver.cpp:106] Iteration 3370, lr = 1e-08
I0526 18:04:22.725131 24213 solver.cpp:228] Iteration 3380, loss = 0.733449
I0526 18:04:22.725184 24213 solver.cpp:244]     Train net output #0: loss = 0.733449 (* 1 = 0.733449 loss)
I0526 18:04:22.725198 24213 sgd_solver.cpp:106] Iteration 3380, lr = 1e-08
I0526 18:04:28.075431 24213 solver.cpp:337] Iteration 3390, Testing net (#0)
I0526 18:04:30.405805 24213 solver.cpp:404]     Test net output #0: accuracy = 0.381818
I0526 18:04:30.405853 24213 solver.cpp:404]     Test net output #1: loss = 2.56201 (* 1 = 2.56201 loss)
I0526 18:04:30.937244 24213 solver.cpp:228] Iteration 3390, loss = 0.622044
I0526 18:04:30.937356 24213 solver.cpp:244]     Train net output #0: loss = 0.622044 (* 1 = 0.622044 loss)
I0526 18:04:30.937398 24213 sgd_solver.cpp:106] Iteration 3390, lr = 1e-08
I0526 18:04:36.877537 24213 solver.cpp:228] Iteration 3400, loss = 0.556817
I0526 18:04:36.877672 24213 solver.cpp:244]     Train net output #0: loss = 0.556817 (* 1 = 0.556817 loss)
I0526 18:04:36.877717 24213 sgd_solver.cpp:106] Iteration 3400, lr = 1e-08
I0526 18:04:42.831861 24213 solver.cpp:228] Iteration 3410, loss = 0.633164
I0526 18:04:42.831907 24213 solver.cpp:244]     Train net output #0: loss = 0.633164 (* 1 = 0.633164 loss)
I0526 18:04:42.831919 24213 sgd_solver.cpp:106] Iteration 3410, lr = 1e-08
I0526 18:04:48.179630 24213 solver.cpp:337] Iteration 3420, Testing net (#0)
I0526 18:04:50.395105 24213 solver.cpp:404]     Test net output #0: accuracy = 0.381818
I0526 18:04:50.395190 24213 solver.cpp:404]     Test net output #1: loss = 2.54867 (* 1 = 2.54867 loss)
I0526 18:04:50.927352 24213 solver.cpp:228] Iteration 3420, loss = 0.620068
I0526 18:04:50.927403 24213 solver.cpp:244]     Train net output #0: loss = 0.620068 (* 1 = 0.620068 loss)
I0526 18:04:50.927420 24213 sgd_solver.cpp:106] Iteration 3420, lr = 1e-08
I0526 18:04:56.869282 24213 solver.cpp:228] Iteration 3430, loss = 0.701142
I0526 18:04:56.869366 24213 solver.cpp:244]     Train net output #0: loss = 0.701142 (* 1 = 0.701142 loss)
I0526 18:04:56.869387 24213 sgd_solver.cpp:106] Iteration 3430, lr = 1e-08
I0526 18:05:02.811825 24213 solver.cpp:228] Iteration 3440, loss = 0.664648
I0526 18:05:02.811883 24213 solver.cpp:244]     Train net output #0: loss = 0.664648 (* 1 = 0.664648 loss)
I0526 18:05:02.811902 24213 sgd_solver.cpp:106] Iteration 3440, lr = 1e-08
I0526 18:05:08.166872 24213 solver.cpp:337] Iteration 3450, Testing net (#0)
I0526 18:05:10.339601 24213 solver.cpp:404]     Test net output #0: accuracy = 0.383636
I0526 18:05:10.339648 24213 solver.cpp:404]     Test net output #1: loss = 2.54212 (* 1 = 2.54212 loss)
I0526 18:05:10.871074 24213 solver.cpp:228] Iteration 3450, loss = 0.679139
I0526 18:05:10.871187 24213 solver.cpp:244]     Train net output #0: loss = 0.679139 (* 1 = 0.679139 loss)
I0526 18:05:10.871237 24213 sgd_solver.cpp:106] Iteration 3450, lr = 1e-08
I0526 18:05:16.815111 24213 solver.cpp:228] Iteration 3460, loss = 0.680137
I0526 18:05:16.815167 24213 solver.cpp:244]     Train net output #0: loss = 0.680137 (* 1 = 0.680137 loss)
I0526 18:05:16.815183 24213 sgd_solver.cpp:106] Iteration 3460, lr = 1e-08
I0526 18:05:23.054524 24213 solver.cpp:228] Iteration 3470, loss = 0.612989
I0526 18:05:23.054790 24213 solver.cpp:244]     Train net output #0: loss = 0.612989 (* 1 = 0.612989 loss)
I0526 18:05:23.054816 24213 sgd_solver.cpp:106] Iteration 3470, lr = 1e-08
I0526 18:05:28.934798 24213 solver.cpp:337] Iteration 3480, Testing net (#0)
I0526 18:05:31.268098 24213 solver.cpp:404]     Test net output #0: accuracy = 0.38
I0526 18:05:31.268219 24213 solver.cpp:404]     Test net output #1: loss = 2.57521 (* 1 = 2.57521 loss)
I0526 18:05:31.800324 24213 solver.cpp:228] Iteration 3480, loss = 0.574932
I0526 18:05:31.800380 24213 solver.cpp:244]     Train net output #0: loss = 0.574932 (* 1 = 0.574932 loss)
I0526 18:05:31.800397 24213 sgd_solver.cpp:106] Iteration 3480, lr = 1e-08
I0526 18:05:37.743438 24213 solver.cpp:228] Iteration 3490, loss = 0.610629
I0526 18:05:37.743495 24213 solver.cpp:244]     Train net output #0: loss = 0.610629 (* 1 = 0.610629 loss)
I0526 18:05:37.743513 24213 sgd_solver.cpp:106] Iteration 3490, lr = 1e-08
I0526 18:05:43.765285 24213 solver.cpp:228] Iteration 3500, loss = 0.66743
I0526 18:05:43.765357 24213 solver.cpp:244]     Train net output #0: loss = 0.66743 (* 1 = 0.66743 loss)
I0526 18:05:43.765377 24213 sgd_solver.cpp:106] Iteration 3500, lr = 1e-08
I0526 18:05:49.471843 24213 solver.cpp:337] Iteration 3510, Testing net (#0)
I0526 18:05:51.762503 24213 solver.cpp:404]     Test net output #0: accuracy = 0.38
I0526 18:05:51.762670 24213 solver.cpp:404]     Test net output #1: loss = 2.57327 (* 1 = 2.57327 loss)
I0526 18:05:52.294769 24213 solver.cpp:228] Iteration 3510, loss = 0.664267
I0526 18:05:52.294872 24213 solver.cpp:244]     Train net output #0: loss = 0.664267 (* 1 = 0.664267 loss)
I0526 18:05:52.294911 24213 sgd_solver.cpp:106] Iteration 3510, lr = 1e-08
I0526 18:05:58.234079 24213 solver.cpp:228] Iteration 3520, loss = 0.651173
I0526 18:05:58.234200 24213 solver.cpp:244]     Train net output #0: loss = 0.651173 (* 1 = 0.651173 loss)
I0526 18:05:58.234218 24213 sgd_solver.cpp:106] Iteration 3520, lr = 1e-08
I0526 18:06:04.174752 24213 solver.cpp:228] Iteration 3530, loss = 0.644864
I0526 18:06:04.174794 24213 solver.cpp:244]     Train net output #0: loss = 0.644864 (* 1 = 0.644864 loss)
I0526 18:06:04.174811 24213 sgd_solver.cpp:106] Iteration 3530, lr = 1e-08
I0526 18:06:09.526901 24213 solver.cpp:337] Iteration 3540, Testing net (#0)
I0526 18:06:11.628690 24213 solver.cpp:404]     Test net output #0: accuracy = 0.381818
I0526 18:06:11.628731 24213 solver.cpp:404]     Test net output #1: loss = 2.56143 (* 1 = 2.56143 loss)
I0526 18:06:12.160686 24213 solver.cpp:228] Iteration 3540, loss = 0.59308
I0526 18:06:12.160727 24213 solver.cpp:244]     Train net output #0: loss = 0.59308 (* 1 = 0.59308 loss)
I0526 18:06:12.160742 24213 sgd_solver.cpp:106] Iteration 3540, lr = 1e-08
I0526 18:06:18.099850 24213 solver.cpp:228] Iteration 3550, loss = 0.692407
I0526 18:06:18.099902 24213 solver.cpp:244]     Train net output #0: loss = 0.692407 (* 1 = 0.692407 loss)
I0526 18:06:18.099913 24213 sgd_solver.cpp:106] Iteration 3550, lr = 1e-08
I0526 18:06:24.041959 24213 solver.cpp:228] Iteration 3560, loss = 0.834981
I0526 18:06:24.042008 24213 solver.cpp:244]     Train net output #0: loss = 0.834981 (* 1 = 0.834981 loss)
I0526 18:06:24.042031 24213 sgd_solver.cpp:106] Iteration 3560, lr = 1e-08
I0526 18:06:29.388753 24213 solver.cpp:337] Iteration 3570, Testing net (#0)
I0526 18:06:31.409539 24213 solver.cpp:404]     Test net output #0: accuracy = 0.381818
I0526 18:06:31.409579 24213 solver.cpp:404]     Test net output #1: loss = 2.56537 (* 1 = 2.56537 loss)
I0526 18:06:31.940843 24213 solver.cpp:228] Iteration 3570, loss = 0.709944
I0526 18:06:31.940896 24213 solver.cpp:244]     Train net output #0: loss = 0.709944 (* 1 = 0.709944 loss)
I0526 18:06:31.940907 24213 sgd_solver.cpp:106] Iteration 3570, lr = 1e-08
I0526 18:06:37.884451 24213 solver.cpp:228] Iteration 3580, loss = 0.638321
I0526 18:06:37.884510 24213 solver.cpp:244]     Train net output #0: loss = 0.638321 (* 1 = 0.638321 loss)
I0526 18:06:37.884526 24213 sgd_solver.cpp:106] Iteration 3580, lr = 1e-08
I0526 18:06:43.827908 24213 solver.cpp:228] Iteration 3590, loss = 0.638957
I0526 18:06:43.827957 24213 solver.cpp:244]     Train net output #0: loss = 0.638957 (* 1 = 0.638957 loss)
I0526 18:06:43.827978 24213 sgd_solver.cpp:106] Iteration 3590, lr = 1e-08
I0526 18:06:49.173272 24213 solver.cpp:337] Iteration 3600, Testing net (#0)
I0526 18:06:51.250166 24213 solver.cpp:404]     Test net output #0: accuracy = 0.390909
I0526 18:06:51.250208 24213 solver.cpp:404]     Test net output #1: loss = 2.53112 (* 1 = 2.53112 loss)
I0526 18:06:51.782440 24213 solver.cpp:228] Iteration 3600, loss = 0.664762
I0526 18:06:51.782492 24213 solver.cpp:244]     Train net output #0: loss = 0.664762 (* 1 = 0.664762 loss)
I0526 18:06:51.782510 24213 sgd_solver.cpp:106] Iteration 3600, lr = 1e-08
I0526 18:06:57.725566 24213 solver.cpp:228] Iteration 3610, loss = 0.778139
I0526 18:06:57.725659 24213 solver.cpp:244]     Train net output #0: loss = 0.778139 (* 1 = 0.778139 loss)
I0526 18:06:57.725695 24213 sgd_solver.cpp:106] Iteration 3610, lr = 1e-08
I0526 18:07:03.664469 24213 solver.cpp:228] Iteration 3620, loss = 0.6935
I0526 18:07:03.664569 24213 solver.cpp:244]     Train net output #0: loss = 0.6935 (* 1 = 0.6935 loss)
I0526 18:07:03.664583 24213 sgd_solver.cpp:106] Iteration 3620, lr = 1e-08
I0526 18:07:09.010610 24213 solver.cpp:337] Iteration 3630, Testing net (#0)
I0526 18:07:11.302884 24213 solver.cpp:404]     Test net output #0: accuracy = 0.376364
I0526 18:07:11.302942 24213 solver.cpp:404]     Test net output #1: loss = 2.58221 (* 1 = 2.58221 loss)
I0526 18:07:11.838378 24213 solver.cpp:228] Iteration 3630, loss = 0.742075
I0526 18:07:11.838426 24213 solver.cpp:244]     Train net output #0: loss = 0.742075 (* 1 = 0.742075 loss)
I0526 18:07:11.838443 24213 sgd_solver.cpp:106] Iteration 3630, lr = 1e-08
I0526 18:07:17.775254 24213 solver.cpp:228] Iteration 3640, loss = 0.666357
I0526 18:07:17.775303 24213 solver.cpp:244]     Train net output #0: loss = 0.666357 (* 1 = 0.666357 loss)
I0526 18:07:17.775315 24213 sgd_solver.cpp:106] Iteration 3640, lr = 1e-08
I0526 18:07:23.718050 24213 solver.cpp:228] Iteration 3650, loss = 0.662318
I0526 18:07:23.718099 24213 solver.cpp:244]     Train net output #0: loss = 0.662318 (* 1 = 0.662318 loss)
I0526 18:07:23.718111 24213 sgd_solver.cpp:106] Iteration 3650, lr = 1e-08
I0526 18:07:29.070524 24213 solver.cpp:337] Iteration 3660, Testing net (#0)
I0526 18:07:31.068372 24213 solver.cpp:404]     Test net output #0: accuracy = 0.38
I0526 18:07:31.068414 24213 solver.cpp:404]     Test net output #1: loss = 2.53792 (* 1 = 2.53792 loss)
I0526 18:07:31.599670 24213 solver.cpp:228] Iteration 3660, loss = 0.640335
I0526 18:07:31.599755 24213 solver.cpp:244]     Train net output #0: loss = 0.640335 (* 1 = 0.640335 loss)
I0526 18:07:31.599781 24213 sgd_solver.cpp:106] Iteration 3660, lr = 1e-08
I0526 18:07:37.538166 24213 solver.cpp:228] Iteration 3670, loss = 0.648133
I0526 18:07:37.538305 24213 solver.cpp:244]     Train net output #0: loss = 0.648133 (* 1 = 0.648133 loss)
I0526 18:07:37.538323 24213 sgd_solver.cpp:106] Iteration 3670, lr = 1e-08
I0526 18:07:43.479635 24213 solver.cpp:228] Iteration 3680, loss = 0.627785
I0526 18:07:43.479678 24213 solver.cpp:244]     Train net output #0: loss = 0.627785 (* 1 = 0.627785 loss)
I0526 18:07:43.479689 24213 sgd_solver.cpp:106] Iteration 3680, lr = 1e-08
I0526 18:07:48.829905 24213 solver.cpp:337] Iteration 3690, Testing net (#0)
I0526 18:07:50.741482 24213 solver.cpp:404]     Test net output #0: accuracy = 0.390909
I0526 18:07:50.741530 24213 solver.cpp:404]     Test net output #1: loss = 2.52565 (* 1 = 2.52565 loss)
I0526 18:07:51.273365 24213 solver.cpp:228] Iteration 3690, loss = 0.601011
I0526 18:07:51.273401 24213 solver.cpp:244]     Train net output #0: loss = 0.601011 (* 1 = 0.601011 loss)
I0526 18:07:51.273413 24213 sgd_solver.cpp:106] Iteration 3690, lr = 1e-08
I0526 18:07:57.213433 24213 solver.cpp:228] Iteration 3700, loss = 0.584334
I0526 18:07:57.213481 24213 solver.cpp:244]     Train net output #0: loss = 0.584334 (* 1 = 0.584334 loss)
I0526 18:07:57.213493 24213 sgd_solver.cpp:106] Iteration 3700, lr = 1e-08
I0526 18:08:03.155484 24213 solver.cpp:228] Iteration 3710, loss = 0.680503
I0526 18:08:03.155539 24213 solver.cpp:244]     Train net output #0: loss = 0.680503 (* 1 = 0.680503 loss)
I0526 18:08:03.155552 24213 sgd_solver.cpp:106] Iteration 3710, lr = 1e-08
I0526 18:08:08.502764 24213 solver.cpp:337] Iteration 3720, Testing net (#0)
I0526 18:08:10.450162 24213 solver.cpp:404]     Test net output #0: accuracy = 0.387273
I0526 18:08:10.450199 24213 solver.cpp:404]     Test net output #1: loss = 2.54622 (* 1 = 2.54622 loss)
I0526 18:08:10.983927 24213 solver.cpp:228] Iteration 3720, loss = 0.667713
I0526 18:08:10.983966 24213 solver.cpp:244]     Train net output #0: loss = 0.667713 (* 1 = 0.667713 loss)
I0526 18:08:10.983978 24213 sgd_solver.cpp:106] Iteration 3720, lr = 1e-08
I0526 18:08:16.919955 24213 solver.cpp:228] Iteration 3730, loss = 0.613298
I0526 18:08:16.920001 24213 solver.cpp:244]     Train net output #0: loss = 0.613298 (* 1 = 0.613298 loss)
I0526 18:08:16.920012 24213 sgd_solver.cpp:106] Iteration 3730, lr = 1e-08
I0526 18:08:22.855814 24213 solver.cpp:228] Iteration 3740, loss = 0.63966
I0526 18:08:22.855870 24213 solver.cpp:244]     Train net output #0: loss = 0.63966 (* 1 = 0.63966 loss)
I0526 18:08:22.855881 24213 sgd_solver.cpp:106] Iteration 3740, lr = 1e-08
I0526 18:08:28.212985 24213 solver.cpp:337] Iteration 3750, Testing net (#0)
I0526 18:08:30.188972 24213 solver.cpp:404]     Test net output #0: accuracy = 0.389091
I0526 18:08:30.189019 24213 solver.cpp:404]     Test net output #1: loss = 2.53671 (* 1 = 2.53671 loss)
I0526 18:08:30.722635 24213 solver.cpp:228] Iteration 3750, loss = 0.652752
I0526 18:08:30.722681 24213 solver.cpp:244]     Train net output #0: loss = 0.652752 (* 1 = 0.652752 loss)
I0526 18:08:30.722702 24213 sgd_solver.cpp:106] Iteration 3750, lr = 1e-08
I0526 18:08:36.656498 24213 solver.cpp:228] Iteration 3760, loss = 0.629523
I0526 18:08:36.656545 24213 solver.cpp:244]     Train net output #0: loss = 0.629523 (* 1 = 0.629523 loss)
I0526 18:08:36.656560 24213 sgd_solver.cpp:106] Iteration 3760, lr = 1e-08
I0526 18:08:42.599138 24213 solver.cpp:228] Iteration 3770, loss = 0.600445
I0526 18:08:42.599256 24213 solver.cpp:244]     Train net output #0: loss = 0.600445 (* 1 = 0.600445 loss)
I0526 18:08:42.599275 24213 sgd_solver.cpp:106] Iteration 3770, lr = 1e-08
I0526 18:08:47.947373 24213 solver.cpp:337] Iteration 3780, Testing net (#0)
I0526 18:08:50.042927 24213 solver.cpp:404]     Test net output #0: accuracy = 0.381818
I0526 18:08:50.042984 24213 solver.cpp:404]     Test net output #1: loss = 2.56469 (* 1 = 2.56469 loss)
I0526 18:08:50.573920 24213 solver.cpp:228] Iteration 3780, loss = 0.606582
I0526 18:08:50.573968 24213 solver.cpp:244]     Train net output #0: loss = 0.606582 (* 1 = 0.606582 loss)
I0526 18:08:50.573982 24213 sgd_solver.cpp:106] Iteration 3780, lr = 1e-08
I0526 18:08:56.517240 24213 solver.cpp:228] Iteration 3790, loss = 0.588468
I0526 18:08:56.517294 24213 solver.cpp:244]     Train net output #0: loss = 0.588468 (* 1 = 0.588468 loss)
I0526 18:08:56.517307 24213 sgd_solver.cpp:106] Iteration 3790, lr = 1e-08
I0526 18:09:02.452169 24213 solver.cpp:228] Iteration 3800, loss = 0.688649
I0526 18:09:02.452208 24213 solver.cpp:244]     Train net output #0: loss = 0.688649 (* 1 = 0.688649 loss)
I0526 18:09:02.452219 24213 sgd_solver.cpp:106] Iteration 3800, lr = 1e-08
I0526 18:09:07.802947 24213 solver.cpp:337] Iteration 3810, Testing net (#0)
I0526 18:09:09.845629 24213 solver.cpp:404]     Test net output #0: accuracy = 0.381818
I0526 18:09:09.845677 24213 solver.cpp:404]     Test net output #1: loss = 2.55179 (* 1 = 2.55179 loss)
I0526 18:09:10.377215 24213 solver.cpp:228] Iteration 3810, loss = 0.735671
I0526 18:09:10.377267 24213 solver.cpp:244]     Train net output #0: loss = 0.735671 (* 1 = 0.735671 loss)
I0526 18:09:10.377280 24213 sgd_solver.cpp:106] Iteration 3810, lr = 1e-08
I0526 18:09:16.321807 24213 solver.cpp:228] Iteration 3820, loss = 0.640135
I0526 18:09:16.321948 24213 solver.cpp:244]     Train net output #0: loss = 0.640135 (* 1 = 0.640135 loss)
I0526 18:09:16.321961 24213 sgd_solver.cpp:106] Iteration 3820, lr = 1e-08
I0526 18:09:22.256605 24213 solver.cpp:228] Iteration 3830, loss = 0.595709
I0526 18:09:22.256664 24213 solver.cpp:244]     Train net output #0: loss = 0.595709 (* 1 = 0.595709 loss)
I0526 18:09:22.256680 24213 sgd_solver.cpp:106] Iteration 3830, lr = 1e-08
I0526 18:09:27.600178 24213 solver.cpp:337] Iteration 3840, Testing net (#0)
I0526 18:09:29.757714 24213 solver.cpp:404]     Test net output #0: accuracy = 0.38
I0526 18:09:29.757757 24213 solver.cpp:404]     Test net output #1: loss = 2.56612 (* 1 = 2.56612 loss)
I0526 18:09:30.290499 24213 solver.cpp:228] Iteration 3840, loss = 0.61654
I0526 18:09:30.290540 24213 solver.cpp:244]     Train net output #0: loss = 0.61654 (* 1 = 0.61654 loss)
I0526 18:09:30.290556 24213 sgd_solver.cpp:106] Iteration 3840, lr = 1e-08
I0526 18:09:36.239151 24213 solver.cpp:228] Iteration 3850, loss = 0.610961
I0526 18:09:36.239212 24213 solver.cpp:244]     Train net output #0: loss = 0.610961 (* 1 = 0.610961 loss)
I0526 18:09:36.239228 24213 sgd_solver.cpp:106] Iteration 3850, lr = 1e-08
I0526 18:09:42.178405 24213 solver.cpp:228] Iteration 3860, loss = 0.734336
I0526 18:09:42.178448 24213 solver.cpp:244]     Train net output #0: loss = 0.734336 (* 1 = 0.734336 loss)
I0526 18:09:42.178465 24213 sgd_solver.cpp:106] Iteration 3860, lr = 1e-08
I0526 18:09:47.526000 24213 solver.cpp:337] Iteration 3870, Testing net (#0)
I0526 18:09:49.685205 24213 solver.cpp:404]     Test net output #0: accuracy = 0.381818
I0526 18:09:49.685247 24213 solver.cpp:404]     Test net output #1: loss = 2.56152 (* 1 = 2.56152 loss)
I0526 18:09:50.217836 24213 solver.cpp:228] Iteration 3870, loss = 0.806157
I0526 18:09:50.217900 24213 solver.cpp:244]     Train net output #0: loss = 0.806157 (* 1 = 0.806157 loss)
I0526 18:09:50.217918 24213 sgd_solver.cpp:106] Iteration 3870, lr = 1e-08
I0526 18:09:56.164310 24213 solver.cpp:228] Iteration 3880, loss = 0.791594
I0526 18:09:56.164377 24213 solver.cpp:244]     Train net output #0: loss = 0.791594 (* 1 = 0.791594 loss)
I0526 18:09:56.164391 24213 sgd_solver.cpp:106] Iteration 3880, lr = 1e-08
I0526 18:10:02.100770 24213 solver.cpp:228] Iteration 3890, loss = 0.595669
I0526 18:10:02.100827 24213 solver.cpp:244]     Train net output #0: loss = 0.595669 (* 1 = 0.595669 loss)
I0526 18:10:02.100838 24213 sgd_solver.cpp:106] Iteration 3890, lr = 1e-08
I0526 18:10:07.446130 24213 solver.cpp:337] Iteration 3900, Testing net (#0)
I0526 18:10:09.582547 24213 solver.cpp:404]     Test net output #0: accuracy = 0.381818
I0526 18:10:09.582654 24213 solver.cpp:404]     Test net output #1: loss = 2.57723 (* 1 = 2.57723 loss)
I0526 18:10:10.114944 24213 solver.cpp:228] Iteration 3900, loss = 0.602232
I0526 18:10:10.114995 24213 solver.cpp:244]     Train net output #0: loss = 0.602232 (* 1 = 0.602232 loss)
I0526 18:10:10.115007 24213 sgd_solver.cpp:106] Iteration 3900, lr = 1e-08
I0526 18:10:16.056447 24213 solver.cpp:228] Iteration 3910, loss = 0.682192
I0526 18:10:16.056495 24213 solver.cpp:244]     Train net output #0: loss = 0.682192 (* 1 = 0.682192 loss)
I0526 18:10:16.056512 24213 sgd_solver.cpp:106] Iteration 3910, lr = 1e-08
I0526 18:10:21.995679 24213 solver.cpp:228] Iteration 3920, loss = 0.678984
I0526 18:10:21.997403 24213 solver.cpp:244]     Train net output #0: loss = 0.678984 (* 1 = 0.678984 loss)
I0526 18:10:21.997428 24213 sgd_solver.cpp:106] Iteration 3920, lr = 1e-08
I0526 18:10:27.343845 24213 solver.cpp:337] Iteration 3930, Testing net (#0)
I0526 18:10:29.750401 24213 solver.cpp:404]     Test net output #0: accuracy = 0.385455
I0526 18:10:29.750541 24213 solver.cpp:404]     Test net output #1: loss = 2.55817 (* 1 = 2.55817 loss)
I0526 18:10:30.283418 24213 solver.cpp:228] Iteration 3930, loss = 0.671561
I0526 18:10:30.283478 24213 solver.cpp:244]     Train net output #0: loss = 0.671561 (* 1 = 0.671561 loss)
I0526 18:10:30.283494 24213 sgd_solver.cpp:106] Iteration 3930, lr = 1e-08
I0526 18:10:36.220115 24213 solver.cpp:228] Iteration 3940, loss = 0.713727
I0526 18:10:36.220173 24213 solver.cpp:244]     Train net output #0: loss = 0.713727 (* 1 = 0.713727 loss)
I0526 18:10:36.220191 24213 sgd_solver.cpp:106] Iteration 3940, lr = 1e-08
I0526 18:10:42.158002 24213 solver.cpp:228] Iteration 3950, loss = 0.697508
I0526 18:10:42.158052 24213 solver.cpp:244]     Train net output #0: loss = 0.697508 (* 1 = 0.697508 loss)
I0526 18:10:42.158064 24213 sgd_solver.cpp:106] Iteration 3950, lr = 1e-08
I0526 18:10:47.503624 24213 solver.cpp:337] Iteration 3960, Testing net (#0)
I0526 18:10:49.667366 24213 solver.cpp:404]     Test net output #0: accuracy = 0.381818
I0526 18:10:49.667405 24213 solver.cpp:404]     Test net output #1: loss = 2.55211 (* 1 = 2.55211 loss)
I0526 18:10:50.199906 24213 solver.cpp:228] Iteration 3960, loss = 0.541189
I0526 18:10:50.199967 24213 solver.cpp:244]     Train net output #0: loss = 0.541189 (* 1 = 0.541189 loss)
I0526 18:10:50.199981 24213 sgd_solver.cpp:106] Iteration 3960, lr = 1e-08
I0526 18:10:56.137629 24213 solver.cpp:228] Iteration 3970, loss = 0.610976
I0526 18:10:56.137739 24213 solver.cpp:244]     Train net output #0: loss = 0.610976 (* 1 = 0.610976 loss)
I0526 18:10:56.137761 24213 sgd_solver.cpp:106] Iteration 3970, lr = 1e-08
I0526 18:11:02.074314 24213 solver.cpp:228] Iteration 3980, loss = 0.708482
I0526 18:11:02.074358 24213 solver.cpp:244]     Train net output #0: loss = 0.708482 (* 1 = 0.708482 loss)
I0526 18:11:02.074374 24213 sgd_solver.cpp:106] Iteration 3980, lr = 1e-08
I0526 18:11:07.425886 24213 solver.cpp:337] Iteration 3990, Testing net (#0)
I0526 18:11:09.612045 24213 solver.cpp:404]     Test net output #0: accuracy = 0.387273
I0526 18:11:09.612114 24213 solver.cpp:404]     Test net output #1: loss = 2.53512 (* 1 = 2.53512 loss)
I0526 18:11:10.144368 24213 solver.cpp:228] Iteration 3990, loss = 0.676236
I0526 18:11:10.144407 24213 solver.cpp:244]     Train net output #0: loss = 0.676236 (* 1 = 0.676236 loss)
I0526 18:11:10.144418 24213 sgd_solver.cpp:106] Iteration 3990, lr = 1e-08
I0526 18:11:15.492588 24213 solver.cpp:454] Snapshotting to binary proto file snapshot2/caffe_CAM_finetuneMIT_iter_4000.caffemodel
I0526 18:11:15.614125 24213 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot2/caffe_CAM_finetuneMIT_iter_4000.solverstate
I0526 18:11:16.180205 24213 solver.cpp:228] Iteration 4000, loss = 0.660002
I0526 18:11:16.180258 24213 solver.cpp:244]     Train net output #0: loss = 0.660002 (* 1 = 0.660002 loss)
I0526 18:11:16.180271 24213 sgd_solver.cpp:106] Iteration 4000, lr = 1e-09
I0526 18:11:22.119066 24213 solver.cpp:228] Iteration 4010, loss = 0.658976
I0526 18:11:22.119133 24213 solver.cpp:244]     Train net output #0: loss = 0.658976 (* 1 = 0.658976 loss)
I0526 18:11:22.119146 24213 sgd_solver.cpp:106] Iteration 4010, lr = 1e-09
I0526 18:11:27.463968 24213 solver.cpp:337] Iteration 4020, Testing net (#0)
I0526 18:11:29.685861 24213 solver.cpp:404]     Test net output #0: accuracy = 0.381818
I0526 18:11:29.685915 24213 solver.cpp:404]     Test net output #1: loss = 2.56991 (* 1 = 2.56991 loss)
I0526 18:11:30.218124 24213 solver.cpp:228] Iteration 4020, loss = 0.635975
I0526 18:11:30.218230 24213 solver.cpp:244]     Train net output #0: loss = 0.635975 (* 1 = 0.635975 loss)
I0526 18:11:30.218281 24213 sgd_solver.cpp:106] Iteration 4020, lr = 1e-09
I0526 18:11:36.155514 24213 solver.cpp:228] Iteration 4030, loss = 0.667362
I0526 18:11:36.155577 24213 solver.cpp:244]     Train net output #0: loss = 0.667362 (* 1 = 0.667362 loss)
I0526 18:11:36.155589 24213 sgd_solver.cpp:106] Iteration 4030, lr = 1e-09
I0526 18:11:42.093089 24213 solver.cpp:228] Iteration 4040, loss = 0.597366
I0526 18:11:42.093128 24213 solver.cpp:244]     Train net output #0: loss = 0.597366 (* 1 = 0.597366 loss)
I0526 18:11:42.093140 24213 sgd_solver.cpp:106] Iteration 4040, lr = 1e-09
I0526 18:11:47.439167 24213 solver.cpp:337] Iteration 4050, Testing net (#0)
I0526 18:11:49.452608 24213 solver.cpp:404]     Test net output #0: accuracy = 0.383636
I0526 18:11:49.452672 24213 solver.cpp:404]     Test net output #1: loss = 2.54933 (* 1 = 2.54933 loss)
I0526 18:11:49.984766 24213 solver.cpp:228] Iteration 4050, loss = 0.742518
I0526 18:11:49.984817 24213 solver.cpp:244]     Train net output #0: loss = 0.742518 (* 1 = 0.742518 loss)
I0526 18:11:49.984828 24213 sgd_solver.cpp:106] Iteration 4050, lr = 1e-09
I0526 18:11:55.929584 24213 solver.cpp:228] Iteration 4060, loss = 0.685599
I0526 18:11:55.929647 24213 solver.cpp:244]     Train net output #0: loss = 0.685599 (* 1 = 0.685599 loss)
I0526 18:11:55.929661 24213 sgd_solver.cpp:106] Iteration 4060, lr = 1e-09
I0526 18:12:01.867908 24213 solver.cpp:228] Iteration 4070, loss = 0.607963
I0526 18:12:01.868038 24213 solver.cpp:244]     Train net output #0: loss = 0.607963 (* 1 = 0.607963 loss)
I0526 18:12:01.868052 24213 sgd_solver.cpp:106] Iteration 4070, lr = 1e-09
I0526 18:12:07.219411 24213 solver.cpp:337] Iteration 4080, Testing net (#0)
I0526 18:12:09.140013 24213 solver.cpp:404]     Test net output #0: accuracy = 0.381818
I0526 18:12:09.140064 24213 solver.cpp:404]     Test net output #1: loss = 2.55636 (* 1 = 2.55636 loss)
I0526 18:12:09.673271 24213 solver.cpp:228] Iteration 4080, loss = 0.703442
I0526 18:12:09.673321 24213 solver.cpp:244]     Train net output #0: loss = 0.703442 (* 1 = 0.703442 loss)
I0526 18:12:09.673332 24213 sgd_solver.cpp:106] Iteration 4080, lr = 1e-09
I0526 18:12:15.611860 24213 solver.cpp:228] Iteration 4090, loss = 0.609087
I0526 18:12:15.611937 24213 solver.cpp:244]     Train net output #0: loss = 0.609087 (* 1 = 0.609087 loss)
I0526 18:12:15.611955 24213 sgd_solver.cpp:106] Iteration 4090, lr = 1e-09
I0526 18:12:21.553938 24213 solver.cpp:228] Iteration 4100, loss = 0.617339
I0526 18:12:21.553997 24213 solver.cpp:244]     Train net output #0: loss = 0.617339 (* 1 = 0.617339 loss)
I0526 18:12:21.554013 24213 sgd_solver.cpp:106] Iteration 4100, lr = 1e-09
I0526 18:12:26.909700 24213 solver.cpp:337] Iteration 4110, Testing net (#0)
I0526 18:12:28.860646 24213 solver.cpp:404]     Test net output #0: accuracy = 0.383636
I0526 18:12:28.860688 24213 solver.cpp:404]     Test net output #1: loss = 2.55012 (* 1 = 2.55012 loss)
I0526 18:12:29.398699 24213 solver.cpp:228] Iteration 4110, loss = 0.646606
I0526 18:12:29.398943 24213 solver.cpp:244]     Train net output #0: loss = 0.646606 (* 1 = 0.646606 loss)
I0526 18:12:29.399013 24213 sgd_solver.cpp:106] Iteration 4110, lr = 1e-09
I0526 18:12:35.339283 24213 solver.cpp:228] Iteration 4120, loss = 0.702039
I0526 18:12:35.339434 24213 solver.cpp:244]     Train net output #0: loss = 0.702039 (* 1 = 0.702039 loss)
I0526 18:12:35.339455 24213 sgd_solver.cpp:106] Iteration 4120, lr = 1e-09
I0526 18:12:41.280308 24213 solver.cpp:228] Iteration 4130, loss = 0.614597
I0526 18:12:41.280364 24213 solver.cpp:244]     Train net output #0: loss = 0.614597 (* 1 = 0.614597 loss)
I0526 18:12:41.280376 24213 sgd_solver.cpp:106] Iteration 4130, lr = 1e-09
I0526 18:12:46.634829 24213 solver.cpp:337] Iteration 4140, Testing net (#0)
I0526 18:12:48.638967 24213 solver.cpp:404]     Test net output #0: accuracy = 0.381818
I0526 18:12:48.639015 24213 solver.cpp:404]     Test net output #1: loss = 2.57191 (* 1 = 2.57191 loss)
I0526 18:12:49.171562 24213 solver.cpp:228] Iteration 4140, loss = 0.563036
I0526 18:12:49.171602 24213 solver.cpp:244]     Train net output #0: loss = 0.563036 (* 1 = 0.563036 loss)
I0526 18:12:49.171618 24213 sgd_solver.cpp:106] Iteration 4140, lr = 1e-09
I0526 18:12:55.123221 24213 solver.cpp:228] Iteration 4150, loss = 0.593988
I0526 18:12:55.123281 24213 solver.cpp:244]     Train net output #0: loss = 0.593988 (* 1 = 0.593988 loss)
I0526 18:12:55.123297 24213 sgd_solver.cpp:106] Iteration 4150, lr = 1e-09
I0526 18:13:01.068439 24213 solver.cpp:228] Iteration 4160, loss = 0.5723
I0526 18:13:01.068572 24213 solver.cpp:244]     Train net output #0: loss = 0.5723 (* 1 = 0.5723 loss)
I0526 18:13:01.068619 24213 sgd_solver.cpp:106] Iteration 4160, lr = 1e-09
I0526 18:13:06.420917 24213 solver.cpp:337] Iteration 4170, Testing net (#0)
I0526 18:13:08.597833 24213 solver.cpp:404]     Test net output #0: accuracy = 0.381818
I0526 18:13:08.597904 24213 solver.cpp:404]     Test net output #1: loss = 2.55173 (* 1 = 2.55173 loss)
I0526 18:13:09.136445 24213 solver.cpp:228] Iteration 4170, loss = 0.737665
I0526 18:13:09.136485 24213 solver.cpp:244]     Train net output #0: loss = 0.737665 (* 1 = 0.737665 loss)
I0526 18:13:09.136497 24213 sgd_solver.cpp:106] Iteration 4170, lr = 1e-09
I0526 18:13:15.081547 24213 solver.cpp:228] Iteration 4180, loss = 0.581183
I0526 18:13:15.081607 24213 solver.cpp:244]     Train net output #0: loss = 0.581183 (* 1 = 0.581183 loss)
I0526 18:13:15.081620 24213 sgd_solver.cpp:106] Iteration 4180, lr = 1e-09
I0526 18:13:21.029181 24213 solver.cpp:228] Iteration 4190, loss = 0.771385
I0526 18:13:21.029234 24213 solver.cpp:244]     Train net output #0: loss = 0.771385 (* 1 = 0.771385 loss)
I0526 18:13:21.029247 24213 sgd_solver.cpp:106] Iteration 4190, lr = 1e-09
I0526 18:13:26.384762 24213 solver.cpp:337] Iteration 4200, Testing net (#0)
I0526 18:13:28.544781 24213 solver.cpp:404]     Test net output #0: accuracy = 0.378182
I0526 18:13:28.544837 24213 solver.cpp:404]     Test net output #1: loss = 2.5591 (* 1 = 2.5591 loss)
I0526 18:13:29.081236 24213 solver.cpp:228] Iteration 4200, loss = 0.678862
I0526 18:13:29.081280 24213 solver.cpp:244]     Train net output #0: loss = 0.678862 (* 1 = 0.678862 loss)
I0526 18:13:29.081292 24213 sgd_solver.cpp:106] Iteration 4200, lr = 1e-09
I0526 18:13:35.032225 24213 solver.cpp:228] Iteration 4210, loss = 0.592078
I0526 18:13:35.032276 24213 solver.cpp:244]     Train net output #0: loss = 0.592078 (* 1 = 0.592078 loss)
I0526 18:13:35.032294 24213 sgd_solver.cpp:106] Iteration 4210, lr = 1e-09
I0526 18:13:40.972692 24213 solver.cpp:228] Iteration 4220, loss = 0.656687
I0526 18:13:40.972805 24213 solver.cpp:244]     Train net output #0: loss = 0.656687 (* 1 = 0.656687 loss)
I0526 18:13:40.972820 24213 sgd_solver.cpp:106] Iteration 4220, lr = 1e-09
I0526 18:13:46.331498 24213 solver.cpp:337] Iteration 4230, Testing net (#0)
I0526 18:13:48.386736 24213 solver.cpp:404]     Test net output #0: accuracy = 0.374545
I0526 18:13:48.386811 24213 solver.cpp:404]     Test net output #1: loss = 2.59487 (* 1 = 2.59487 loss)
I0526 18:13:48.918263 24213 solver.cpp:228] Iteration 4230, loss = 0.723357
I0526 18:13:48.918325 24213 solver.cpp:244]     Train net output #0: loss = 0.723357 (* 1 = 0.723357 loss)
I0526 18:13:48.918344 24213 sgd_solver.cpp:106] Iteration 4230, lr = 1e-09
I0526 18:13:54.863034 24213 solver.cpp:228] Iteration 4240, loss = 0.66539
I0526 18:13:54.863092 24213 solver.cpp:244]     Train net output #0: loss = 0.66539 (* 1 = 0.66539 loss)
I0526 18:13:54.863106 24213 sgd_solver.cpp:106] Iteration 4240, lr = 1e-09
I0526 18:14:00.814337 24213 solver.cpp:228] Iteration 4250, loss = 0.685876
I0526 18:14:00.814396 24213 solver.cpp:244]     Train net output #0: loss = 0.685876 (* 1 = 0.685876 loss)
I0526 18:14:00.814406 24213 sgd_solver.cpp:106] Iteration 4250, lr = 1e-09
I0526 18:14:06.166339 24213 solver.cpp:337] Iteration 4260, Testing net (#0)
I0526 18:14:08.398144 24213 solver.cpp:404]     Test net output #0: accuracy = 0.387273
I0526 18:14:08.398205 24213 solver.cpp:404]     Test net output #1: loss = 2.5379 (* 1 = 2.5379 loss)
I0526 18:14:08.932234 24213 solver.cpp:228] Iteration 4260, loss = 0.683239
I0526 18:14:08.932294 24213 solver.cpp:244]     Train net output #0: loss = 0.683239 (* 1 = 0.683239 loss)
I0526 18:14:08.932312 24213 sgd_solver.cpp:106] Iteration 4260, lr = 1e-09
I0526 18:14:14.882942 24213 solver.cpp:228] Iteration 4270, loss = 0.62574
I0526 18:14:14.883116 24213 solver.cpp:244]     Train net output #0: loss = 0.62574 (* 1 = 0.62574 loss)
I0526 18:14:14.883136 24213 sgd_solver.cpp:106] Iteration 4270, lr = 1e-09
I0526 18:14:20.826349 24213 solver.cpp:228] Iteration 4280, loss = 0.623136
I0526 18:14:20.826400 24213 solver.cpp:244]     Train net output #0: loss = 0.623136 (* 1 = 0.623136 loss)
I0526 18:14:20.826412 24213 sgd_solver.cpp:106] Iteration 4280, lr = 1e-09
I0526 18:14:26.184787 24213 solver.cpp:337] Iteration 4290, Testing net (#0)
I0526 18:14:28.173442 24213 solver.cpp:404]     Test net output #0: accuracy = 0.383636
I0526 18:14:28.173529 24213 solver.cpp:404]     Test net output #1: loss = 2.53749 (* 1 = 2.53749 loss)
I0526 18:14:28.709799 24213 solver.cpp:228] Iteration 4290, loss = 0.668003
I0526 18:14:28.709851 24213 solver.cpp:244]     Train net output #0: loss = 0.668003 (* 1 = 0.668003 loss)
I0526 18:14:28.709863 24213 sgd_solver.cpp:106] Iteration 4290, lr = 1e-09
I0526 18:14:34.660501 24213 solver.cpp:228] Iteration 4300, loss = 0.731776
I0526 18:14:34.660559 24213 solver.cpp:244]     Train net output #0: loss = 0.731776 (* 1 = 0.731776 loss)
I0526 18:14:34.660573 24213 sgd_solver.cpp:106] Iteration 4300, lr = 1e-09
I0526 18:14:40.601577 24213 solver.cpp:228] Iteration 4310, loss = 0.7419
I0526 18:14:40.601621 24213 solver.cpp:244]     Train net output #0: loss = 0.7419 (* 1 = 0.7419 loss)
I0526 18:14:40.601634 24213 sgd_solver.cpp:106] Iteration 4310, lr = 1e-09
I0526 18:14:45.954949 24213 solver.cpp:337] Iteration 4320, Testing net (#0)
I0526 18:14:48.186529 24213 solver.cpp:404]     Test net output #0: accuracy = 0.38
I0526 18:14:48.186576 24213 solver.cpp:404]     Test net output #1: loss = 2.57452 (* 1 = 2.57452 loss)
I0526 18:14:48.719162 24213 solver.cpp:228] Iteration 4320, loss = 0.626882
I0526 18:14:48.719213 24213 solver.cpp:244]     Train net output #0: loss = 0.626882 (* 1 = 0.626882 loss)
I0526 18:14:48.719229 24213 sgd_solver.cpp:106] Iteration 4320, lr = 1e-09
I0526 18:14:54.670853 24213 solver.cpp:228] Iteration 4330, loss = 0.648401
I0526 18:14:54.670907 24213 solver.cpp:244]     Train net output #0: loss = 0.648401 (* 1 = 0.648401 loss)
I0526 18:14:54.670923 24213 sgd_solver.cpp:106] Iteration 4330, lr = 1e-09
I0526 18:15:00.615131 24213 solver.cpp:228] Iteration 4340, loss = 0.618803
I0526 18:15:00.615188 24213 solver.cpp:244]     Train net output #0: loss = 0.618803 (* 1 = 0.618803 loss)
I0526 18:15:00.615206 24213 sgd_solver.cpp:106] Iteration 4340, lr = 1e-09
I0526 18:15:05.967466 24213 solver.cpp:337] Iteration 4350, Testing net (#0)
I0526 18:15:08.052021 24213 solver.cpp:404]     Test net output #0: accuracy = 0.383636
I0526 18:15:08.052072 24213 solver.cpp:404]     Test net output #1: loss = 2.55922 (* 1 = 2.55922 loss)
I0526 18:15:08.583668 24213 solver.cpp:228] Iteration 4350, loss = 0.737322
I0526 18:15:08.583737 24213 solver.cpp:244]     Train net output #0: loss = 0.737322 (* 1 = 0.737322 loss)
I0526 18:15:08.583755 24213 sgd_solver.cpp:106] Iteration 4350, lr = 1e-09
I0526 18:15:14.532333 24213 solver.cpp:228] Iteration 4360, loss = 0.692623
I0526 18:15:14.532385 24213 solver.cpp:244]     Train net output #0: loss = 0.692623 (* 1 = 0.692623 loss)
I0526 18:15:14.532397 24213 sgd_solver.cpp:106] Iteration 4360, lr = 1e-09
I0526 18:15:20.482323 24213 solver.cpp:228] Iteration 4370, loss = 0.741459
I0526 18:15:20.482496 24213 solver.cpp:244]     Train net output #0: loss = 0.741459 (* 1 = 0.741459 loss)
I0526 18:15:20.482517 24213 sgd_solver.cpp:106] Iteration 4370, lr = 1e-09
I0526 18:15:25.829268 24213 solver.cpp:337] Iteration 4380, Testing net (#0)
I0526 18:15:27.915812 24213 solver.cpp:404]     Test net output #0: accuracy = 0.381818
I0526 18:15:27.915860 24213 solver.cpp:404]     Test net output #1: loss = 2.54633 (* 1 = 2.54633 loss)
I0526 18:15:28.449720 24213 solver.cpp:228] Iteration 4380, loss = 0.657361
I0526 18:15:28.449766 24213 solver.cpp:244]     Train net output #0: loss = 0.657361 (* 1 = 0.657361 loss)
I0526 18:15:28.449779 24213 sgd_solver.cpp:106] Iteration 4380, lr = 1e-09
I0526 18:15:34.395721 24213 solver.cpp:228] Iteration 4390, loss = 0.676152
I0526 18:15:34.395783 24213 solver.cpp:244]     Train net output #0: loss = 0.676152 (* 1 = 0.676152 loss)
I0526 18:15:34.395800 24213 sgd_solver.cpp:106] Iteration 4390, lr = 1e-09
I0526 18:15:40.346453 24213 solver.cpp:228] Iteration 4400, loss = 0.649135
I0526 18:15:40.346504 24213 solver.cpp:244]     Train net output #0: loss = 0.649135 (* 1 = 0.649135 loss)
I0526 18:15:40.346518 24213 sgd_solver.cpp:106] Iteration 4400, lr = 1e-09
I0526 18:15:45.700825 24213 solver.cpp:337] Iteration 4410, Testing net (#0)
I0526 18:15:47.763437 24213 solver.cpp:404]     Test net output #0: accuracy = 0.381818
I0526 18:15:47.763497 24213 solver.cpp:404]     Test net output #1: loss = 2.56084 (* 1 = 2.56084 loss)
I0526 18:15:48.295339 24213 solver.cpp:228] Iteration 4410, loss = 0.708927
I0526 18:15:48.295385 24213 solver.cpp:244]     Train net output #0: loss = 0.708927 (* 1 = 0.708927 loss)
I0526 18:15:48.295402 24213 sgd_solver.cpp:106] Iteration 4410, lr = 1e-09
I0526 18:15:54.240962 24213 solver.cpp:228] Iteration 4420, loss = 0.738672
I0526 18:15:54.241092 24213 solver.cpp:244]     Train net output #0: loss = 0.738672 (* 1 = 0.738672 loss)
I0526 18:15:54.241112 24213 sgd_solver.cpp:106] Iteration 4420, lr = 1e-09
I0526 18:16:00.188602 24213 solver.cpp:228] Iteration 4430, loss = 0.607359
I0526 18:16:00.188659 24213 solver.cpp:244]     Train net output #0: loss = 0.607359 (* 1 = 0.607359 loss)
I0526 18:16:00.188678 24213 sgd_solver.cpp:106] Iteration 4430, lr = 1e-09
I0526 18:16:05.544932 24213 solver.cpp:337] Iteration 4440, Testing net (#0)
I0526 18:16:07.610525 24213 solver.cpp:404]     Test net output #0: accuracy = 0.38
I0526 18:16:07.610563 24213 solver.cpp:404]     Test net output #1: loss = 2.56949 (* 1 = 2.56949 loss)
I0526 18:16:08.146471 24213 solver.cpp:228] Iteration 4440, loss = 0.654933
I0526 18:16:08.146509 24213 solver.cpp:244]     Train net output #0: loss = 0.654933 (* 1 = 0.654933 loss)
I0526 18:16:08.146522 24213 sgd_solver.cpp:106] Iteration 4440, lr = 1e-09
I0526 18:16:14.088860 24213 solver.cpp:228] Iteration 4450, loss = 0.694799
I0526 18:16:14.088915 24213 solver.cpp:244]     Train net output #0: loss = 0.694799 (* 1 = 0.694799 loss)
I0526 18:16:14.088927 24213 sgd_solver.cpp:106] Iteration 4450, lr = 1e-09
I0526 18:16:20.032995 24213 solver.cpp:228] Iteration 4460, loss = 0.602942
I0526 18:16:20.033038 24213 solver.cpp:244]     Train net output #0: loss = 0.602942 (* 1 = 0.602942 loss)
I0526 18:16:20.033049 24213 sgd_solver.cpp:106] Iteration 4460, lr = 1e-09
I0526 18:16:25.385788 24213 solver.cpp:337] Iteration 4470, Testing net (#0)
I0526 18:16:27.477509 24213 solver.cpp:404]     Test net output #0: accuracy = 0.381818
I0526 18:16:27.477552 24213 solver.cpp:404]     Test net output #1: loss = 2.56773 (* 1 = 2.56773 loss)
I0526 18:16:28.014987 24213 solver.cpp:228] Iteration 4470, loss = 0.61908
I0526 18:16:28.015034 24213 solver.cpp:244]     Train net output #0: loss = 0.61908 (* 1 = 0.61908 loss)
I0526 18:16:28.015048 24213 sgd_solver.cpp:106] Iteration 4470, lr = 1e-09
I0526 18:16:33.958488 24213 solver.cpp:228] Iteration 4480, loss = 0.656483
I0526 18:16:33.958526 24213 solver.cpp:244]     Train net output #0: loss = 0.656483 (* 1 = 0.656483 loss)
I0526 18:16:33.958539 24213 sgd_solver.cpp:106] Iteration 4480, lr = 1e-09
I0526 18:16:39.902509 24213 solver.cpp:228] Iteration 4490, loss = 0.651008
I0526 18:16:39.902576 24213 solver.cpp:244]     Train net output #0: loss = 0.651008 (* 1 = 0.651008 loss)
I0526 18:16:39.902593 24213 sgd_solver.cpp:106] Iteration 4490, lr = 1e-09
I0526 18:16:45.256567 24213 solver.cpp:337] Iteration 4500, Testing net (#0)
I0526 18:16:47.275035 24213 solver.cpp:404]     Test net output #0: accuracy = 0.381818
I0526 18:16:47.275076 24213 solver.cpp:404]     Test net output #1: loss = 2.56977 (* 1 = 2.56977 loss)
I0526 18:16:47.809028 24213 solver.cpp:228] Iteration 4500, loss = 0.654471
I0526 18:16:47.809069 24213 solver.cpp:244]     Train net output #0: loss = 0.654471 (* 1 = 0.654471 loss)
I0526 18:16:47.809085 24213 sgd_solver.cpp:106] Iteration 4500, lr = 1e-09
I0526 18:16:53.751294 24213 solver.cpp:228] Iteration 4510, loss = 0.64351
I0526 18:16:53.751353 24213 solver.cpp:244]     Train net output #0: loss = 0.64351 (* 1 = 0.64351 loss)
I0526 18:16:53.751366 24213 sgd_solver.cpp:106] Iteration 4510, lr = 1e-09
I0526 18:16:59.696544 24213 solver.cpp:228] Iteration 4520, loss = 0.712025
I0526 18:16:59.696753 24213 solver.cpp:244]     Train net output #0: loss = 0.712025 (* 1 = 0.712025 loss)
I0526 18:16:59.696769 24213 sgd_solver.cpp:106] Iteration 4520, lr = 1e-09
I0526 18:17:05.053689 24213 solver.cpp:337] Iteration 4530, Testing net (#0)
I0526 18:17:07.004573 24213 solver.cpp:404]     Test net output #0: accuracy = 0.387273
I0526 18:17:07.004616 24213 solver.cpp:404]     Test net output #1: loss = 2.53563 (* 1 = 2.53563 loss)
I0526 18:17:07.536453 24213 solver.cpp:228] Iteration 4530, loss = 0.757456
I0526 18:17:07.536496 24213 solver.cpp:244]     Train net output #0: loss = 0.757456 (* 1 = 0.757456 loss)
I0526 18:17:07.536514 24213 sgd_solver.cpp:106] Iteration 4530, lr = 1e-09
I0526 18:17:13.482079 24213 solver.cpp:228] Iteration 4540, loss = 0.669204
I0526 18:17:13.482139 24213 solver.cpp:244]     Train net output #0: loss = 0.669204 (* 1 = 0.669204 loss)
I0526 18:17:13.482156 24213 sgd_solver.cpp:106] Iteration 4540, lr = 1e-09
I0526 18:17:19.426841 24213 solver.cpp:228] Iteration 4550, loss = 0.648602
I0526 18:17:19.426889 24213 solver.cpp:244]     Train net output #0: loss = 0.648602 (* 1 = 0.648602 loss)
I0526 18:17:19.426905 24213 sgd_solver.cpp:106] Iteration 4550, lr = 1e-09
I0526 18:17:24.894870 24213 solver.cpp:337] Iteration 4560, Testing net (#0)
I0526 18:17:27.165189 24213 solver.cpp:404]     Test net output #0: accuracy = 0.381818
I0526 18:17:27.165241 24213 solver.cpp:404]     Test net output #1: loss = 2.57245 (* 1 = 2.57245 loss)
I0526 18:17:27.699203 24213 solver.cpp:228] Iteration 4560, loss = 0.683175
I0526 18:17:27.699254 24213 solver.cpp:244]     Train net output #0: loss = 0.683175 (* 1 = 0.683175 loss)
I0526 18:17:27.699266 24213 sgd_solver.cpp:106] Iteration 4560, lr = 1e-09
I0526 18:17:33.649308 24213 solver.cpp:228] Iteration 4570, loss = 0.68227
I0526 18:17:33.649447 24213 solver.cpp:244]     Train net output #0: loss = 0.68227 (* 1 = 0.68227 loss)
I0526 18:17:33.649461 24213 sgd_solver.cpp:106] Iteration 4570, lr = 1e-09
I0526 18:17:39.588348 24213 solver.cpp:228] Iteration 4580, loss = 0.658656
I0526 18:17:39.588395 24213 solver.cpp:244]     Train net output #0: loss = 0.658656 (* 1 = 0.658656 loss)
I0526 18:17:39.588412 24213 sgd_solver.cpp:106] Iteration 4580, lr = 1e-09
I0526 18:17:44.939259 24213 solver.cpp:337] Iteration 4590, Testing net (#0)
I0526 18:17:46.911917 24213 solver.cpp:404]     Test net output #0: accuracy = 0.378182
I0526 18:17:46.911967 24213 solver.cpp:404]     Test net output #1: loss = 2.54965 (* 1 = 2.54965 loss)
I0526 18:17:47.443830 24213 solver.cpp:228] Iteration 4590, loss = 0.655909
I0526 18:17:47.443886 24213 solver.cpp:244]     Train net output #0: loss = 0.655909 (* 1 = 0.655909 loss)
I0526 18:17:47.443899 24213 sgd_solver.cpp:106] Iteration 4590, lr = 1e-09
I0526 18:17:53.384929 24213 solver.cpp:228] Iteration 4600, loss = 0.640523
I0526 18:17:53.384989 24213 solver.cpp:244]     Train net output #0: loss = 0.640523 (* 1 = 0.640523 loss)
I0526 18:17:53.385000 24213 sgd_solver.cpp:106] Iteration 4600, lr = 1e-09
I0526 18:17:59.334259 24213 solver.cpp:228] Iteration 4610, loss = 0.780071
I0526 18:17:59.334316 24213 solver.cpp:244]     Train net output #0: loss = 0.780071 (* 1 = 0.780071 loss)
I0526 18:17:59.334331 24213 sgd_solver.cpp:106] Iteration 4610, lr = 1e-09
I0526 18:18:04.680976 24213 solver.cpp:337] Iteration 4620, Testing net (#0)
I0526 18:18:06.632457 24213 solver.cpp:404]     Test net output #0: accuracy = 0.387273
I0526 18:18:06.632501 24213 solver.cpp:404]     Test net output #1: loss = 2.52751 (* 1 = 2.52751 loss)
I0526 18:18:07.164685 24213 solver.cpp:228] Iteration 4620, loss = 0.761492
I0526 18:18:07.164743 24213 solver.cpp:244]     Train net output #0: loss = 0.761492 (* 1 = 0.761492 loss)
I0526 18:18:07.164762 24213 sgd_solver.cpp:106] Iteration 4620, lr = 1e-09
I0526 18:18:13.109741 24213 solver.cpp:228] Iteration 4630, loss = 0.627318
I0526 18:18:13.109797 24213 solver.cpp:244]     Train net output #0: loss = 0.627318 (* 1 = 0.627318 loss)
I0526 18:18:13.109809 24213 sgd_solver.cpp:106] Iteration 4630, lr = 1e-09
I0526 18:18:19.060201 24213 solver.cpp:228] Iteration 4640, loss = 0.595492
I0526 18:18:19.060245 24213 solver.cpp:244]     Train net output #0: loss = 0.595492 (* 1 = 0.595492 loss)
I0526 18:18:19.060255 24213 sgd_solver.cpp:106] Iteration 4640, lr = 1e-09
I0526 18:18:24.416471 24213 solver.cpp:337] Iteration 4650, Testing net (#0)
I0526 18:18:26.362081 24213 solver.cpp:404]     Test net output #0: accuracy = 0.390909
I0526 18:18:26.362118 24213 solver.cpp:404]     Test net output #1: loss = 2.53423 (* 1 = 2.53423 loss)
I0526 18:18:26.898180 24213 solver.cpp:228] Iteration 4650, loss = 0.706651
I0526 18:18:26.898233 24213 solver.cpp:244]     Train net output #0: loss = 0.706651 (* 1 = 0.706651 loss)
I0526 18:18:26.898247 24213 sgd_solver.cpp:106] Iteration 4650, lr = 1e-09
I0526 18:18:32.843814 24213 solver.cpp:228] Iteration 4660, loss = 0.606277
I0526 18:18:32.843859 24213 solver.cpp:244]     Train net output #0: loss = 0.606277 (* 1 = 0.606277 loss)
I0526 18:18:32.843871 24213 sgd_solver.cpp:106] Iteration 4660, lr = 1e-09
I0526 18:18:38.793522 24213 solver.cpp:228] Iteration 4670, loss = 0.834932
I0526 18:18:38.793624 24213 solver.cpp:244]     Train net output #0: loss = 0.834932 (* 1 = 0.834932 loss)
I0526 18:18:38.793638 24213 sgd_solver.cpp:106] Iteration 4670, lr = 1e-09
I0526 18:18:44.146052 24213 solver.cpp:337] Iteration 4680, Testing net (#0)
I0526 18:18:46.105023 24213 solver.cpp:404]     Test net output #0: accuracy = 0.383636
I0526 18:18:46.105064 24213 solver.cpp:404]     Test net output #1: loss = 2.55298 (* 1 = 2.55298 loss)
I0526 18:18:46.640583 24213 solver.cpp:228] Iteration 4680, loss = 0.76204
I0526 18:18:46.640624 24213 solver.cpp:244]     Train net output #0: loss = 0.76204 (* 1 = 0.76204 loss)
I0526 18:18:46.640640 24213 sgd_solver.cpp:106] Iteration 4680, lr = 1e-09
I0526 18:18:52.583222 24213 solver.cpp:228] Iteration 4690, loss = 0.700778
I0526 18:18:52.583266 24213 solver.cpp:244]     Train net output #0: loss = 0.700778 (* 1 = 0.700778 loss)
I0526 18:18:52.583277 24213 sgd_solver.cpp:106] Iteration 4690, lr = 1e-09
I0526 18:18:58.525410 24213 solver.cpp:228] Iteration 4700, loss = 0.656141
I0526 18:18:58.525452 24213 solver.cpp:244]     Train net output #0: loss = 0.656141 (* 1 = 0.656141 loss)
I0526 18:18:58.525463 24213 sgd_solver.cpp:106] Iteration 4700, lr = 1e-09
I0526 18:19:03.879472 24213 solver.cpp:337] Iteration 4710, Testing net (#0)
I0526 18:19:05.842658 24213 solver.cpp:404]     Test net output #0: accuracy = 0.385455
I0526 18:19:05.842705 24213 solver.cpp:404]     Test net output #1: loss = 2.56305 (* 1 = 2.56305 loss)
I0526 18:19:06.374011 24213 solver.cpp:228] Iteration 4710, loss = 0.607063
I0526 18:19:06.374053 24213 solver.cpp:244]     Train net output #0: loss = 0.607063 (* 1 = 0.607063 loss)
I0526 18:19:06.374064 24213 sgd_solver.cpp:106] Iteration 4710, lr = 1e-09
I0526 18:19:12.316833 24213 solver.cpp:228] Iteration 4720, loss = 0.575838
I0526 18:19:12.316997 24213 solver.cpp:244]     Train net output #0: loss = 0.575838 (* 1 = 0.575838 loss)
I0526 18:19:12.317014 24213 sgd_solver.cpp:106] Iteration 4720, lr = 1e-09
I0526 18:19:18.259097 24213 solver.cpp:228] Iteration 4730, loss = 0.697864
I0526 18:19:18.259140 24213 solver.cpp:244]     Train net output #0: loss = 0.697864 (* 1 = 0.697864 loss)
I0526 18:19:18.259151 24213 sgd_solver.cpp:106] Iteration 4730, lr = 1e-09
I0526 18:19:23.614356 24213 solver.cpp:337] Iteration 4740, Testing net (#0)
I0526 18:19:25.643173 24213 solver.cpp:404]     Test net output #0: accuracy = 0.383636
I0526 18:19:25.643226 24213 solver.cpp:404]     Test net output #1: loss = 2.53742 (* 1 = 2.53742 loss)
I0526 18:19:26.175634 24213 solver.cpp:228] Iteration 4740, loss = 0.650169
I0526 18:19:26.175685 24213 solver.cpp:244]     Train net output #0: loss = 0.650169 (* 1 = 0.650169 loss)
I0526 18:19:26.175699 24213 sgd_solver.cpp:106] Iteration 4740, lr = 1e-09
I0526 18:19:32.117799 24213 solver.cpp:228] Iteration 4750, loss = 0.762164
I0526 18:19:32.117856 24213 solver.cpp:244]     Train net output #0: loss = 0.762164 (* 1 = 0.762164 loss)
I0526 18:19:32.117868 24213 sgd_solver.cpp:106] Iteration 4750, lr = 1e-09
I0526 18:19:38.065665 24213 solver.cpp:228] Iteration 4760, loss = 0.648132
I0526 18:19:38.065726 24213 solver.cpp:244]     Train net output #0: loss = 0.648132 (* 1 = 0.648132 loss)
I0526 18:19:38.065742 24213 sgd_solver.cpp:106] Iteration 4760, lr = 1e-09
I0526 18:19:43.413836 24213 solver.cpp:337] Iteration 4770, Testing net (#0)
I0526 18:19:45.433863 24213 solver.cpp:404]     Test net output #0: accuracy = 0.381818
I0526 18:19:45.433923 24213 solver.cpp:404]     Test net output #1: loss = 2.56764 (* 1 = 2.56764 loss)
I0526 18:19:45.972707 24213 solver.cpp:228] Iteration 4770, loss = 0.543994
I0526 18:19:45.972897 24213 solver.cpp:244]     Train net output #0: loss = 0.543994 (* 1 = 0.543994 loss)
I0526 18:19:45.972949 24213 sgd_solver.cpp:106] Iteration 4770, lr = 1e-09
I0526 18:19:51.918086 24213 solver.cpp:228] Iteration 4780, loss = 0.645446
I0526 18:19:51.918130 24213 solver.cpp:244]     Train net output #0: loss = 0.645446 (* 1 = 0.645446 loss)
I0526 18:19:51.918141 24213 sgd_solver.cpp:106] Iteration 4780, lr = 1e-09
I0526 18:19:57.861088 24213 solver.cpp:228] Iteration 4790, loss = 0.760838
I0526 18:19:57.861143 24213 solver.cpp:244]     Train net output #0: loss = 0.760838 (* 1 = 0.760838 loss)
I0526 18:19:57.861155 24213 sgd_solver.cpp:106] Iteration 4790, lr = 1e-09
I0526 18:20:03.219177 24213 solver.cpp:337] Iteration 4800, Testing net (#0)
I0526 18:20:05.502039 24213 solver.cpp:404]     Test net output #0: accuracy = 0.38
I0526 18:20:05.502087 24213 solver.cpp:404]     Test net output #1: loss = 2.55967 (* 1 = 2.55967 loss)
I0526 18:20:06.033695 24213 solver.cpp:228] Iteration 4800, loss = 0.564883
I0526 18:20:06.033746 24213 solver.cpp:244]     Train net output #0: loss = 0.564883 (* 1 = 0.564883 loss)
I0526 18:20:06.033757 24213 sgd_solver.cpp:106] Iteration 4800, lr = 1e-09
I0526 18:20:11.979814 24213 solver.cpp:228] Iteration 4810, loss = 0.656689
I0526 18:20:11.979848 24213 solver.cpp:244]     Train net output #0: loss = 0.656689 (* 1 = 0.656689 loss)
I0526 18:20:11.979859 24213 sgd_solver.cpp:106] Iteration 4810, lr = 1e-09
I0526 18:20:17.916090 24213 solver.cpp:228] Iteration 4820, loss = 0.59827
I0526 18:20:17.916201 24213 solver.cpp:244]     Train net output #0: loss = 0.59827 (* 1 = 0.59827 loss)
I0526 18:20:17.916214 24213 sgd_solver.cpp:106] Iteration 4820, lr = 1e-09
I0526 18:20:23.267194 24213 solver.cpp:337] Iteration 4830, Testing net (#0)
I0526 18:20:25.438305 24213 solver.cpp:404]     Test net output #0: accuracy = 0.381818
I0526 18:20:25.438369 24213 solver.cpp:404]     Test net output #1: loss = 2.57087 (* 1 = 2.57087 loss)
I0526 18:20:25.970763 24213 solver.cpp:228] Iteration 4830, loss = 0.645309
I0526 18:20:25.970803 24213 solver.cpp:244]     Train net output #0: loss = 0.645309 (* 1 = 0.645309 loss)
I0526 18:20:25.970813 24213 sgd_solver.cpp:106] Iteration 4830, lr = 1e-09
I0526 18:20:31.915055 24213 solver.cpp:228] Iteration 4840, loss = 0.592445
I0526 18:20:31.915094 24213 solver.cpp:244]     Train net output #0: loss = 0.592445 (* 1 = 0.592445 loss)
I0526 18:20:31.915107 24213 sgd_solver.cpp:106] Iteration 4840, lr = 1e-09
I0526 18:20:37.857013 24213 solver.cpp:228] Iteration 4850, loss = 0.70773
I0526 18:20:37.857085 24213 solver.cpp:244]     Train net output #0: loss = 0.70773 (* 1 = 0.70773 loss)
I0526 18:20:37.857098 24213 sgd_solver.cpp:106] Iteration 4850, lr = 1e-09
I0526 18:20:43.206897 24213 solver.cpp:337] Iteration 4860, Testing net (#0)
I0526 18:20:44.001252 24213 blocking_queue.cpp:50] Data layer prefetch queue empty
I0526 18:20:45.373082 24213 solver.cpp:404]     Test net output #0: accuracy = 0.383636
I0526 18:20:45.373131 24213 solver.cpp:404]     Test net output #1: loss = 2.56814 (* 1 = 2.56814 loss)
I0526 18:20:45.910599 24213 solver.cpp:228] Iteration 4860, loss = 0.702832
I0526 18:20:45.910650 24213 solver.cpp:244]     Train net output #0: loss = 0.702832 (* 1 = 0.702832 loss)
I0526 18:20:45.910661 24213 sgd_solver.cpp:106] Iteration 4860, lr = 1e-09
I0526 18:20:51.853683 24213 solver.cpp:228] Iteration 4870, loss = 0.731506
I0526 18:20:51.853816 24213 solver.cpp:244]     Train net output #0: loss = 0.731506 (* 1 = 0.731506 loss)
I0526 18:20:51.853831 24213 sgd_solver.cpp:106] Iteration 4870, lr = 1e-09
I0526 18:20:57.796288 24213 solver.cpp:228] Iteration 4880, loss = 0.632809
I0526 18:20:57.796334 24213 solver.cpp:244]     Train net output #0: loss = 0.632809 (* 1 = 0.632809 loss)
I0526 18:20:57.796346 24213 sgd_solver.cpp:106] Iteration 4880, lr = 1e-09
I0526 18:21:03.144083 24213 solver.cpp:337] Iteration 4890, Testing net (#0)
I0526 18:21:05.302556 24213 solver.cpp:404]     Test net output #0: accuracy = 0.383636
I0526 18:21:05.302594 24213 solver.cpp:404]     Test net output #1: loss = 2.55617 (* 1 = 2.55617 loss)
I0526 18:21:05.839375 24213 solver.cpp:228] Iteration 4890, loss = 0.668577
I0526 18:21:05.839435 24213 solver.cpp:244]     Train net output #0: loss = 0.668577 (* 1 = 0.668577 loss)
I0526 18:21:05.839448 24213 sgd_solver.cpp:106] Iteration 4890, lr = 1e-09
I0526 18:21:11.786828 24213 solver.cpp:228] Iteration 4900, loss = 0.574542
I0526 18:21:11.786870 24213 solver.cpp:244]     Train net output #0: loss = 0.574542 (* 1 = 0.574542 loss)
I0526 18:21:11.786885 24213 sgd_solver.cpp:106] Iteration 4900, lr = 1e-09
I0526 18:21:17.730016 24213 solver.cpp:228] Iteration 4910, loss = 0.57859
I0526 18:21:17.730070 24213 solver.cpp:244]     Train net output #0: loss = 0.57859 (* 1 = 0.57859 loss)
I0526 18:21:17.730082 24213 sgd_solver.cpp:106] Iteration 4910, lr = 1e-09
I0526 18:21:23.082846 24213 solver.cpp:337] Iteration 4920, Testing net (#0)
I0526 18:21:25.102543 24213 solver.cpp:404]     Test net output #0: accuracy = 0.385455
I0526 18:21:25.102596 24213 solver.cpp:404]     Test net output #1: loss = 2.53454 (* 1 = 2.53454 loss)
I0526 18:21:25.634675 24213 solver.cpp:228] Iteration 4920, loss = 0.756101
I0526 18:21:25.634714 24213 solver.cpp:244]     Train net output #0: loss = 0.756101 (* 1 = 0.756101 loss)
I0526 18:21:25.634727 24213 sgd_solver.cpp:106] Iteration 4920, lr = 1e-09
I0526 18:21:31.577006 24213 solver.cpp:228] Iteration 4930, loss = 0.705551
I0526 18:21:31.577051 24213 solver.cpp:244]     Train net output #0: loss = 0.705551 (* 1 = 0.705551 loss)
I0526 18:21:31.577061 24213 sgd_solver.cpp:106] Iteration 4930, lr = 1e-09
I0526 18:21:37.514482 24213 solver.cpp:228] Iteration 4940, loss = 0.710771
I0526 18:21:37.514528 24213 solver.cpp:244]     Train net output #0: loss = 0.710771 (* 1 = 0.710771 loss)
I0526 18:21:37.514545 24213 sgd_solver.cpp:106] Iteration 4940, lr = 1e-09
I0526 18:21:42.866291 24213 solver.cpp:337] Iteration 4950, Testing net (#0)
I0526 18:21:44.768620 24213 solver.cpp:404]     Test net output #0: accuracy = 0.383636
I0526 18:21:44.768667 24213 solver.cpp:404]     Test net output #1: loss = 2.55984 (* 1 = 2.55984 loss)
I0526 18:21:45.301054 24213 solver.cpp:228] Iteration 4950, loss = 0.554223
I0526 18:21:45.301110 24213 solver.cpp:244]     Train net output #0: loss = 0.554223 (* 1 = 0.554223 loss)
I0526 18:21:45.301126 24213 sgd_solver.cpp:106] Iteration 4950, lr = 1e-09
I0526 18:21:51.242517 24213 solver.cpp:228] Iteration 4960, loss = 0.617169
I0526 18:21:51.242566 24213 solver.cpp:244]     Train net output #0: loss = 0.617169 (* 1 = 0.617169 loss)
I0526 18:21:51.242578 24213 sgd_solver.cpp:106] Iteration 4960, lr = 1e-09
I0526 18:21:57.182293 24213 solver.cpp:228] Iteration 4970, loss = 0.624084
I0526 18:21:57.182426 24213 solver.cpp:244]     Train net output #0: loss = 0.624084 (* 1 = 0.624084 loss)
I0526 18:21:57.182440 24213 sgd_solver.cpp:106] Iteration 4970, lr = 1e-09
I0526 18:22:02.532481 24213 solver.cpp:337] Iteration 4980, Testing net (#0)
I0526 18:22:04.483489 24213 solver.cpp:404]     Test net output #0: accuracy = 0.381818
I0526 18:22:04.483551 24213 solver.cpp:404]     Test net output #1: loss = 2.5623 (* 1 = 2.5623 loss)
I0526 18:22:05.015029 24213 solver.cpp:228] Iteration 4980, loss = 0.62075
I0526 18:22:05.015074 24213 solver.cpp:244]     Train net output #0: loss = 0.62075 (* 1 = 0.62075 loss)
I0526 18:22:05.015090 24213 sgd_solver.cpp:106] Iteration 4980, lr = 1e-09
I0526 18:22:10.964011 24213 solver.cpp:228] Iteration 4990, loss = 0.683463
I0526 18:22:10.964054 24213 solver.cpp:244]     Train net output #0: loss = 0.683463 (* 1 = 0.683463 loss)
I0526 18:22:10.964071 24213 sgd_solver.cpp:106] Iteration 4990, lr = 1e-09
I0526 18:22:16.313019 24213 solver.cpp:454] Snapshotting to binary proto file snapshot2/caffe_CAM_finetuneMIT_iter_5000.caffemodel
I0526 18:22:16.418750 24213 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot2/caffe_CAM_finetuneMIT_iter_5000.solverstate
I0526 18:22:16.979938 24213 solver.cpp:228] Iteration 5000, loss = 0.667934
I0526 18:22:16.980000 24213 solver.cpp:244]     Train net output #0: loss = 0.667934 (* 1 = 0.667934 loss)
I0526 18:22:16.980015 24213 sgd_solver.cpp:106] Iteration 5000, lr = 1e-10
I0526 18:22:22.333003 24213 solver.cpp:337] Iteration 5010, Testing net (#0)
I0526 18:22:24.233881 24213 solver.cpp:404]     Test net output #0: accuracy = 0.385455
I0526 18:22:24.233929 24213 solver.cpp:404]     Test net output #1: loss = 2.54658 (* 1 = 2.54658 loss)
I0526 18:22:24.765929 24213 solver.cpp:228] Iteration 5010, loss = 0.662645
I0526 18:22:24.765971 24213 solver.cpp:244]     Train net output #0: loss = 0.662645 (* 1 = 0.662645 loss)
I0526 18:22:24.765987 24213 sgd_solver.cpp:106] Iteration 5010, lr = 1e-10
I0526 18:22:30.705430 24213 solver.cpp:228] Iteration 5020, loss = 0.629643
I0526 18:22:30.705575 24213 solver.cpp:244]     Train net output #0: loss = 0.629643 (* 1 = 0.629643 loss)
I0526 18:22:30.705605 24213 sgd_solver.cpp:106] Iteration 5020, lr = 1e-10
I0526 18:22:36.647616 24213 solver.cpp:228] Iteration 5030, loss = 0.631883
I0526 18:22:36.647672 24213 solver.cpp:244]     Train net output #0: loss = 0.631883 (* 1 = 0.631883 loss)
I0526 18:22:36.647686 24213 sgd_solver.cpp:106] Iteration 5030, lr = 1e-10
I0526 18:22:42.005239 24213 solver.cpp:337] Iteration 5040, Testing net (#0)
I0526 18:22:43.948621 24213 solver.cpp:404]     Test net output #0: accuracy = 0.38
I0526 18:22:43.948662 24213 solver.cpp:404]     Test net output #1: loss = 2.55746 (* 1 = 2.55746 loss)
I0526 18:22:44.480461 24213 solver.cpp:228] Iteration 5040, loss = 0.789066
I0526 18:22:44.480506 24213 solver.cpp:244]     Train net output #0: loss = 0.789066 (* 1 = 0.789066 loss)
I0526 18:22:44.480517 24213 sgd_solver.cpp:106] Iteration 5040, lr = 1e-10
I0526 18:22:50.426084 24213 solver.cpp:228] Iteration 5050, loss = 0.674218
I0526 18:22:50.426153 24213 solver.cpp:244]     Train net output #0: loss = 0.674218 (* 1 = 0.674218 loss)
I0526 18:22:50.426172 24213 sgd_solver.cpp:106] Iteration 5050, lr = 1e-10
I0526 18:22:56.369156 24213 solver.cpp:228] Iteration 5060, loss = 0.700514
I0526 18:22:56.369206 24213 solver.cpp:244]     Train net output #0: loss = 0.700514 (* 1 = 0.700514 loss)
I0526 18:22:56.369216 24213 sgd_solver.cpp:106] Iteration 5060, lr = 1e-10
I0526 18:23:01.719596 24213 solver.cpp:337] Iteration 5070, Testing net (#0)
I0526 18:23:03.731853 24213 solver.cpp:404]     Test net output #0: accuracy = 0.381818
I0526 18:23:03.731914 24213 solver.cpp:404]     Test net output #1: loss = 2.55334 (* 1 = 2.55334 loss)
I0526 18:23:04.264070 24213 solver.cpp:228] Iteration 5070, loss = 0.632249
I0526 18:23:04.264119 24213 solver.cpp:244]     Train net output #0: loss = 0.632249 (* 1 = 0.632249 loss)
I0526 18:23:04.264132 24213 sgd_solver.cpp:106] Iteration 5070, lr = 1e-10
I0526 18:23:10.210326 24213 solver.cpp:228] Iteration 5080, loss = 0.63348
I0526 18:23:10.210384 24213 solver.cpp:244]     Train net output #0: loss = 0.63348 (* 1 = 0.63348 loss)
I0526 18:23:10.210400 24213 sgd_solver.cpp:106] Iteration 5080, lr = 1e-10
I0526 18:23:16.152020 24213 solver.cpp:228] Iteration 5090, loss = 0.579343
I0526 18:23:16.152071 24213 solver.cpp:244]     Train net output #0: loss = 0.579343 (* 1 = 0.579343 loss)
I0526 18:23:16.152083 24213 sgd_solver.cpp:106] Iteration 5090, lr = 1e-10
I0526 18:23:21.503157 24213 solver.cpp:337] Iteration 5100, Testing net (#0)
I0526 18:23:23.735438 24213 solver.cpp:404]     Test net output #0: accuracy = 0.385455
I0526 18:23:23.735496 24213 solver.cpp:404]     Test net output #1: loss = 2.55902 (* 1 = 2.55902 loss)
I0526 18:23:24.267333 24213 solver.cpp:228] Iteration 5100, loss = 0.680162
I0526 18:23:24.267381 24213 solver.cpp:244]     Train net output #0: loss = 0.680162 (* 1 = 0.680162 loss)
I0526 18:23:24.267393 24213 sgd_solver.cpp:106] Iteration 5100, lr = 1e-10
I0526 18:23:30.208365 24213 solver.cpp:228] Iteration 5110, loss = 0.688674
I0526 18:23:30.208421 24213 solver.cpp:244]     Train net output #0: loss = 0.688674 (* 1 = 0.688674 loss)
I0526 18:23:30.208436 24213 sgd_solver.cpp:106] Iteration 5110, lr = 1e-10
I0526 18:23:36.149440 24213 solver.cpp:228] Iteration 5120, loss = 0.680409
I0526 18:23:36.149585 24213 solver.cpp:244]     Train net output #0: loss = 0.680409 (* 1 = 0.680409 loss)
I0526 18:23:36.149605 24213 sgd_solver.cpp:106] Iteration 5120, lr = 1e-10
I0526 18:23:41.511385 24213 solver.cpp:337] Iteration 5130, Testing net (#0)
I0526 18:23:43.619186 24213 solver.cpp:404]     Test net output #0: accuracy = 0.378182
I0526 18:23:43.619237 24213 solver.cpp:404]     Test net output #1: loss = 2.56821 (* 1 = 2.56821 loss)
I0526 18:23:44.152542 24213 solver.cpp:228] Iteration 5130, loss = 0.631903
I0526 18:23:44.152578 24213 solver.cpp:244]     Train net output #0: loss = 0.631903 (* 1 = 0.631903 loss)
I0526 18:23:44.152590 24213 sgd_solver.cpp:106] Iteration 5130, lr = 1e-10
I0526 18:23:50.092561 24213 solver.cpp:228] Iteration 5140, loss = 0.525698
I0526 18:23:50.092612 24213 solver.cpp:244]     Train net output #0: loss = 0.525698 (* 1 = 0.525698 loss)
I0526 18:23:50.092622 24213 sgd_solver.cpp:106] Iteration 5140, lr = 1e-10
I0526 18:23:56.040639 24213 solver.cpp:228] Iteration 5150, loss = 0.5525
I0526 18:23:56.040684 24213 solver.cpp:244]     Train net output #0: loss = 0.5525 (* 1 = 0.5525 loss)
I0526 18:23:56.040696 24213 sgd_solver.cpp:106] Iteration 5150, lr = 1e-10
I0526 18:24:01.394896 24213 solver.cpp:337] Iteration 5160, Testing net (#0)
I0526 18:24:03.437762 24213 solver.cpp:404]     Test net output #0: accuracy = 0.374545
I0526 18:24:03.437798 24213 solver.cpp:404]     Test net output #1: loss = 2.57966 (* 1 = 2.57966 loss)
I0526 18:24:03.969097 24213 solver.cpp:228] Iteration 5160, loss = 0.64136
I0526 18:24:03.969141 24213 solver.cpp:244]     Train net output #0: loss = 0.64136 (* 1 = 0.64136 loss)
I0526 18:24:03.969153 24213 sgd_solver.cpp:106] Iteration 5160, lr = 1e-10
I0526 18:24:09.915873 24213 solver.cpp:228] Iteration 5170, loss = 0.78064
I0526 18:24:09.915964 24213 solver.cpp:244]     Train net output #0: loss = 0.78064 (* 1 = 0.78064 loss)
I0526 18:24:09.915978 24213 sgd_solver.cpp:106] Iteration 5170, lr = 1e-10
I0526 18:24:15.858453 24213 solver.cpp:228] Iteration 5180, loss = 0.70782
I0526 18:24:15.858517 24213 solver.cpp:244]     Train net output #0: loss = 0.70782 (* 1 = 0.70782 loss)
I0526 18:24:15.858535 24213 sgd_solver.cpp:106] Iteration 5180, lr = 1e-10
I0526 18:24:21.211441 24213 solver.cpp:337] Iteration 5190, Testing net (#0)
I0526 18:24:23.274351 24213 solver.cpp:404]     Test net output #0: accuracy = 0.383636
I0526 18:24:23.274410 24213 solver.cpp:404]     Test net output #1: loss = 2.55263 (* 1 = 2.55263 loss)
I0526 18:24:23.806677 24213 solver.cpp:228] Iteration 5190, loss = 0.781042
I0526 18:24:23.806715 24213 solver.cpp:244]     Train net output #0: loss = 0.781042 (* 1 = 0.781042 loss)
I0526 18:24:23.806725 24213 sgd_solver.cpp:106] Iteration 5190, lr = 1e-10
I0526 18:24:29.746929 24213 solver.cpp:228] Iteration 5200, loss = 0.644893
I0526 18:24:29.746985 24213 solver.cpp:244]     Train net output #0: loss = 0.644893 (* 1 = 0.644893 loss)
I0526 18:24:29.746999 24213 sgd_solver.cpp:106] Iteration 5200, lr = 1e-10
I0526 18:24:35.698854 24213 solver.cpp:228] Iteration 5210, loss = 0.691705
I0526 18:24:35.698899 24213 solver.cpp:244]     Train net output #0: loss = 0.691705 (* 1 = 0.691705 loss)
I0526 18:24:35.698910 24213 sgd_solver.cpp:106] Iteration 5210, lr = 1e-10
I0526 18:24:41.048641 24213 solver.cpp:337] Iteration 5220, Testing net (#0)
I0526 18:24:43.151469 24213 solver.cpp:404]     Test net output #0: accuracy = 0.383636
I0526 18:24:43.151513 24213 solver.cpp:404]     Test net output #1: loss = 2.54707 (* 1 = 2.54707 loss)
I0526 18:24:43.682605 24213 solver.cpp:228] Iteration 5220, loss = 0.776208
I0526 18:24:43.682649 24213 solver.cpp:244]     Train net output #0: loss = 0.776208 (* 1 = 0.776208 loss)
I0526 18:24:43.682665 24213 sgd_solver.cpp:106] Iteration 5220, lr = 1e-10
I0526 18:24:49.628976 24213 solver.cpp:228] Iteration 5230, loss = 0.712609
I0526 18:24:49.629045 24213 solver.cpp:244]     Train net output #0: loss = 0.712609 (* 1 = 0.712609 loss)
I0526 18:24:49.629055 24213 sgd_solver.cpp:106] Iteration 5230, lr = 1e-10
I0526 18:24:55.575219 24213 solver.cpp:228] Iteration 5240, loss = 0.698037
I0526 18:24:55.575264 24213 solver.cpp:244]     Train net output #0: loss = 0.698037 (* 1 = 0.698037 loss)
I0526 18:24:55.575276 24213 sgd_solver.cpp:106] Iteration 5240, lr = 1e-10
I0526 18:25:00.927000 24213 solver.cpp:337] Iteration 5250, Testing net (#0)
I0526 18:25:02.935283 24213 solver.cpp:404]     Test net output #0: accuracy = 0.381818
I0526 18:25:02.935325 24213 solver.cpp:404]     Test net output #1: loss = 2.55904 (* 1 = 2.55904 loss)
I0526 18:25:03.467075 24213 solver.cpp:228] Iteration 5250, loss = 0.710059
I0526 18:25:03.467170 24213 solver.cpp:244]     Train net output #0: loss = 0.710059 (* 1 = 0.710059 loss)
I0526 18:25:03.467190 24213 sgd_solver.cpp:106] Iteration 5250, lr = 1e-10
I0526 18:25:09.412041 24213 solver.cpp:228] Iteration 5260, loss = 0.636541
I0526 18:25:09.412152 24213 solver.cpp:244]     Train net output #0: loss = 0.636541 (* 1 = 0.636541 loss)
I0526 18:25:09.412164 24213 sgd_solver.cpp:106] Iteration 5260, lr = 1e-10
I0526 18:25:15.362838 24213 solver.cpp:228] Iteration 5270, loss = 0.65861
I0526 18:25:15.362958 24213 solver.cpp:244]     Train net output #0: loss = 0.65861 (* 1 = 0.65861 loss)
I0526 18:25:15.362972 24213 sgd_solver.cpp:106] Iteration 5270, lr = 1e-10
I0526 18:25:20.709708 24213 solver.cpp:337] Iteration 5280, Testing net (#0)
I0526 18:25:22.907078 24213 solver.cpp:404]     Test net output #0: accuracy = 0.38
I0526 18:25:22.907150 24213 solver.cpp:404]     Test net output #1: loss = 2.57404 (* 1 = 2.57404 loss)
I0526 18:25:23.440634 24213 solver.cpp:228] Iteration 5280, loss = 0.65613
I0526 18:25:23.440671 24213 solver.cpp:244]     Train net output #0: loss = 0.65613 (* 1 = 0.65613 loss)
I0526 18:25:23.440682 24213 sgd_solver.cpp:106] Iteration 5280, lr = 1e-10
I0526 18:25:29.385037 24213 solver.cpp:228] Iteration 5290, loss = 0.762151
I0526 18:25:29.385079 24213 solver.cpp:244]     Train net output #0: loss = 0.762151 (* 1 = 0.762151 loss)
I0526 18:25:29.385090 24213 sgd_solver.cpp:106] Iteration 5290, lr = 1e-10
I0526 18:25:35.327424 24213 solver.cpp:228] Iteration 5300, loss = 0.655329
I0526 18:25:35.327466 24213 solver.cpp:244]     Train net output #0: loss = 0.655329 (* 1 = 0.655329 loss)
I0526 18:25:35.327477 24213 sgd_solver.cpp:106] Iteration 5300, lr = 1e-10
I0526 18:25:40.674566 24213 solver.cpp:337] Iteration 5310, Testing net (#0)
I0526 18:25:42.618352 24213 solver.cpp:404]     Test net output #0: accuracy = 0.385455
I0526 18:25:42.618396 24213 solver.cpp:404]     Test net output #1: loss = 2.54242 (* 1 = 2.54242 loss)
I0526 18:25:43.154623 24213 solver.cpp:228] Iteration 5310, loss = 0.608448
I0526 18:25:43.154726 24213 solver.cpp:244]     Train net output #0: loss = 0.608448 (* 1 = 0.608448 loss)
I0526 18:25:43.154767 24213 sgd_solver.cpp:106] Iteration 5310, lr = 1e-10
I0526 18:25:49.099239 24213 solver.cpp:228] Iteration 5320, loss = 0.651077
I0526 18:25:49.099367 24213 solver.cpp:244]     Train net output #0: loss = 0.651077 (* 1 = 0.651077 loss)
I0526 18:25:49.099381 24213 sgd_solver.cpp:106] Iteration 5320, lr = 1e-10
I0526 18:25:55.047071 24213 solver.cpp:228] Iteration 5330, loss = 0.677691
I0526 18:25:55.047113 24213 solver.cpp:244]     Train net output #0: loss = 0.677691 (* 1 = 0.677691 loss)
I0526 18:25:55.047124 24213 sgd_solver.cpp:106] Iteration 5330, lr = 1e-10
I0526 18:26:00.402174 24213 solver.cpp:337] Iteration 5340, Testing net (#0)
I0526 18:26:02.661782 24213 solver.cpp:404]     Test net output #0: accuracy = 0.383636
I0526 18:26:02.661830 24213 solver.cpp:404]     Test net output #1: loss = 2.54587 (* 1 = 2.54587 loss)
I0526 18:26:03.193253 24213 solver.cpp:228] Iteration 5340, loss = 0.652168
I0526 18:26:03.193300 24213 solver.cpp:244]     Train net output #0: loss = 0.652168 (* 1 = 0.652168 loss)
I0526 18:26:03.193311 24213 sgd_solver.cpp:106] Iteration 5340, lr = 1e-10
I0526 18:26:09.132433 24213 solver.cpp:228] Iteration 5350, loss = 0.67498
I0526 18:26:09.132486 24213 solver.cpp:244]     Train net output #0: loss = 0.67498 (* 1 = 0.67498 loss)
I0526 18:26:09.132504 24213 sgd_solver.cpp:106] Iteration 5350, lr = 1e-10
I0526 18:26:15.082059 24213 solver.cpp:228] Iteration 5360, loss = 0.66643
I0526 18:26:15.082118 24213 solver.cpp:244]     Train net output #0: loss = 0.66643 (* 1 = 0.66643 loss)
I0526 18:26:15.082144 24213 sgd_solver.cpp:106] Iteration 5360, lr = 1e-10
I0526 18:26:20.483559 24213 solver.cpp:337] Iteration 5370, Testing net (#0)
I0526 18:26:22.800781 24213 solver.cpp:404]     Test net output #0: accuracy = 0.378182
I0526 18:26:22.800840 24213 solver.cpp:404]     Test net output #1: loss = 2.57448 (* 1 = 2.57448 loss)
I0526 18:26:23.334492 24213 solver.cpp:228] Iteration 5370, loss = 0.730519
I0526 18:26:23.334542 24213 solver.cpp:244]     Train net output #0: loss = 0.730519 (* 1 = 0.730519 loss)
I0526 18:26:23.334554 24213 sgd_solver.cpp:106] Iteration 5370, lr = 1e-10
I0526 18:26:29.276746 24213 solver.cpp:228] Iteration 5380, loss = 0.665228
I0526 18:26:29.276801 24213 solver.cpp:244]     Train net output #0: loss = 0.665228 (* 1 = 0.665228 loss)
I0526 18:26:29.276816 24213 sgd_solver.cpp:106] Iteration 5380, lr = 1e-10
I0526 18:26:35.220403 24213 solver.cpp:228] Iteration 5390, loss = 0.714446
I0526 18:26:35.220446 24213 solver.cpp:244]     Train net output #0: loss = 0.714446 (* 1 = 0.714446 loss)
I0526 18:26:35.220458 24213 sgd_solver.cpp:106] Iteration 5390, lr = 1e-10
I0526 18:26:40.566493 24213 solver.cpp:337] Iteration 5400, Testing net (#0)
I0526 18:26:42.784837 24213 solver.cpp:404]     Test net output #0: accuracy = 0.381818
I0526 18:26:42.784898 24213 solver.cpp:404]     Test net output #1: loss = 2.56683 (* 1 = 2.56683 loss)
I0526 18:26:43.316560 24213 solver.cpp:228] Iteration 5400, loss = 0.571297
I0526 18:26:43.316598 24213 solver.cpp:244]     Train net output #0: loss = 0.571297 (* 1 = 0.571297 loss)
I0526 18:26:43.316613 24213 sgd_solver.cpp:106] Iteration 5400, lr = 1e-10
I0526 18:26:49.266356 24213 solver.cpp:228] Iteration 5410, loss = 0.645476
I0526 18:26:49.266410 24213 solver.cpp:244]     Train net output #0: loss = 0.645476 (* 1 = 0.645476 loss)
I0526 18:26:49.266422 24213 sgd_solver.cpp:106] Iteration 5410, lr = 1e-10
I0526 18:26:55.210254 24213 solver.cpp:228] Iteration 5420, loss = 0.677689
I0526 18:26:55.210384 24213 solver.cpp:244]     Train net output #0: loss = 0.677689 (* 1 = 0.677689 loss)
I0526 18:26:55.210398 24213 sgd_solver.cpp:106] Iteration 5420, lr = 1e-10
I0526 18:27:00.557159 24213 solver.cpp:337] Iteration 5430, Testing net (#0)
I0526 18:27:02.710295 24213 solver.cpp:404]     Test net output #0: accuracy = 0.383636
I0526 18:27:02.710342 24213 solver.cpp:404]     Test net output #1: loss = 2.56917 (* 1 = 2.56917 loss)
I0526 18:27:03.245075 24213 solver.cpp:228] Iteration 5430, loss = 0.750328
I0526 18:27:03.245169 24213 solver.cpp:244]     Train net output #0: loss = 0.750328 (* 1 = 0.750328 loss)
I0526 18:27:03.245209 24213 sgd_solver.cpp:106] Iteration 5430, lr = 1e-10
I0526 18:27:09.191505 24213 solver.cpp:228] Iteration 5440, loss = 0.76759
I0526 18:27:09.191545 24213 solver.cpp:244]     Train net output #0: loss = 0.76759 (* 1 = 0.76759 loss)
I0526 18:27:09.191557 24213 sgd_solver.cpp:106] Iteration 5440, lr = 1e-10
I0526 18:27:15.135730 24213 solver.cpp:228] Iteration 5450, loss = 0.631919
I0526 18:27:15.135833 24213 solver.cpp:244]     Train net output #0: loss = 0.631919 (* 1 = 0.631919 loss)
I0526 18:27:15.135862 24213 sgd_solver.cpp:106] Iteration 5450, lr = 1e-10
I0526 18:27:20.481806 24213 solver.cpp:337] Iteration 5460, Testing net (#0)
I0526 18:27:22.724797 24213 solver.cpp:404]     Test net output #0: accuracy = 0.383636
I0526 18:27:22.724846 24213 solver.cpp:404]     Test net output #1: loss = 2.54557 (* 1 = 2.54557 loss)
I0526 18:27:23.259961 24213 solver.cpp:228] Iteration 5460, loss = 0.658314
I0526 18:27:23.260040 24213 solver.cpp:244]     Train net output #0: loss = 0.658314 (* 1 = 0.658314 loss)
I0526 18:27:23.260059 24213 sgd_solver.cpp:106] Iteration 5460, lr = 1e-10
I0526 18:27:29.200845 24213 solver.cpp:228] Iteration 5470, loss = 0.634683
I0526 18:27:29.201079 24213 solver.cpp:244]     Train net output #0: loss = 0.634683 (* 1 = 0.634683 loss)
I0526 18:27:29.201092 24213 sgd_solver.cpp:106] Iteration 5470, lr = 1e-10
I0526 18:27:35.140641 24213 solver.cpp:228] Iteration 5480, loss = 0.756292
I0526 18:27:35.140696 24213 solver.cpp:244]     Train net output #0: loss = 0.756292 (* 1 = 0.756292 loss)
I0526 18:27:35.140707 24213 sgd_solver.cpp:106] Iteration 5480, lr = 1e-10
I0526 18:27:40.489917 24213 solver.cpp:337] Iteration 5490, Testing net (#0)
I0526 18:27:42.478168 24213 solver.cpp:404]     Test net output #0: accuracy = 0.385455
I0526 18:27:42.478207 24213 solver.cpp:404]     Test net output #1: loss = 2.54824 (* 1 = 2.54824 loss)
I0526 18:27:43.010936 24213 solver.cpp:228] Iteration 5490, loss = 0.762198
I0526 18:27:43.010983 24213 solver.cpp:244]     Train net output #0: loss = 0.762198 (* 1 = 0.762198 loss)
I0526 18:27:43.010998 24213 sgd_solver.cpp:106] Iteration 5490, lr = 1e-10
I0526 18:27:48.959679 24213 solver.cpp:228] Iteration 5500, loss = 0.661226
I0526 18:27:48.959728 24213 solver.cpp:244]     Train net output #0: loss = 0.661226 (* 1 = 0.661226 loss)
I0526 18:27:48.959743 24213 sgd_solver.cpp:106] Iteration 5500, lr = 1e-10
I0526 18:27:54.900743 24213 solver.cpp:228] Iteration 5510, loss = 0.586467
I0526 18:27:54.900789 24213 solver.cpp:244]     Train net output #0: loss = 0.586467 (* 1 = 0.586467 loss)
I0526 18:27:54.900804 24213 sgd_solver.cpp:106] Iteration 5510, lr = 1e-10
I0526 18:28:00.250795 24213 solver.cpp:337] Iteration 5520, Testing net (#0)
I0526 18:28:02.365712 24213 solver.cpp:404]     Test net output #0: accuracy = 0.376364
I0526 18:28:02.365762 24213 solver.cpp:404]     Test net output #1: loss = 2.5745 (* 1 = 2.5745 loss)
I0526 18:28:02.900085 24213 solver.cpp:228] Iteration 5520, loss = 0.61481
I0526 18:28:02.900125 24213 solver.cpp:244]     Train net output #0: loss = 0.61481 (* 1 = 0.61481 loss)
I0526 18:28:02.900136 24213 sgd_solver.cpp:106] Iteration 5520, lr = 1e-10
I0526 18:28:08.839838 24213 solver.cpp:228] Iteration 5530, loss = 0.690199
I0526 18:28:08.839891 24213 solver.cpp:244]     Train net output #0: loss = 0.690199 (* 1 = 0.690199 loss)
I0526 18:28:08.839902 24213 sgd_solver.cpp:106] Iteration 5530, lr = 1e-10
I0526 18:28:14.790860 24213 solver.cpp:228] Iteration 5540, loss = 0.664849
I0526 18:28:14.790912 24213 solver.cpp:244]     Train net output #0: loss = 0.664849 (* 1 = 0.664849 loss)
I0526 18:28:14.790925 24213 sgd_solver.cpp:106] Iteration 5540, lr = 1e-10
I0526 18:28:20.139652 24213 solver.cpp:337] Iteration 5550, Testing net (#0)
I0526 18:28:22.021684 24213 solver.cpp:404]     Test net output #0: accuracy = 0.381818
I0526 18:28:22.021730 24213 solver.cpp:404]     Test net output #1: loss = 2.53697 (* 1 = 2.53697 loss)
I0526 18:28:22.553975 24213 solver.cpp:228] Iteration 5550, loss = 0.711228
I0526 18:28:22.554016 24213 solver.cpp:244]     Train net output #0: loss = 0.711228 (* 1 = 0.711228 loss)
I0526 18:28:22.554162 24213 sgd_solver.cpp:106] Iteration 5550, lr = 1e-10
I0526 18:28:28.496497 24213 solver.cpp:228] Iteration 5560, loss = 0.768239
I0526 18:28:28.496537 24213 solver.cpp:244]     Train net output #0: loss = 0.768239 (* 1 = 0.768239 loss)
I0526 18:28:28.496565 24213 sgd_solver.cpp:106] Iteration 5560, lr = 1e-10
I0526 18:28:34.441143 24213 solver.cpp:228] Iteration 5570, loss = 0.658503
I0526 18:28:34.441267 24213 solver.cpp:244]     Train net output #0: loss = 0.658503 (* 1 = 0.658503 loss)
I0526 18:28:34.441282 24213 sgd_solver.cpp:106] Iteration 5570, lr = 1e-10
I0526 18:28:39.791761 24213 solver.cpp:337] Iteration 5580, Testing net (#0)
I0526 18:28:42.027636 24213 solver.cpp:404]     Test net output #0: accuracy = 0.392727
I0526 18:28:42.027693 24213 solver.cpp:404]     Test net output #1: loss = 2.52532 (* 1 = 2.52532 loss)
I0526 18:28:42.562990 24213 solver.cpp:228] Iteration 5580, loss = 0.565249
I0526 18:28:42.563033 24213 solver.cpp:244]     Train net output #0: loss = 0.565249 (* 1 = 0.565249 loss)
I0526 18:28:42.563050 24213 sgd_solver.cpp:106] Iteration 5580, lr = 1e-10
I0526 18:28:48.511526 24213 solver.cpp:228] Iteration 5590, loss = 0.720857
I0526 18:28:48.511570 24213 solver.cpp:244]     Train net output #0: loss = 0.720857 (* 1 = 0.720857 loss)
I0526 18:28:48.511581 24213 sgd_solver.cpp:106] Iteration 5590, lr = 1e-10
I0526 18:28:54.456974 24213 solver.cpp:228] Iteration 5600, loss = 0.628304
I0526 18:28:54.457020 24213 solver.cpp:244]     Train net output #0: loss = 0.628304 (* 1 = 0.628304 loss)
I0526 18:28:54.457031 24213 sgd_solver.cpp:106] Iteration 5600, lr = 1e-10
I0526 18:28:59.807668 24213 solver.cpp:337] Iteration 5610, Testing net (#0)
I0526 18:29:01.754317 24213 solver.cpp:404]     Test net output #0: accuracy = 0.387273
I0526 18:29:01.754374 24213 solver.cpp:404]     Test net output #1: loss = 2.53988 (* 1 = 2.53988 loss)
I0526 18:29:02.291571 24213 solver.cpp:228] Iteration 5610, loss = 0.636002
I0526 18:29:02.291622 24213 solver.cpp:244]     Train net output #0: loss = 0.636002 (* 1 = 0.636002 loss)
I0526 18:29:02.291635 24213 sgd_solver.cpp:106] Iteration 5610, lr = 1e-10
I0526 18:29:08.231906 24213 solver.cpp:228] Iteration 5620, loss = 0.719778
I0526 18:29:08.232111 24213 solver.cpp:244]     Train net output #0: loss = 0.719778 (* 1 = 0.719778 loss)
I0526 18:29:08.232125 24213 sgd_solver.cpp:106] Iteration 5620, lr = 1e-10
I0526 18:29:14.173285 24213 solver.cpp:228] Iteration 5630, loss = 0.722555
I0526 18:29:14.173338 24213 solver.cpp:244]     Train net output #0: loss = 0.722555 (* 1 = 0.722555 loss)
I0526 18:29:14.173349 24213 sgd_solver.cpp:106] Iteration 5630, lr = 1e-10
I0526 18:29:19.522155 24213 solver.cpp:337] Iteration 5640, Testing net (#0)
I0526 18:29:21.488212 24213 solver.cpp:404]     Test net output #0: accuracy = 0.383636
I0526 18:29:21.488324 24213 solver.cpp:404]     Test net output #1: loss = 2.57182 (* 1 = 2.57182 loss)
I0526 18:29:22.026533 24213 solver.cpp:228] Iteration 5640, loss = 0.670249
I0526 18:29:22.026572 24213 solver.cpp:244]     Train net output #0: loss = 0.670249 (* 1 = 0.670249 loss)
I0526 18:29:22.026583 24213 sgd_solver.cpp:106] Iteration 5640, lr = 1e-10
I0526 18:29:27.967059 24213 solver.cpp:228] Iteration 5650, loss = 0.692566
I0526 18:29:27.967110 24213 solver.cpp:244]     Train net output #0: loss = 0.692566 (* 1 = 0.692566 loss)
I0526 18:29:27.967123 24213 sgd_solver.cpp:106] Iteration 5650, lr = 1e-10
I0526 18:29:33.908437 24213 solver.cpp:228] Iteration 5660, loss = 0.618253
I0526 18:29:33.908478 24213 solver.cpp:244]     Train net output #0: loss = 0.618253 (* 1 = 0.618253 loss)
I0526 18:29:33.908489 24213 sgd_solver.cpp:106] Iteration 5660, lr = 1e-10
I0526 18:29:39.262986 24213 solver.cpp:337] Iteration 5670, Testing net (#0)
I0526 18:29:41.370556 24213 solver.cpp:404]     Test net output #0: accuracy = 0.385455
I0526 18:29:41.370601 24213 solver.cpp:404]     Test net output #1: loss = 2.534 (* 1 = 2.534 loss)
I0526 18:29:41.902238 24213 solver.cpp:228] Iteration 5670, loss = 0.742048
I0526 18:29:41.902277 24213 solver.cpp:244]     Train net output #0: loss = 0.742048 (* 1 = 0.742048 loss)
I0526 18:29:41.902288 24213 sgd_solver.cpp:106] Iteration 5670, lr = 1e-10
I0526 18:29:47.846381 24213 solver.cpp:228] Iteration 5680, loss = 0.705661
I0526 18:29:47.846441 24213 solver.cpp:244]     Train net output #0: loss = 0.705661 (* 1 = 0.705661 loss)
I0526 18:29:47.846457 24213 sgd_solver.cpp:106] Iteration 5680, lr = 1e-10
I0526 18:29:53.783705 24213 solver.cpp:228] Iteration 5690, loss = 0.707333
I0526 18:29:53.783752 24213 solver.cpp:244]     Train net output #0: loss = 0.707333 (* 1 = 0.707333 loss)
I0526 18:29:53.783764 24213 sgd_solver.cpp:106] Iteration 5690, lr = 1e-10
I0526 18:29:59.138478 24213 solver.cpp:337] Iteration 5700, Testing net (#0)
I0526 18:30:01.358229 24213 solver.cpp:404]     Test net output #0: accuracy = 0.381818
I0526 18:30:01.358268 24213 solver.cpp:404]     Test net output #1: loss = 2.56859 (* 1 = 2.56859 loss)
I0526 18:30:01.896208 24213 solver.cpp:228] Iteration 5700, loss = 0.644653
I0526 18:30:01.896263 24213 solver.cpp:244]     Train net output #0: loss = 0.644653 (* 1 = 0.644653 loss)
I0526 18:30:01.896276 24213 sgd_solver.cpp:106] Iteration 5700, lr = 1e-10
I0526 18:30:07.836977 24213 solver.cpp:228] Iteration 5710, loss = 0.600672
I0526 18:30:07.837033 24213 solver.cpp:244]     Train net output #0: loss = 0.600672 (* 1 = 0.600672 loss)
I0526 18:30:07.837050 24213 sgd_solver.cpp:106] Iteration 5710, lr = 1e-10
I0526 18:30:13.779834 24213 solver.cpp:228] Iteration 5720, loss = 0.612135
I0526 18:30:13.779919 24213 solver.cpp:244]     Train net output #0: loss = 0.612135 (* 1 = 0.612135 loss)
I0526 18:30:13.779942 24213 sgd_solver.cpp:106] Iteration 5720, lr = 1e-10
I0526 18:30:19.133337 24213 solver.cpp:337] Iteration 5730, Testing net (#0)
I0526 18:30:21.157073 24213 solver.cpp:404]     Test net output #0: accuracy = 0.378182
I0526 18:30:21.157119 24213 solver.cpp:404]     Test net output #1: loss = 2.56395 (* 1 = 2.56395 loss)
I0526 18:30:21.688357 24213 solver.cpp:228] Iteration 5730, loss = 0.619849
I0526 18:30:21.688400 24213 solver.cpp:244]     Train net output #0: loss = 0.619849 (* 1 = 0.619849 loss)
I0526 18:30:21.688416 24213 sgd_solver.cpp:106] Iteration 5730, lr = 1e-10
I0526 18:30:27.634471 24213 solver.cpp:228] Iteration 5740, loss = 0.71838
I0526 18:30:27.634554 24213 solver.cpp:244]     Train net output #0: loss = 0.71838 (* 1 = 0.71838 loss)
I0526 18:30:27.634572 24213 sgd_solver.cpp:106] Iteration 5740, lr = 1e-10
I0526 18:30:33.581634 24213 solver.cpp:228] Iteration 5750, loss = 0.707732
I0526 18:30:33.581678 24213 solver.cpp:244]     Train net output #0: loss = 0.707732 (* 1 = 0.707732 loss)
I0526 18:30:33.581691 24213 sgd_solver.cpp:106] Iteration 5750, lr = 1e-10
I0526 18:30:38.928365 24213 solver.cpp:337] Iteration 5760, Testing net (#0)
I0526 18:30:41.014974 24213 solver.cpp:404]     Test net output #0: accuracy = 0.385455
I0526 18:30:41.015017 24213 solver.cpp:404]     Test net output #1: loss = 2.54604 (* 1 = 2.54604 loss)
I0526 18:30:41.553840 24213 solver.cpp:228] Iteration 5760, loss = 0.573807
I0526 18:30:41.553912 24213 solver.cpp:244]     Train net output #0: loss = 0.573807 (* 1 = 0.573807 loss)
I0526 18:30:41.553953 24213 sgd_solver.cpp:106] Iteration 5760, lr = 1e-10
I0526 18:30:47.497344 24213 solver.cpp:228] Iteration 5770, loss = 0.571153
I0526 18:30:47.497501 24213 solver.cpp:244]     Train net output #0: loss = 0.571153 (* 1 = 0.571153 loss)
I0526 18:30:47.497520 24213 sgd_solver.cpp:106] Iteration 5770, lr = 1e-10
I0526 18:30:53.530346 24213 solver.cpp:228] Iteration 5780, loss = 0.634234
I0526 18:30:53.530391 24213 solver.cpp:244]     Train net output #0: loss = 0.634234 (* 1 = 0.634234 loss)
I0526 18:30:53.530406 24213 sgd_solver.cpp:106] Iteration 5780, lr = 1e-10
I0526 18:30:59.114980 24213 solver.cpp:337] Iteration 5790, Testing net (#0)
I0526 18:31:01.417301 24213 solver.cpp:404]     Test net output #0: accuracy = 0.378182
I0526 18:31:01.417364 24213 solver.cpp:404]     Test net output #1: loss = 2.59167 (* 1 = 2.59167 loss)
I0526 18:31:01.951223 24213 solver.cpp:228] Iteration 5790, loss = 0.680396
I0526 18:31:01.951273 24213 solver.cpp:244]     Train net output #0: loss = 0.680396 (* 1 = 0.680396 loss)
I0526 18:31:01.951288 24213 sgd_solver.cpp:106] Iteration 5790, lr = 1e-10
I0526 18:31:07.891530 24213 solver.cpp:228] Iteration 5800, loss = 0.572719
I0526 18:31:07.891573 24213 solver.cpp:244]     Train net output #0: loss = 0.572719 (* 1 = 0.572719 loss)
I0526 18:31:07.891585 24213 sgd_solver.cpp:106] Iteration 5800, lr = 1e-10
I0526 18:31:13.839921 24213 solver.cpp:228] Iteration 5810, loss = 0.674792
I0526 18:31:13.839958 24213 solver.cpp:244]     Train net output #0: loss = 0.674792 (* 1 = 0.674792 loss)
I0526 18:31:13.839968 24213 sgd_solver.cpp:106] Iteration 5810, lr = 1e-10
I0526 18:31:19.192505 24213 solver.cpp:337] Iteration 5820, Testing net (#0)
I0526 18:31:21.464434 24213 solver.cpp:404]     Test net output #0: accuracy = 0.387273
I0526 18:31:21.464489 24213 solver.cpp:404]     Test net output #1: loss = 2.55129 (* 1 = 2.55129 loss)
I0526 18:31:22.002696 24213 solver.cpp:228] Iteration 5820, loss = 0.65526
I0526 18:31:22.002774 24213 solver.cpp:244]     Train net output #0: loss = 0.65526 (* 1 = 0.65526 loss)
I0526 18:31:22.002791 24213 sgd_solver.cpp:106] Iteration 5820, lr = 1e-10
I0526 18:31:27.948988 24213 solver.cpp:228] Iteration 5830, loss = 0.584581
I0526 18:31:27.949046 24213 solver.cpp:244]     Train net output #0: loss = 0.584581 (* 1 = 0.584581 loss)
I0526 18:31:27.949061 24213 sgd_solver.cpp:106] Iteration 5830, lr = 1e-10
I0526 18:31:33.930299 24213 solver.cpp:228] Iteration 5840, loss = 0.64888
I0526 18:31:33.930357 24213 solver.cpp:244]     Train net output #0: loss = 0.64888 (* 1 = 0.64888 loss)
I0526 18:31:33.930368 24213 sgd_solver.cpp:106] Iteration 5840, lr = 1e-10
I0526 18:31:39.287497 24213 solver.cpp:337] Iteration 5850, Testing net (#0)
I0526 18:31:41.546113 24213 solver.cpp:404]     Test net output #0: accuracy = 0.381818
I0526 18:31:41.546159 24213 solver.cpp:404]     Test net output #1: loss = 2.54774 (* 1 = 2.54774 loss)
I0526 18:31:42.078307 24213 solver.cpp:228] Iteration 5850, loss = 0.676769
I0526 18:31:42.078385 24213 solver.cpp:244]     Train net output #0: loss = 0.676769 (* 1 = 0.676769 loss)
I0526 18:31:42.078405 24213 sgd_solver.cpp:106] Iteration 5850, lr = 1e-10
I0526 18:31:48.021332 24213 solver.cpp:228] Iteration 5860, loss = 0.69577
I0526 18:31:48.021401 24213 solver.cpp:244]     Train net output #0: loss = 0.69577 (* 1 = 0.69577 loss)
I0526 18:31:48.021419 24213 sgd_solver.cpp:106] Iteration 5860, lr = 1e-10
I0526 18:31:53.970062 24213 solver.cpp:228] Iteration 5870, loss = 0.732435
I0526 18:31:53.970157 24213 solver.cpp:244]     Train net output #0: loss = 0.732435 (* 1 = 0.732435 loss)
I0526 18:31:53.970170 24213 sgd_solver.cpp:106] Iteration 5870, lr = 1e-10
I0526 18:31:59.321903 24213 solver.cpp:337] Iteration 5880, Testing net (#0)
I0526 18:32:01.572115 24213 solver.cpp:404]     Test net output #0: accuracy = 0.385455
I0526 18:32:01.572173 24213 solver.cpp:404]     Test net output #1: loss = 2.54979 (* 1 = 2.54979 loss)
I0526 18:32:02.107697 24213 solver.cpp:228] Iteration 5880, loss = 0.64994
I0526 18:32:02.107753 24213 solver.cpp:244]     Train net output #0: loss = 0.64994 (* 1 = 0.64994 loss)
I0526 18:32:02.107770 24213 sgd_solver.cpp:106] Iteration 5880, lr = 1e-10
I0526 18:32:08.057741 24213 solver.cpp:228] Iteration 5890, loss = 0.578526
I0526 18:32:08.057783 24213 solver.cpp:244]     Train net output #0: loss = 0.578526 (* 1 = 0.578526 loss)
I0526 18:32:08.057795 24213 sgd_solver.cpp:106] Iteration 5890, lr = 1e-10
I0526 18:32:14.002383 24213 solver.cpp:228] Iteration 5900, loss = 0.591775
I0526 18:32:14.002440 24213 solver.cpp:244]     Train net output #0: loss = 0.591775 (* 1 = 0.591775 loss)
I0526 18:32:14.002452 24213 sgd_solver.cpp:106] Iteration 5900, lr = 1e-10
I0526 18:32:19.356669 24213 solver.cpp:337] Iteration 5910, Testing net (#0)
I0526 18:32:21.346246 24213 solver.cpp:404]     Test net output #0: accuracy = 0.381818
I0526 18:32:21.346300 24213 solver.cpp:404]     Test net output #1: loss = 2.56669 (* 1 = 2.56669 loss)
I0526 18:32:21.884176 24213 solver.cpp:228] Iteration 5910, loss = 0.624836
I0526 18:32:21.884228 24213 solver.cpp:244]     Train net output #0: loss = 0.624836 (* 1 = 0.624836 loss)
I0526 18:32:21.884241 24213 sgd_solver.cpp:106] Iteration 5910, lr = 1e-10
I0526 18:32:27.821470 24213 solver.cpp:228] Iteration 5920, loss = 0.684211
I0526 18:32:27.821619 24213 solver.cpp:244]     Train net output #0: loss = 0.684211 (* 1 = 0.684211 loss)
I0526 18:32:27.821640 24213 sgd_solver.cpp:106] Iteration 5920, lr = 1e-10
I0526 18:32:33.769992 24213 solver.cpp:228] Iteration 5930, loss = 0.729719
I0526 18:32:33.770061 24213 solver.cpp:244]     Train net output #0: loss = 0.729719 (* 1 = 0.729719 loss)
I0526 18:32:33.770076 24213 sgd_solver.cpp:106] Iteration 5930, lr = 1e-10
I0526 18:32:39.119983 24213 solver.cpp:337] Iteration 5940, Testing net (#0)
I0526 18:32:41.124012 24213 solver.cpp:404]     Test net output #0: accuracy = 0.389091
I0526 18:32:41.124059 24213 solver.cpp:404]     Test net output #1: loss = 2.53117 (* 1 = 2.53117 loss)
I0526 18:32:41.655575 24213 solver.cpp:228] Iteration 5940, loss = 0.670475
I0526 18:32:41.655622 24213 solver.cpp:244]     Train net output #0: loss = 0.670475 (* 1 = 0.670475 loss)
I0526 18:32:41.655637 24213 sgd_solver.cpp:106] Iteration 5940, lr = 1e-10
I0526 18:32:47.598455 24213 solver.cpp:228] Iteration 5950, loss = 0.748058
I0526 18:32:47.598498 24213 solver.cpp:244]     Train net output #0: loss = 0.748058 (* 1 = 0.748058 loss)
I0526 18:32:47.598510 24213 sgd_solver.cpp:106] Iteration 5950, lr = 1e-10
I0526 18:32:53.549742 24213 solver.cpp:228] Iteration 5960, loss = 0.683857
I0526 18:32:53.549878 24213 solver.cpp:244]     Train net output #0: loss = 0.683857 (* 1 = 0.683857 loss)
I0526 18:32:53.549916 24213 sgd_solver.cpp:106] Iteration 5960, lr = 1e-10
I0526 18:32:58.903789 24213 solver.cpp:337] Iteration 5970, Testing net (#0)
I0526 18:33:00.743974 24213 solver.cpp:404]     Test net output #0: accuracy = 0.376364
I0526 18:33:00.744017 24213 solver.cpp:404]     Test net output #1: loss = 2.56937 (* 1 = 2.56937 loss)
I0526 18:33:01.275452 24213 solver.cpp:228] Iteration 5970, loss = 0.580643
I0526 18:33:01.275502 24213 solver.cpp:244]     Train net output #0: loss = 0.580643 (* 1 = 0.580643 loss)
I0526 18:33:01.275514 24213 sgd_solver.cpp:106] Iteration 5970, lr = 1e-10
I0526 18:33:07.222030 24213 solver.cpp:228] Iteration 5980, loss = 0.69104
I0526 18:33:07.222070 24213 solver.cpp:244]     Train net output #0: loss = 0.69104 (* 1 = 0.69104 loss)
I0526 18:33:07.222081 24213 sgd_solver.cpp:106] Iteration 5980, lr = 1e-10
I0526 18:33:13.172832 24213 solver.cpp:228] Iteration 5990, loss = 0.807045
I0526 18:33:13.172885 24213 solver.cpp:244]     Train net output #0: loss = 0.807045 (* 1 = 0.807045 loss)
I0526 18:33:13.172897 24213 sgd_solver.cpp:106] Iteration 5990, lr = 1e-10
I0526 18:33:18.520954 24213 solver.cpp:454] Snapshotting to binary proto file snapshot2/caffe_CAM_finetuneMIT_iter_6000.caffemodel
I0526 18:33:18.630228 24213 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot2/caffe_CAM_finetuneMIT_iter_6000.solverstate
I0526 18:33:18.655165 24213 solver.cpp:337] Iteration 6000, Testing net (#0)
I0526 18:33:20.532552 24213 solver.cpp:404]     Test net output #0: accuracy = 0.385455
I0526 18:33:20.532594 24213 solver.cpp:404]     Test net output #1: loss = 2.54828 (* 1 = 2.54828 loss)
I0526 18:33:21.063691 24213 solver.cpp:228] Iteration 6000, loss = 0.641118
I0526 18:33:21.063745 24213 solver.cpp:244]     Train net output #0: loss = 0.641118 (* 1 = 0.641118 loss)
I0526 18:33:21.063755 24213 sgd_solver.cpp:106] Iteration 6000, lr = 1e-11
I0526 18:33:27.013455 24213 solver.cpp:228] Iteration 6010, loss = 0.517241
I0526 18:33:27.013510 24213 solver.cpp:244]     Train net output #0: loss = 0.517241 (* 1 = 0.517241 loss)
I0526 18:33:27.013522 24213 sgd_solver.cpp:106] Iteration 6010, lr = 1e-11
I0526 18:33:32.957511 24213 solver.cpp:228] Iteration 6020, loss = 0.642114
I0526 18:33:32.957675 24213 solver.cpp:244]     Train net output #0: loss = 0.642114 (* 1 = 0.642114 loss)
I0526 18:33:32.957697 24213 sgd_solver.cpp:106] Iteration 6020, lr = 1e-11
I0526 18:33:38.309397 24213 solver.cpp:337] Iteration 6030, Testing net (#0)
I0526 18:33:40.494767 24213 solver.cpp:404]     Test net output #0: accuracy = 0.381818
I0526 18:33:40.494827 24213 solver.cpp:404]     Test net output #1: loss = 2.57118 (* 1 = 2.57118 loss)
I0526 18:33:41.026238 24213 solver.cpp:228] Iteration 6030, loss = 0.698212
I0526 18:33:41.026288 24213 solver.cpp:244]     Train net output #0: loss = 0.698212 (* 1 = 0.698212 loss)
I0526 18:33:41.026304 24213 sgd_solver.cpp:106] Iteration 6030, lr = 1e-11
I0526 18:33:46.975389 24213 solver.cpp:228] Iteration 6040, loss = 0.764187
I0526 18:33:46.975446 24213 solver.cpp:244]     Train net output #0: loss = 0.764187 (* 1 = 0.764187 loss)
I0526 18:33:46.975461 24213 sgd_solver.cpp:106] Iteration 6040, lr = 1e-11
I0526 18:33:52.920613 24213 solver.cpp:228] Iteration 6050, loss = 0.693356
I0526 18:33:52.920707 24213 solver.cpp:244]     Train net output #0: loss = 0.693356 (* 1 = 0.693356 loss)
I0526 18:33:52.920737 24213 sgd_solver.cpp:106] Iteration 6050, lr = 1e-11
I0526 18:33:58.277750 24213 solver.cpp:337] Iteration 6060, Testing net (#0)
I0526 18:34:00.524154 24213 solver.cpp:404]     Test net output #0: accuracy = 0.381818
I0526 18:34:00.524201 24213 solver.cpp:404]     Test net output #1: loss = 2.55525 (* 1 = 2.55525 loss)
I0526 18:34:01.062161 24213 solver.cpp:228] Iteration 6060, loss = 0.696416
I0526 18:34:01.062209 24213 solver.cpp:244]     Train net output #0: loss = 0.696416 (* 1 = 0.696416 loss)
I0526 18:34:01.062224 24213 sgd_solver.cpp:106] Iteration 6060, lr = 1e-11
I0526 18:34:07.008805 24213 solver.cpp:228] Iteration 6070, loss = 0.670011
I0526 18:34:07.008908 24213 solver.cpp:244]     Train net output #0: loss = 0.670011 (* 1 = 0.670011 loss)
I0526 18:34:07.008920 24213 sgd_solver.cpp:106] Iteration 6070, lr = 1e-11
I0526 18:34:12.951066 24213 solver.cpp:228] Iteration 6080, loss = 0.64865
I0526 18:34:12.951117 24213 solver.cpp:244]     Train net output #0: loss = 0.64865 (* 1 = 0.64865 loss)
I0526 18:34:12.951133 24213 sgd_solver.cpp:106] Iteration 6080, lr = 1e-11
I0526 18:34:18.302906 24213 solver.cpp:337] Iteration 6090, Testing net (#0)
I0526 18:34:20.347607 24213 solver.cpp:404]     Test net output #0: accuracy = 0.374545
I0526 18:34:20.347643 24213 solver.cpp:404]     Test net output #1: loss = 2.56908 (* 1 = 2.56908 loss)
I0526 18:34:20.887630 24213 solver.cpp:228] Iteration 6090, loss = 0.660125
I0526 18:34:20.887688 24213 solver.cpp:244]     Train net output #0: loss = 0.660125 (* 1 = 0.660125 loss)
I0526 18:34:20.887708 24213 sgd_solver.cpp:106] Iteration 6090, lr = 1e-11
I0526 18:34:26.832193 24213 solver.cpp:228] Iteration 6100, loss = 0.751287
I0526 18:34:26.832248 24213 solver.cpp:244]     Train net output #0: loss = 0.751287 (* 1 = 0.751287 loss)
I0526 18:34:26.832263 24213 sgd_solver.cpp:106] Iteration 6100, lr = 1e-11
I0526 18:34:32.780184 24213 solver.cpp:228] Iteration 6110, loss = 0.64401
I0526 18:34:32.780223 24213 solver.cpp:244]     Train net output #0: loss = 0.64401 (* 1 = 0.64401 loss)
I0526 18:34:32.780235 24213 sgd_solver.cpp:106] Iteration 6110, lr = 1e-11
I0526 18:34:38.123951 24213 solver.cpp:337] Iteration 6120, Testing net (#0)
I0526 18:34:40.103193 24213 solver.cpp:404]     Test net output #0: accuracy = 0.38
I0526 18:34:40.103238 24213 solver.cpp:404]     Test net output #1: loss = 2.57603 (* 1 = 2.57603 loss)
I0526 18:34:40.635490 24213 solver.cpp:228] Iteration 6120, loss = 0.663121
I0526 18:34:40.635545 24213 solver.cpp:244]     Train net output #0: loss = 0.663121 (* 1 = 0.663121 loss)
I0526 18:34:40.635561 24213 sgd_solver.cpp:106] Iteration 6120, lr = 1e-11
I0526 18:34:46.579946 24213 solver.cpp:228] Iteration 6130, loss = 0.648866
I0526 18:34:46.579982 24213 solver.cpp:244]     Train net output #0: loss = 0.648866 (* 1 = 0.648866 loss)
I0526 18:34:46.579993 24213 sgd_solver.cpp:106] Iteration 6130, lr = 1e-11
I0526 18:34:52.518744 24213 solver.cpp:228] Iteration 6140, loss = 0.646017
I0526 18:34:52.518781 24213 solver.cpp:244]     Train net output #0: loss = 0.646017 (* 1 = 0.646017 loss)
I0526 18:34:52.518793 24213 sgd_solver.cpp:106] Iteration 6140, lr = 1e-11
I0526 18:34:57.872608 24213 solver.cpp:337] Iteration 6150, Testing net (#0)
I0526 18:34:59.933360 24213 solver.cpp:404]     Test net output #0: accuracy = 0.383636
I0526 18:34:59.933418 24213 solver.cpp:404]     Test net output #1: loss = 2.54265 (* 1 = 2.54265 loss)
I0526 18:35:00.474689 24213 solver.cpp:228] Iteration 6150, loss = 0.70438
I0526 18:35:00.474725 24213 solver.cpp:244]     Train net output #0: loss = 0.70438 (* 1 = 0.70438 loss)
I0526 18:35:00.474735 24213 sgd_solver.cpp:106] Iteration 6150, lr = 1e-11
I0526 18:35:06.413501 24213 solver.cpp:228] Iteration 6160, loss = 0.648281
I0526 18:35:06.413537 24213 solver.cpp:244]     Train net output #0: loss = 0.648281 (* 1 = 0.648281 loss)
I0526 18:35:06.413547 24213 sgd_solver.cpp:106] Iteration 6160, lr = 1e-11
I0526 18:35:12.359285 24213 solver.cpp:228] Iteration 6170, loss = 0.721782
I0526 18:35:12.359382 24213 solver.cpp:244]     Train net output #0: loss = 0.721782 (* 1 = 0.721782 loss)
I0526 18:35:12.359401 24213 sgd_solver.cpp:106] Iteration 6170, lr = 1e-11
I0526 18:35:17.704710 24213 solver.cpp:337] Iteration 6180, Testing net (#0)
I0526 18:35:19.938139 24213 solver.cpp:404]     Test net output #0: accuracy = 0.385455
I0526 18:35:19.938184 24213 solver.cpp:404]     Test net output #1: loss = 2.54763 (* 1 = 2.54763 loss)
I0526 18:35:20.475934 24213 solver.cpp:228] Iteration 6180, loss = 0.705939
I0526 18:35:20.476001 24213 solver.cpp:244]     Train net output #0: loss = 0.705939 (* 1 = 0.705939 loss)
I0526 18:35:20.476017 24213 sgd_solver.cpp:106] Iteration 6180, lr = 1e-11
I0526 18:35:26.420604 24213 solver.cpp:228] Iteration 6190, loss = 0.699729
I0526 18:35:26.420650 24213 solver.cpp:244]     Train net output #0: loss = 0.699729 (* 1 = 0.699729 loss)
I0526 18:35:26.420665 24213 sgd_solver.cpp:106] Iteration 6190, lr = 1e-11
I0526 18:35:32.359097 24213 solver.cpp:228] Iteration 6200, loss = 0.657482
I0526 18:35:32.359154 24213 solver.cpp:244]     Train net output #0: loss = 0.657482 (* 1 = 0.657482 loss)
I0526 18:35:32.359169 24213 sgd_solver.cpp:106] Iteration 6200, lr = 1e-11
I0526 18:35:37.709379 24213 solver.cpp:337] Iteration 6210, Testing net (#0)
I0526 18:35:39.704080 24213 solver.cpp:404]     Test net output #0: accuracy = 0.381818
I0526 18:35:39.704118 24213 solver.cpp:404]     Test net output #1: loss = 2.57139 (* 1 = 2.57139 loss)
I0526 18:35:40.236027 24213 solver.cpp:228] Iteration 6210, loss = 0.619384
I0526 18:35:40.236081 24213 solver.cpp:244]     Train net output #0: loss = 0.619384 (* 1 = 0.619384 loss)
I0526 18:35:40.236093 24213 sgd_solver.cpp:106] Iteration 6210, lr = 1e-11
I0526 18:35:46.185360 24213 solver.cpp:228] Iteration 6220, loss = 0.652962
I0526 18:35:46.185469 24213 solver.cpp:244]     Train net output #0: loss = 0.652962 (* 1 = 0.652962 loss)
I0526 18:35:46.185483 24213 sgd_solver.cpp:106] Iteration 6220, lr = 1e-11
I0526 18:35:52.131191 24213 solver.cpp:228] Iteration 6230, loss = 0.801541
I0526 18:35:52.131247 24213 solver.cpp:244]     Train net output #0: loss = 0.801541 (* 1 = 0.801541 loss)
I0526 18:35:52.131263 24213 sgd_solver.cpp:106] Iteration 6230, lr = 1e-11
I0526 18:35:57.485543 24213 solver.cpp:337] Iteration 6240, Testing net (#0)
I0526 18:35:59.489096 24213 solver.cpp:404]     Test net output #0: accuracy = 0.381818
I0526 18:35:59.489147 24213 solver.cpp:404]     Test net output #1: loss = 2.55191 (* 1 = 2.55191 loss)
I0526 18:36:00.021589 24213 solver.cpp:228] Iteration 6240, loss = 0.808494
I0526 18:36:00.021636 24213 solver.cpp:244]     Train net output #0: loss = 0.808494 (* 1 = 0.808494 loss)
I0526 18:36:00.021652 24213 sgd_solver.cpp:106] Iteration 6240, lr = 1e-11
I0526 18:36:05.966661 24213 solver.cpp:228] Iteration 6250, loss = 0.667753
I0526 18:36:05.966702 24213 solver.cpp:244]     Train net output #0: loss = 0.667753 (* 1 = 0.667753 loss)
I0526 18:36:05.966718 24213 sgd_solver.cpp:106] Iteration 6250, lr = 1e-11
I0526 18:36:11.905241 24213 solver.cpp:228] Iteration 6260, loss = 0.614118
I0526 18:36:11.905290 24213 solver.cpp:244]     Train net output #0: loss = 0.614118 (* 1 = 0.614118 loss)
I0526 18:36:11.905318 24213 sgd_solver.cpp:106] Iteration 6260, lr = 1e-11
I0526 18:36:17.265738 24213 solver.cpp:337] Iteration 6270, Testing net (#0)
I0526 18:36:19.559221 24213 solver.cpp:404]     Test net output #0: accuracy = 0.383636
I0526 18:36:19.559278 24213 solver.cpp:404]     Test net output #1: loss = 2.53988 (* 1 = 2.53988 loss)
I0526 18:36:20.091178 24213 solver.cpp:228] Iteration 6270, loss = 0.640682
I0526 18:36:20.091217 24213 solver.cpp:244]     Train net output #0: loss = 0.640682 (* 1 = 0.640682 loss)
I0526 18:36:20.091229 24213 sgd_solver.cpp:106] Iteration 6270, lr = 1e-11
I0526 18:36:26.034660 24213 solver.cpp:228] Iteration 6280, loss = 0.600207
I0526 18:36:26.034700 24213 solver.cpp:244]     Train net output #0: loss = 0.600207 (* 1 = 0.600207 loss)
I0526 18:36:26.034713 24213 sgd_solver.cpp:106] Iteration 6280, lr = 1e-11
I0526 18:36:31.981179 24213 solver.cpp:228] Iteration 6290, loss = 0.727374
I0526 18:36:31.981241 24213 solver.cpp:244]     Train net output #0: loss = 0.727374 (* 1 = 0.727374 loss)
I0526 18:36:31.981254 24213 sgd_solver.cpp:106] Iteration 6290, lr = 1e-11
I0526 18:36:37.335571 24213 solver.cpp:337] Iteration 6300, Testing net (#0)
I0526 18:36:39.305847 24213 solver.cpp:404]     Test net output #0: accuracy = 0.38
I0526 18:36:39.305899 24213 solver.cpp:404]     Test net output #1: loss = 2.57691 (* 1 = 2.57691 loss)
I0526 18:36:39.837764 24213 solver.cpp:228] Iteration 6300, loss = 0.638319
I0526 18:36:39.837800 24213 solver.cpp:244]     Train net output #0: loss = 0.638319 (* 1 = 0.638319 loss)
I0526 18:36:39.837811 24213 sgd_solver.cpp:106] Iteration 6300, lr = 1e-11
I0526 18:36:45.782578 24213 solver.cpp:228] Iteration 6310, loss = 0.74865
I0526 18:36:45.782621 24213 solver.cpp:244]     Train net output #0: loss = 0.74865 (* 1 = 0.74865 loss)
I0526 18:36:45.782634 24213 sgd_solver.cpp:106] Iteration 6310, lr = 1e-11
I0526 18:36:51.731027 24213 solver.cpp:228] Iteration 6320, loss = 0.596847
I0526 18:36:51.731780 24213 solver.cpp:244]     Train net output #0: loss = 0.596847 (* 1 = 0.596847 loss)
I0526 18:36:51.731832 24213 sgd_solver.cpp:106] Iteration 6320, lr = 1e-11
I0526 18:36:57.084539 24213 solver.cpp:337] Iteration 6330, Testing net (#0)
I0526 18:36:59.210921 24213 solver.cpp:404]     Test net output #0: accuracy = 0.38
I0526 18:36:59.210979 24213 solver.cpp:404]     Test net output #1: loss = 2.57116 (* 1 = 2.57116 loss)
I0526 18:36:59.743157 24213 solver.cpp:228] Iteration 6330, loss = 0.575824
I0526 18:36:59.743211 24213 solver.cpp:244]     Train net output #0: loss = 0.575824 (* 1 = 0.575824 loss)
I0526 18:36:59.743227 24213 sgd_solver.cpp:106] Iteration 6330, lr = 1e-11
I0526 18:37:05.683104 24213 solver.cpp:228] Iteration 6340, loss = 0.697686
I0526 18:37:05.683145 24213 solver.cpp:244]     Train net output #0: loss = 0.697686 (* 1 = 0.697686 loss)
I0526 18:37:05.683162 24213 sgd_solver.cpp:106] Iteration 6340, lr = 1e-11
I0526 18:37:11.626183 24213 solver.cpp:228] Iteration 6350, loss = 0.68506
I0526 18:37:11.626227 24213 solver.cpp:244]     Train net output #0: loss = 0.68506 (* 1 = 0.68506 loss)
I0526 18:37:11.626240 24213 sgd_solver.cpp:106] Iteration 6350, lr = 1e-11
I0526 18:37:16.979569 24213 solver.cpp:337] Iteration 6360, Testing net (#0)
I0526 18:37:19.148557 24213 solver.cpp:404]     Test net output #0: accuracy = 0.381818
I0526 18:37:19.148597 24213 solver.cpp:404]     Test net output #1: loss = 2.56337 (* 1 = 2.56337 loss)
I0526 18:37:19.680302 24213 solver.cpp:228] Iteration 6360, loss = 0.629758
I0526 18:37:19.680349 24213 solver.cpp:244]     Train net output #0: loss = 0.629758 (* 1 = 0.629758 loss)
I0526 18:37:19.680367 24213 sgd_solver.cpp:106] Iteration 6360, lr = 1e-11
I0526 18:37:25.622375 24213 solver.cpp:228] Iteration 6370, loss = 0.680019
I0526 18:37:25.622512 24213 solver.cpp:244]     Train net output #0: loss = 0.680019 (* 1 = 0.680019 loss)
I0526 18:37:25.622526 24213 sgd_solver.cpp:106] Iteration 6370, lr = 1e-11
I0526 18:37:31.564298 24213 solver.cpp:228] Iteration 6380, loss = 0.669014
I0526 18:37:31.564345 24213 solver.cpp:244]     Train net output #0: loss = 0.669014 (* 1 = 0.669014 loss)
I0526 18:37:31.564358 24213 sgd_solver.cpp:106] Iteration 6380, lr = 1e-11
I0526 18:37:36.915736 24213 solver.cpp:337] Iteration 6390, Testing net (#0)
I0526 18:37:39.241571 24213 solver.cpp:404]     Test net output #0: accuracy = 0.38
I0526 18:37:39.241608 24213 solver.cpp:404]     Test net output #1: loss = 2.56829 (* 1 = 2.56829 loss)
I0526 18:37:39.776051 24213 solver.cpp:228] Iteration 6390, loss = 0.655187
I0526 18:37:39.776120 24213 solver.cpp:244]     Train net output #0: loss = 0.655187 (* 1 = 0.655187 loss)
I0526 18:37:39.776139 24213 sgd_solver.cpp:106] Iteration 6390, lr = 1e-11
I0526 18:37:45.718823 24213 solver.cpp:228] Iteration 6400, loss = 0.667121
I0526 18:37:45.718870 24213 solver.cpp:244]     Train net output #0: loss = 0.667121 (* 1 = 0.667121 loss)
I0526 18:37:45.718899 24213 sgd_solver.cpp:106] Iteration 6400, lr = 1e-11
I0526 18:37:51.663370 24213 solver.cpp:228] Iteration 6410, loss = 0.678291
I0526 18:37:51.663424 24213 solver.cpp:244]     Train net output #0: loss = 0.678291 (* 1 = 0.678291 loss)
I0526 18:37:51.663439 24213 sgd_solver.cpp:106] Iteration 6410, lr = 1e-11
I0526 18:37:57.019009 24213 solver.cpp:337] Iteration 6420, Testing net (#0)
I0526 18:37:59.169256 24213 solver.cpp:404]     Test net output #0: accuracy = 0.392727
I0526 18:37:59.169294 24213 solver.cpp:404]     Test net output #1: loss = 2.52175 (* 1 = 2.52175 loss)
I0526 18:37:59.700732 24213 solver.cpp:228] Iteration 6420, loss = 0.643537
I0526 18:37:59.700865 24213 solver.cpp:244]     Train net output #0: loss = 0.643537 (* 1 = 0.643537 loss)
I0526 18:37:59.700923 24213 sgd_solver.cpp:106] Iteration 6420, lr = 1e-11
I0526 18:38:05.635844 24213 solver.cpp:228] Iteration 6430, loss = 0.642163
I0526 18:38:05.635892 24213 solver.cpp:244]     Train net output #0: loss = 0.642163 (* 1 = 0.642163 loss)
I0526 18:38:05.635910 24213 sgd_solver.cpp:106] Iteration 6430, lr = 1e-11
I0526 18:38:11.576016 24213 solver.cpp:228] Iteration 6440, loss = 0.664278
I0526 18:38:11.576058 24213 solver.cpp:244]     Train net output #0: loss = 0.664278 (* 1 = 0.664278 loss)
I0526 18:38:11.576074 24213 sgd_solver.cpp:106] Iteration 6440, lr = 1e-11
I0526 18:38:16.926378 24213 solver.cpp:337] Iteration 6450, Testing net (#0)
I0526 18:38:19.210767 24213 solver.cpp:404]     Test net output #0: accuracy = 0.376364
I0526 18:38:19.210827 24213 solver.cpp:404]     Test net output #1: loss = 2.58933 (* 1 = 2.58933 loss)
I0526 18:38:19.743870 24213 solver.cpp:228] Iteration 6450, loss = 0.675731
I0526 18:38:19.743916 24213 solver.cpp:244]     Train net output #0: loss = 0.675731 (* 1 = 0.675731 loss)
I0526 18:38:19.743930 24213 sgd_solver.cpp:106] Iteration 6450, lr = 1e-11
I0526 18:38:25.684612 24213 solver.cpp:228] Iteration 6460, loss = 0.665176
I0526 18:38:25.684653 24213 solver.cpp:244]     Train net output #0: loss = 0.665176 (* 1 = 0.665176 loss)
I0526 18:38:25.684665 24213 sgd_solver.cpp:106] Iteration 6460, lr = 1e-11
I0526 18:38:31.631427 24213 solver.cpp:228] Iteration 6470, loss = 0.74003
I0526 18:38:31.631556 24213 solver.cpp:244]     Train net output #0: loss = 0.74003 (* 1 = 0.74003 loss)
I0526 18:38:31.631569 24213 sgd_solver.cpp:106] Iteration 6470, lr = 1e-11
I0526 18:38:36.980607 24213 solver.cpp:337] Iteration 6480, Testing net (#0)
I0526 18:38:38.946156 24213 solver.cpp:404]     Test net output #0: accuracy = 0.378182
I0526 18:38:38.946208 24213 solver.cpp:404]     Test net output #1: loss = 2.54089 (* 1 = 2.54089 loss)
I0526 18:38:39.481998 24213 solver.cpp:228] Iteration 6480, loss = 0.667848
I0526 18:38:39.482044 24213 solver.cpp:244]     Train net output #0: loss = 0.667848 (* 1 = 0.667848 loss)
I0526 18:38:39.482061 24213 sgd_solver.cpp:106] Iteration 6480, lr = 1e-11
I0526 18:38:45.422732 24213 solver.cpp:228] Iteration 6490, loss = 0.794129
I0526 18:38:45.422790 24213 solver.cpp:244]     Train net output #0: loss = 0.794129 (* 1 = 0.794129 loss)
I0526 18:38:45.422802 24213 sgd_solver.cpp:106] Iteration 6490, lr = 1e-11
I0526 18:38:51.362892 24213 solver.cpp:228] Iteration 6500, loss = 0.601596
I0526 18:38:51.362947 24213 solver.cpp:244]     Train net output #0: loss = 0.601596 (* 1 = 0.601596 loss)
I0526 18:38:51.362958 24213 sgd_solver.cpp:106] Iteration 6500, lr = 1e-11
I0526 18:38:56.718323 24213 solver.cpp:337] Iteration 6510, Testing net (#0)
I0526 18:38:58.783992 24213 solver.cpp:404]     Test net output #0: accuracy = 0.390909
I0526 18:38:58.784026 24213 solver.cpp:404]     Test net output #1: loss = 2.5251 (* 1 = 2.5251 loss)
I0526 18:38:59.319584 24213 solver.cpp:228] Iteration 6510, loss = 0.658976
I0526 18:38:59.319629 24213 solver.cpp:244]     Train net output #0: loss = 0.658976 (* 1 = 0.658976 loss)
I0526 18:38:59.319644 24213 sgd_solver.cpp:106] Iteration 6510, lr = 1e-11
I0526 18:39:05.262962 24213 solver.cpp:228] Iteration 6520, loss = 0.629437
I0526 18:39:05.263082 24213 solver.cpp:244]     Train net output #0: loss = 0.629437 (* 1 = 0.629437 loss)
I0526 18:39:05.263097 24213 sgd_solver.cpp:106] Iteration 6520, lr = 1e-11
I0526 18:39:11.204222 24213 solver.cpp:228] Iteration 6530, loss = 0.70528
I0526 18:39:11.204272 24213 solver.cpp:244]     Train net output #0: loss = 0.70528 (* 1 = 0.70528 loss)
I0526 18:39:11.204288 24213 sgd_solver.cpp:106] Iteration 6530, lr = 1e-11
I0526 18:39:16.556939 24213 solver.cpp:337] Iteration 6540, Testing net (#0)
I0526 18:39:18.627967 24213 solver.cpp:404]     Test net output #0: accuracy = 0.389091
I0526 18:39:18.628008 24213 solver.cpp:404]     Test net output #1: loss = 2.54309 (* 1 = 2.54309 loss)
I0526 18:39:19.162529 24213 solver.cpp:228] Iteration 6540, loss = 0.639452
I0526 18:39:19.162626 24213 solver.cpp:244]     Train net output #0: loss = 0.639452 (* 1 = 0.639452 loss)
I0526 18:39:19.162647 24213 sgd_solver.cpp:106] Iteration 6540, lr = 1e-11
I0526 18:39:25.106840 24213 solver.cpp:228] Iteration 6550, loss = 0.718998
I0526 18:39:25.106883 24213 solver.cpp:244]     Train net output #0: loss = 0.718998 (* 1 = 0.718998 loss)
I0526 18:39:25.106894 24213 sgd_solver.cpp:106] Iteration 6550, lr = 1e-11
I0526 18:39:31.054786 24213 solver.cpp:228] Iteration 6560, loss = 0.718993
I0526 18:39:31.054846 24213 solver.cpp:244]     Train net output #0: loss = 0.718993 (* 1 = 0.718993 loss)
I0526 18:39:31.054862 24213 sgd_solver.cpp:106] Iteration 6560, lr = 1e-11
I0526 18:39:36.411626 24213 solver.cpp:337] Iteration 6570, Testing net (#0)
I0526 18:39:38.478428 24213 solver.cpp:404]     Test net output #0: accuracy = 0.387273
I0526 18:39:38.478466 24213 solver.cpp:404]     Test net output #1: loss = 2.53742 (* 1 = 2.53742 loss)
I0526 18:39:39.011061 24213 solver.cpp:228] Iteration 6570, loss = 0.674087
I0526 18:39:39.011108 24213 solver.cpp:244]     Train net output #0: loss = 0.674087 (* 1 = 0.674087 loss)
I0526 18:39:39.011128 24213 sgd_solver.cpp:106] Iteration 6570, lr = 1e-11
I0526 18:39:44.953809 24213 solver.cpp:228] Iteration 6580, loss = 0.52987
I0526 18:39:44.953851 24213 solver.cpp:244]     Train net output #0: loss = 0.52987 (* 1 = 0.52987 loss)
I0526 18:39:44.953862 24213 sgd_solver.cpp:106] Iteration 6580, lr = 1e-11
I0526 18:39:50.898427 24213 solver.cpp:228] Iteration 6590, loss = 0.611993
I0526 18:39:50.898481 24213 solver.cpp:244]     Train net output #0: loss = 0.611993 (* 1 = 0.611993 loss)
I0526 18:39:50.898494 24213 sgd_solver.cpp:106] Iteration 6590, lr = 1e-11
I0526 18:39:56.249516 24213 solver.cpp:337] Iteration 6600, Testing net (#0)
I0526 18:39:58.219949 24213 solver.cpp:404]     Test net output #0: accuracy = 0.383636
I0526 18:39:58.219995 24213 solver.cpp:404]     Test net output #1: loss = 2.56501 (* 1 = 2.56501 loss)
I0526 18:39:58.755331 24213 solver.cpp:228] Iteration 6600, loss = 0.691703
I0526 18:39:58.755369 24213 solver.cpp:244]     Train net output #0: loss = 0.691703 (* 1 = 0.691703 loss)
I0526 18:39:58.755381 24213 sgd_solver.cpp:106] Iteration 6600, lr = 1e-11
I0526 18:40:04.700760 24213 solver.cpp:228] Iteration 6610, loss = 0.75382
I0526 18:40:04.700809 24213 solver.cpp:244]     Train net output #0: loss = 0.75382 (* 1 = 0.75382 loss)
I0526 18:40:04.700824 24213 sgd_solver.cpp:106] Iteration 6610, lr = 1e-11
I0526 18:40:10.647299 24213 solver.cpp:228] Iteration 6620, loss = 0.70511
I0526 18:40:10.647495 24213 solver.cpp:244]     Train net output #0: loss = 0.70511 (* 1 = 0.70511 loss)
I0526 18:40:10.647512 24213 sgd_solver.cpp:106] Iteration 6620, lr = 1e-11
I0526 18:40:16.246994 24213 solver.cpp:337] Iteration 6630, Testing net (#0)
I0526 18:40:18.366089 24213 solver.cpp:404]     Test net output #0: accuracy = 0.381818
I0526 18:40:18.366132 24213 solver.cpp:404]     Test net output #1: loss = 2.55118 (* 1 = 2.55118 loss)
I0526 18:40:18.899384 24213 solver.cpp:228] Iteration 6630, loss = 0.593568
I0526 18:40:18.899425 24213 solver.cpp:244]     Train net output #0: loss = 0.593568 (* 1 = 0.593568 loss)
I0526 18:40:18.899440 24213 sgd_solver.cpp:106] Iteration 6630, lr = 1e-11
I0526 18:40:24.849705 24213 solver.cpp:228] Iteration 6640, loss = 0.609527
I0526 18:40:24.849777 24213 solver.cpp:244]     Train net output #0: loss = 0.609527 (* 1 = 0.609527 loss)
I0526 18:40:24.849793 24213 sgd_solver.cpp:106] Iteration 6640, lr = 1e-11
I0526 18:40:30.787434 24213 solver.cpp:228] Iteration 6650, loss = 0.690172
I0526 18:40:30.787492 24213 solver.cpp:244]     Train net output #0: loss = 0.690172 (* 1 = 0.690172 loss)
I0526 18:40:30.787506 24213 sgd_solver.cpp:106] Iteration 6650, lr = 1e-11
I0526 18:40:36.140652 24213 solver.cpp:337] Iteration 6660, Testing net (#0)
I0526 18:40:38.253518 24213 solver.cpp:404]     Test net output #0: accuracy = 0.378182
I0526 18:40:38.253557 24213 solver.cpp:404]     Test net output #1: loss = 2.56953 (* 1 = 2.56953 loss)
I0526 18:40:38.788439 24213 solver.cpp:228] Iteration 6660, loss = 0.723498
I0526 18:40:38.788481 24213 solver.cpp:244]     Train net output #0: loss = 0.723498 (* 1 = 0.723498 loss)
I0526 18:40:38.788497 24213 sgd_solver.cpp:106] Iteration 6660, lr = 1e-11
I0526 18:40:44.726738 24213 solver.cpp:228] Iteration 6670, loss = 0.755442
I0526 18:40:44.726867 24213 solver.cpp:244]     Train net output #0: loss = 0.755442 (* 1 = 0.755442 loss)
I0526 18:40:44.726881 24213 sgd_solver.cpp:106] Iteration 6670, lr = 1e-11
I0526 18:40:50.663481 24213 solver.cpp:228] Iteration 6680, loss = 0.728588
I0526 18:40:50.663538 24213 solver.cpp:244]     Train net output #0: loss = 0.728588 (* 1 = 0.728588 loss)
I0526 18:40:50.663554 24213 sgd_solver.cpp:106] Iteration 6680, lr = 1e-11
I0526 18:40:56.026952 24213 solver.cpp:337] Iteration 6690, Testing net (#0)
I0526 18:40:58.105115 24213 solver.cpp:404]     Test net output #0: accuracy = 0.383636
I0526 18:40:58.105200 24213 solver.cpp:404]     Test net output #1: loss = 2.55921 (* 1 = 2.55921 loss)
I0526 18:40:58.637037 24213 solver.cpp:228] Iteration 6690, loss = 0.651393
I0526 18:40:58.637085 24213 solver.cpp:244]     Train net output #0: loss = 0.651393 (* 1 = 0.651393 loss)
I0526 18:40:58.637097 24213 sgd_solver.cpp:106] Iteration 6690, lr = 1e-11
I0526 18:41:04.577973 24213 solver.cpp:228] Iteration 6700, loss = 0.64335
I0526 18:41:04.578052 24213 solver.cpp:244]     Train net output #0: loss = 0.64335 (* 1 = 0.64335 loss)
I0526 18:41:04.578073 24213 sgd_solver.cpp:106] Iteration 6700, lr = 1e-11
I0526 18:41:10.516881 24213 solver.cpp:228] Iteration 6710, loss = 0.551584
I0526 18:41:10.516932 24213 solver.cpp:244]     Train net output #0: loss = 0.551584 (* 1 = 0.551584 loss)
I0526 18:41:10.516943 24213 sgd_solver.cpp:106] Iteration 6710, lr = 1e-11
I0526 18:41:15.869842 24213 solver.cpp:337] Iteration 6720, Testing net (#0)
I0526 18:41:17.876313 24213 solver.cpp:404]     Test net output #0: accuracy = 0.38
I0526 18:41:17.876351 24213 solver.cpp:404]     Test net output #1: loss = 2.57863 (* 1 = 2.57863 loss)
I0526 18:41:18.407855 24213 solver.cpp:228] Iteration 6720, loss = 0.575562
I0526 18:41:18.407897 24213 solver.cpp:244]     Train net output #0: loss = 0.575562 (* 1 = 0.575562 loss)
I0526 18:41:18.407914 24213 sgd_solver.cpp:106] Iteration 6720, lr = 1e-11
I0526 18:41:24.350864 24213 solver.cpp:228] Iteration 6730, loss = 0.74621
I0526 18:41:24.350901 24213 solver.cpp:244]     Train net output #0: loss = 0.74621 (* 1 = 0.74621 loss)
I0526 18:41:24.350914 24213 sgd_solver.cpp:106] Iteration 6730, lr = 1e-11
I0526 18:41:30.289666 24213 solver.cpp:228] Iteration 6740, loss = 0.817608
I0526 18:41:30.289707 24213 solver.cpp:244]     Train net output #0: loss = 0.817608 (* 1 = 0.817608 loss)
I0526 18:41:30.289718 24213 sgd_solver.cpp:106] Iteration 6740, lr = 1e-11
I0526 18:41:35.640833 24213 solver.cpp:337] Iteration 6750, Testing net (#0)
I0526 18:41:37.716150 24213 solver.cpp:404]     Test net output #0: accuracy = 0.387273
I0526 18:41:37.716300 24213 solver.cpp:404]     Test net output #1: loss = 2.55364 (* 1 = 2.55364 loss)
I0526 18:41:38.254770 24213 solver.cpp:228] Iteration 6750, loss = 0.70125
I0526 18:41:38.254812 24213 solver.cpp:244]     Train net output #0: loss = 0.70125 (* 1 = 0.70125 loss)
I0526 18:41:38.254829 24213 sgd_solver.cpp:106] Iteration 6750, lr = 1e-11
I0526 18:41:44.202596 24213 solver.cpp:228] Iteration 6760, loss = 0.63591
I0526 18:41:44.202673 24213 solver.cpp:244]     Train net output #0: loss = 0.63591 (* 1 = 0.63591 loss)
I0526 18:41:44.202690 24213 sgd_solver.cpp:106] Iteration 6760, lr = 1e-11
I0526 18:41:50.140746 24213 solver.cpp:228] Iteration 6770, loss = 0.588507
I0526 18:41:50.140858 24213 solver.cpp:244]     Train net output #0: loss = 0.588507 (* 1 = 0.588507 loss)
I0526 18:41:50.140872 24213 sgd_solver.cpp:106] Iteration 6770, lr = 1e-11
I0526 18:41:55.498013 24213 solver.cpp:337] Iteration 6780, Testing net (#0)
I0526 18:41:57.516883 24213 solver.cpp:404]     Test net output #0: accuracy = 0.381818
I0526 18:41:57.516919 24213 solver.cpp:404]     Test net output #1: loss = 2.55303 (* 1 = 2.55303 loss)
I0526 18:41:58.048573 24213 solver.cpp:228] Iteration 6780, loss = 0.584855
I0526 18:41:58.048615 24213 solver.cpp:244]     Train net output #0: loss = 0.584855 (* 1 = 0.584855 loss)
I0526 18:41:58.048627 24213 sgd_solver.cpp:106] Iteration 6780, lr = 1e-11
I0526 18:42:03.996448 24213 solver.cpp:228] Iteration 6790, loss = 0.635944
I0526 18:42:03.996506 24213 solver.cpp:244]     Train net output #0: loss = 0.635944 (* 1 = 0.635944 loss)
I0526 18:42:03.996520 24213 sgd_solver.cpp:106] Iteration 6790, lr = 1e-11
I0526 18:42:09.936326 24213 solver.cpp:228] Iteration 6800, loss = 0.768344
I0526 18:42:09.936388 24213 solver.cpp:244]     Train net output #0: loss = 0.768344 (* 1 = 0.768344 loss)
I0526 18:42:09.936400 24213 sgd_solver.cpp:106] Iteration 6800, lr = 1e-11
I0526 18:42:15.284904 24213 solver.cpp:337] Iteration 6810, Testing net (#0)
I0526 18:42:17.296838 24213 solver.cpp:404]     Test net output #0: accuracy = 0.387273
I0526 18:42:17.296880 24213 solver.cpp:404]     Test net output #1: loss = 2.53022 (* 1 = 2.53022 loss)
I0526 18:42:17.829149 24213 solver.cpp:228] Iteration 6810, loss = 0.578137
I0526 18:42:17.829187 24213 solver.cpp:244]     Train net output #0: loss = 0.578137 (* 1 = 0.578137 loss)
I0526 18:42:17.829198 24213 sgd_solver.cpp:106] Iteration 6810, lr = 1e-11
I0526 18:42:23.770164 24213 solver.cpp:228] Iteration 6820, loss = 0.62694
I0526 18:42:23.770309 24213 solver.cpp:244]     Train net output #0: loss = 0.62694 (* 1 = 0.62694 loss)
I0526 18:42:23.770329 24213 sgd_solver.cpp:106] Iteration 6820, lr = 1e-11
I0526 18:42:29.717525 24213 solver.cpp:228] Iteration 6830, loss = 0.619247
I0526 18:42:29.717597 24213 solver.cpp:244]     Train net output #0: loss = 0.619247 (* 1 = 0.619247 loss)
I0526 18:42:29.717609 24213 sgd_solver.cpp:106] Iteration 6830, lr = 1e-11
I0526 18:42:35.069856 24213 solver.cpp:337] Iteration 6840, Testing net (#0)
I0526 18:42:37.416252 24213 solver.cpp:404]     Test net output #0: accuracy = 0.38
I0526 18:42:37.416329 24213 solver.cpp:404]     Test net output #1: loss = 2.57839 (* 1 = 2.57839 loss)
I0526 18:42:37.947967 24213 solver.cpp:228] Iteration 6840, loss = 0.636473
I0526 18:42:37.948019 24213 solver.cpp:244]     Train net output #0: loss = 0.636473 (* 1 = 0.636473 loss)
I0526 18:42:37.948031 24213 sgd_solver.cpp:106] Iteration 6840, lr = 1e-11
I0526 18:42:43.891706 24213 solver.cpp:228] Iteration 6850, loss = 0.647111
I0526 18:42:43.891757 24213 solver.cpp:244]     Train net output #0: loss = 0.647111 (* 1 = 0.647111 loss)
I0526 18:42:43.891772 24213 sgd_solver.cpp:106] Iteration 6850, lr = 1e-11
I0526 18:42:49.840418 24213 solver.cpp:228] Iteration 6860, loss = 0.787738
I0526 18:42:49.840518 24213 solver.cpp:244]     Train net output #0: loss = 0.787738 (* 1 = 0.787738 loss)
I0526 18:42:49.840558 24213 sgd_solver.cpp:106] Iteration 6860, lr = 1e-11
I0526 18:42:55.197741 24213 solver.cpp:337] Iteration 6870, Testing net (#0)
I0526 18:42:57.322291 24213 solver.cpp:404]     Test net output #0: accuracy = 0.383636
I0526 18:42:57.322351 24213 solver.cpp:404]     Test net output #1: loss = 2.55007 (* 1 = 2.55007 loss)
I0526 18:42:57.853819 24213 solver.cpp:228] Iteration 6870, loss = 0.68281
I0526 18:42:57.853871 24213 solver.cpp:244]     Train net output #0: loss = 0.68281 (* 1 = 0.68281 loss)
I0526 18:42:57.853883 24213 sgd_solver.cpp:106] Iteration 6870, lr = 1e-11
I0526 18:43:03.802371 24213 solver.cpp:228] Iteration 6880, loss = 0.644956
I0526 18:43:03.802423 24213 solver.cpp:244]     Train net output #0: loss = 0.644956 (* 1 = 0.644956 loss)
I0526 18:43:03.802433 24213 sgd_solver.cpp:106] Iteration 6880, lr = 1e-11
I0526 18:43:09.750983 24213 solver.cpp:228] Iteration 6890, loss = 0.566528
I0526 18:43:09.751026 24213 solver.cpp:244]     Train net output #0: loss = 0.566528 (* 1 = 0.566528 loss)
I0526 18:43:09.751037 24213 sgd_solver.cpp:106] Iteration 6890, lr = 1e-11
I0526 18:43:15.105134 24213 solver.cpp:337] Iteration 6900, Testing net (#0)
I0526 18:43:17.050290 24213 solver.cpp:404]     Test net output #0: accuracy = 0.383636
I0526 18:43:17.050350 24213 solver.cpp:404]     Test net output #1: loss = 2.54843 (* 1 = 2.54843 loss)
I0526 18:43:17.582056 24213 solver.cpp:228] Iteration 6900, loss = 0.700005
I0526 18:43:17.582105 24213 solver.cpp:244]     Train net output #0: loss = 0.700005 (* 1 = 0.700005 loss)
I0526 18:43:17.582123 24213 sgd_solver.cpp:106] Iteration 6900, lr = 1e-11
I0526 18:43:23.524821 24213 solver.cpp:228] Iteration 6910, loss = 0.673757
I0526 18:43:23.524880 24213 solver.cpp:244]     Train net output #0: loss = 0.673757 (* 1 = 0.673757 loss)
I0526 18:43:23.524895 24213 sgd_solver.cpp:106] Iteration 6910, lr = 1e-11
I0526 18:43:29.469599 24213 solver.cpp:228] Iteration 6920, loss = 0.650063
I0526 18:43:29.469725 24213 solver.cpp:244]     Train net output #0: loss = 0.650063 (* 1 = 0.650063 loss)
I0526 18:43:29.469745 24213 sgd_solver.cpp:106] Iteration 6920, lr = 1e-11
I0526 18:43:35.037861 24213 solver.cpp:337] Iteration 6930, Testing net (#0)
I0526 18:43:37.084324 24213 solver.cpp:404]     Test net output #0: accuracy = 0.381818
I0526 18:43:37.084367 24213 solver.cpp:404]     Test net output #1: loss = 2.55768 (* 1 = 2.55768 loss)
I0526 18:43:37.617151 24213 solver.cpp:228] Iteration 6930, loss = 0.633073
I0526 18:43:37.617193 24213 solver.cpp:244]     Train net output #0: loss = 0.633073 (* 1 = 0.633073 loss)
I0526 18:43:37.617209 24213 sgd_solver.cpp:106] Iteration 6930, lr = 1e-11
I0526 18:43:43.557647 24213 solver.cpp:228] Iteration 6940, loss = 0.623327
I0526 18:43:43.557695 24213 solver.cpp:244]     Train net output #0: loss = 0.623327 (* 1 = 0.623327 loss)
I0526 18:43:43.557714 24213 sgd_solver.cpp:106] Iteration 6940, lr = 1e-11
I0526 18:43:49.500787 24213 solver.cpp:228] Iteration 6950, loss = 0.613613
I0526 18:43:49.500828 24213 solver.cpp:244]     Train net output #0: loss = 0.613613 (* 1 = 0.613613 loss)
I0526 18:43:49.500839 24213 sgd_solver.cpp:106] Iteration 6950, lr = 1e-11
I0526 18:43:54.855383 24213 solver.cpp:337] Iteration 6960, Testing net (#0)
I0526 18:43:56.895431 24213 solver.cpp:404]     Test net output #0: accuracy = 0.381818
I0526 18:43:56.895484 24213 solver.cpp:404]     Test net output #1: loss = 2.57168 (* 1 = 2.57168 loss)
I0526 18:43:57.428333 24213 solver.cpp:228] Iteration 6960, loss = 0.650855
I0526 18:43:57.428377 24213 solver.cpp:244]     Train net output #0: loss = 0.650855 (* 1 = 0.650855 loss)
I0526 18:43:57.428393 24213 sgd_solver.cpp:106] Iteration 6960, lr = 1e-11
I0526 18:44:03.367771 24213 solver.cpp:228] Iteration 6970, loss = 0.735346
I0526 18:44:03.367923 24213 solver.cpp:244]     Train net output #0: loss = 0.735346 (* 1 = 0.735346 loss)
I0526 18:44:03.367938 24213 sgd_solver.cpp:106] Iteration 6970, lr = 1e-11
I0526 18:44:09.306887 24213 solver.cpp:228] Iteration 6980, loss = 0.598708
I0526 18:44:09.306937 24213 solver.cpp:244]     Train net output #0: loss = 0.598708 (* 1 = 0.598708 loss)
I0526 18:44:09.306948 24213 sgd_solver.cpp:106] Iteration 6980, lr = 1e-11
I0526 18:44:14.661090 24213 solver.cpp:337] Iteration 6990, Testing net (#0)
I0526 18:44:16.773737 24213 solver.cpp:404]     Test net output #0: accuracy = 0.381818
I0526 18:44:16.773787 24213 solver.cpp:404]     Test net output #1: loss = 2.55085 (* 1 = 2.55085 loss)
I0526 18:44:17.309306 24213 solver.cpp:228] Iteration 6990, loss = 0.644825
I0526 18:44:17.309346 24213 solver.cpp:244]     Train net output #0: loss = 0.644825 (* 1 = 0.644825 loss)
I0526 18:44:17.309362 24213 sgd_solver.cpp:106] Iteration 6990, lr = 1e-11
I0526 18:44:22.663173 24213 solver.cpp:454] Snapshotting to binary proto file snapshot2/caffe_CAM_finetuneMIT_iter_7000.caffemodel
I0526 18:44:22.770124 24213 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot2/caffe_CAM_finetuneMIT_iter_7000.solverstate
I0526 18:44:23.325906 24213 solver.cpp:228] Iteration 7000, loss = 0.641089
I0526 18:44:23.325969 24213 solver.cpp:244]     Train net output #0: loss = 0.641089 (* 1 = 0.641089 loss)
I0526 18:44:23.325981 24213 sgd_solver.cpp:106] Iteration 7000, lr = 1e-12
I0526 18:44:29.268576 24213 solver.cpp:228] Iteration 7010, loss = 0.64223
I0526 18:44:29.268628 24213 solver.cpp:244]     Train net output #0: loss = 0.64223 (* 1 = 0.64223 loss)
I0526 18:44:29.268640 24213 sgd_solver.cpp:106] Iteration 7010, lr = 1e-12
I0526 18:44:34.620789 24213 solver.cpp:337] Iteration 7020, Testing net (#0)
I0526 18:44:36.618670 24213 solver.cpp:404]     Test net output #0: accuracy = 0.38
I0526 18:44:36.618721 24213 solver.cpp:404]     Test net output #1: loss = 2.55656 (* 1 = 2.55656 loss)
I0526 18:44:37.149785 24213 solver.cpp:228] Iteration 7020, loss = 0.591758
I0526 18:44:37.149833 24213 solver.cpp:244]     Train net output #0: loss = 0.591758 (* 1 = 0.591758 loss)
I0526 18:44:37.149845 24213 sgd_solver.cpp:106] Iteration 7020, lr = 1e-12
I0526 18:44:43.098040 24213 solver.cpp:228] Iteration 7030, loss = 0.549015
I0526 18:44:43.098091 24213 solver.cpp:244]     Train net output #0: loss = 0.549015 (* 1 = 0.549015 loss)
I0526 18:44:43.098107 24213 sgd_solver.cpp:106] Iteration 7030, lr = 1e-12
I0526 18:44:49.038494 24213 solver.cpp:228] Iteration 7040, loss = 0.741506
I0526 18:44:49.038571 24213 solver.cpp:244]     Train net output #0: loss = 0.741506 (* 1 = 0.741506 loss)
I0526 18:44:49.038584 24213 sgd_solver.cpp:106] Iteration 7040, lr = 1e-12
I0526 18:44:54.388288 24213 solver.cpp:337] Iteration 7050, Testing net (#0)
I0526 18:44:56.554625 24213 solver.cpp:404]     Test net output #0: accuracy = 0.374545
I0526 18:44:56.554675 24213 solver.cpp:404]     Test net output #1: loss = 2.5899 (* 1 = 2.5899 loss)
I0526 18:44:57.087426 24213 solver.cpp:228] Iteration 7050, loss = 0.67947
I0526 18:44:57.087471 24213 solver.cpp:244]     Train net output #0: loss = 0.67947 (* 1 = 0.67947 loss)
I0526 18:44:57.087488 24213 sgd_solver.cpp:106] Iteration 7050, lr = 1e-12
I0526 18:45:03.028928 24213 solver.cpp:228] Iteration 7060, loss = 0.711344
I0526 18:45:03.028973 24213 solver.cpp:244]     Train net output #0: loss = 0.711344 (* 1 = 0.711344 loss)
I0526 18:45:03.028991 24213 sgd_solver.cpp:106] Iteration 7060, lr = 1e-12
I0526 18:45:08.975932 24213 solver.cpp:228] Iteration 7070, loss = 0.603062
I0526 18:45:08.976099 24213 solver.cpp:244]     Train net output #0: loss = 0.603062 (* 1 = 0.603062 loss)
I0526 18:45:08.976145 24213 sgd_solver.cpp:106] Iteration 7070, lr = 1e-12
I0526 18:45:14.321058 24213 solver.cpp:337] Iteration 7080, Testing net (#0)
I0526 18:45:16.247393 24213 solver.cpp:404]     Test net output #0: accuracy = 0.385455
I0526 18:45:16.247465 24213 solver.cpp:404]     Test net output #1: loss = 2.54469 (* 1 = 2.54469 loss)
I0526 18:45:16.781270 24213 solver.cpp:228] Iteration 7080, loss = 0.634635
I0526 18:45:16.781374 24213 solver.cpp:244]     Train net output #0: loss = 0.634635 (* 1 = 0.634635 loss)
I0526 18:45:16.781414 24213 sgd_solver.cpp:106] Iteration 7080, lr = 1e-12
I0526 18:45:22.724354 24213 solver.cpp:228] Iteration 7090, loss = 0.639121
I0526 18:45:22.724406 24213 solver.cpp:244]     Train net output #0: loss = 0.639121 (* 1 = 0.639121 loss)
I0526 18:45:22.724418 24213 sgd_solver.cpp:106] Iteration 7090, lr = 1e-12
I0526 18:45:28.665215 24213 solver.cpp:228] Iteration 7100, loss = 0.724841
I0526 18:45:28.665267 24213 solver.cpp:244]     Train net output #0: loss = 0.724841 (* 1 = 0.724841 loss)
I0526 18:45:28.665278 24213 sgd_solver.cpp:106] Iteration 7100, lr = 1e-12
I0526 18:45:34.019917 24213 solver.cpp:337] Iteration 7110, Testing net (#0)
I0526 18:45:36.081336 24213 solver.cpp:404]     Test net output #0: accuracy = 0.383636
I0526 18:45:36.081385 24213 solver.cpp:404]     Test net output #1: loss = 2.53868 (* 1 = 2.53868 loss)
I0526 18:45:36.613489 24213 solver.cpp:228] Iteration 7110, loss = 0.750923
I0526 18:45:36.613540 24213 solver.cpp:244]     Train net output #0: loss = 0.750923 (* 1 = 0.750923 loss)
I0526 18:45:36.613553 24213 sgd_solver.cpp:106] Iteration 7110, lr = 1e-12
I0526 18:45:42.561007 24213 solver.cpp:228] Iteration 7120, loss = 0.71807
I0526 18:45:42.561102 24213 solver.cpp:244]     Train net output #0: loss = 0.71807 (* 1 = 0.71807 loss)
I0526 18:45:42.561120 24213 sgd_solver.cpp:106] Iteration 7120, lr = 1e-12
I0526 18:45:48.502564 24213 solver.cpp:228] Iteration 7130, loss = 0.627141
I0526 18:45:48.502626 24213 solver.cpp:244]     Train net output #0: loss = 0.627141 (* 1 = 0.627141 loss)
I0526 18:45:48.502638 24213 sgd_solver.cpp:106] Iteration 7130, lr = 1e-12
I0526 18:45:53.851450 24213 solver.cpp:337] Iteration 7140, Testing net (#0)
I0526 18:45:56.013288 24213 solver.cpp:404]     Test net output #0: accuracy = 0.381818
I0526 18:45:56.013346 24213 solver.cpp:404]     Test net output #1: loss = 2.57369 (* 1 = 2.57369 loss)
I0526 18:45:56.548487 24213 solver.cpp:228] Iteration 7140, loss = 0.632791
I0526 18:45:56.548552 24213 solver.cpp:244]     Train net output #0: loss = 0.632791 (* 1 = 0.632791 loss)
I0526 18:45:56.548569 24213 sgd_solver.cpp:106] Iteration 7140, lr = 1e-12
I0526 18:46:02.497057 24213 solver.cpp:228] Iteration 7150, loss = 0.675541
I0526 18:46:02.497095 24213 solver.cpp:244]     Train net output #0: loss = 0.675541 (* 1 = 0.675541 loss)
I0526 18:46:02.497107 24213 sgd_solver.cpp:106] Iteration 7150, lr = 1e-12
I0526 18:46:08.440533 24213 solver.cpp:228] Iteration 7160, loss = 0.658636
I0526 18:46:08.440578 24213 solver.cpp:244]     Train net output #0: loss = 0.658636 (* 1 = 0.658636 loss)
I0526 18:46:08.440590 24213 sgd_solver.cpp:106] Iteration 7160, lr = 1e-12
I0526 18:46:13.790599 24213 solver.cpp:337] Iteration 7170, Testing net (#0)
I0526 18:46:16.072566 24213 solver.cpp:404]     Test net output #0: accuracy = 0.381818
I0526 18:46:16.072604 24213 solver.cpp:404]     Test net output #1: loss = 2.56043 (* 1 = 2.56043 loss)
I0526 18:46:16.605096 24213 solver.cpp:228] Iteration 7170, loss = 0.681085
I0526 18:46:16.605134 24213 solver.cpp:244]     Train net output #0: loss = 0.681085 (* 1 = 0.681085 loss)
I0526 18:46:16.605145 24213 sgd_solver.cpp:106] Iteration 7170, lr = 1e-12
I0526 18:46:22.552533 24213 solver.cpp:228] Iteration 7180, loss = 0.664228
I0526 18:46:22.552574 24213 solver.cpp:244]     Train net output #0: loss = 0.664228 (* 1 = 0.664228 loss)
I0526 18:46:22.552587 24213 sgd_solver.cpp:106] Iteration 7180, lr = 1e-12
I0526 18:46:28.492409 24213 solver.cpp:228] Iteration 7190, loss = 0.687438
I0526 18:46:28.492506 24213 solver.cpp:244]     Train net output #0: loss = 0.687438 (* 1 = 0.687438 loss)
I0526 18:46:28.492527 24213 sgd_solver.cpp:106] Iteration 7190, lr = 1e-12
I0526 18:46:33.846323 24213 solver.cpp:337] Iteration 7200, Testing net (#0)
I0526 18:46:36.033146 24213 solver.cpp:404]     Test net output #0: accuracy = 0.383636
I0526 18:46:36.033186 24213 solver.cpp:404]     Test net output #1: loss = 2.54081 (* 1 = 2.54081 loss)
I0526 18:46:36.565754 24213 solver.cpp:228] Iteration 7200, loss = 0.659761
I0526 18:46:36.565805 24213 solver.cpp:244]     Train net output #0: loss = 0.659761 (* 1 = 0.659761 loss)
I0526 18:46:36.565817 24213 sgd_solver.cpp:106] Iteration 7200, lr = 1e-12
I0526 18:46:42.515213 24213 solver.cpp:228] Iteration 7210, loss = 0.649587
I0526 18:46:42.515254 24213 solver.cpp:244]     Train net output #0: loss = 0.649587 (* 1 = 0.649587 loss)
I0526 18:46:42.515264 24213 sgd_solver.cpp:106] Iteration 7210, lr = 1e-12
I0526 18:46:48.449856 24213 solver.cpp:228] Iteration 7220, loss = 0.712625
I0526 18:46:48.449975 24213 solver.cpp:244]     Train net output #0: loss = 0.712625 (* 1 = 0.712625 loss)
I0526 18:46:48.449990 24213 sgd_solver.cpp:106] Iteration 7220, lr = 1e-12
I0526 18:46:53.797368 24213 solver.cpp:337] Iteration 7230, Testing net (#0)
I0526 18:46:55.779531 24213 solver.cpp:404]     Test net output #0: accuracy = 0.381818
I0526 18:46:55.779569 24213 solver.cpp:404]     Test net output #1: loss = 2.55889 (* 1 = 2.55889 loss)
I0526 18:46:56.311110 24213 solver.cpp:228] Iteration 7230, loss = 0.710645
I0526 18:46:56.311177 24213 solver.cpp:244]     Train net output #0: loss = 0.710645 (* 1 = 0.710645 loss)
I0526 18:46:56.311192 24213 sgd_solver.cpp:106] Iteration 7230, lr = 1e-12
I0526 18:47:02.255015 24213 solver.cpp:228] Iteration 7240, loss = 0.604607
I0526 18:47:02.255054 24213 solver.cpp:244]     Train net output #0: loss = 0.604607 (* 1 = 0.604607 loss)
I0526 18:47:02.255064 24213 sgd_solver.cpp:106] Iteration 7240, lr = 1e-12
I0526 18:47:08.192971 24213 solver.cpp:228] Iteration 7250, loss = 0.738619
I0526 18:47:08.193022 24213 solver.cpp:244]     Train net output #0: loss = 0.738619 (* 1 = 0.738619 loss)
I0526 18:47:08.193034 24213 sgd_solver.cpp:106] Iteration 7250, lr = 1e-12
I0526 18:47:13.540629 24213 solver.cpp:337] Iteration 7260, Testing net (#0)
I0526 18:47:15.552121 24213 solver.cpp:404]     Test net output #0: accuracy = 0.38
I0526 18:47:15.552162 24213 solver.cpp:404]     Test net output #1: loss = 2.57382 (* 1 = 2.57382 loss)
I0526 18:47:16.083822 24213 solver.cpp:228] Iteration 7260, loss = 0.535807
I0526 18:47:16.083864 24213 solver.cpp:244]     Train net output #0: loss = 0.535807 (* 1 = 0.535807 loss)
I0526 18:47:16.083880 24213 sgd_solver.cpp:106] Iteration 7260, lr = 1e-12
I0526 18:47:22.028388 24213 solver.cpp:228] Iteration 7270, loss = 0.590751
I0526 18:47:22.028518 24213 solver.cpp:244]     Train net output #0: loss = 0.590751 (* 1 = 0.590751 loss)
I0526 18:47:22.028532 24213 sgd_solver.cpp:106] Iteration 7270, lr = 1e-12
I0526 18:47:27.974812 24213 solver.cpp:228] Iteration 7280, loss = 0.594812
I0526 18:47:27.974867 24213 solver.cpp:244]     Train net output #0: loss = 0.594812 (* 1 = 0.594812 loss)
I0526 18:47:27.974885 24213 sgd_solver.cpp:106] Iteration 7280, lr = 1e-12
I0526 18:47:33.323066 24213 solver.cpp:337] Iteration 7290, Testing net (#0)
I0526 18:47:35.840214 24213 solver.cpp:404]     Test net output #0: accuracy = 0.38
I0526 18:47:35.840260 24213 solver.cpp:404]     Test net output #1: loss = 2.57094 (* 1 = 2.57094 loss)
I0526 18:47:36.377277 24213 solver.cpp:228] Iteration 7290, loss = 0.756121
I0526 18:47:36.377327 24213 solver.cpp:244]     Train net output #0: loss = 0.756121 (* 1 = 0.756121 loss)
I0526 18:47:36.377338 24213 sgd_solver.cpp:106] Iteration 7290, lr = 1e-12
I0526 18:47:42.316238 24213 solver.cpp:228] Iteration 7300, loss = 0.753529
I0526 18:47:42.316287 24213 solver.cpp:244]     Train net output #0: loss = 0.753529 (* 1 = 0.753529 loss)
I0526 18:47:42.316301 24213 sgd_solver.cpp:106] Iteration 7300, lr = 1e-12
I0526 18:47:48.260006 24213 solver.cpp:228] Iteration 7310, loss = 0.59873
I0526 18:47:48.260071 24213 solver.cpp:244]     Train net output #0: loss = 0.59873 (* 1 = 0.59873 loss)
I0526 18:47:48.260084 24213 sgd_solver.cpp:106] Iteration 7310, lr = 1e-12
I0526 18:47:53.606204 24213 solver.cpp:337] Iteration 7320, Testing net (#0)
I0526 18:47:55.713111 24213 solver.cpp:404]     Test net output #0: accuracy = 0.383636
I0526 18:47:55.713153 24213 solver.cpp:404]     Test net output #1: loss = 2.56485 (* 1 = 2.56485 loss)
I0526 18:47:56.244942 24213 solver.cpp:228] Iteration 7320, loss = 0.639133
I0526 18:47:56.245002 24213 solver.cpp:244]     Train net output #0: loss = 0.639133 (* 1 = 0.639133 loss)
I0526 18:47:56.245031 24213 sgd_solver.cpp:106] Iteration 7320, lr = 1e-12
I0526 18:48:02.180043 24213 solver.cpp:228] Iteration 7330, loss = 0.648821
I0526 18:48:02.180083 24213 solver.cpp:244]     Train net output #0: loss = 0.648821 (* 1 = 0.648821 loss)
I0526 18:48:02.180095 24213 sgd_solver.cpp:106] Iteration 7330, lr = 1e-12
I0526 18:48:08.123003 24213 solver.cpp:228] Iteration 7340, loss = 0.591044
I0526 18:48:08.123057 24213 solver.cpp:244]     Train net output #0: loss = 0.591044 (* 1 = 0.591044 loss)
I0526 18:48:08.123070 24213 sgd_solver.cpp:106] Iteration 7340, lr = 1e-12
I0526 18:48:13.472164 24213 solver.cpp:337] Iteration 7350, Testing net (#0)
I0526 18:48:15.502218 24213 solver.cpp:404]     Test net output #0: accuracy = 0.387273
I0526 18:48:15.502269 24213 solver.cpp:404]     Test net output #1: loss = 2.53861 (* 1 = 2.53861 loss)
I0526 18:48:16.033164 24213 solver.cpp:228] Iteration 7350, loss = 0.697427
I0526 18:48:16.033215 24213 solver.cpp:244]     Train net output #0: loss = 0.697427 (* 1 = 0.697427 loss)
I0526 18:48:16.033231 24213 sgd_solver.cpp:106] Iteration 7350, lr = 1e-12
I0526 18:48:21.975409 24213 solver.cpp:228] Iteration 7360, loss = 0.804388
I0526 18:48:21.975460 24213 solver.cpp:244]     Train net output #0: loss = 0.804388 (* 1 = 0.804388 loss)
I0526 18:48:21.975471 24213 sgd_solver.cpp:106] Iteration 7360, lr = 1e-12
I0526 18:48:27.913147 24213 solver.cpp:228] Iteration 7370, loss = 0.664353
I0526 18:48:27.913272 24213 solver.cpp:244]     Train net output #0: loss = 0.664353 (* 1 = 0.664353 loss)
I0526 18:48:27.913286 24213 sgd_solver.cpp:106] Iteration 7370, lr = 1e-12
I0526 18:48:33.254478 24213 solver.cpp:337] Iteration 7380, Testing net (#0)
I0526 18:48:35.254410 24213 solver.cpp:404]     Test net output #0: accuracy = 0.381818
I0526 18:48:35.254448 24213 solver.cpp:404]     Test net output #1: loss = 2.56931 (* 1 = 2.56931 loss)
I0526 18:48:35.787606 24213 solver.cpp:228] Iteration 7380, loss = 0.578681
I0526 18:48:35.787654 24213 solver.cpp:244]     Train net output #0: loss = 0.578681 (* 1 = 0.578681 loss)
I0526 18:48:35.787669 24213 sgd_solver.cpp:106] Iteration 7380, lr = 1e-12
I0526 18:48:41.728651 24213 solver.cpp:228] Iteration 7390, loss = 0.633838
I0526 18:48:41.728708 24213 solver.cpp:244]     Train net output #0: loss = 0.633838 (* 1 = 0.633838 loss)
I0526 18:48:41.728720 24213 sgd_solver.cpp:106] Iteration 7390, lr = 1e-12
I0526 18:48:47.664965 24213 solver.cpp:228] Iteration 7400, loss = 0.604294
I0526 18:48:47.665009 24213 solver.cpp:244]     Train net output #0: loss = 0.604294 (* 1 = 0.604294 loss)
I0526 18:48:47.665020 24213 sgd_solver.cpp:106] Iteration 7400, lr = 1e-12
I0526 18:48:53.011569 24213 solver.cpp:337] Iteration 7410, Testing net (#0)
I0526 18:48:55.241740 24213 solver.cpp:404]     Test net output #0: accuracy = 0.376364
I0526 18:48:55.241786 24213 solver.cpp:404]     Test net output #1: loss = 2.55363 (* 1 = 2.55363 loss)
I0526 18:48:55.773411 24213 solver.cpp:228] Iteration 7410, loss = 0.694181
I0526 18:48:55.773452 24213 solver.cpp:244]     Train net output #0: loss = 0.694181 (* 1 = 0.694181 loss)
I0526 18:48:55.773468 24213 sgd_solver.cpp:106] Iteration 7410, lr = 1e-12
I0526 18:49:01.720780 24213 solver.cpp:228] Iteration 7420, loss = 0.689783
I0526 18:49:01.720966 24213 solver.cpp:244]     Train net output #0: loss = 0.689783 (* 1 = 0.689783 loss)
I0526 18:49:01.720986 24213 sgd_solver.cpp:106] Iteration 7420, lr = 1e-12
I0526 18:49:07.656173 24213 solver.cpp:228] Iteration 7430, loss = 0.657787
I0526 18:49:07.656215 24213 solver.cpp:244]     Train net output #0: loss = 0.657787 (* 1 = 0.657787 loss)
I0526 18:49:07.656227 24213 sgd_solver.cpp:106] Iteration 7430, lr = 1e-12
I0526 18:49:13.008680 24213 solver.cpp:337] Iteration 7440, Testing net (#0)
I0526 18:49:15.177330 24213 solver.cpp:404]     Test net output #0: accuracy = 0.389091
I0526 18:49:15.177391 24213 solver.cpp:404]     Test net output #1: loss = 2.52276 (* 1 = 2.52276 loss)
I0526 18:49:15.709744 24213 solver.cpp:228] Iteration 7440, loss = 0.667969
I0526 18:49:15.709806 24213 solver.cpp:244]     Train net output #0: loss = 0.667969 (* 1 = 0.667969 loss)
I0526 18:49:15.709820 24213 sgd_solver.cpp:106] Iteration 7440, lr = 1e-12
I0526 18:49:21.655055 24213 solver.cpp:228] Iteration 7450, loss = 0.589396
I0526 18:49:21.655119 24213 solver.cpp:244]     Train net output #0: loss = 0.589396 (* 1 = 0.589396 loss)
I0526 18:49:21.655136 24213 sgd_solver.cpp:106] Iteration 7450, lr = 1e-12
I0526 18:49:27.588732 24213 solver.cpp:228] Iteration 7460, loss = 0.645257
I0526 18:49:27.588790 24213 solver.cpp:244]     Train net output #0: loss = 0.645257 (* 1 = 0.645257 loss)
I0526 18:49:27.588807 24213 sgd_solver.cpp:106] Iteration 7460, lr = 1e-12
I0526 18:49:32.940882 24213 solver.cpp:337] Iteration 7470, Testing net (#0)
I0526 18:49:35.039614 24213 solver.cpp:404]     Test net output #0: accuracy = 0.390909
I0526 18:49:35.039665 24213 solver.cpp:404]     Test net output #1: loss = 2.53716 (* 1 = 2.53716 loss)
I0526 18:49:35.571174 24213 solver.cpp:228] Iteration 7470, loss = 0.675698
I0526 18:49:35.571223 24213 solver.cpp:244]     Train net output #0: loss = 0.675698 (* 1 = 0.675698 loss)
I0526 18:49:35.571239 24213 sgd_solver.cpp:106] Iteration 7470, lr = 1e-12
I0526 18:49:41.511502 24213 solver.cpp:228] Iteration 7480, loss = 0.625653
I0526 18:49:41.511567 24213 solver.cpp:244]     Train net output #0: loss = 0.625653 (* 1 = 0.625653 loss)
I0526 18:49:41.511580 24213 sgd_solver.cpp:106] Iteration 7480, lr = 1e-12
I0526 18:49:47.444682 24213 solver.cpp:228] Iteration 7490, loss = 0.634637
I0526 18:49:47.444731 24213 solver.cpp:244]     Train net output #0: loss = 0.634637 (* 1 = 0.634637 loss)
I0526 18:49:47.444743 24213 sgd_solver.cpp:106] Iteration 7490, lr = 1e-12
I0526 18:49:52.801205 24213 solver.cpp:337] Iteration 7500, Testing net (#0)
I0526 18:49:54.916213 24213 solver.cpp:404]     Test net output #0: accuracy = 0.383636
I0526 18:49:54.916255 24213 solver.cpp:404]     Test net output #1: loss = 2.54789 (* 1 = 2.54789 loss)
I0526 18:49:55.448359 24213 solver.cpp:228] Iteration 7500, loss = 0.776864
I0526 18:49:55.448447 24213 solver.cpp:244]     Train net output #0: loss = 0.776864 (* 1 = 0.776864 loss)
I0526 18:49:55.448488 24213 sgd_solver.cpp:106] Iteration 7500, lr = 1e-12
I0526 18:50:01.385762 24213 solver.cpp:228] Iteration 7510, loss = 0.584743
I0526 18:50:01.385808 24213 solver.cpp:244]     Train net output #0: loss = 0.584743 (* 1 = 0.584743 loss)
I0526 18:50:01.385824 24213 sgd_solver.cpp:106] Iteration 7510, lr = 1e-12
I0526 18:50:07.328336 24213 solver.cpp:228] Iteration 7520, loss = 0.596918
I0526 18:50:07.328507 24213 solver.cpp:244]     Train net output #0: loss = 0.596918 (* 1 = 0.596918 loss)
I0526 18:50:07.328522 24213 sgd_solver.cpp:106] Iteration 7520, lr = 1e-12
I0526 18:50:12.674407 24213 solver.cpp:337] Iteration 7530, Testing net (#0)
I0526 18:50:15.051545 24213 solver.cpp:404]     Test net output #0: accuracy = 0.383636
I0526 18:50:15.051604 24213 solver.cpp:404]     Test net output #1: loss = 2.57156 (* 1 = 2.57156 loss)
I0526 18:50:15.583195 24213 solver.cpp:228] Iteration 7530, loss = 0.613453
I0526 18:50:15.583302 24213 solver.cpp:244]     Train net output #0: loss = 0.613453 (* 1 = 0.613453 loss)
I0526 18:50:15.583340 24213 sgd_solver.cpp:106] Iteration 7530, lr = 1e-12
I0526 18:50:21.525466 24213 solver.cpp:228] Iteration 7540, loss = 0.688476
I0526 18:50:21.525535 24213 solver.cpp:244]     Train net output #0: loss = 0.688476 (* 1 = 0.688476 loss)
I0526 18:50:21.525548 24213 sgd_solver.cpp:106] Iteration 7540, lr = 1e-12
I0526 18:50:27.467218 24213 solver.cpp:228] Iteration 7550, loss = 0.705779
I0526 18:50:27.467296 24213 solver.cpp:244]     Train net output #0: loss = 0.705779 (* 1 = 0.705779 loss)
I0526 18:50:27.467335 24213 sgd_solver.cpp:106] Iteration 7550, lr = 1e-12
I0526 18:50:32.817994 24213 solver.cpp:337] Iteration 7560, Testing net (#0)
I0526 18:50:34.950379 24213 solver.cpp:404]     Test net output #0: accuracy = 0.385455
I0526 18:50:34.950450 24213 solver.cpp:404]     Test net output #1: loss = 2.53099 (* 1 = 2.53099 loss)
I0526 18:50:35.482097 24213 solver.cpp:228] Iteration 7560, loss = 0.712625
I0526 18:50:35.482139 24213 solver.cpp:244]     Train net output #0: loss = 0.712625 (* 1 = 0.712625 loss)
I0526 18:50:35.482156 24213 sgd_solver.cpp:106] Iteration 7560, lr = 1e-12
I0526 18:50:41.428808 24213 solver.cpp:228] Iteration 7570, loss = 0.650936
I0526 18:50:41.428995 24213 solver.cpp:244]     Train net output #0: loss = 0.650936 (* 1 = 0.650936 loss)
I0526 18:50:41.429016 24213 sgd_solver.cpp:106] Iteration 7570, lr = 1e-12
I0526 18:50:47.480003 24213 solver.cpp:228] Iteration 7580, loss = 0.599973
I0526 18:50:47.480062 24213 solver.cpp:244]     Train net output #0: loss = 0.599973 (* 1 = 0.599973 loss)
I0526 18:50:47.480080 24213 sgd_solver.cpp:106] Iteration 7580, lr = 1e-12
I0526 18:50:53.246783 24213 solver.cpp:337] Iteration 7590, Testing net (#0)
I0526 18:50:55.533172 24213 solver.cpp:404]     Test net output #0: accuracy = 0.381818
I0526 18:50:55.533221 24213 solver.cpp:404]     Test net output #1: loss = 2.56999 (* 1 = 2.56999 loss)
I0526 18:50:56.064716 24213 solver.cpp:228] Iteration 7590, loss = 0.663877
I0526 18:50:56.064780 24213 solver.cpp:244]     Train net output #0: loss = 0.663877 (* 1 = 0.663877 loss)
I0526 18:50:56.064800 24213 sgd_solver.cpp:106] Iteration 7590, lr = 1e-12
I0526 18:51:02.006857 24213 solver.cpp:228] Iteration 7600, loss = 0.711932
I0526 18:51:02.006923 24213 solver.cpp:244]     Train net output #0: loss = 0.711932 (* 1 = 0.711932 loss)
I0526 18:51:02.006937 24213 sgd_solver.cpp:106] Iteration 7600, lr = 1e-12
I0526 18:51:07.937729 24213 solver.cpp:228] Iteration 7610, loss = 0.747095
I0526 18:51:07.937790 24213 solver.cpp:244]     Train net output #0: loss = 0.747095 (* 1 = 0.747095 loss)
I0526 18:51:07.937803 24213 sgd_solver.cpp:106] Iteration 7610, lr = 1e-12
I0526 18:51:13.287256 24213 solver.cpp:337] Iteration 7620, Testing net (#0)
I0526 18:51:15.305747 24213 solver.cpp:404]     Test net output #0: accuracy = 0.38
I0526 18:51:15.305801 24213 solver.cpp:404]     Test net output #1: loss = 2.55284 (* 1 = 2.55284 loss)
I0526 18:51:15.837628 24213 solver.cpp:228] Iteration 7620, loss = 0.572359
I0526 18:51:15.837674 24213 solver.cpp:244]     Train net output #0: loss = 0.572359 (* 1 = 0.572359 loss)
I0526 18:51:15.837692 24213 sgd_solver.cpp:106] Iteration 7620, lr = 1e-12
I0526 18:51:21.781713 24213 solver.cpp:228] Iteration 7630, loss = 0.614816
I0526 18:51:21.781781 24213 solver.cpp:244]     Train net output #0: loss = 0.614816 (* 1 = 0.614816 loss)
I0526 18:51:21.781798 24213 sgd_solver.cpp:106] Iteration 7630, lr = 1e-12
I0526 18:51:27.721065 24213 solver.cpp:228] Iteration 7640, loss = 0.583821
I0526 18:51:27.721112 24213 solver.cpp:244]     Train net output #0: loss = 0.583821 (* 1 = 0.583821 loss)
I0526 18:51:27.721128 24213 sgd_solver.cpp:106] Iteration 7640, lr = 1e-12
I0526 18:51:33.205178 24213 solver.cpp:337] Iteration 7650, Testing net (#0)
I0526 18:51:35.375849 24213 solver.cpp:404]     Test net output #0: accuracy = 0.38
I0526 18:51:35.375897 24213 solver.cpp:404]     Test net output #1: loss = 2.58104 (* 1 = 2.58104 loss)
I0526 18:51:35.914238 24213 solver.cpp:228] Iteration 7650, loss = 0.635402
I0526 18:51:35.914289 24213 solver.cpp:244]     Train net output #0: loss = 0.635402 (* 1 = 0.635402 loss)
I0526 18:51:35.914302 24213 sgd_solver.cpp:106] Iteration 7650, lr = 1e-12
I0526 18:51:41.853708 24213 solver.cpp:228] Iteration 7660, loss = 0.629036
I0526 18:51:41.853843 24213 solver.cpp:244]     Train net output #0: loss = 0.629036 (* 1 = 0.629036 loss)
I0526 18:51:41.853885 24213 sgd_solver.cpp:106] Iteration 7660, lr = 1e-12
I0526 18:51:48.095048 24213 solver.cpp:228] Iteration 7670, loss = 0.643082
I0526 18:51:48.095232 24213 solver.cpp:244]     Train net output #0: loss = 0.643082 (* 1 = 0.643082 loss)
I0526 18:51:48.095270 24213 sgd_solver.cpp:106] Iteration 7670, lr = 1e-12
I0526 18:51:53.823701 24213 solver.cpp:337] Iteration 7680, Testing net (#0)
I0526 18:51:56.176571 24213 solver.cpp:404]     Test net output #0: accuracy = 0.383636
I0526 18:51:56.176620 24213 solver.cpp:404]     Test net output #1: loss = 2.56706 (* 1 = 2.56706 loss)
I0526 18:51:56.712622 24213 solver.cpp:228] Iteration 7680, loss = 0.747454
I0526 18:51:56.712700 24213 solver.cpp:244]     Train net output #0: loss = 0.747454 (* 1 = 0.747454 loss)
I0526 18:51:56.712718 24213 sgd_solver.cpp:106] Iteration 7680, lr = 1e-12
I0526 18:52:02.650329 24213 solver.cpp:228] Iteration 7690, loss = 0.58857
I0526 18:52:02.650379 24213 solver.cpp:244]     Train net output #0: loss = 0.58857 (* 1 = 0.58857 loss)
I0526 18:52:02.650391 24213 sgd_solver.cpp:106] Iteration 7690, lr = 1e-12
I0526 18:52:08.594934 24213 solver.cpp:228] Iteration 7700, loss = 0.65055
I0526 18:52:08.594982 24213 solver.cpp:244]     Train net output #0: loss = 0.65055 (* 1 = 0.65055 loss)
I0526 18:52:08.595005 24213 sgd_solver.cpp:106] Iteration 7700, lr = 1e-12
I0526 18:52:13.946208 24213 solver.cpp:337] Iteration 7710, Testing net (#0)
I0526 18:52:16.034963 24213 solver.cpp:404]     Test net output #0: accuracy = 0.383636
I0526 18:52:16.035027 24213 solver.cpp:404]     Test net output #1: loss = 2.55739 (* 1 = 2.55739 loss)
I0526 18:52:16.567363 24213 solver.cpp:228] Iteration 7710, loss = 0.65853
I0526 18:52:16.567414 24213 solver.cpp:244]     Train net output #0: loss = 0.65853 (* 1 = 0.65853 loss)
I0526 18:52:16.567430 24213 sgd_solver.cpp:106] Iteration 7710, lr = 1e-12
I0526 18:52:22.507025 24213 solver.cpp:228] Iteration 7720, loss = 0.777637
I0526 18:52:22.507164 24213 solver.cpp:244]     Train net output #0: loss = 0.777637 (* 1 = 0.777637 loss)
I0526 18:52:22.507179 24213 sgd_solver.cpp:106] Iteration 7720, lr = 1e-12
I0526 18:52:28.448658 24213 solver.cpp:228] Iteration 7730, loss = 0.642742
I0526 18:52:28.448731 24213 solver.cpp:244]     Train net output #0: loss = 0.642742 (* 1 = 0.642742 loss)
I0526 18:52:28.448750 24213 sgd_solver.cpp:106] Iteration 7730, lr = 1e-12
I0526 18:52:33.793129 24213 solver.cpp:337] Iteration 7740, Testing net (#0)
I0526 18:52:35.810364 24213 solver.cpp:404]     Test net output #0: accuracy = 0.385455
I0526 18:52:35.810411 24213 solver.cpp:404]     Test net output #1: loss = 2.53487 (* 1 = 2.53487 loss)
I0526 18:52:36.342584 24213 solver.cpp:228] Iteration 7740, loss = 0.706433
I0526 18:52:36.342649 24213 solver.cpp:244]     Train net output #0: loss = 0.706433 (* 1 = 0.706433 loss)
I0526 18:52:36.342666 24213 sgd_solver.cpp:106] Iteration 7740, lr = 1e-12
I0526 18:52:42.285666 24213 solver.cpp:228] Iteration 7750, loss = 0.686699
I0526 18:52:42.285718 24213 solver.cpp:244]     Train net output #0: loss = 0.686699 (* 1 = 0.686699 loss)
I0526 18:52:42.285730 24213 sgd_solver.cpp:106] Iteration 7750, lr = 1e-12
I0526 18:52:48.225728 24213 solver.cpp:228] Iteration 7760, loss = 0.600479
I0526 18:52:48.225836 24213 solver.cpp:244]     Train net output #0: loss = 0.600479 (* 1 = 0.600479 loss)
I0526 18:52:48.225862 24213 sgd_solver.cpp:106] Iteration 7760, lr = 1e-12
I0526 18:52:53.578840 24213 solver.cpp:337] Iteration 7770, Testing net (#0)
I0526 18:52:56.209710 24213 solver.cpp:404]     Test net output #0: accuracy = 0.383636
I0526 18:52:56.209779 24213 solver.cpp:404]     Test net output #1: loss = 2.55983 (* 1 = 2.55983 loss)
I0526 18:52:56.742107 24213 solver.cpp:228] Iteration 7770, loss = 0.757621
I0526 18:52:56.742161 24213 solver.cpp:244]     Train net output #0: loss = 0.757621 (* 1 = 0.757621 loss)
I0526 18:52:56.742174 24213 sgd_solver.cpp:106] Iteration 7770, lr = 1e-12
I0526 18:53:02.677490 24213 solver.cpp:228] Iteration 7780, loss = 0.625028
I0526 18:53:02.677548 24213 solver.cpp:244]     Train net output #0: loss = 0.625028 (* 1 = 0.625028 loss)
I0526 18:53:02.677564 24213 sgd_solver.cpp:106] Iteration 7780, lr = 1e-12
I0526 18:53:08.623644 24213 solver.cpp:228] Iteration 7790, loss = 0.606912
I0526 18:53:08.623721 24213 solver.cpp:244]     Train net output #0: loss = 0.606912 (* 1 = 0.606912 loss)
I0526 18:53:08.623739 24213 sgd_solver.cpp:106] Iteration 7790, lr = 1e-12
I0526 18:53:14.156491 24213 solver.cpp:337] Iteration 7800, Testing net (#0)
I0526 18:53:16.259989 24213 solver.cpp:404]     Test net output #0: accuracy = 0.383636
I0526 18:53:16.260051 24213 solver.cpp:404]     Test net output #1: loss = 2.55034 (* 1 = 2.55034 loss)
I0526 18:53:16.794783 24213 solver.cpp:228] Iteration 7800, loss = 0.632336
I0526 18:53:16.794848 24213 solver.cpp:244]     Train net output #0: loss = 0.632336 (* 1 = 0.632336 loss)
I0526 18:53:16.794863 24213 sgd_solver.cpp:106] Iteration 7800, lr = 1e-12
I0526 18:53:22.735077 24213 solver.cpp:228] Iteration 7810, loss = 0.608055
I0526 18:53:22.735170 24213 solver.cpp:244]     Train net output #0: loss = 0.608055 (* 1 = 0.608055 loss)
I0526 18:53:22.735201 24213 sgd_solver.cpp:106] Iteration 7810, lr = 1e-12
I0526 18:53:28.677125 24213 solver.cpp:228] Iteration 7820, loss = 0.669636
I0526 18:53:28.677278 24213 solver.cpp:244]     Train net output #0: loss = 0.669636 (* 1 = 0.669636 loss)
I0526 18:53:28.677330 24213 sgd_solver.cpp:106] Iteration 7820, lr = 1e-12
I0526 18:53:34.018694 24213 solver.cpp:337] Iteration 7830, Testing net (#0)
I0526 18:53:36.354295 24213 solver.cpp:404]     Test net output #0: accuracy = 0.385455
I0526 18:53:36.354408 24213 solver.cpp:404]     Test net output #1: loss = 2.55125 (* 1 = 2.55125 loss)
I0526 18:53:36.886379 24213 solver.cpp:228] Iteration 7830, loss = 0.594432
I0526 18:53:36.886425 24213 solver.cpp:244]     Train net output #0: loss = 0.594432 (* 1 = 0.594432 loss)
I0526 18:53:36.886438 24213 sgd_solver.cpp:106] Iteration 7830, lr = 1e-12
I0526 18:53:42.832443 24213 solver.cpp:228] Iteration 7840, loss = 0.609523
I0526 18:53:42.832586 24213 solver.cpp:244]     Train net output #0: loss = 0.609523 (* 1 = 0.609523 loss)
I0526 18:53:42.832648 24213 sgd_solver.cpp:106] Iteration 7840, lr = 1e-12
I0526 18:53:48.773252 24213 solver.cpp:228] Iteration 7850, loss = 0.7125
I0526 18:53:48.773301 24213 solver.cpp:244]     Train net output #0: loss = 0.7125 (* 1 = 0.7125 loss)
I0526 18:53:48.773313 24213 sgd_solver.cpp:106] Iteration 7850, lr = 1e-12
I0526 18:53:54.118638 24213 solver.cpp:337] Iteration 7860, Testing net (#0)
I0526 18:53:56.083895 24213 solver.cpp:404]     Test net output #0: accuracy = 0.378182
I0526 18:53:56.083937 24213 solver.cpp:404]     Test net output #1: loss = 2.56394 (* 1 = 2.56394 loss)
I0526 18:53:56.615241 24213 solver.cpp:228] Iteration 7860, loss = 0.716244
I0526 18:53:56.615291 24213 solver.cpp:244]     Train net output #0: loss = 0.716244 (* 1 = 0.716244 loss)
I0526 18:53:56.615308 24213 sgd_solver.cpp:106] Iteration 7860, lr = 1e-12
I0526 18:54:02.558385 24213 solver.cpp:228] Iteration 7870, loss = 0.667833
I0526 18:54:02.558521 24213 solver.cpp:244]     Train net output #0: loss = 0.667833 (* 1 = 0.667833 loss)
I0526 18:54:02.558542 24213 sgd_solver.cpp:106] Iteration 7870, lr = 1e-12
I0526 18:54:08.498553 24213 solver.cpp:228] Iteration 7880, loss = 0.602765
I0526 18:54:08.498605 24213 solver.cpp:244]     Train net output #0: loss = 0.602765 (* 1 = 0.602765 loss)
I0526 18:54:08.498616 24213 sgd_solver.cpp:106] Iteration 7880, lr = 1e-12
I0526 18:54:13.856268 24213 solver.cpp:337] Iteration 7890, Testing net (#0)
I0526 18:54:15.911315 24213 solver.cpp:404]     Test net output #0: accuracy = 0.383636
I0526 18:54:15.911360 24213 solver.cpp:404]     Test net output #1: loss = 2.54802 (* 1 = 2.54802 loss)
I0526 18:54:16.444934 24213 solver.cpp:228] Iteration 7890, loss = 0.617101
I0526 18:54:16.445066 24213 solver.cpp:244]     Train net output #0: loss = 0.617101 (* 1 = 0.617101 loss)
I0526 18:54:16.445102 24213 sgd_solver.cpp:106] Iteration 7890, lr = 1e-12
I0526 18:54:22.390162 24213 solver.cpp:228] Iteration 7900, loss = 0.688082
I0526 18:54:22.390202 24213 solver.cpp:244]     Train net output #0: loss = 0.688082 (* 1 = 0.688082 loss)
I0526 18:54:22.390213 24213 sgd_solver.cpp:106] Iteration 7900, lr = 1e-12
I0526 18:54:28.333245 24213 solver.cpp:228] Iteration 7910, loss = 0.752627
I0526 18:54:28.333295 24213 solver.cpp:244]     Train net output #0: loss = 0.752627 (* 1 = 0.752627 loss)
I0526 18:54:28.333310 24213 sgd_solver.cpp:106] Iteration 7910, lr = 1e-12
I0526 18:54:33.680563 24213 solver.cpp:337] Iteration 7920, Testing net (#0)
I0526 18:54:35.765261 24213 solver.cpp:404]     Test net output #0: accuracy = 0.383636
I0526 18:54:35.765303 24213 solver.cpp:404]     Test net output #1: loss = 2.56301 (* 1 = 2.56301 loss)
I0526 18:54:36.297963 24213 solver.cpp:228] Iteration 7920, loss = 0.705642
I0526 18:54:36.298039 24213 solver.cpp:244]     Train net output #0: loss = 0.705642 (* 1 = 0.705642 loss)
I0526 18:54:36.298060 24213 sgd_solver.cpp:106] Iteration 7920, lr = 1e-12
I0526 18:54:42.237243 24213 solver.cpp:228] Iteration 7930, loss = 0.73041
I0526 18:54:42.237301 24213 solver.cpp:244]     Train net output #0: loss = 0.73041 (* 1 = 0.73041 loss)
I0526 18:54:42.237319 24213 sgd_solver.cpp:106] Iteration 7930, lr = 1e-12
I0526 18:54:48.350898 24213 solver.cpp:228] Iteration 7940, loss = 0.651605
I0526 18:54:48.350962 24213 solver.cpp:244]     Train net output #0: loss = 0.651605 (* 1 = 0.651605 loss)
I0526 18:54:48.350980 24213 sgd_solver.cpp:106] Iteration 7940, lr = 1e-12
I0526 18:54:54.079725 24213 solver.cpp:337] Iteration 7950, Testing net (#0)
I0526 18:54:56.379155 24213 solver.cpp:404]     Test net output #0: accuracy = 0.378182
I0526 18:54:56.379204 24213 solver.cpp:404]     Test net output #1: loss = 2.56853 (* 1 = 2.56853 loss)
I0526 18:54:56.918503 24213 solver.cpp:228] Iteration 7950, loss = 0.592188
I0526 18:54:56.918552 24213 solver.cpp:244]     Train net output #0: loss = 0.592188 (* 1 = 0.592188 loss)
I0526 18:54:56.918565 24213 sgd_solver.cpp:106] Iteration 7950, lr = 1e-12
I0526 18:55:02.858466 24213 solver.cpp:228] Iteration 7960, loss = 0.62383
I0526 18:55:02.858538 24213 solver.cpp:244]     Train net output #0: loss = 0.62383 (* 1 = 0.62383 loss)
I0526 18:55:02.858556 24213 sgd_solver.cpp:106] Iteration 7960, lr = 1e-12
I0526 18:55:08.799443 24213 solver.cpp:228] Iteration 7970, loss = 0.639747
I0526 18:55:08.799566 24213 solver.cpp:244]     Train net output #0: loss = 0.639747 (* 1 = 0.639747 loss)
I0526 18:55:08.799579 24213 sgd_solver.cpp:106] Iteration 7970, lr = 1e-12
I0526 18:55:14.151151 24213 solver.cpp:337] Iteration 7980, Testing net (#0)
I0526 18:55:16.274098 24213 solver.cpp:404]     Test net output #0: accuracy = 0.376364
I0526 18:55:16.274147 24213 solver.cpp:404]     Test net output #1: loss = 2.57848 (* 1 = 2.57848 loss)
I0526 18:55:16.806149 24213 solver.cpp:228] Iteration 7980, loss = 0.666378
I0526 18:55:16.806188 24213 solver.cpp:244]     Train net output #0: loss = 0.666378 (* 1 = 0.666378 loss)
I0526 18:55:16.806200 24213 sgd_solver.cpp:106] Iteration 7980, lr = 1e-12
I0526 18:55:22.748582 24213 solver.cpp:228] Iteration 7990, loss = 0.69563
I0526 18:55:22.748651 24213 solver.cpp:244]     Train net output #0: loss = 0.69563 (* 1 = 0.69563 loss)
I0526 18:55:22.748663 24213 sgd_solver.cpp:106] Iteration 7990, lr = 1e-12
I0526 18:55:28.094993 24213 solver.cpp:454] Snapshotting to binary proto file snapshot2/caffe_CAM_finetuneMIT_iter_8000.caffemodel
I0526 18:55:28.203320 24213 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot2/caffe_CAM_finetuneMIT_iter_8000.solverstate
I0526 18:55:28.531493 24213 solver.cpp:317] Iteration 8000, loss = 0.609293
I0526 18:55:28.531533 24213 solver.cpp:322] Optimization Done.
I0526 18:55:28.531539 24213 caffe.cpp:222] Optimization Done.
