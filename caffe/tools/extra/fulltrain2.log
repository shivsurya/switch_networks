I0514 11:22:35.907994 12912 caffe.cpp:185] Using GPUs 2
I0514 11:22:35.935297 12912 caffe.cpp:190] GPU 2: GeForce GTX TITAN X
I0514 11:22:36.179497 12912 solver.cpp:48] Initializing solver from parameters: 
test_iter: 6800
test_interval: 1000
base_lr: 0.0005
display: 50
max_iter: 80000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
snapshot: 1000
snapshot_prefix: "/data1/shiv/ModelA/Training/fulls2_tr"
solver_mode: GPU
device_id: 2
net: "/data1/shiv/ModelA/fullC5trains.prototxt"
test_initialization: true
I0514 11:22:36.179662 12912 solver.cpp:91] Creating training net from net file: /data1/shiv/ModelA/fullC5trains.prototxt
I0514 11:22:36.181061 12912 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0514 11:22:36.181129 12912 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0514 11:22:36.181496 12912 net.cpp:49] Initializing net from parameters: 
name: "VGG"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  image_data_param {
    source: "/data1/shiv/img_folderAlexJitter1/train1.txt"
    batch_size: 15
    shuffle: true
  }
}
layer {
  name: "C1_1a"
  type: "Convolution"
  bottom: "data"
  top: "C1_1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn1a"
  type: "BatchNorm"
  bottom: "C1_1a"
  top: "bn1a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "relu1_1a"
  type: "ReLU"
  bottom: "bn1a"
  top: "relu1_1a"
}
layer {
  name: "C1_2a"
  type: "Convolution"
  bottom: "relu1_1a"
  top: "C1_2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn2a"
  type: "BatchNorm"
  bottom: "C1_2a"
  top: "bn2a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "relu1_2a"
  type: "ReLU"
  bottom: "bn2a"
  top: "relu1_2a"
}
layer {
  name: "pool1a"
  type: "Pooling"
  bottom: "relu1_2a"
  top: "pool1a"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "C2_1a"
  type: "Convolution"
  bottom: "pool1a"
  top: "C2_1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn3a"
  type: "BatchNorm"
  bottom: "C2_1a"
  top: "bn3a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "relu2_1a"
  type: "ReLU"
  bottom: "bn3a"
  top: "relu2_1a"
}
layer {
  name: "C2_2a"
  type: "Convolution"
  bottom: "relu2_1a"
  top: "C2_2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn4a"
  type: "BatchNorm"
  bottom: "C2_2a"
  top: "bn4a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "relu2_2a"
  type: "ReLU"
  bottom: "bn4a"
  top: "relu2_2a"
}
layer {
  name: "pool2a"
  type: "Pooling"
  bottom: "relu2_2a"
  top: "pool2a"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "C3_1a"
  type: "Convolution"
  bottom: "pool2a"
  top: "C3_1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn5a"
  type: "BatchNorm"
  bottom: "C3_1a"
  top: "bn5a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "relu3_1a"
  type: "ReLU"
  bottom: "bn5a"
  top: "relu3_1a"
}
layer {
  name: "C3_2a"
  type: "Convolution"
  bottom: "relu3_1a"
  top: "C3_2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn6a"
  type: "BatchNorm"
  bottom: "C3_2a"
  top: "bn6a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "relu3_2a"
  type: "ReLU"
  bottom: "bn6a"
  top: "relu3_2a"
}
layer {
  name: "C3_3a"
  type: "Convolution"
  bottom: "relu3_2a"
  top: "C3_3a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn7a"
  type: "BatchNorm"
  bottom: "C3_3a"
  top: "bn7a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "relu3_3a"
  type: "ReLU"
  bottom: "bn7a"
  top: "relu3_3a"
}
layer {
  name: "pool3a"
  type: "Pooling"
  bottom: "relu3_3a"
  top: "pool3a"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "C4_1a"
  type: "Convolution"
  bottom: "pool3a"
  top: "C4_1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn8a"
  type: "BatchNorm"
  bottom: "C4_1a"
  top: "bn8a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "relu4_1a"
  type: "ReLU"
  bottom: "bn8a"
  top: "relu4_1a"
}
layer {
  name: "C4_2a"
  type: "Convolution"
  bottom: "relu4_1a"
  top: "C4_2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn9a"
  type: "BatchNorm"
  bottom: "C4_2a"
  top: "bn9a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "relu4_2a"
  type: "ReLU"
  bottom: "bn9a"
  top: "relu4_2a"
}
layer {
  name: "C4_3a"
  type: "Convolution"
  bottom: "relu4_2a"
  top: "C4_3a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn10a"
  type: "BatchNorm"
  bottom: "C4_3a"
  top: "bn10a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "relu4_3a"
  type: "ReLU"
  bottom: "bn10a"
  top: "relu4_3a"
}
layer {
  name: "pool4a"
  type: "Pooling"
  bottom: "relu4_3a"
  top: "pool4a"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "C5_1a"
  type: "Convolution"
  bottom: "pool4a"
  top: "C5_1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn11a"
  type: "BatchNorm"
  bottom: "C5_1a"
  top: "bn11a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "relu5_1a"
  type: "ReLU"
  bottom: "bn11a"
  top: "relu5_1a"
}
layer {
  name: "C5_2a"
  type: "Convolution"
  bottom: "relu5_1a"
  top: "C5_2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn12a"
  type: "BatchNorm"
  bottom: "C5_2a"
  top: "bn12a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "relu5_2a"
  type: "ReLU"
  bottom: "bn12a"
  top: "relu5_2a"
}
layer {
  name: "C5_3a"
  type: "Convolution"
  bottom: "relu5_2a"
  top: "C5_3a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn13a"
  type: "BatchNorm"
  bottom: "C5_3a"
  top: "bn13a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "relu5_3a"
  type: "ReLU"
  bottom: "bn13a"
  top: "relu5_3a"
}
layer {
  name: "GP"
  type: "Pooling"
  bottom: "relu5_3a"
  top: "GP"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "fc"
  type: "InnerProduct"
  bottom: "GP"
  top: "fc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 50
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc"
  bottom: "label"
  top: "loss"
  include {
    phase: TRAIN
  }
}
I0514 11:22:36.181843 12912 layer_factory.hpp:77] Creating layer data
I0514 11:22:36.181910 12912 net.cpp:91] Creating Layer data
I0514 11:22:36.181927 12912 net.cpp:399] data -> data
I0514 11:22:36.181965 12912 net.cpp:399] data -> label
I0514 11:22:36.182515 12912 image_data_layer.cpp:38] Opening file /data1/shiv/img_folderAlexJitter1/train1.txt
I0514 11:22:36.225739 12912 image_data_layer.cpp:48] Shuffling data
I0514 11:22:36.233212 12912 image_data_layer.cpp:53] A total of 70480 images.
I0514 11:22:36.248019 12912 image_data_layer.cpp:80] output data size: 15,3,224,224
I0514 11:22:36.261369 12912 net.cpp:141] Setting up data
I0514 11:22:36.261473 12912 net.cpp:148] Top shape: 15 3 224 224 (2257920)
I0514 11:22:36.261512 12912 net.cpp:148] Top shape: 15 (15)
I0514 11:22:36.261536 12912 net.cpp:156] Memory required for data: 9031740
I0514 11:22:36.261564 12912 layer_factory.hpp:77] Creating layer C1_1a
I0514 11:22:36.261610 12912 net.cpp:91] Creating Layer C1_1a
I0514 11:22:36.261638 12912 net.cpp:425] C1_1a <- data
I0514 11:22:36.261674 12912 net.cpp:399] C1_1a -> C1_1a
I0514 11:22:36.263195 12912 net.cpp:141] Setting up C1_1a
I0514 11:22:36.263252 12912 net.cpp:148] Top shape: 15 64 224 224 (48168960)
I0514 11:22:36.263285 12912 net.cpp:156] Memory required for data: 201707580
I0514 11:22:36.263329 12912 layer_factory.hpp:77] Creating layer bn1a
I0514 11:22:36.263376 12912 net.cpp:91] Creating Layer bn1a
I0514 11:22:36.263406 12912 net.cpp:425] bn1a <- C1_1a
I0514 11:22:36.263434 12912 net.cpp:399] bn1a -> bn1a
I0514 11:22:36.263770 12912 net.cpp:141] Setting up bn1a
I0514 11:22:36.263809 12912 net.cpp:148] Top shape: 15 64 224 224 (48168960)
I0514 11:22:36.263860 12912 net.cpp:156] Memory required for data: 394383420
I0514 11:22:36.263901 12912 layer_factory.hpp:77] Creating layer relu1_1a
I0514 11:22:36.263933 12912 net.cpp:91] Creating Layer relu1_1a
I0514 11:22:36.263958 12912 net.cpp:425] relu1_1a <- bn1a
I0514 11:22:36.263984 12912 net.cpp:399] relu1_1a -> relu1_1a
I0514 11:22:36.264041 12912 net.cpp:141] Setting up relu1_1a
I0514 11:22:36.264075 12912 net.cpp:148] Top shape: 15 64 224 224 (48168960)
I0514 11:22:36.264099 12912 net.cpp:156] Memory required for data: 587059260
I0514 11:22:36.264122 12912 layer_factory.hpp:77] Creating layer C1_2a
I0514 11:22:36.264161 12912 net.cpp:91] Creating Layer C1_2a
I0514 11:22:36.264194 12912 net.cpp:425] C1_2a <- relu1_1a
I0514 11:22:36.264227 12912 net.cpp:399] C1_2a -> C1_2a
I0514 11:22:36.267012 12912 net.cpp:141] Setting up C1_2a
I0514 11:22:36.267067 12912 net.cpp:148] Top shape: 15 64 224 224 (48168960)
I0514 11:22:36.267097 12912 net.cpp:156] Memory required for data: 779735100
I0514 11:22:36.267132 12912 layer_factory.hpp:77] Creating layer bn2a
I0514 11:22:36.267168 12912 net.cpp:91] Creating Layer bn2a
I0514 11:22:36.267197 12912 net.cpp:425] bn2a <- C1_2a
I0514 11:22:36.267230 12912 net.cpp:399] bn2a -> bn2a
I0514 11:22:36.267494 12912 net.cpp:141] Setting up bn2a
I0514 11:22:36.267511 12912 net.cpp:148] Top shape: 15 64 224 224 (48168960)
I0514 11:22:36.267519 12912 net.cpp:156] Memory required for data: 972410940
I0514 11:22:36.267539 12912 layer_factory.hpp:77] Creating layer relu1_2a
I0514 11:22:36.267551 12912 net.cpp:91] Creating Layer relu1_2a
I0514 11:22:36.267560 12912 net.cpp:425] relu1_2a <- bn2a
I0514 11:22:36.267572 12912 net.cpp:399] relu1_2a -> relu1_2a
I0514 11:22:36.267611 12912 net.cpp:141] Setting up relu1_2a
I0514 11:22:36.267628 12912 net.cpp:148] Top shape: 15 64 224 224 (48168960)
I0514 11:22:36.267635 12912 net.cpp:156] Memory required for data: 1165086780
I0514 11:22:36.267642 12912 layer_factory.hpp:77] Creating layer pool1a
I0514 11:22:36.267654 12912 net.cpp:91] Creating Layer pool1a
I0514 11:22:36.267663 12912 net.cpp:425] pool1a <- relu1_2a
I0514 11:22:36.267673 12912 net.cpp:399] pool1a -> pool1a
I0514 11:22:36.267976 12912 net.cpp:141] Setting up pool1a
I0514 11:22:36.267995 12912 net.cpp:148] Top shape: 15 64 112 112 (12042240)
I0514 11:22:36.268003 12912 net.cpp:156] Memory required for data: 1213255740
I0514 11:22:36.268010 12912 layer_factory.hpp:77] Creating layer C2_1a
I0514 11:22:36.268033 12912 net.cpp:91] Creating Layer C2_1a
I0514 11:22:36.268043 12912 net.cpp:425] C2_1a <- pool1a
I0514 11:22:36.268059 12912 net.cpp:399] C2_1a -> C2_1a
I0514 11:22:36.271981 12912 net.cpp:141] Setting up C2_1a
I0514 11:22:36.272058 12912 net.cpp:148] Top shape: 15 128 112 112 (24084480)
I0514 11:22:36.272089 12912 net.cpp:156] Memory required for data: 1309593660
I0514 11:22:36.272121 12912 layer_factory.hpp:77] Creating layer bn3a
I0514 11:22:36.272161 12912 net.cpp:91] Creating Layer bn3a
I0514 11:22:36.272189 12912 net.cpp:425] bn3a <- C2_1a
I0514 11:22:36.272223 12912 net.cpp:399] bn3a -> bn3a
I0514 11:22:36.272536 12912 net.cpp:141] Setting up bn3a
I0514 11:22:36.272578 12912 net.cpp:148] Top shape: 15 128 112 112 (24084480)
I0514 11:22:36.272605 12912 net.cpp:156] Memory required for data: 1405931580
I0514 11:22:36.272641 12912 layer_factory.hpp:77] Creating layer relu2_1a
I0514 11:22:36.272677 12912 net.cpp:91] Creating Layer relu2_1a
I0514 11:22:36.272708 12912 net.cpp:425] relu2_1a <- bn3a
I0514 11:22:36.272740 12912 net.cpp:399] relu2_1a -> relu2_1a
I0514 11:22:36.272804 12912 net.cpp:141] Setting up relu2_1a
I0514 11:22:36.272840 12912 net.cpp:148] Top shape: 15 128 112 112 (24084480)
I0514 11:22:36.272868 12912 net.cpp:156] Memory required for data: 1502269500
I0514 11:22:36.272894 12912 layer_factory.hpp:77] Creating layer C2_2a
I0514 11:22:36.272935 12912 net.cpp:91] Creating Layer C2_2a
I0514 11:22:36.272966 12912 net.cpp:425] C2_2a <- relu2_1a
I0514 11:22:36.273003 12912 net.cpp:399] C2_2a -> C2_2a
I0514 11:22:36.280228 12912 net.cpp:141] Setting up C2_2a
I0514 11:22:36.280308 12912 net.cpp:148] Top shape: 15 128 112 112 (24084480)
I0514 11:22:36.280355 12912 net.cpp:156] Memory required for data: 1598607420
I0514 11:22:36.280398 12912 layer_factory.hpp:77] Creating layer bn4a
I0514 11:22:36.280441 12912 net.cpp:91] Creating Layer bn4a
I0514 11:22:36.280473 12912 net.cpp:425] bn4a <- C2_2a
I0514 11:22:36.280508 12912 net.cpp:399] bn4a -> bn4a
I0514 11:22:36.280822 12912 net.cpp:141] Setting up bn4a
I0514 11:22:36.280975 12912 net.cpp:148] Top shape: 15 128 112 112 (24084480)
I0514 11:22:36.281007 12912 net.cpp:156] Memory required for data: 1694945340
I0514 11:22:36.281044 12912 layer_factory.hpp:77] Creating layer relu2_2a
I0514 11:22:36.281080 12912 net.cpp:91] Creating Layer relu2_2a
I0514 11:22:36.281113 12912 net.cpp:425] relu2_2a <- bn4a
I0514 11:22:36.281146 12912 net.cpp:399] relu2_2a -> relu2_2a
I0514 11:22:36.281209 12912 net.cpp:141] Setting up relu2_2a
I0514 11:22:36.281249 12912 net.cpp:148] Top shape: 15 128 112 112 (24084480)
I0514 11:22:36.281276 12912 net.cpp:156] Memory required for data: 1791283260
I0514 11:22:36.281302 12912 layer_factory.hpp:77] Creating layer pool2a
I0514 11:22:36.281334 12912 net.cpp:91] Creating Layer pool2a
I0514 11:22:36.281363 12912 net.cpp:425] pool2a <- relu2_2a
I0514 11:22:36.281397 12912 net.cpp:399] pool2a -> pool2a
I0514 11:22:36.281486 12912 net.cpp:141] Setting up pool2a
I0514 11:22:36.281524 12912 net.cpp:148] Top shape: 15 128 56 56 (6021120)
I0514 11:22:36.281553 12912 net.cpp:156] Memory required for data: 1815367740
I0514 11:22:36.281579 12912 layer_factory.hpp:77] Creating layer C3_1a
I0514 11:22:36.281621 12912 net.cpp:91] Creating Layer C3_1a
I0514 11:22:36.281653 12912 net.cpp:425] C3_1a <- pool2a
I0514 11:22:36.281687 12912 net.cpp:399] C3_1a -> C3_1a
I0514 11:22:36.293377 12912 net.cpp:141] Setting up C3_1a
I0514 11:22:36.293411 12912 net.cpp:148] Top shape: 15 256 56 56 (12042240)
I0514 11:22:36.293418 12912 net.cpp:156] Memory required for data: 1863536700
I0514 11:22:36.293431 12912 layer_factory.hpp:77] Creating layer bn5a
I0514 11:22:36.293453 12912 net.cpp:91] Creating Layer bn5a
I0514 11:22:36.293462 12912 net.cpp:425] bn5a <- C3_1a
I0514 11:22:36.293473 12912 net.cpp:399] bn5a -> bn5a
I0514 11:22:36.293762 12912 net.cpp:141] Setting up bn5a
I0514 11:22:36.293779 12912 net.cpp:148] Top shape: 15 256 56 56 (12042240)
I0514 11:22:36.293788 12912 net.cpp:156] Memory required for data: 1911705660
I0514 11:22:36.293804 12912 layer_factory.hpp:77] Creating layer relu3_1a
I0514 11:22:36.293819 12912 net.cpp:91] Creating Layer relu3_1a
I0514 11:22:36.293828 12912 net.cpp:425] relu3_1a <- bn5a
I0514 11:22:36.293840 12912 net.cpp:399] relu3_1a -> relu3_1a
I0514 11:22:36.293880 12912 net.cpp:141] Setting up relu3_1a
I0514 11:22:36.293894 12912 net.cpp:148] Top shape: 15 256 56 56 (12042240)
I0514 11:22:36.293900 12912 net.cpp:156] Memory required for data: 1959874620
I0514 11:22:36.293908 12912 layer_factory.hpp:77] Creating layer C3_2a
I0514 11:22:36.293928 12912 net.cpp:91] Creating Layer C3_2a
I0514 11:22:36.293937 12912 net.cpp:425] C3_2a <- relu3_1a
I0514 11:22:36.293951 12912 net.cpp:399] C3_2a -> C3_2a
I0514 11:22:36.315611 12912 net.cpp:141] Setting up C3_2a
I0514 11:22:36.315640 12912 net.cpp:148] Top shape: 15 256 56 56 (12042240)
I0514 11:22:36.315647 12912 net.cpp:156] Memory required for data: 2008043580
I0514 11:22:36.315662 12912 layer_factory.hpp:77] Creating layer bn6a
I0514 11:22:36.315680 12912 net.cpp:91] Creating Layer bn6a
I0514 11:22:36.315688 12912 net.cpp:425] bn6a <- C3_2a
I0514 11:22:36.315701 12912 net.cpp:399] bn6a -> bn6a
I0514 11:22:36.315991 12912 net.cpp:141] Setting up bn6a
I0514 11:22:36.316009 12912 net.cpp:148] Top shape: 15 256 56 56 (12042240)
I0514 11:22:36.316017 12912 net.cpp:156] Memory required for data: 2056212540
I0514 11:22:36.316032 12912 layer_factory.hpp:77] Creating layer relu3_2a
I0514 11:22:36.316045 12912 net.cpp:91] Creating Layer relu3_2a
I0514 11:22:36.316053 12912 net.cpp:425] relu3_2a <- bn6a
I0514 11:22:36.316064 12912 net.cpp:399] relu3_2a -> relu3_2a
I0514 11:22:36.316108 12912 net.cpp:141] Setting up relu3_2a
I0514 11:22:36.316144 12912 net.cpp:148] Top shape: 15 256 56 56 (12042240)
I0514 11:22:36.316154 12912 net.cpp:156] Memory required for data: 2104381500
I0514 11:22:36.316161 12912 layer_factory.hpp:77] Creating layer C3_3a
I0514 11:22:36.316182 12912 net.cpp:91] Creating Layer C3_3a
I0514 11:22:36.316191 12912 net.cpp:425] C3_3a <- relu3_2a
I0514 11:22:36.316207 12912 net.cpp:399] C3_3a -> C3_3a
I0514 11:22:36.338251 12912 net.cpp:141] Setting up C3_3a
I0514 11:22:36.338290 12912 net.cpp:148] Top shape: 15 256 56 56 (12042240)
I0514 11:22:36.338297 12912 net.cpp:156] Memory required for data: 2152550460
I0514 11:22:36.338311 12912 layer_factory.hpp:77] Creating layer bn7a
I0514 11:22:36.338326 12912 net.cpp:91] Creating Layer bn7a
I0514 11:22:36.338335 12912 net.cpp:425] bn7a <- C3_3a
I0514 11:22:36.338351 12912 net.cpp:399] bn7a -> bn7a
I0514 11:22:36.338644 12912 net.cpp:141] Setting up bn7a
I0514 11:22:36.338660 12912 net.cpp:148] Top shape: 15 256 56 56 (12042240)
I0514 11:22:36.338668 12912 net.cpp:156] Memory required for data: 2200719420
I0514 11:22:36.338697 12912 layer_factory.hpp:77] Creating layer relu3_3a
I0514 11:22:36.338712 12912 net.cpp:91] Creating Layer relu3_3a
I0514 11:22:36.338721 12912 net.cpp:425] relu3_3a <- bn7a
I0514 11:22:36.338732 12912 net.cpp:399] relu3_3a -> relu3_3a
I0514 11:22:36.338773 12912 net.cpp:141] Setting up relu3_3a
I0514 11:22:36.338786 12912 net.cpp:148] Top shape: 15 256 56 56 (12042240)
I0514 11:22:36.338793 12912 net.cpp:156] Memory required for data: 2248888380
I0514 11:22:36.338800 12912 layer_factory.hpp:77] Creating layer pool3a
I0514 11:22:36.338816 12912 net.cpp:91] Creating Layer pool3a
I0514 11:22:36.338824 12912 net.cpp:425] pool3a <- relu3_3a
I0514 11:22:36.338840 12912 net.cpp:399] pool3a -> pool3a
I0514 11:22:36.338901 12912 net.cpp:141] Setting up pool3a
I0514 11:22:36.338917 12912 net.cpp:148] Top shape: 15 256 28 28 (3010560)
I0514 11:22:36.338923 12912 net.cpp:156] Memory required for data: 2260930620
I0514 11:22:36.338930 12912 layer_factory.hpp:77] Creating layer C4_1a
I0514 11:22:36.338950 12912 net.cpp:91] Creating Layer C4_1a
I0514 11:22:36.338960 12912 net.cpp:425] C4_1a <- pool3a
I0514 11:22:36.338976 12912 net.cpp:399] C4_1a -> C4_1a
I0514 11:22:36.390954 12912 net.cpp:141] Setting up C4_1a
I0514 11:22:36.390985 12912 net.cpp:148] Top shape: 15 512 28 28 (6021120)
I0514 11:22:36.391005 12912 net.cpp:156] Memory required for data: 2285015100
I0514 11:22:36.391021 12912 layer_factory.hpp:77] Creating layer bn8a
I0514 11:22:36.391044 12912 net.cpp:91] Creating Layer bn8a
I0514 11:22:36.391054 12912 net.cpp:425] bn8a <- C4_1a
I0514 11:22:36.391067 12912 net.cpp:399] bn8a -> bn8a
I0514 11:22:36.391330 12912 net.cpp:141] Setting up bn8a
I0514 11:22:36.391346 12912 net.cpp:148] Top shape: 15 512 28 28 (6021120)
I0514 11:22:36.391355 12912 net.cpp:156] Memory required for data: 2309099580
I0514 11:22:36.391372 12912 layer_factory.hpp:77] Creating layer relu4_1a
I0514 11:22:36.391386 12912 net.cpp:91] Creating Layer relu4_1a
I0514 11:22:36.391392 12912 net.cpp:425] relu4_1a <- bn8a
I0514 11:22:36.391403 12912 net.cpp:399] relu4_1a -> relu4_1a
I0514 11:22:36.391443 12912 net.cpp:141] Setting up relu4_1a
I0514 11:22:36.391459 12912 net.cpp:148] Top shape: 15 512 28 28 (6021120)
I0514 11:22:36.391466 12912 net.cpp:156] Memory required for data: 2333184060
I0514 11:22:36.391474 12912 layer_factory.hpp:77] Creating layer C4_2a
I0514 11:22:36.391497 12912 net.cpp:91] Creating Layer C4_2a
I0514 11:22:36.391505 12912 net.cpp:425] C4_2a <- relu4_1a
I0514 11:22:36.391516 12912 net.cpp:399] C4_2a -> C4_2a
I0514 11:22:36.491691 12912 net.cpp:141] Setting up C4_2a
I0514 11:22:36.491730 12912 net.cpp:148] Top shape: 15 512 28 28 (6021120)
I0514 11:22:36.491737 12912 net.cpp:156] Memory required for data: 2357268540
I0514 11:22:36.491752 12912 layer_factory.hpp:77] Creating layer bn9a
I0514 11:22:36.491768 12912 net.cpp:91] Creating Layer bn9a
I0514 11:22:36.491806 12912 net.cpp:425] bn9a <- C4_2a
I0514 11:22:36.491852 12912 net.cpp:399] bn9a -> bn9a
I0514 11:22:36.492115 12912 net.cpp:141] Setting up bn9a
I0514 11:22:36.492132 12912 net.cpp:148] Top shape: 15 512 28 28 (6021120)
I0514 11:22:36.492139 12912 net.cpp:156] Memory required for data: 2381353020
I0514 11:22:36.492177 12912 layer_factory.hpp:77] Creating layer relu4_2a
I0514 11:22:36.492209 12912 net.cpp:91] Creating Layer relu4_2a
I0514 11:22:36.492247 12912 net.cpp:425] relu4_2a <- bn9a
I0514 11:22:36.492286 12912 net.cpp:399] relu4_2a -> relu4_2a
I0514 11:22:36.492353 12912 net.cpp:141] Setting up relu4_2a
I0514 11:22:36.492372 12912 net.cpp:148] Top shape: 15 512 28 28 (6021120)
I0514 11:22:36.492379 12912 net.cpp:156] Memory required for data: 2405437500
I0514 11:22:36.492406 12912 layer_factory.hpp:77] Creating layer C4_3a
I0514 11:22:36.492447 12912 net.cpp:91] Creating Layer C4_3a
I0514 11:22:36.492477 12912 net.cpp:425] C4_3a <- relu4_2a
I0514 11:22:36.492512 12912 net.cpp:399] C4_3a -> C4_3a
I0514 11:22:36.583406 12912 net.cpp:141] Setting up C4_3a
I0514 11:22:36.583467 12912 net.cpp:148] Top shape: 15 512 28 28 (6021120)
I0514 11:22:36.583473 12912 net.cpp:156] Memory required for data: 2429521980
I0514 11:22:36.583488 12912 layer_factory.hpp:77] Creating layer bn10a
I0514 11:22:36.583513 12912 net.cpp:91] Creating Layer bn10a
I0514 11:22:36.583524 12912 net.cpp:425] bn10a <- C4_3a
I0514 11:22:36.583539 12912 net.cpp:399] bn10a -> bn10a
I0514 11:22:36.583835 12912 net.cpp:141] Setting up bn10a
I0514 11:22:36.583850 12912 net.cpp:148] Top shape: 15 512 28 28 (6021120)
I0514 11:22:36.583859 12912 net.cpp:156] Memory required for data: 2453606460
I0514 11:22:36.583875 12912 layer_factory.hpp:77] Creating layer relu4_3a
I0514 11:22:36.583889 12912 net.cpp:91] Creating Layer relu4_3a
I0514 11:22:36.583897 12912 net.cpp:425] relu4_3a <- bn10a
I0514 11:22:36.583909 12912 net.cpp:399] relu4_3a -> relu4_3a
I0514 11:22:36.583950 12912 net.cpp:141] Setting up relu4_3a
I0514 11:22:36.583964 12912 net.cpp:148] Top shape: 15 512 28 28 (6021120)
I0514 11:22:36.583972 12912 net.cpp:156] Memory required for data: 2477690940
I0514 11:22:36.583979 12912 layer_factory.hpp:77] Creating layer pool4a
I0514 11:22:36.583989 12912 net.cpp:91] Creating Layer pool4a
I0514 11:22:36.583998 12912 net.cpp:425] pool4a <- relu4_3a
I0514 11:22:36.584008 12912 net.cpp:399] pool4a -> pool4a
I0514 11:22:36.584064 12912 net.cpp:141] Setting up pool4a
I0514 11:22:36.584077 12912 net.cpp:148] Top shape: 15 512 14 14 (1505280)
I0514 11:22:36.584084 12912 net.cpp:156] Memory required for data: 2483712060
I0514 11:22:36.584090 12912 layer_factory.hpp:77] Creating layer C5_1a
I0514 11:22:36.584111 12912 net.cpp:91] Creating Layer C5_1a
I0514 11:22:36.584120 12912 net.cpp:425] C5_1a <- pool4a
I0514 11:22:36.584133 12912 net.cpp:399] C5_1a -> C5_1a
I0514 11:22:36.696511 12912 net.cpp:141] Setting up C5_1a
I0514 11:22:36.696564 12912 net.cpp:148] Top shape: 15 512 14 14 (1505280)
I0514 11:22:36.696573 12912 net.cpp:156] Memory required for data: 2489733180
I0514 11:22:36.696586 12912 layer_factory.hpp:77] Creating layer bn11a
I0514 11:22:36.696604 12912 net.cpp:91] Creating Layer bn11a
I0514 11:22:36.696643 12912 net.cpp:425] bn11a <- C5_1a
I0514 11:22:36.696660 12912 net.cpp:399] bn11a -> bn11a
I0514 11:22:36.696966 12912 net.cpp:141] Setting up bn11a
I0514 11:22:36.696981 12912 net.cpp:148] Top shape: 15 512 14 14 (1505280)
I0514 11:22:36.696990 12912 net.cpp:156] Memory required for data: 2495754300
I0514 11:22:36.697005 12912 layer_factory.hpp:77] Creating layer relu5_1a
I0514 11:22:36.697019 12912 net.cpp:91] Creating Layer relu5_1a
I0514 11:22:36.697027 12912 net.cpp:425] relu5_1a <- bn11a
I0514 11:22:36.697039 12912 net.cpp:399] relu5_1a -> relu5_1a
I0514 11:22:36.697080 12912 net.cpp:141] Setting up relu5_1a
I0514 11:22:36.697093 12912 net.cpp:148] Top shape: 15 512 14 14 (1505280)
I0514 11:22:36.697101 12912 net.cpp:156] Memory required for data: 2501775420
I0514 11:22:36.697109 12912 layer_factory.hpp:77] Creating layer C5_2a
I0514 11:22:36.697129 12912 net.cpp:91] Creating Layer C5_2a
I0514 11:22:36.697137 12912 net.cpp:425] C5_2a <- relu5_1a
I0514 11:22:36.697170 12912 net.cpp:399] C5_2a -> C5_2a
I0514 11:22:36.809931 12912 net.cpp:141] Setting up C5_2a
I0514 11:22:36.809984 12912 net.cpp:148] Top shape: 15 512 14 14 (1505280)
I0514 11:22:36.809991 12912 net.cpp:156] Memory required for data: 2507796540
I0514 11:22:36.810006 12912 layer_factory.hpp:77] Creating layer bn12a
I0514 11:22:36.810060 12912 net.cpp:91] Creating Layer bn12a
I0514 11:22:36.810089 12912 net.cpp:425] bn12a <- C5_2a
I0514 11:22:36.810120 12912 net.cpp:399] bn12a -> bn12a
I0514 11:22:36.810436 12912 net.cpp:141] Setting up bn12a
I0514 11:22:36.810470 12912 net.cpp:148] Top shape: 15 512 14 14 (1505280)
I0514 11:22:36.810493 12912 net.cpp:156] Memory required for data: 2513817660
I0514 11:22:36.810511 12912 layer_factory.hpp:77] Creating layer relu5_2a
I0514 11:22:36.810542 12912 net.cpp:91] Creating Layer relu5_2a
I0514 11:22:36.810570 12912 net.cpp:425] relu5_2a <- bn12a
I0514 11:22:36.810598 12912 net.cpp:399] relu5_2a -> relu5_2a
I0514 11:22:36.810643 12912 net.cpp:141] Setting up relu5_2a
I0514 11:22:36.810655 12912 net.cpp:148] Top shape: 15 512 14 14 (1505280)
I0514 11:22:36.810664 12912 net.cpp:156] Memory required for data: 2519838780
I0514 11:22:36.810672 12912 layer_factory.hpp:77] Creating layer C5_3a
I0514 11:22:36.810693 12912 net.cpp:91] Creating Layer C5_3a
I0514 11:22:36.810701 12912 net.cpp:425] C5_3a <- relu5_2a
I0514 11:22:36.810735 12912 net.cpp:399] C5_3a -> C5_3a
I0514 11:22:36.922615 12912 net.cpp:141] Setting up C5_3a
I0514 11:22:36.922668 12912 net.cpp:148] Top shape: 15 512 14 14 (1505280)
I0514 11:22:36.922677 12912 net.cpp:156] Memory required for data: 2525859900
I0514 11:22:36.922691 12912 layer_factory.hpp:77] Creating layer bn13a
I0514 11:22:36.922706 12912 net.cpp:91] Creating Layer bn13a
I0514 11:22:36.922720 12912 net.cpp:425] bn13a <- C5_3a
I0514 11:22:36.922761 12912 net.cpp:399] bn13a -> bn13a
I0514 11:22:36.923089 12912 net.cpp:141] Setting up bn13a
I0514 11:22:36.923105 12912 net.cpp:148] Top shape: 15 512 14 14 (1505280)
I0514 11:22:36.923122 12912 net.cpp:156] Memory required for data: 2531881020
I0514 11:22:36.923152 12912 layer_factory.hpp:77] Creating layer relu5_3a
I0514 11:22:36.923168 12912 net.cpp:91] Creating Layer relu5_3a
I0514 11:22:36.923177 12912 net.cpp:425] relu5_3a <- bn13a
I0514 11:22:36.923209 12912 net.cpp:399] relu5_3a -> relu5_3a
I0514 11:22:36.923272 12912 net.cpp:141] Setting up relu5_3a
I0514 11:22:36.923287 12912 net.cpp:148] Top shape: 15 512 14 14 (1505280)
I0514 11:22:36.923296 12912 net.cpp:156] Memory required for data: 2537902140
I0514 11:22:36.923322 12912 layer_factory.hpp:77] Creating layer GP
I0514 11:22:36.923354 12912 net.cpp:91] Creating Layer GP
I0514 11:22:36.923379 12912 net.cpp:425] GP <- relu5_3a
I0514 11:22:36.923394 12912 net.cpp:399] GP -> GP
I0514 11:22:36.923435 12912 net.cpp:141] Setting up GP
I0514 11:22:36.923449 12912 net.cpp:148] Top shape: 15 512 1 1 (7680)
I0514 11:22:36.923456 12912 net.cpp:156] Memory required for data: 2537932860
I0514 11:22:36.923482 12912 layer_factory.hpp:77] Creating layer fc
I0514 11:22:36.923514 12912 net.cpp:91] Creating Layer fc
I0514 11:22:36.923524 12912 net.cpp:425] fc <- GP
I0514 11:22:36.923554 12912 net.cpp:399] fc -> fc
I0514 11:22:36.925644 12912 net.cpp:141] Setting up fc
I0514 11:22:36.925664 12912 net.cpp:148] Top shape: 15 50 (750)
I0514 11:22:36.925673 12912 net.cpp:156] Memory required for data: 2537935860
I0514 11:22:36.925709 12912 layer_factory.hpp:77] Creating layer loss
I0514 11:22:36.925725 12912 net.cpp:91] Creating Layer loss
I0514 11:22:36.925734 12912 net.cpp:425] loss <- fc
I0514 11:22:36.925745 12912 net.cpp:425] loss <- label
I0514 11:22:36.925760 12912 net.cpp:399] loss -> loss
I0514 11:22:36.925782 12912 layer_factory.hpp:77] Creating layer loss
I0514 11:22:36.925928 12912 net.cpp:141] Setting up loss
I0514 11:22:36.925942 12912 net.cpp:148] Top shape: (1)
I0514 11:22:36.925951 12912 net.cpp:151]     with loss weight 1
I0514 11:22:36.925974 12912 net.cpp:156] Memory required for data: 2537935864
I0514 11:22:36.926002 12912 net.cpp:217] loss needs backward computation.
I0514 11:22:36.926009 12912 net.cpp:217] fc needs backward computation.
I0514 11:22:36.926019 12912 net.cpp:217] GP needs backward computation.
I0514 11:22:36.926033 12912 net.cpp:217] relu5_3a needs backward computation.
I0514 11:22:36.926040 12912 net.cpp:217] bn13a needs backward computation.
I0514 11:22:36.926070 12912 net.cpp:217] C5_3a needs backward computation.
I0514 11:22:36.926095 12912 net.cpp:217] relu5_2a needs backward computation.
I0514 11:22:36.926120 12912 net.cpp:217] bn12a needs backward computation.
I0514 11:22:36.926129 12912 net.cpp:217] C5_2a needs backward computation.
I0514 11:22:36.926138 12912 net.cpp:217] relu5_1a needs backward computation.
I0514 11:22:36.926147 12912 net.cpp:217] bn11a needs backward computation.
I0514 11:22:36.926156 12912 net.cpp:217] C5_1a needs backward computation.
I0514 11:22:36.926165 12912 net.cpp:217] pool4a needs backward computation.
I0514 11:22:36.926173 12912 net.cpp:217] relu4_3a needs backward computation.
I0514 11:22:36.926182 12912 net.cpp:217] bn10a needs backward computation.
I0514 11:22:36.926190 12912 net.cpp:217] C4_3a needs backward computation.
I0514 11:22:36.926199 12912 net.cpp:217] relu4_2a needs backward computation.
I0514 11:22:36.926208 12912 net.cpp:217] bn9a needs backward computation.
I0514 11:22:36.926218 12912 net.cpp:217] C4_2a needs backward computation.
I0514 11:22:36.926226 12912 net.cpp:217] relu4_1a needs backward computation.
I0514 11:22:36.926235 12912 net.cpp:217] bn8a needs backward computation.
I0514 11:22:36.926244 12912 net.cpp:217] C4_1a needs backward computation.
I0514 11:22:36.926252 12912 net.cpp:217] pool3a needs backward computation.
I0514 11:22:36.926264 12912 net.cpp:217] relu3_3a needs backward computation.
I0514 11:22:36.926272 12912 net.cpp:217] bn7a needs backward computation.
I0514 11:22:36.926281 12912 net.cpp:217] C3_3a needs backward computation.
I0514 11:22:36.926290 12912 net.cpp:217] relu3_2a needs backward computation.
I0514 11:22:36.926298 12912 net.cpp:217] bn6a needs backward computation.
I0514 11:22:36.926307 12912 net.cpp:217] C3_2a needs backward computation.
I0514 11:22:36.926316 12912 net.cpp:217] relu3_1a needs backward computation.
I0514 11:22:36.926324 12912 net.cpp:217] bn5a needs backward computation.
I0514 11:22:36.926333 12912 net.cpp:217] C3_1a needs backward computation.
I0514 11:22:36.926342 12912 net.cpp:217] pool2a needs backward computation.
I0514 11:22:36.926350 12912 net.cpp:217] relu2_2a needs backward computation.
I0514 11:22:36.926359 12912 net.cpp:217] bn4a needs backward computation.
I0514 11:22:36.926367 12912 net.cpp:217] C2_2a needs backward computation.
I0514 11:22:36.926376 12912 net.cpp:217] relu2_1a needs backward computation.
I0514 11:22:36.926385 12912 net.cpp:217] bn3a needs backward computation.
I0514 11:22:36.926393 12912 net.cpp:217] C2_1a needs backward computation.
I0514 11:22:36.926403 12912 net.cpp:217] pool1a needs backward computation.
I0514 11:22:36.926410 12912 net.cpp:217] relu1_2a needs backward computation.
I0514 11:22:36.926419 12912 net.cpp:217] bn2a needs backward computation.
I0514 11:22:36.926429 12912 net.cpp:217] C1_2a needs backward computation.
I0514 11:22:36.926436 12912 net.cpp:217] relu1_1a needs backward computation.
I0514 11:22:36.926445 12912 net.cpp:217] bn1a needs backward computation.
I0514 11:22:36.926470 12912 net.cpp:217] C1_1a needs backward computation.
I0514 11:22:36.926493 12912 net.cpp:219] data does not need backward computation.
I0514 11:22:36.926514 12912 net.cpp:261] This network produces output loss
I0514 11:22:36.926583 12912 net.cpp:274] Network initialization done.
I0514 11:22:36.929208 12912 solver.cpp:181] Creating test net (#0) specified by net file: /data1/shiv/ModelA/fullC5trains.prototxt
I0514 11:22:36.929345 12912 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0514 11:22:36.929414 12912 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss
I0514 11:22:36.929998 12912 net.cpp:49] Initializing net from parameters: 
name: "VGG"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  image_data_param {
    source: "/data1/shiv/img_folderAlexJitter1/val1.txt"
    batch_size: 1
    shuffle: false
  }
}
layer {
  name: "C1_1a"
  type: "Convolution"
  bottom: "data"
  top: "C1_1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn1a"
  type: "BatchNorm"
  bottom: "C1_1a"
  top: "bn1a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "relu1_1a"
  type: "ReLU"
  bottom: "bn1a"
  top: "relu1_1a"
}
layer {
  name: "C1_2a"
  type: "Convolution"
  bottom: "relu1_1a"
  top: "C1_2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn2a"
  type: "BatchNorm"
  bottom: "C1_2a"
  top: "bn2a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "relu1_2a"
  type: "ReLU"
  bottom: "bn2a"
  top: "relu1_2a"
}
layer {
  name: "pool1a"
  type: "Pooling"
  bottom: "relu1_2a"
  top: "pool1a"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "C2_1a"
  type: "Convolution"
  bottom: "pool1a"
  top: "C2_1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn3a"
  type: "BatchNorm"
  bottom: "C2_1a"
  top: "bn3a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "relu2_1a"
  type: "ReLU"
  bottom: "bn3a"
  top: "relu2_1a"
}
layer {
  name: "C2_2a"
  type: "Convolution"
  bottom: "relu2_1a"
  top: "C2_2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn4a"
  type: "BatchNorm"
  bottom: "C2_2a"
  top: "bn4a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "relu2_2a"
  type: "ReLU"
  bottom: "bn4a"
  top: "relu2_2a"
}
layer {
  name: "pool2a"
  type: "Pooling"
  bottom: "relu2_2a"
  top: "pool2a"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "C3_1a"
  type: "Convolution"
  bottom: "pool2a"
  top: "C3_1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn5a"
  type: "BatchNorm"
  bottom: "C3_1a"
  top: "bn5a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "relu3_1a"
  type: "ReLU"
  bottom: "bn5a"
  top: "relu3_1a"
}
layer {
  name: "C3_2a"
  type: "Convolution"
  bottom: "relu3_1a"
  top: "C3_2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn6a"
  type: "BatchNorm"
  bottom: "C3_2a"
  top: "bn6a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "relu3_2a"
  type: "ReLU"
  bottom: "bn6a"
  top: "relu3_2a"
}
layer {
  name: "C3_3a"
  type: "Convolution"
  bottom: "relu3_2a"
  top: "C3_3a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn7a"
  type: "BatchNorm"
  bottom: "C3_3a"
  top: "bn7a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "relu3_3a"
  type: "ReLU"
  bottom: "bn7a"
  top: "relu3_3a"
}
layer {
  name: "pool3a"
  type: "Pooling"
  bottom: "relu3_3a"
  top: "pool3a"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "C4_1a"
  type: "Convolution"
  bottom: "pool3a"
  top: "C4_1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn8a"
  type: "BatchNorm"
  bottom: "C4_1a"
  top: "bn8a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "relu4_1a"
  type: "ReLU"
  bottom: "bn8a"
  top: "relu4_1a"
}
layer {
  name: "C4_2a"
  type: "Convolution"
  bottom: "relu4_1a"
  top: "C4_2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn9a"
  type: "BatchNorm"
  bottom: "C4_2a"
  top: "bn9a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "relu4_2a"
  type: "ReLU"
  bottom: "bn9a"
  top: "relu4_2a"
}
layer {
  name: "C4_3a"
  type: "Convolution"
  bottom: "relu4_2a"
  top: "C4_3a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn10a"
  type: "BatchNorm"
  bottom: "C4_3a"
  top: "bn10a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "relu4_3a"
  type: "ReLU"
  bottom: "bn10a"
  top: "relu4_3a"
}
layer {
  name: "pool4a"
  type: "Pooling"
  bottom: "relu4_3a"
  top: "pool4a"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "C5_1a"
  type: "Convolution"
  bottom: "pool4a"
  top: "C5_1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn11a"
  type: "BatchNorm"
  bottom: "C5_1a"
  top: "bn11a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "relu5_1a"
  type: "ReLU"
  bottom: "bn11a"
  top: "relu5_1a"
}
layer {
  name: "C5_2a"
  type: "Convolution"
  bottom: "relu5_1a"
  top: "C5_2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn12a"
  type: "BatchNorm"
  bottom: "C5_2a"
  top: "bn12a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "relu5_2a"
  type: "ReLU"
  bottom: "bn12a"
  top: "relu5_2a"
}
layer {
  name: "C5_3a"
  type: "Convolution"
  bottom: "relu5_2a"
  top: "C5_3a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn13a"
  type: "BatchNorm"
  bottom: "C5_3a"
  top: "bn13a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "relu5_3a"
  type: "ReLU"
  bottom: "bn13a"
  top: "relu5_3a"
}
layer {
  name: "GP"
  type: "Pooling"
  bottom: "relu5_3a"
  top: "GP"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "fc"
  type: "InnerProduct"
  bottom: "GP"
  top: "fc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 50
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
I0514 11:22:36.930315 12912 layer_factory.hpp:77] Creating layer data
I0514 11:22:36.930344 12912 net.cpp:91] Creating Layer data
I0514 11:22:36.930356 12912 net.cpp:399] data -> data
I0514 11:22:36.930374 12912 net.cpp:399] data -> label
I0514 11:22:36.930392 12912 image_data_layer.cpp:38] Opening file /data1/shiv/img_folderAlexJitter1/val1.txt
I0514 11:22:36.938103 12912 image_data_layer.cpp:53] A total of 6875 images.
I0514 11:22:36.938856 12912 image_data_layer.cpp:80] output data size: 1,3,224,224
I0514 11:22:36.941256 12912 net.cpp:141] Setting up data
I0514 11:22:36.941318 12912 net.cpp:148] Top shape: 1 3 224 224 (150528)
I0514 11:22:36.941352 12912 net.cpp:148] Top shape: 1 (1)
I0514 11:22:36.941406 12912 net.cpp:156] Memory required for data: 602116
I0514 11:22:36.941439 12912 layer_factory.hpp:77] Creating layer C1_1a
I0514 11:22:36.941486 12912 net.cpp:91] Creating Layer C1_1a
I0514 11:22:36.941521 12912 net.cpp:425] C1_1a <- data
I0514 11:22:36.941557 12912 net.cpp:399] C1_1a -> C1_1a
I0514 11:22:36.942129 12912 net.cpp:141] Setting up C1_1a
I0514 11:22:36.942175 12912 net.cpp:148] Top shape: 1 64 224 224 (3211264)
I0514 11:22:36.942203 12912 net.cpp:156] Memory required for data: 13447172
I0514 11:22:36.942245 12912 layer_factory.hpp:77] Creating layer bn1a
I0514 11:22:36.942281 12912 net.cpp:91] Creating Layer bn1a
I0514 11:22:36.942308 12912 net.cpp:425] bn1a <- C1_1a
I0514 11:22:36.942337 12912 net.cpp:399] bn1a -> bn1a
I0514 11:22:36.942677 12912 net.cpp:141] Setting up bn1a
I0514 11:22:36.942719 12912 net.cpp:148] Top shape: 1 64 224 224 (3211264)
I0514 11:22:36.942749 12912 net.cpp:156] Memory required for data: 26292228
I0514 11:22:36.942791 12912 layer_factory.hpp:77] Creating layer relu1_1a
I0514 11:22:36.942824 12912 net.cpp:91] Creating Layer relu1_1a
I0514 11:22:36.942852 12912 net.cpp:425] relu1_1a <- bn1a
I0514 11:22:36.942883 12912 net.cpp:399] relu1_1a -> relu1_1a
I0514 11:22:36.942944 12912 net.cpp:141] Setting up relu1_1a
I0514 11:22:36.942980 12912 net.cpp:148] Top shape: 1 64 224 224 (3211264)
I0514 11:22:36.943006 12912 net.cpp:156] Memory required for data: 39137284
I0514 11:22:36.943033 12912 layer_factory.hpp:77] Creating layer C1_2a
I0514 11:22:36.943070 12912 net.cpp:91] Creating Layer C1_2a
I0514 11:22:36.943099 12912 net.cpp:425] C1_2a <- relu1_1a
I0514 11:22:36.943130 12912 net.cpp:399] C1_2a -> C1_2a
I0514 11:22:36.945268 12912 net.cpp:141] Setting up C1_2a
I0514 11:22:36.945317 12912 net.cpp:148] Top shape: 1 64 224 224 (3211264)
I0514 11:22:36.945359 12912 net.cpp:156] Memory required for data: 51982340
I0514 11:22:36.945410 12912 layer_factory.hpp:77] Creating layer bn2a
I0514 11:22:36.945446 12912 net.cpp:91] Creating Layer bn2a
I0514 11:22:36.945473 12912 net.cpp:425] bn2a <- C1_2a
I0514 11:22:36.945505 12912 net.cpp:399] bn2a -> bn2a
I0514 11:22:36.946604 12912 net.cpp:141] Setting up bn2a
I0514 11:22:36.946652 12912 net.cpp:148] Top shape: 1 64 224 224 (3211264)
I0514 11:22:36.946684 12912 net.cpp:156] Memory required for data: 64827396
I0514 11:22:36.946727 12912 layer_factory.hpp:77] Creating layer relu1_2a
I0514 11:22:36.946763 12912 net.cpp:91] Creating Layer relu1_2a
I0514 11:22:36.946791 12912 net.cpp:425] relu1_2a <- bn2a
I0514 11:22:36.946823 12912 net.cpp:399] relu1_2a -> relu1_2a
I0514 11:22:36.946887 12912 net.cpp:141] Setting up relu1_2a
I0514 11:22:36.946929 12912 net.cpp:148] Top shape: 1 64 224 224 (3211264)
I0514 11:22:36.946957 12912 net.cpp:156] Memory required for data: 77672452
I0514 11:22:36.946985 12912 layer_factory.hpp:77] Creating layer pool1a
I0514 11:22:36.947016 12912 net.cpp:91] Creating Layer pool1a
I0514 11:22:36.947042 12912 net.cpp:425] pool1a <- relu1_2a
I0514 11:22:36.947073 12912 net.cpp:399] pool1a -> pool1a
I0514 11:22:36.947159 12912 net.cpp:141] Setting up pool1a
I0514 11:22:36.947194 12912 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0514 11:22:36.947221 12912 net.cpp:156] Memory required for data: 80883716
I0514 11:22:36.947248 12912 layer_factory.hpp:77] Creating layer C2_1a
I0514 11:22:36.947290 12912 net.cpp:91] Creating Layer C2_1a
I0514 11:22:36.947320 12912 net.cpp:425] C2_1a <- pool1a
I0514 11:22:36.947353 12912 net.cpp:399] C2_1a -> C2_1a
I0514 11:22:36.951143 12912 net.cpp:141] Setting up C2_1a
I0514 11:22:36.951196 12912 net.cpp:148] Top shape: 1 128 112 112 (1605632)
I0514 11:22:36.951228 12912 net.cpp:156] Memory required for data: 87306244
I0514 11:22:36.951263 12912 layer_factory.hpp:77] Creating layer bn3a
I0514 11:22:36.951297 12912 net.cpp:91] Creating Layer bn3a
I0514 11:22:36.951326 12912 net.cpp:425] bn3a <- C2_1a
I0514 11:22:36.951361 12912 net.cpp:399] bn3a -> bn3a
I0514 11:22:36.951689 12912 net.cpp:141] Setting up bn3a
I0514 11:22:36.951730 12912 net.cpp:148] Top shape: 1 128 112 112 (1605632)
I0514 11:22:36.951759 12912 net.cpp:156] Memory required for data: 93728772
I0514 11:22:36.951795 12912 layer_factory.hpp:77] Creating layer relu2_1a
I0514 11:22:36.951828 12912 net.cpp:91] Creating Layer relu2_1a
I0514 11:22:36.951855 12912 net.cpp:425] relu2_1a <- bn3a
I0514 11:22:36.951886 12912 net.cpp:399] relu2_1a -> relu2_1a
I0514 11:22:36.951951 12912 net.cpp:141] Setting up relu2_1a
I0514 11:22:36.951987 12912 net.cpp:148] Top shape: 1 128 112 112 (1605632)
I0514 11:22:36.952014 12912 net.cpp:156] Memory required for data: 100151300
I0514 11:22:36.952041 12912 layer_factory.hpp:77] Creating layer C2_2a
I0514 11:22:36.952077 12912 net.cpp:91] Creating Layer C2_2a
I0514 11:22:36.952106 12912 net.cpp:425] C2_2a <- relu2_1a
I0514 11:22:36.952143 12912 net.cpp:399] C2_2a -> C2_2a
I0514 11:22:36.958030 12912 net.cpp:141] Setting up C2_2a
I0514 11:22:36.958057 12912 net.cpp:148] Top shape: 1 128 112 112 (1605632)
I0514 11:22:36.958065 12912 net.cpp:156] Memory required for data: 106573828
I0514 11:22:36.958092 12912 layer_factory.hpp:77] Creating layer bn4a
I0514 11:22:36.958107 12912 net.cpp:91] Creating Layer bn4a
I0514 11:22:36.958117 12912 net.cpp:425] bn4a <- C2_2a
I0514 11:22:36.958130 12912 net.cpp:399] bn4a -> bn4a
I0514 11:22:36.958439 12912 net.cpp:141] Setting up bn4a
I0514 11:22:36.958456 12912 net.cpp:148] Top shape: 1 128 112 112 (1605632)
I0514 11:22:36.958462 12912 net.cpp:156] Memory required for data: 112996356
I0514 11:22:36.958482 12912 layer_factory.hpp:77] Creating layer relu2_2a
I0514 11:22:36.958494 12912 net.cpp:91] Creating Layer relu2_2a
I0514 11:22:36.958503 12912 net.cpp:425] relu2_2a <- bn4a
I0514 11:22:36.958513 12912 net.cpp:399] relu2_2a -> relu2_2a
I0514 11:22:36.958550 12912 net.cpp:141] Setting up relu2_2a
I0514 11:22:36.958564 12912 net.cpp:148] Top shape: 1 128 112 112 (1605632)
I0514 11:22:36.958590 12912 net.cpp:156] Memory required for data: 119418884
I0514 11:22:36.958600 12912 layer_factory.hpp:77] Creating layer pool2a
I0514 11:22:36.958614 12912 net.cpp:91] Creating Layer pool2a
I0514 11:22:36.958622 12912 net.cpp:425] pool2a <- relu2_2a
I0514 11:22:36.958633 12912 net.cpp:399] pool2a -> pool2a
I0514 11:22:36.958699 12912 net.cpp:141] Setting up pool2a
I0514 11:22:36.958714 12912 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0514 11:22:36.958720 12912 net.cpp:156] Memory required for data: 121024516
I0514 11:22:36.958727 12912 layer_factory.hpp:77] Creating layer C3_1a
I0514 11:22:36.958746 12912 net.cpp:91] Creating Layer C3_1a
I0514 11:22:36.958755 12912 net.cpp:425] C3_1a <- pool2a
I0514 11:22:36.958770 12912 net.cpp:399] C3_1a -> C3_1a
I0514 11:22:36.970188 12912 net.cpp:141] Setting up C3_1a
I0514 11:22:36.970234 12912 net.cpp:148] Top shape: 1 256 56 56 (802816)
I0514 11:22:36.970245 12912 net.cpp:156] Memory required for data: 124235780
I0514 11:22:36.970268 12912 layer_factory.hpp:77] Creating layer bn5a
I0514 11:22:36.970294 12912 net.cpp:91] Creating Layer bn5a
I0514 11:22:36.970306 12912 net.cpp:425] bn5a <- C3_1a
I0514 11:22:36.970322 12912 net.cpp:399] bn5a -> bn5a
I0514 11:22:36.970649 12912 net.cpp:141] Setting up bn5a
I0514 11:22:36.970671 12912 net.cpp:148] Top shape: 1 256 56 56 (802816)
I0514 11:22:36.970681 12912 net.cpp:156] Memory required for data: 127447044
I0514 11:22:36.970700 12912 layer_factory.hpp:77] Creating layer relu3_1a
I0514 11:22:36.970715 12912 net.cpp:91] Creating Layer relu3_1a
I0514 11:22:36.970726 12912 net.cpp:425] relu3_1a <- bn5a
I0514 11:22:36.970738 12912 net.cpp:399] relu3_1a -> relu3_1a
I0514 11:22:36.970780 12912 net.cpp:141] Setting up relu3_1a
I0514 11:22:36.970795 12912 net.cpp:148] Top shape: 1 256 56 56 (802816)
I0514 11:22:36.970804 12912 net.cpp:156] Memory required for data: 130658308
I0514 11:22:36.970814 12912 layer_factory.hpp:77] Creating layer C3_2a
I0514 11:22:36.970839 12912 net.cpp:91] Creating Layer C3_2a
I0514 11:22:36.970850 12912 net.cpp:425] C3_2a <- relu3_1a
I0514 11:22:36.970863 12912 net.cpp:399] C3_2a -> C3_2a
I0514 11:22:36.998600 12912 net.cpp:141] Setting up C3_2a
I0514 11:22:36.998646 12912 net.cpp:148] Top shape: 1 256 56 56 (802816)
I0514 11:22:36.998654 12912 net.cpp:156] Memory required for data: 133869572
I0514 11:22:36.998670 12912 layer_factory.hpp:77] Creating layer bn6a
I0514 11:22:36.998692 12912 net.cpp:91] Creating Layer bn6a
I0514 11:22:36.998703 12912 net.cpp:425] bn6a <- C3_2a
I0514 11:22:36.998718 12912 net.cpp:399] bn6a -> bn6a
I0514 11:22:36.999063 12912 net.cpp:141] Setting up bn6a
I0514 11:22:36.999085 12912 net.cpp:148] Top shape: 1 256 56 56 (802816)
I0514 11:22:36.999096 12912 net.cpp:156] Memory required for data: 137080836
I0514 11:22:36.999125 12912 layer_factory.hpp:77] Creating layer relu3_2a
I0514 11:22:36.999140 12912 net.cpp:91] Creating Layer relu3_2a
I0514 11:22:36.999150 12912 net.cpp:425] relu3_2a <- bn6a
I0514 11:22:36.999162 12912 net.cpp:399] relu3_2a -> relu3_2a
I0514 11:22:36.999208 12912 net.cpp:141] Setting up relu3_2a
I0514 11:22:36.999225 12912 net.cpp:148] Top shape: 1 256 56 56 (802816)
I0514 11:22:36.999235 12912 net.cpp:156] Memory required for data: 140292100
I0514 11:22:36.999243 12912 layer_factory.hpp:77] Creating layer C3_3a
I0514 11:22:36.999263 12912 net.cpp:91] Creating Layer C3_3a
I0514 11:22:36.999274 12912 net.cpp:425] C3_3a <- relu3_2a
I0514 11:22:36.999292 12912 net.cpp:399] C3_3a -> C3_3a
I0514 11:22:37.028225 12912 net.cpp:141] Setting up C3_3a
I0514 11:22:37.028273 12912 net.cpp:148] Top shape: 1 256 56 56 (802816)
I0514 11:22:37.028282 12912 net.cpp:156] Memory required for data: 143503364
I0514 11:22:37.028298 12912 layer_factory.hpp:77] Creating layer bn7a
I0514 11:22:37.028323 12912 net.cpp:91] Creating Layer bn7a
I0514 11:22:37.028337 12912 net.cpp:425] bn7a <- C3_3a
I0514 11:22:37.028353 12912 net.cpp:399] bn7a -> bn7a
I0514 11:22:37.028687 12912 net.cpp:141] Setting up bn7a
I0514 11:22:37.028708 12912 net.cpp:148] Top shape: 1 256 56 56 (802816)
I0514 11:22:37.028736 12912 net.cpp:156] Memory required for data: 146714628
I0514 11:22:37.028766 12912 layer_factory.hpp:77] Creating layer relu3_3a
I0514 11:22:37.028784 12912 net.cpp:91] Creating Layer relu3_3a
I0514 11:22:37.028792 12912 net.cpp:425] relu3_3a <- bn7a
I0514 11:22:37.028803 12912 net.cpp:399] relu3_3a -> relu3_3a
I0514 11:22:37.028849 12912 net.cpp:141] Setting up relu3_3a
I0514 11:22:37.028867 12912 net.cpp:148] Top shape: 1 256 56 56 (802816)
I0514 11:22:37.028875 12912 net.cpp:156] Memory required for data: 149925892
I0514 11:22:37.028882 12912 layer_factory.hpp:77] Creating layer pool3a
I0514 11:22:37.028899 12912 net.cpp:91] Creating Layer pool3a
I0514 11:22:37.028908 12912 net.cpp:425] pool3a <- relu3_3a
I0514 11:22:37.028920 12912 net.cpp:399] pool3a -> pool3a
I0514 11:22:37.028993 12912 net.cpp:141] Setting up pool3a
I0514 11:22:37.029011 12912 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0514 11:22:37.029021 12912 net.cpp:156] Memory required for data: 150728708
I0514 11:22:37.029031 12912 layer_factory.hpp:77] Creating layer C4_1a
I0514 11:22:37.029052 12912 net.cpp:91] Creating Layer C4_1a
I0514 11:22:37.029062 12912 net.cpp:425] C4_1a <- pool3a
I0514 11:22:37.029075 12912 net.cpp:399] C4_1a -> C4_1a
I0514 11:22:37.090097 12912 net.cpp:141] Setting up C4_1a
I0514 11:22:37.090137 12912 net.cpp:148] Top shape: 1 512 28 28 (401408)
I0514 11:22:37.090142 12912 net.cpp:156] Memory required for data: 152334340
I0514 11:22:37.090152 12912 layer_factory.hpp:77] Creating layer bn8a
I0514 11:22:37.090165 12912 net.cpp:91] Creating Layer bn8a
I0514 11:22:37.090172 12912 net.cpp:425] bn8a <- C4_1a
I0514 11:22:37.090186 12912 net.cpp:399] bn8a -> bn8a
I0514 11:22:37.090394 12912 net.cpp:141] Setting up bn8a
I0514 11:22:37.090404 12912 net.cpp:148] Top shape: 1 512 28 28 (401408)
I0514 11:22:37.090409 12912 net.cpp:156] Memory required for data: 153939972
I0514 11:22:37.090416 12912 layer_factory.hpp:77] Creating layer relu4_1a
I0514 11:22:37.090425 12912 net.cpp:91] Creating Layer relu4_1a
I0514 11:22:37.090430 12912 net.cpp:425] relu4_1a <- bn8a
I0514 11:22:37.090435 12912 net.cpp:399] relu4_1a -> relu4_1a
I0514 11:22:37.090457 12912 net.cpp:141] Setting up relu4_1a
I0514 11:22:37.090466 12912 net.cpp:148] Top shape: 1 512 28 28 (401408)
I0514 11:22:37.090469 12912 net.cpp:156] Memory required for data: 155545604
I0514 11:22:37.090472 12912 layer_factory.hpp:77] Creating layer C4_2a
I0514 11:22:37.090487 12912 net.cpp:91] Creating Layer C4_2a
I0514 11:22:37.090490 12912 net.cpp:425] C4_2a <- relu4_1a
I0514 11:22:37.090497 12912 net.cpp:399] C4_2a -> C4_2a
I0514 11:22:37.207087 12912 net.cpp:141] Setting up C4_2a
I0514 11:22:37.207129 12912 net.cpp:148] Top shape: 1 512 28 28 (401408)
I0514 11:22:37.207136 12912 net.cpp:156] Memory required for data: 157151236
I0514 11:22:37.207150 12912 layer_factory.hpp:77] Creating layer bn9a
I0514 11:22:37.207167 12912 net.cpp:91] Creating Layer bn9a
I0514 11:22:37.207203 12912 net.cpp:425] bn9a <- C4_2a
I0514 11:22:37.207234 12912 net.cpp:399] bn9a -> bn9a
I0514 11:22:37.207516 12912 net.cpp:141] Setting up bn9a
I0514 11:22:37.207535 12912 net.cpp:148] Top shape: 1 512 28 28 (401408)
I0514 11:22:37.207542 12912 net.cpp:156] Memory required for data: 158756868
I0514 11:22:37.207579 12912 layer_factory.hpp:77] Creating layer relu4_2a
I0514 11:22:37.207612 12912 net.cpp:91] Creating Layer relu4_2a
I0514 11:22:37.207643 12912 net.cpp:425] relu4_2a <- bn9a
I0514 11:22:37.207676 12912 net.cpp:399] relu4_2a -> relu4_2a
I0514 11:22:37.207743 12912 net.cpp:141] Setting up relu4_2a
I0514 11:22:37.207761 12912 net.cpp:148] Top shape: 1 512 28 28 (401408)
I0514 11:22:37.207788 12912 net.cpp:156] Memory required for data: 160362500
I0514 11:22:37.207814 12912 layer_factory.hpp:77] Creating layer C4_3a
I0514 11:22:37.207850 12912 net.cpp:91] Creating Layer C4_3a
I0514 11:22:37.207880 12912 net.cpp:425] C4_3a <- relu4_2a
I0514 11:22:37.207917 12912 net.cpp:399] C4_3a -> C4_3a
I0514 11:22:37.287868 12912 net.cpp:141] Setting up C4_3a
I0514 11:22:37.287909 12912 net.cpp:148] Top shape: 1 512 28 28 (401408)
I0514 11:22:37.287966 12912 net.cpp:156] Memory required for data: 161968132
I0514 11:22:37.288000 12912 layer_factory.hpp:77] Creating layer bn10a
I0514 11:22:37.288043 12912 net.cpp:91] Creating Layer bn10a
I0514 11:22:37.288072 12912 net.cpp:425] bn10a <- C4_3a
I0514 11:22:37.288103 12912 net.cpp:399] bn10a -> bn10a
I0514 11:22:37.288365 12912 net.cpp:141] Setting up bn10a
I0514 11:22:37.288383 12912 net.cpp:148] Top shape: 1 512 28 28 (401408)
I0514 11:22:37.288389 12912 net.cpp:156] Memory required for data: 163573764
I0514 11:22:37.288426 12912 layer_factory.hpp:77] Creating layer relu4_3a
I0514 11:22:37.288458 12912 net.cpp:91] Creating Layer relu4_3a
I0514 11:22:37.288485 12912 net.cpp:425] relu4_3a <- bn10a
I0514 11:22:37.288516 12912 net.cpp:399] relu4_3a -> relu4_3a
I0514 11:22:37.288583 12912 net.cpp:141] Setting up relu4_3a
I0514 11:22:37.288597 12912 net.cpp:148] Top shape: 1 512 28 28 (401408)
I0514 11:22:37.288605 12912 net.cpp:156] Memory required for data: 165179396
I0514 11:22:37.288632 12912 layer_factory.hpp:77] Creating layer pool4a
I0514 11:22:37.288666 12912 net.cpp:91] Creating Layer pool4a
I0514 11:22:37.288691 12912 net.cpp:425] pool4a <- relu4_3a
I0514 11:22:37.288723 12912 net.cpp:399] pool4a -> pool4a
I0514 11:22:37.288810 12912 net.cpp:141] Setting up pool4a
I0514 11:22:37.288825 12912 net.cpp:148] Top shape: 1 512 14 14 (100352)
I0514 11:22:37.288832 12912 net.cpp:156] Memory required for data: 165580804
I0514 11:22:37.288859 12912 layer_factory.hpp:77] Creating layer C5_1a
I0514 11:22:37.288898 12912 net.cpp:91] Creating Layer C5_1a
I0514 11:22:37.288928 12912 net.cpp:425] C5_1a <- pool4a
I0514 11:22:37.288962 12912 net.cpp:399] C5_1a -> C5_1a
I0514 11:22:37.372864 12912 net.cpp:141] Setting up C5_1a
I0514 11:22:37.372948 12912 net.cpp:148] Top shape: 1 512 14 14 (100352)
I0514 11:22:37.372977 12912 net.cpp:156] Memory required for data: 165982212
I0514 11:22:37.373013 12912 layer_factory.hpp:77] Creating layer bn11a
I0514 11:22:37.373046 12912 net.cpp:91] Creating Layer bn11a
I0514 11:22:37.373080 12912 net.cpp:425] bn11a <- C5_1a
I0514 11:22:37.373111 12912 net.cpp:399] bn11a -> bn11a
I0514 11:22:37.373455 12912 net.cpp:141] Setting up bn11a
I0514 11:22:37.373497 12912 net.cpp:148] Top shape: 1 512 14 14 (100352)
I0514 11:22:37.373525 12912 net.cpp:156] Memory required for data: 166383620
I0514 11:22:37.373560 12912 layer_factory.hpp:77] Creating layer relu5_1a
I0514 11:22:37.373594 12912 net.cpp:91] Creating Layer relu5_1a
I0514 11:22:37.373620 12912 net.cpp:425] relu5_1a <- bn11a
I0514 11:22:37.373652 12912 net.cpp:399] relu5_1a -> relu5_1a
I0514 11:22:37.373723 12912 net.cpp:141] Setting up relu5_1a
I0514 11:22:37.373760 12912 net.cpp:148] Top shape: 1 512 14 14 (100352)
I0514 11:22:37.373787 12912 net.cpp:156] Memory required for data: 166785028
I0514 11:22:37.373813 12912 layer_factory.hpp:77] Creating layer C5_2a
I0514 11:22:37.373853 12912 net.cpp:91] Creating Layer C5_2a
I0514 11:22:37.373885 12912 net.cpp:425] C5_2a <- relu5_1a
I0514 11:22:37.373917 12912 net.cpp:399] C5_2a -> C5_2a
I0514 11:22:37.453919 12912 net.cpp:141] Setting up C5_2a
I0514 11:22:37.453956 12912 net.cpp:148] Top shape: 1 512 14 14 (100352)
I0514 11:22:37.453964 12912 net.cpp:156] Memory required for data: 167186436
I0514 11:22:37.453979 12912 layer_factory.hpp:77] Creating layer bn12a
I0514 11:22:37.454020 12912 net.cpp:91] Creating Layer bn12a
I0514 11:22:37.454056 12912 net.cpp:425] bn12a <- C5_2a
I0514 11:22:37.454090 12912 net.cpp:399] bn12a -> bn12a
I0514 11:22:37.454365 12912 net.cpp:141] Setting up bn12a
I0514 11:22:37.454383 12912 net.cpp:148] Top shape: 1 512 14 14 (100352)
I0514 11:22:37.454391 12912 net.cpp:156] Memory required for data: 167587844
I0514 11:22:37.454427 12912 layer_factory.hpp:77] Creating layer relu5_2a
I0514 11:22:37.454479 12912 net.cpp:91] Creating Layer relu5_2a
I0514 11:22:37.454514 12912 net.cpp:425] relu5_2a <- bn12a
I0514 11:22:37.454550 12912 net.cpp:399] relu5_2a -> relu5_2a
I0514 11:22:37.454627 12912 net.cpp:141] Setting up relu5_2a
I0514 11:22:37.454656 12912 net.cpp:148] Top shape: 1 512 14 14 (100352)
I0514 11:22:37.454685 12912 net.cpp:156] Memory required for data: 167989252
I0514 11:22:37.454711 12912 layer_factory.hpp:77] Creating layer C5_3a
I0514 11:22:37.454753 12912 net.cpp:91] Creating Layer C5_3a
I0514 11:22:37.454784 12912 net.cpp:425] C5_3a <- relu5_2a
I0514 11:22:37.454819 12912 net.cpp:399] C5_3a -> C5_3a
I0514 11:22:37.541016 12912 net.cpp:141] Setting up C5_3a
I0514 11:22:37.541064 12912 net.cpp:148] Top shape: 1 512 14 14 (100352)
I0514 11:22:37.541072 12912 net.cpp:156] Memory required for data: 168390660
I0514 11:22:37.541086 12912 layer_factory.hpp:77] Creating layer bn13a
I0514 11:22:37.541105 12912 net.cpp:91] Creating Layer bn13a
I0514 11:22:37.541144 12912 net.cpp:425] bn13a <- C5_3a
I0514 11:22:37.541179 12912 net.cpp:399] bn13a -> bn13a
I0514 11:22:37.541462 12912 net.cpp:141] Setting up bn13a
I0514 11:22:37.541481 12912 net.cpp:148] Top shape: 1 512 14 14 (100352)
I0514 11:22:37.541488 12912 net.cpp:156] Memory required for data: 168792068
I0514 11:22:37.541544 12912 layer_factory.hpp:77] Creating layer relu5_3a
I0514 11:22:37.541582 12912 net.cpp:91] Creating Layer relu5_3a
I0514 11:22:37.541611 12912 net.cpp:425] relu5_3a <- bn13a
I0514 11:22:37.541647 12912 net.cpp:399] relu5_3a -> relu5_3a
I0514 11:22:37.541714 12912 net.cpp:141] Setting up relu5_3a
I0514 11:22:37.541730 12912 net.cpp:148] Top shape: 1 512 14 14 (100352)
I0514 11:22:37.541738 12912 net.cpp:156] Memory required for data: 169193476
I0514 11:22:37.541764 12912 layer_factory.hpp:77] Creating layer GP
I0514 11:22:37.541798 12912 net.cpp:91] Creating Layer GP
I0514 11:22:37.541826 12912 net.cpp:425] GP <- relu5_3a
I0514 11:22:37.541857 12912 net.cpp:399] GP -> GP
I0514 11:22:37.541929 12912 net.cpp:141] Setting up GP
I0514 11:22:37.541946 12912 net.cpp:148] Top shape: 1 512 1 1 (512)
I0514 11:22:37.541954 12912 net.cpp:156] Memory required for data: 169195524
I0514 11:22:37.541965 12912 layer_factory.hpp:77] Creating layer fc
I0514 11:22:37.541978 12912 net.cpp:91] Creating Layer fc
I0514 11:22:37.541985 12912 net.cpp:425] fc <- GP
I0514 11:22:37.542001 12912 net.cpp:399] fc -> fc
I0514 11:22:37.543025 12912 net.cpp:141] Setting up fc
I0514 11:22:37.543042 12912 net.cpp:148] Top shape: 1 50 (50)
I0514 11:22:37.543050 12912 net.cpp:156] Memory required for data: 169195724
I0514 11:22:37.543062 12912 layer_factory.hpp:77] Creating layer accuracy
I0514 11:22:37.543099 12912 net.cpp:91] Creating Layer accuracy
I0514 11:22:37.543126 12912 net.cpp:425] accuracy <- fc
I0514 11:22:37.543154 12912 net.cpp:425] accuracy <- label
I0514 11:22:37.543186 12912 net.cpp:399] accuracy -> accuracy
I0514 11:22:37.543226 12912 net.cpp:141] Setting up accuracy
I0514 11:22:37.543258 12912 net.cpp:148] Top shape: (1)
I0514 11:22:37.543287 12912 net.cpp:156] Memory required for data: 169195728
I0514 11:22:37.543313 12912 net.cpp:219] accuracy does not need backward computation.
I0514 11:22:37.543341 12912 net.cpp:219] fc does not need backward computation.
I0514 11:22:37.543368 12912 net.cpp:219] GP does not need backward computation.
I0514 11:22:37.543392 12912 net.cpp:219] relu5_3a does not need backward computation.
I0514 11:22:37.543421 12912 net.cpp:219] bn13a does not need backward computation.
I0514 11:22:37.543447 12912 net.cpp:219] C5_3a does not need backward computation.
I0514 11:22:37.543472 12912 net.cpp:219] relu5_2a does not need backward computation.
I0514 11:22:37.543498 12912 net.cpp:219] bn12a does not need backward computation.
I0514 11:22:37.543525 12912 net.cpp:219] C5_2a does not need backward computation.
I0514 11:22:37.543550 12912 net.cpp:219] relu5_1a does not need backward computation.
I0514 11:22:37.543575 12912 net.cpp:219] bn11a does not need backward computation.
I0514 11:22:37.543601 12912 net.cpp:219] C5_1a does not need backward computation.
I0514 11:22:37.543628 12912 net.cpp:219] pool4a does not need backward computation.
I0514 11:22:37.543653 12912 net.cpp:219] relu4_3a does not need backward computation.
I0514 11:22:37.543689 12912 net.cpp:219] bn10a does not need backward computation.
I0514 11:22:37.543735 12912 net.cpp:219] C4_3a does not need backward computation.
I0514 11:22:37.543761 12912 net.cpp:219] relu4_2a does not need backward computation.
I0514 11:22:37.543788 12912 net.cpp:219] bn9a does not need backward computation.
I0514 11:22:37.543815 12912 net.cpp:219] C4_2a does not need backward computation.
I0514 11:22:37.543840 12912 net.cpp:219] relu4_1a does not need backward computation.
I0514 11:22:37.543867 12912 net.cpp:219] bn8a does not need backward computation.
I0514 11:22:37.543894 12912 net.cpp:219] C4_1a does not need backward computation.
I0514 11:22:37.543917 12912 net.cpp:219] pool3a does not need backward computation.
I0514 11:22:37.543942 12912 net.cpp:219] relu3_3a does not need backward computation.
I0514 11:22:37.543968 12912 net.cpp:219] bn7a does not need backward computation.
I0514 11:22:37.543995 12912 net.cpp:219] C3_3a does not need backward computation.
I0514 11:22:37.544020 12912 net.cpp:219] relu3_2a does not need backward computation.
I0514 11:22:37.544044 12912 net.cpp:219] bn6a does not need backward computation.
I0514 11:22:37.544069 12912 net.cpp:219] C3_2a does not need backward computation.
I0514 11:22:37.544095 12912 net.cpp:219] relu3_1a does not need backward computation.
I0514 11:22:37.544121 12912 net.cpp:219] bn5a does not need backward computation.
I0514 11:22:37.544163 12912 net.cpp:219] C3_1a does not need backward computation.
I0514 11:22:37.544193 12912 net.cpp:219] pool2a does not need backward computation.
I0514 11:22:37.544220 12912 net.cpp:219] relu2_2a does not need backward computation.
I0514 11:22:37.544248 12912 net.cpp:219] bn4a does not need backward computation.
I0514 11:22:37.544275 12912 net.cpp:219] C2_2a does not need backward computation.
I0514 11:22:37.544298 12912 net.cpp:219] relu2_1a does not need backward computation.
I0514 11:22:37.544324 12912 net.cpp:219] bn3a does not need backward computation.
I0514 11:22:37.544353 12912 net.cpp:219] C2_1a does not need backward computation.
I0514 11:22:37.544378 12912 net.cpp:219] pool1a does not need backward computation.
I0514 11:22:37.544401 12912 net.cpp:219] relu1_2a does not need backward computation.
I0514 11:22:37.544427 12912 net.cpp:219] bn2a does not need backward computation.
I0514 11:22:37.544455 12912 net.cpp:219] C1_2a does not need backward computation.
I0514 11:22:37.544481 12912 net.cpp:219] relu1_1a does not need backward computation.
I0514 11:22:37.544507 12912 net.cpp:219] bn1a does not need backward computation.
I0514 11:22:37.544530 12912 net.cpp:219] C1_1a does not need backward computation.
I0514 11:22:37.544564 12912 net.cpp:219] data does not need backward computation.
I0514 11:22:37.544592 12912 net.cpp:261] This network produces output accuracy
I0514 11:22:37.544661 12912 net.cpp:274] Network initialization done.
I0514 11:22:37.544903 12912 solver.cpp:60] Solver scaffolding done.
I0514 11:22:37.547372 12912 caffe.cpp:219] Starting Optimization
I0514 11:22:37.547394 12912 solver.cpp:279] Solving VGG
I0514 11:22:37.547401 12912 solver.cpp:280] Learning Rate Policy: multistep
I0514 11:22:37.550204 12912 solver.cpp:337] Iteration 0, Testing net (#0)
I0514 11:22:37.560753 12912 net.cpp:685] Ignoring source layer loss
I0514 11:24:12.179602 12912 solver.cpp:404]     Test net output #0: accuracy = 0.0176471
I0514 11:24:12.475996 12912 solver.cpp:228] Iteration 0, loss = 3.92101
I0514 11:24:12.476155 12912 solver.cpp:244]     Train net output #0: loss = 3.92101 (* 1 = 3.92101 loss)
I0514 11:24:12.476229 12912 sgd_solver.cpp:106] Iteration 0, lr = 0.0005
I0514 11:24:46.954128 12912 solver.cpp:228] Iteration 50, loss = 3.90059
I0514 11:24:46.954296 12912 solver.cpp:244]     Train net output #0: loss = 3.90059 (* 1 = 3.90059 loss)
I0514 11:24:46.954335 12912 sgd_solver.cpp:106] Iteration 50, lr = 0.0005
I0514 11:25:21.405249 12912 solver.cpp:228] Iteration 100, loss = 3.91739
I0514 11:25:21.405414 12912 solver.cpp:244]     Train net output #0: loss = 3.91739 (* 1 = 3.91739 loss)
I0514 11:25:21.405432 12912 sgd_solver.cpp:106] Iteration 100, lr = 0.0005
I0514 11:25:55.871947 12912 solver.cpp:228] Iteration 150, loss = 3.6776
I0514 11:25:55.872071 12912 solver.cpp:244]     Train net output #0: loss = 3.6776 (* 1 = 3.6776 loss)
I0514 11:25:55.872087 12912 sgd_solver.cpp:106] Iteration 150, lr = 0.0005
I0514 11:26:30.321027 12912 solver.cpp:228] Iteration 200, loss = 3.74065
I0514 11:26:30.327410 12912 solver.cpp:244]     Train net output #0: loss = 3.74065 (* 1 = 3.74065 loss)
I0514 11:26:30.327436 12912 sgd_solver.cpp:106] Iteration 200, lr = 0.0005
I0514 11:27:04.772733 12912 solver.cpp:228] Iteration 250, loss = 3.57344
I0514 11:27:04.772994 12912 solver.cpp:244]     Train net output #0: loss = 3.57344 (* 1 = 3.57344 loss)
I0514 11:27:04.773013 12912 sgd_solver.cpp:106] Iteration 250, lr = 0.0005
I0514 11:27:39.214520 12912 solver.cpp:228] Iteration 300, loss = 3.63723
I0514 11:27:39.214628 12912 solver.cpp:244]     Train net output #0: loss = 3.63723 (* 1 = 3.63723 loss)
I0514 11:27:39.214643 12912 sgd_solver.cpp:106] Iteration 300, lr = 0.0005
I0514 11:28:13.655220 12912 solver.cpp:228] Iteration 350, loss = 3.57631
I0514 11:28:13.657207 12912 solver.cpp:244]     Train net output #0: loss = 3.57631 (* 1 = 3.57631 loss)
I0514 11:28:13.657225 12912 sgd_solver.cpp:106] Iteration 350, lr = 0.0005
I0514 11:28:48.093714 12912 solver.cpp:228] Iteration 400, loss = 3.74022
I0514 11:28:48.093822 12912 solver.cpp:244]     Train net output #0: loss = 3.74022 (* 1 = 3.74022 loss)
I0514 11:28:48.093840 12912 sgd_solver.cpp:106] Iteration 400, lr = 0.0005
I0514 11:29:22.542121 12912 solver.cpp:228] Iteration 450, loss = 3.38279
I0514 11:29:22.542220 12912 solver.cpp:244]     Train net output #0: loss = 3.38279 (* 1 = 3.38279 loss)
I0514 11:29:22.542232 12912 sgd_solver.cpp:106] Iteration 450, lr = 0.0005
I0514 11:29:56.984875 12912 solver.cpp:228] Iteration 500, loss = 3.53208
I0514 11:29:56.985064 12912 solver.cpp:244]     Train net output #0: loss = 3.53208 (* 1 = 3.53208 loss)
I0514 11:29:56.985113 12912 sgd_solver.cpp:106] Iteration 500, lr = 0.0005
I0514 11:30:31.394511 12912 solver.cpp:228] Iteration 550, loss = 3.74322
I0514 11:30:31.394661 12912 solver.cpp:244]     Train net output #0: loss = 3.74322 (* 1 = 3.74322 loss)
I0514 11:30:31.394701 12912 sgd_solver.cpp:106] Iteration 550, lr = 0.0005
I0514 11:31:05.820466 12912 solver.cpp:228] Iteration 600, loss = 3.28377
I0514 11:31:05.820557 12912 solver.cpp:244]     Train net output #0: loss = 3.28377 (* 1 = 3.28377 loss)
I0514 11:31:05.820569 12912 sgd_solver.cpp:106] Iteration 600, lr = 0.0005
I0514 11:31:40.231639 12912 solver.cpp:228] Iteration 650, loss = 3.47583
I0514 11:31:40.231789 12912 solver.cpp:244]     Train net output #0: loss = 3.47583 (* 1 = 3.47583 loss)
I0514 11:31:40.231807 12912 sgd_solver.cpp:106] Iteration 650, lr = 0.0005
I0514 11:32:14.636950 12912 solver.cpp:228] Iteration 700, loss = 3.55101
I0514 11:32:14.637058 12912 solver.cpp:244]     Train net output #0: loss = 3.55101 (* 1 = 3.55101 loss)
I0514 11:32:14.637070 12912 sgd_solver.cpp:106] Iteration 700, lr = 0.0005
I0514 11:32:49.042457 12912 solver.cpp:228] Iteration 750, loss = 3.48613
I0514 11:32:49.042624 12912 solver.cpp:244]     Train net output #0: loss = 3.48613 (* 1 = 3.48613 loss)
I0514 11:32:49.042665 12912 sgd_solver.cpp:106] Iteration 750, lr = 0.0005
I0514 11:33:23.486080 12912 solver.cpp:228] Iteration 800, loss = 3.53227
I0514 11:33:23.486240 12912 solver.cpp:244]     Train net output #0: loss = 3.53227 (* 1 = 3.53227 loss)
I0514 11:33:23.486277 12912 sgd_solver.cpp:106] Iteration 800, lr = 0.0005
I0514 11:33:57.916857 12912 solver.cpp:228] Iteration 850, loss = 3.09033
I0514 11:33:57.916991 12912 solver.cpp:244]     Train net output #0: loss = 3.09033 (* 1 = 3.09033 loss)
I0514 11:33:57.917006 12912 sgd_solver.cpp:106] Iteration 850, lr = 0.0005
I0514 11:34:32.354686 12912 solver.cpp:228] Iteration 900, loss = 3.21629
I0514 11:34:32.354842 12912 solver.cpp:244]     Train net output #0: loss = 3.21629 (* 1 = 3.21629 loss)
I0514 11:34:32.354856 12912 sgd_solver.cpp:106] Iteration 900, lr = 0.0005
I0514 11:35:06.797417 12912 solver.cpp:228] Iteration 950, loss = 3.33577
I0514 11:35:06.797610 12912 solver.cpp:244]     Train net output #0: loss = 3.33577 (* 1 = 3.33577 loss)
I0514 11:35:06.797652 12912 sgd_solver.cpp:106] Iteration 950, lr = 0.0005
I0514 11:35:40.967392 12912 solver.cpp:454] Snapshotting to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_1000.caffemodel
I0514 11:35:41.882302 12912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_1000.solverstate
I0514 11:35:42.025789 12912 solver.cpp:337] Iteration 1000, Testing net (#0)
I0514 11:35:42.025924 12912 net.cpp:685] Ignoring source layer loss
I0514 11:36:55.655344 12912 blocking_queue.cpp:50] Data layer prefetch queue empty
I0514 11:37:16.885479 12912 solver.cpp:404]     Test net output #0: accuracy = 0.0911765
I0514 11:37:17.150130 12912 solver.cpp:228] Iteration 1000, loss = 3.20079
I0514 11:37:17.150230 12912 solver.cpp:244]     Train net output #0: loss = 3.20079 (* 1 = 3.20079 loss)
I0514 11:37:17.150261 12912 sgd_solver.cpp:106] Iteration 1000, lr = 0.0005
I0514 11:37:51.557101 12912 solver.cpp:228] Iteration 1050, loss = 3.45153
I0514 11:37:51.557196 12912 solver.cpp:244]     Train net output #0: loss = 3.45153 (* 1 = 3.45153 loss)
I0514 11:37:51.557209 12912 sgd_solver.cpp:106] Iteration 1050, lr = 0.0005
I0514 11:38:27.640023 12912 solver.cpp:228] Iteration 1100, loss = 3.29456
I0514 11:38:27.640151 12912 solver.cpp:244]     Train net output #0: loss = 3.29456 (* 1 = 3.29456 loss)
I0514 11:38:27.640168 12912 sgd_solver.cpp:106] Iteration 1100, lr = 0.0005
I0514 11:39:03.418519 12912 solver.cpp:228] Iteration 1150, loss = 3.07484
I0514 11:39:03.418690 12912 solver.cpp:244]     Train net output #0: loss = 3.07484 (* 1 = 3.07484 loss)
I0514 11:39:03.418726 12912 sgd_solver.cpp:106] Iteration 1150, lr = 0.0005
I0514 11:39:39.765933 12912 solver.cpp:228] Iteration 1200, loss = 3.00575
I0514 11:39:39.766067 12912 solver.cpp:244]     Train net output #0: loss = 3.00575 (* 1 = 3.00575 loss)
I0514 11:39:39.766082 12912 sgd_solver.cpp:106] Iteration 1200, lr = 0.0005
I0514 11:40:16.771776 12912 solver.cpp:228] Iteration 1250, loss = 3.41574
I0514 11:40:16.771996 12912 solver.cpp:244]     Train net output #0: loss = 3.41574 (* 1 = 3.41574 loss)
I0514 11:40:16.772013 12912 sgd_solver.cpp:106] Iteration 1250, lr = 0.0005
I0514 11:40:54.484552 12912 solver.cpp:228] Iteration 1300, loss = 3.25766
I0514 11:40:54.484697 12912 solver.cpp:244]     Train net output #0: loss = 3.25766 (* 1 = 3.25766 loss)
I0514 11:40:54.484714 12912 sgd_solver.cpp:106] Iteration 1300, lr = 0.0005
I0514 11:41:32.438765 12912 solver.cpp:228] Iteration 1350, loss = 3.22409
I0514 11:41:32.438902 12912 solver.cpp:244]     Train net output #0: loss = 3.22409 (* 1 = 3.22409 loss)
I0514 11:41:32.438928 12912 sgd_solver.cpp:106] Iteration 1350, lr = 0.0005
I0514 11:42:10.453150 12912 solver.cpp:228] Iteration 1400, loss = 2.75386
I0514 11:42:10.453279 12912 solver.cpp:244]     Train net output #0: loss = 2.75386 (* 1 = 2.75386 loss)
I0514 11:42:10.453297 12912 sgd_solver.cpp:106] Iteration 1400, lr = 0.0005
I0514 11:42:48.458093 12912 solver.cpp:228] Iteration 1450, loss = 3.41324
I0514 11:42:48.458220 12912 solver.cpp:244]     Train net output #0: loss = 3.41324 (* 1 = 3.41324 loss)
I0514 11:42:48.458236 12912 sgd_solver.cpp:106] Iteration 1450, lr = 0.0005
I0514 11:43:26.481276 12912 solver.cpp:228] Iteration 1500, loss = 2.88458
I0514 11:43:26.481381 12912 solver.cpp:244]     Train net output #0: loss = 2.88458 (* 1 = 2.88458 loss)
I0514 11:43:26.481400 12912 sgd_solver.cpp:106] Iteration 1500, lr = 0.0005
I0514 11:44:04.490486 12912 solver.cpp:228] Iteration 1550, loss = 3.01079
I0514 11:44:04.490610 12912 solver.cpp:244]     Train net output #0: loss = 3.01079 (* 1 = 3.01079 loss)
I0514 11:44:04.490627 12912 sgd_solver.cpp:106] Iteration 1550, lr = 0.0005
I0514 11:44:42.520575 12912 solver.cpp:228] Iteration 1600, loss = 3.12982
I0514 11:44:42.520704 12912 solver.cpp:244]     Train net output #0: loss = 3.12982 (* 1 = 3.12982 loss)
I0514 11:44:42.520720 12912 sgd_solver.cpp:106] Iteration 1600, lr = 0.0005
I0514 11:45:20.521865 12912 solver.cpp:228] Iteration 1650, loss = 3.20885
I0514 11:45:20.521980 12912 solver.cpp:244]     Train net output #0: loss = 3.20885 (* 1 = 3.20885 loss)
I0514 11:45:20.521998 12912 sgd_solver.cpp:106] Iteration 1650, lr = 0.0005
I0514 11:45:58.535321 12912 solver.cpp:228] Iteration 1700, loss = 3.24986
I0514 11:45:58.535426 12912 solver.cpp:244]     Train net output #0: loss = 3.24986 (* 1 = 3.24986 loss)
I0514 11:45:58.535440 12912 sgd_solver.cpp:106] Iteration 1700, lr = 0.0005
I0514 11:46:36.551758 12912 solver.cpp:228] Iteration 1750, loss = 2.46025
I0514 11:46:36.551919 12912 solver.cpp:244]     Train net output #0: loss = 2.46025 (* 1 = 2.46025 loss)
I0514 11:46:36.551962 12912 sgd_solver.cpp:106] Iteration 1750, lr = 0.0005
I0514 11:47:14.560698 12912 solver.cpp:228] Iteration 1800, loss = 3.11125
I0514 11:47:14.560842 12912 solver.cpp:244]     Train net output #0: loss = 3.11125 (* 1 = 3.11125 loss)
I0514 11:47:14.560858 12912 sgd_solver.cpp:106] Iteration 1800, lr = 0.0005
I0514 11:47:52.581271 12912 solver.cpp:228] Iteration 1850, loss = 3.32441
I0514 11:47:52.581398 12912 solver.cpp:244]     Train net output #0: loss = 3.32441 (* 1 = 3.32441 loss)
I0514 11:47:52.581419 12912 sgd_solver.cpp:106] Iteration 1850, lr = 0.0005
I0514 11:48:30.602540 12912 solver.cpp:228] Iteration 1900, loss = 2.81747
I0514 11:48:30.602651 12912 solver.cpp:244]     Train net output #0: loss = 2.81747 (* 1 = 2.81747 loss)
I0514 11:48:30.602670 12912 sgd_solver.cpp:106] Iteration 1900, lr = 0.0005
I0514 11:49:08.616250 12912 solver.cpp:228] Iteration 1950, loss = 3.22236
I0514 11:49:08.616359 12912 solver.cpp:244]     Train net output #0: loss = 3.22236 (* 1 = 3.22236 loss)
I0514 11:49:08.616372 12912 sgd_solver.cpp:106] Iteration 1950, lr = 0.0005
I0514 11:49:46.278587 12912 solver.cpp:454] Snapshotting to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_2000.caffemodel
I0514 11:49:46.959981 12912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_2000.solverstate
I0514 11:49:47.043520 12912 solver.cpp:337] Iteration 2000, Testing net (#0)
I0514 11:49:47.043583 12912 net.cpp:685] Ignoring source layer loss
I0514 11:51:30.745662 12912 solver.cpp:404]     Test net output #0: accuracy = 0.175735
I0514 11:51:31.035441 12912 solver.cpp:228] Iteration 2000, loss = 2.35801
I0514 11:51:31.035496 12912 solver.cpp:244]     Train net output #0: loss = 2.35801 (* 1 = 2.35801 loss)
I0514 11:51:31.035512 12912 sgd_solver.cpp:106] Iteration 2000, lr = 0.0005
I0514 11:52:09.031857 12912 solver.cpp:228] Iteration 2050, loss = 3.19793
I0514 11:52:09.031972 12912 solver.cpp:244]     Train net output #0: loss = 3.19793 (* 1 = 3.19793 loss)
I0514 11:52:09.031991 12912 sgd_solver.cpp:106] Iteration 2050, lr = 0.0005
I0514 11:52:47.033954 12912 solver.cpp:228] Iteration 2100, loss = 2.95683
I0514 11:52:47.034085 12912 solver.cpp:244]     Train net output #0: loss = 2.95683 (* 1 = 2.95683 loss)
I0514 11:52:47.034103 12912 sgd_solver.cpp:106] Iteration 2100, lr = 0.0005
I0514 11:53:25.046097 12912 solver.cpp:228] Iteration 2150, loss = 2.75344
I0514 11:53:25.047238 12912 solver.cpp:244]     Train net output #0: loss = 2.75344 (* 1 = 2.75344 loss)
I0514 11:53:25.047271 12912 sgd_solver.cpp:106] Iteration 2150, lr = 0.0005
I0514 11:54:03.061693 12912 solver.cpp:228] Iteration 2200, loss = 2.92756
I0514 11:54:03.061885 12912 solver.cpp:244]     Train net output #0: loss = 2.92756 (* 1 = 2.92756 loss)
I0514 11:54:03.061904 12912 sgd_solver.cpp:106] Iteration 2200, lr = 0.0005
I0514 11:54:41.070274 12912 solver.cpp:228] Iteration 2250, loss = 2.71023
I0514 11:54:41.070404 12912 solver.cpp:244]     Train net output #0: loss = 2.71023 (* 1 = 2.71023 loss)
I0514 11:54:41.070418 12912 sgd_solver.cpp:106] Iteration 2250, lr = 0.0005
I0514 11:55:19.091492 12912 solver.cpp:228] Iteration 2300, loss = 2.51749
I0514 11:55:19.091660 12912 solver.cpp:244]     Train net output #0: loss = 2.51749 (* 1 = 2.51749 loss)
I0514 11:55:19.091684 12912 sgd_solver.cpp:106] Iteration 2300, lr = 0.0005
I0514 11:55:57.087734 12912 solver.cpp:228] Iteration 2350, loss = 2.91721
I0514 11:55:57.087878 12912 solver.cpp:244]     Train net output #0: loss = 2.91721 (* 1 = 2.91721 loss)
I0514 11:55:57.087894 12912 sgd_solver.cpp:106] Iteration 2350, lr = 0.0005
I0514 11:56:35.100776 12912 solver.cpp:228] Iteration 2400, loss = 3.20244
I0514 11:56:35.100878 12912 solver.cpp:244]     Train net output #0: loss = 3.20244 (* 1 = 3.20244 loss)
I0514 11:56:35.100896 12912 sgd_solver.cpp:106] Iteration 2400, lr = 0.0005
I0514 11:57:13.123869 12912 solver.cpp:228] Iteration 2450, loss = 3.04449
I0514 11:57:13.123989 12912 solver.cpp:244]     Train net output #0: loss = 3.04449 (* 1 = 3.04449 loss)
I0514 11:57:13.124002 12912 sgd_solver.cpp:106] Iteration 2450, lr = 0.0005
I0514 11:57:51.132565 12912 solver.cpp:228] Iteration 2500, loss = 2.69265
I0514 11:57:51.132669 12912 solver.cpp:244]     Train net output #0: loss = 2.69265 (* 1 = 2.69265 loss)
I0514 11:57:51.132688 12912 sgd_solver.cpp:106] Iteration 2500, lr = 0.0005
I0514 11:58:29.139225 12912 solver.cpp:228] Iteration 2550, loss = 3.12305
I0514 11:58:29.139317 12912 solver.cpp:244]     Train net output #0: loss = 3.12305 (* 1 = 3.12305 loss)
I0514 11:58:29.139330 12912 sgd_solver.cpp:106] Iteration 2550, lr = 0.0005
I0514 11:59:07.155095 12912 solver.cpp:228] Iteration 2600, loss = 2.81677
I0514 11:59:07.155233 12912 solver.cpp:244]     Train net output #0: loss = 2.81677 (* 1 = 2.81677 loss)
I0514 11:59:07.155258 12912 sgd_solver.cpp:106] Iteration 2600, lr = 0.0005
I0514 11:59:45.183610 12912 solver.cpp:228] Iteration 2650, loss = 2.83528
I0514 11:59:45.183748 12912 solver.cpp:244]     Train net output #0: loss = 2.83528 (* 1 = 2.83528 loss)
I0514 11:59:45.183766 12912 sgd_solver.cpp:106] Iteration 2650, lr = 0.0005
I0514 12:00:23.215962 12912 solver.cpp:228] Iteration 2700, loss = 3.02138
I0514 12:00:23.216133 12912 solver.cpp:244]     Train net output #0: loss = 3.02138 (* 1 = 3.02138 loss)
I0514 12:00:23.216151 12912 sgd_solver.cpp:106] Iteration 2700, lr = 0.0005
I0514 12:01:01.237337 12912 solver.cpp:228] Iteration 2750, loss = 2.01806
I0514 12:01:01.237498 12912 solver.cpp:244]     Train net output #0: loss = 2.01806 (* 1 = 2.01806 loss)
I0514 12:01:01.237515 12912 sgd_solver.cpp:106] Iteration 2750, lr = 0.0005
I0514 12:01:39.252825 12912 solver.cpp:228] Iteration 2800, loss = 2.52927
I0514 12:01:39.252990 12912 solver.cpp:244]     Train net output #0: loss = 2.52927 (* 1 = 2.52927 loss)
I0514 12:01:39.253010 12912 sgd_solver.cpp:106] Iteration 2800, lr = 0.0005
I0514 12:02:17.275988 12912 solver.cpp:228] Iteration 2850, loss = 2.61279
I0514 12:02:17.276167 12912 solver.cpp:244]     Train net output #0: loss = 2.61279 (* 1 = 2.61279 loss)
I0514 12:02:17.276211 12912 sgd_solver.cpp:106] Iteration 2850, lr = 0.0005
I0514 12:02:55.289593 12912 solver.cpp:228] Iteration 2900, loss = 2.30506
I0514 12:02:55.289753 12912 solver.cpp:244]     Train net output #0: loss = 2.30506 (* 1 = 2.30506 loss)
I0514 12:02:55.289803 12912 sgd_solver.cpp:106] Iteration 2900, lr = 0.0005
I0514 12:03:33.292650 12912 solver.cpp:228] Iteration 2950, loss = 2.42013
I0514 12:03:33.292778 12912 solver.cpp:244]     Train net output #0: loss = 2.42013 (* 1 = 2.42013 loss)
I0514 12:03:33.292796 12912 sgd_solver.cpp:106] Iteration 2950, lr = 0.0005
I0514 12:04:11.021159 12912 solver.cpp:454] Snapshotting to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_3000.caffemodel
I0514 12:04:11.221026 12912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_3000.solverstate
I0514 12:04:11.314470 12912 solver.cpp:337] Iteration 3000, Testing net (#0)
I0514 12:04:11.314607 12912 net.cpp:685] Ignoring source layer loss
I0514 12:05:55.538774 12912 solver.cpp:404]     Test net output #0: accuracy = 0.281324
I0514 12:05:55.828778 12912 solver.cpp:228] Iteration 3000, loss = 3.03419
I0514 12:05:55.828927 12912 solver.cpp:244]     Train net output #0: loss = 3.03419 (* 1 = 3.03419 loss)
I0514 12:05:55.828966 12912 sgd_solver.cpp:106] Iteration 3000, lr = 0.0005
I0514 12:06:33.849925 12912 solver.cpp:228] Iteration 3050, loss = 2.06337
I0514 12:06:33.850061 12912 solver.cpp:244]     Train net output #0: loss = 2.06337 (* 1 = 2.06337 loss)
I0514 12:06:33.850081 12912 sgd_solver.cpp:106] Iteration 3050, lr = 0.0005
I0514 12:07:11.916802 12912 solver.cpp:228] Iteration 3100, loss = 2.77778
I0514 12:07:11.916968 12912 solver.cpp:244]     Train net output #0: loss = 2.77778 (* 1 = 2.77778 loss)
I0514 12:07:11.917007 12912 sgd_solver.cpp:106] Iteration 3100, lr = 0.0005
I0514 12:07:49.898030 12912 solver.cpp:228] Iteration 3150, loss = 2.38433
I0514 12:07:49.898213 12912 solver.cpp:244]     Train net output #0: loss = 2.38433 (* 1 = 2.38433 loss)
I0514 12:07:49.898252 12912 sgd_solver.cpp:106] Iteration 3150, lr = 0.0005
I0514 12:08:27.893187 12912 solver.cpp:228] Iteration 3200, loss = 2.52001
I0514 12:08:27.893318 12912 solver.cpp:244]     Train net output #0: loss = 2.52001 (* 1 = 2.52001 loss)
I0514 12:08:27.893335 12912 sgd_solver.cpp:106] Iteration 3200, lr = 0.0005
I0514 12:09:05.882208 12912 solver.cpp:228] Iteration 3250, loss = 2.0881
I0514 12:09:05.882330 12912 solver.cpp:244]     Train net output #0: loss = 2.0881 (* 1 = 2.0881 loss)
I0514 12:09:05.882349 12912 sgd_solver.cpp:106] Iteration 3250, lr = 0.0005
I0514 12:09:43.834760 12912 solver.cpp:228] Iteration 3300, loss = 1.97332
I0514 12:09:43.834933 12912 solver.cpp:244]     Train net output #0: loss = 1.97332 (* 1 = 1.97332 loss)
I0514 12:09:43.834971 12912 sgd_solver.cpp:106] Iteration 3300, lr = 0.0005
I0514 12:10:21.835256 12912 solver.cpp:228] Iteration 3350, loss = 2.48247
I0514 12:10:21.835407 12912 solver.cpp:244]     Train net output #0: loss = 2.48247 (* 1 = 2.48247 loss)
I0514 12:10:21.835425 12912 sgd_solver.cpp:106] Iteration 3350, lr = 0.0005
I0514 12:10:59.847609 12912 solver.cpp:228] Iteration 3400, loss = 1.69729
I0514 12:10:59.847753 12912 solver.cpp:244]     Train net output #0: loss = 1.69729 (* 1 = 1.69729 loss)
I0514 12:10:59.847769 12912 sgd_solver.cpp:106] Iteration 3400, lr = 0.0005
I0514 12:11:37.843403 12912 solver.cpp:228] Iteration 3450, loss = 2.38261
I0514 12:11:37.843523 12912 solver.cpp:244]     Train net output #0: loss = 2.38261 (* 1 = 2.38261 loss)
I0514 12:11:37.843538 12912 sgd_solver.cpp:106] Iteration 3450, lr = 0.0005
I0514 12:12:15.855263 12912 solver.cpp:228] Iteration 3500, loss = 2.68263
I0514 12:12:15.855388 12912 solver.cpp:244]     Train net output #0: loss = 2.68263 (* 1 = 2.68263 loss)
I0514 12:12:15.855402 12912 sgd_solver.cpp:106] Iteration 3500, lr = 0.0005
I0514 12:12:53.871907 12912 solver.cpp:228] Iteration 3550, loss = 2.0847
I0514 12:12:53.882148 12912 solver.cpp:244]     Train net output #0: loss = 2.0847 (* 1 = 2.0847 loss)
I0514 12:12:53.882221 12912 sgd_solver.cpp:106] Iteration 3550, lr = 0.0005
I0514 12:13:31.914122 12912 solver.cpp:228] Iteration 3600, loss = 2.29299
I0514 12:13:31.914254 12912 solver.cpp:244]     Train net output #0: loss = 2.29299 (* 1 = 2.29299 loss)
I0514 12:13:31.914274 12912 sgd_solver.cpp:106] Iteration 3600, lr = 0.0005
I0514 12:14:09.964324 12912 solver.cpp:228] Iteration 3650, loss = 2.07105
I0514 12:14:09.964520 12912 solver.cpp:244]     Train net output #0: loss = 2.07105 (* 1 = 2.07105 loss)
I0514 12:14:09.964539 12912 sgd_solver.cpp:106] Iteration 3650, lr = 0.0005
I0514 12:14:48.019161 12912 solver.cpp:228] Iteration 3700, loss = 2.72676
I0514 12:14:48.019345 12912 solver.cpp:244]     Train net output #0: loss = 2.72676 (* 1 = 2.72676 loss)
I0514 12:14:48.019389 12912 sgd_solver.cpp:106] Iteration 3700, lr = 0.0005
I0514 12:15:26.057230 12912 solver.cpp:228] Iteration 3750, loss = 2.12274
I0514 12:15:26.057404 12912 solver.cpp:244]     Train net output #0: loss = 2.12274 (* 1 = 2.12274 loss)
I0514 12:15:26.057441 12912 sgd_solver.cpp:106] Iteration 3750, lr = 0.0005
I0514 12:16:04.115766 12912 solver.cpp:228] Iteration 3800, loss = 2.13293
I0514 12:16:04.115996 12912 solver.cpp:244]     Train net output #0: loss = 2.13293 (* 1 = 2.13293 loss)
I0514 12:16:04.116016 12912 sgd_solver.cpp:106] Iteration 3800, lr = 0.0005
I0514 12:16:42.165913 12912 solver.cpp:228] Iteration 3850, loss = 2.31493
I0514 12:16:42.166055 12912 solver.cpp:244]     Train net output #0: loss = 2.31493 (* 1 = 2.31493 loss)
I0514 12:16:42.166069 12912 sgd_solver.cpp:106] Iteration 3850, lr = 0.0005
I0514 12:17:20.179767 12912 solver.cpp:228] Iteration 3900, loss = 2.21161
I0514 12:17:20.179877 12912 solver.cpp:244]     Train net output #0: loss = 2.21161 (* 1 = 2.21161 loss)
I0514 12:17:20.179891 12912 sgd_solver.cpp:106] Iteration 3900, lr = 0.0005
I0514 12:17:58.236026 12912 solver.cpp:228] Iteration 3950, loss = 2.42896
I0514 12:17:58.236141 12912 solver.cpp:244]     Train net output #0: loss = 2.42896 (* 1 = 2.42896 loss)
I0514 12:17:58.236155 12912 sgd_solver.cpp:106] Iteration 3950, lr = 0.0005
I0514 12:18:35.967872 12912 solver.cpp:454] Snapshotting to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_4000.caffemodel
I0514 12:18:36.165002 12912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_4000.solverstate
I0514 12:18:36.305610 12912 solver.cpp:337] Iteration 4000, Testing net (#0)
I0514 12:18:36.305734 12912 net.cpp:685] Ignoring source layer loss
I0514 12:20:21.617703 12912 solver.cpp:404]     Test net output #0: accuracy = 0.320294
I0514 12:20:21.909837 12912 solver.cpp:228] Iteration 4000, loss = 2.30145
I0514 12:20:21.909947 12912 solver.cpp:244]     Train net output #0: loss = 2.30145 (* 1 = 2.30145 loss)
I0514 12:20:21.909986 12912 sgd_solver.cpp:106] Iteration 4000, lr = 0.0005
I0514 12:20:59.941723 12912 solver.cpp:228] Iteration 4050, loss = 1.83636
I0514 12:20:59.941823 12912 solver.cpp:244]     Train net output #0: loss = 1.83636 (* 1 = 1.83636 loss)
I0514 12:20:59.941841 12912 sgd_solver.cpp:106] Iteration 4050, lr = 0.0005
I0514 12:21:37.996598 12912 solver.cpp:228] Iteration 4100, loss = 1.9566
I0514 12:21:37.996821 12912 solver.cpp:244]     Train net output #0: loss = 1.9566 (* 1 = 1.9566 loss)
I0514 12:21:37.996897 12912 sgd_solver.cpp:106] Iteration 4100, lr = 0.0005
I0514 12:22:16.057469 12912 solver.cpp:228] Iteration 4150, loss = 1.85572
I0514 12:22:16.057652 12912 solver.cpp:244]     Train net output #0: loss = 1.85572 (* 1 = 1.85572 loss)
I0514 12:22:16.057692 12912 sgd_solver.cpp:106] Iteration 4150, lr = 0.0005
I0514 12:22:54.141819 12912 solver.cpp:228] Iteration 4200, loss = 2.50158
I0514 12:22:54.141985 12912 solver.cpp:244]     Train net output #0: loss = 2.50158 (* 1 = 2.50158 loss)
I0514 12:22:54.142009 12912 sgd_solver.cpp:106] Iteration 4200, lr = 0.0005
I0514 12:23:32.214733 12912 solver.cpp:228] Iteration 4250, loss = 1.84476
I0514 12:23:32.214903 12912 solver.cpp:244]     Train net output #0: loss = 1.84476 (* 1 = 1.84476 loss)
I0514 12:23:32.214946 12912 sgd_solver.cpp:106] Iteration 4250, lr = 0.0005
I0514 12:24:10.273680 12912 solver.cpp:228] Iteration 4300, loss = 1.96857
I0514 12:24:10.273866 12912 solver.cpp:244]     Train net output #0: loss = 1.96857 (* 1 = 1.96857 loss)
I0514 12:24:10.273913 12912 sgd_solver.cpp:106] Iteration 4300, lr = 0.0005
I0514 12:24:48.328482 12912 solver.cpp:228] Iteration 4350, loss = 1.89934
I0514 12:24:48.328682 12912 solver.cpp:244]     Train net output #0: loss = 1.89934 (* 1 = 1.89934 loss)
I0514 12:24:48.328722 12912 sgd_solver.cpp:106] Iteration 4350, lr = 0.0005
I0514 12:25:26.392894 12912 solver.cpp:228] Iteration 4400, loss = 1.75461
I0514 12:25:26.393030 12912 solver.cpp:244]     Train net output #0: loss = 1.75461 (* 1 = 1.75461 loss)
I0514 12:25:26.393048 12912 sgd_solver.cpp:106] Iteration 4400, lr = 0.0005
I0514 12:26:04.424367 12912 solver.cpp:228] Iteration 4450, loss = 1.77371
I0514 12:26:04.424489 12912 solver.cpp:244]     Train net output #0: loss = 1.77371 (* 1 = 1.77371 loss)
I0514 12:26:04.424506 12912 sgd_solver.cpp:106] Iteration 4450, lr = 0.0005
I0514 12:26:42.664818 12912 solver.cpp:228] Iteration 4500, loss = 1.76285
I0514 12:26:42.665066 12912 solver.cpp:244]     Train net output #0: loss = 1.76285 (* 1 = 1.76285 loss)
I0514 12:26:42.665130 12912 sgd_solver.cpp:106] Iteration 4500, lr = 0.0005
I0514 12:27:20.625109 12912 solver.cpp:228] Iteration 4550, loss = 2.30766
I0514 12:27:20.625222 12912 solver.cpp:244]     Train net output #0: loss = 2.30766 (* 1 = 2.30766 loss)
I0514 12:27:20.625241 12912 sgd_solver.cpp:106] Iteration 4550, lr = 0.0005
I0514 12:27:58.571370 12912 solver.cpp:228] Iteration 4600, loss = 1.65463
I0514 12:27:58.571486 12912 solver.cpp:244]     Train net output #0: loss = 1.65463 (* 1 = 1.65463 loss)
I0514 12:27:58.571499 12912 sgd_solver.cpp:106] Iteration 4600, lr = 0.0005
I0514 12:28:36.528863 12912 solver.cpp:228] Iteration 4650, loss = 1.40471
I0514 12:28:36.529045 12912 solver.cpp:244]     Train net output #0: loss = 1.40471 (* 1 = 1.40471 loss)
I0514 12:28:36.529085 12912 sgd_solver.cpp:106] Iteration 4650, lr = 0.0005
I0514 12:29:14.534950 12912 solver.cpp:228] Iteration 4700, loss = 1.34959
I0514 12:29:14.535043 12912 solver.cpp:244]     Train net output #0: loss = 1.34959 (* 1 = 1.34959 loss)
I0514 12:29:14.535054 12912 sgd_solver.cpp:106] Iteration 4700, lr = 0.0005
I0514 12:29:52.557862 12912 solver.cpp:228] Iteration 4750, loss = 2.1737
I0514 12:29:52.558097 12912 solver.cpp:244]     Train net output #0: loss = 2.1737 (* 1 = 2.1737 loss)
I0514 12:29:52.558121 12912 sgd_solver.cpp:106] Iteration 4750, lr = 0.0005
I0514 12:30:30.603123 12912 solver.cpp:228] Iteration 4800, loss = 1.86668
I0514 12:30:30.603245 12912 solver.cpp:244]     Train net output #0: loss = 1.86668 (* 1 = 1.86668 loss)
I0514 12:30:30.603258 12912 sgd_solver.cpp:106] Iteration 4800, lr = 0.0005
I0514 12:31:08.622653 12912 solver.cpp:228] Iteration 4850, loss = 1.08574
I0514 12:31:08.622766 12912 solver.cpp:244]     Train net output #0: loss = 1.08574 (* 1 = 1.08574 loss)
I0514 12:31:08.622778 12912 sgd_solver.cpp:106] Iteration 4850, lr = 0.0005
I0514 12:31:46.612216 12912 solver.cpp:228] Iteration 4900, loss = 1.76166
I0514 12:31:46.612357 12912 solver.cpp:244]     Train net output #0: loss = 1.76166 (* 1 = 1.76166 loss)
I0514 12:31:46.612376 12912 sgd_solver.cpp:106] Iteration 4900, lr = 0.0005
I0514 12:32:24.630429 12912 solver.cpp:228] Iteration 4950, loss = 2.40142
I0514 12:32:24.630578 12912 solver.cpp:244]     Train net output #0: loss = 2.40142 (* 1 = 2.40142 loss)
I0514 12:32:24.630596 12912 sgd_solver.cpp:106] Iteration 4950, lr = 0.0005
I0514 12:33:02.393682 12912 solver.cpp:454] Snapshotting to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_5000.caffemodel
I0514 12:33:02.895928 12912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_5000.solverstate
I0514 12:33:02.976173 12912 solver.cpp:337] Iteration 5000, Testing net (#0)
I0514 12:33:02.976243 12912 net.cpp:685] Ignoring source layer loss
I0514 12:34:47.358134 12912 solver.cpp:404]     Test net output #0: accuracy = 0.376176
I0514 12:34:47.648813 12912 solver.cpp:228] Iteration 5000, loss = 1.43697
I0514 12:34:47.648932 12912 solver.cpp:244]     Train net output #0: loss = 1.43697 (* 1 = 1.43697 loss)
I0514 12:34:47.648969 12912 sgd_solver.cpp:106] Iteration 5000, lr = 0.0005
I0514 12:35:25.661108 12912 solver.cpp:228] Iteration 5050, loss = 1.45567
I0514 12:35:25.661288 12912 solver.cpp:244]     Train net output #0: loss = 1.45567 (* 1 = 1.45567 loss)
I0514 12:35:25.661301 12912 sgd_solver.cpp:106] Iteration 5050, lr = 0.0005
I0514 12:36:03.688967 12912 solver.cpp:228] Iteration 5100, loss = 1.69642
I0514 12:36:03.689080 12912 solver.cpp:244]     Train net output #0: loss = 1.69642 (* 1 = 1.69642 loss)
I0514 12:36:03.689097 12912 sgd_solver.cpp:106] Iteration 5100, lr = 0.0005
I0514 12:36:43.050582 12912 solver.cpp:228] Iteration 5150, loss = 1.31432
I0514 12:36:43.050745 12912 solver.cpp:244]     Train net output #0: loss = 1.31432 (* 1 = 1.31432 loss)
I0514 12:36:43.050762 12912 sgd_solver.cpp:106] Iteration 5150, lr = 0.0005
I0514 12:37:21.059496 12912 solver.cpp:228] Iteration 5200, loss = 2.39406
I0514 12:37:21.059737 12912 solver.cpp:244]     Train net output #0: loss = 2.39406 (* 1 = 2.39406 loss)
I0514 12:37:21.059761 12912 sgd_solver.cpp:106] Iteration 5200, lr = 0.0005
I0514 12:37:59.062758 12912 solver.cpp:228] Iteration 5250, loss = 1.4538
I0514 12:37:59.062997 12912 solver.cpp:244]     Train net output #0: loss = 1.4538 (* 1 = 1.4538 loss)
I0514 12:37:59.063040 12912 sgd_solver.cpp:106] Iteration 5250, lr = 0.0005
I0514 12:38:37.069484 12912 solver.cpp:228] Iteration 5300, loss = 1.84062
I0514 12:38:37.069842 12912 solver.cpp:244]     Train net output #0: loss = 1.84062 (* 1 = 1.84062 loss)
I0514 12:38:37.069908 12912 sgd_solver.cpp:106] Iteration 5300, lr = 0.0005
I0514 12:39:15.066072 12912 solver.cpp:228] Iteration 5350, loss = 1.29303
I0514 12:39:15.066232 12912 solver.cpp:244]     Train net output #0: loss = 1.29303 (* 1 = 1.29303 loss)
I0514 12:39:15.066249 12912 sgd_solver.cpp:106] Iteration 5350, lr = 0.0005
I0514 12:39:53.067330 12912 solver.cpp:228] Iteration 5400, loss = 1.38692
I0514 12:39:53.067497 12912 solver.cpp:244]     Train net output #0: loss = 1.38692 (* 1 = 1.38692 loss)
I0514 12:39:53.067517 12912 sgd_solver.cpp:106] Iteration 5400, lr = 0.0005
I0514 12:40:31.111340 12912 solver.cpp:228] Iteration 5450, loss = 1.5056
I0514 12:40:31.111438 12912 solver.cpp:244]     Train net output #0: loss = 1.5056 (* 1 = 1.5056 loss)
I0514 12:40:31.111449 12912 sgd_solver.cpp:106] Iteration 5450, lr = 0.0005
I0514 12:41:09.129536 12912 solver.cpp:228] Iteration 5500, loss = 1.62012
I0514 12:41:09.129662 12912 solver.cpp:244]     Train net output #0: loss = 1.62012 (* 1 = 1.62012 loss)
I0514 12:41:09.129678 12912 sgd_solver.cpp:106] Iteration 5500, lr = 0.0005
I0514 12:41:47.108458 12912 solver.cpp:228] Iteration 5550, loss = 1.51068
I0514 12:41:47.108700 12912 solver.cpp:244]     Train net output #0: loss = 1.51068 (* 1 = 1.51068 loss)
I0514 12:41:47.108726 12912 sgd_solver.cpp:106] Iteration 5550, lr = 0.0005
I0514 12:42:25.122378 12912 solver.cpp:228] Iteration 5600, loss = 1.48641
I0514 12:42:25.122510 12912 solver.cpp:244]     Train net output #0: loss = 1.48641 (* 1 = 1.48641 loss)
I0514 12:42:25.122521 12912 sgd_solver.cpp:106] Iteration 5600, lr = 0.0005
I0514 12:43:03.126003 12912 solver.cpp:228] Iteration 5650, loss = 1.61474
I0514 12:43:03.126135 12912 solver.cpp:244]     Train net output #0: loss = 1.61474 (* 1 = 1.61474 loss)
I0514 12:43:03.126152 12912 sgd_solver.cpp:106] Iteration 5650, lr = 0.0005
I0514 12:43:41.134831 12912 solver.cpp:228] Iteration 5700, loss = 2.04206
I0514 12:43:41.134934 12912 solver.cpp:244]     Train net output #0: loss = 2.04206 (* 1 = 2.04206 loss)
I0514 12:43:41.134951 12912 sgd_solver.cpp:106] Iteration 5700, lr = 0.0005
I0514 12:44:19.152245 12912 solver.cpp:228] Iteration 5750, loss = 1.49677
I0514 12:44:19.152396 12912 solver.cpp:244]     Train net output #0: loss = 1.49677 (* 1 = 1.49677 loss)
I0514 12:44:19.152415 12912 sgd_solver.cpp:106] Iteration 5750, lr = 0.0005
I0514 12:44:57.159154 12912 solver.cpp:228] Iteration 5800, loss = 1.93918
I0514 12:44:57.159394 12912 solver.cpp:244]     Train net output #0: loss = 1.93918 (* 1 = 1.93918 loss)
I0514 12:44:57.159415 12912 sgd_solver.cpp:106] Iteration 5800, lr = 0.0005
I0514 12:45:35.155161 12912 solver.cpp:228] Iteration 5850, loss = 1.35244
I0514 12:45:35.155349 12912 solver.cpp:244]     Train net output #0: loss = 1.35244 (* 1 = 1.35244 loss)
I0514 12:45:35.155390 12912 sgd_solver.cpp:106] Iteration 5850, lr = 0.0005
I0514 12:46:13.100214 12912 solver.cpp:228] Iteration 5900, loss = 2.19624
I0514 12:46:13.100399 12912 solver.cpp:244]     Train net output #0: loss = 2.19624 (* 1 = 2.19624 loss)
I0514 12:46:13.100437 12912 sgd_solver.cpp:106] Iteration 5900, lr = 0.0005
I0514 12:46:51.050468 12912 solver.cpp:228] Iteration 5950, loss = 1.68008
I0514 12:46:51.050585 12912 solver.cpp:244]     Train net output #0: loss = 1.68008 (* 1 = 1.68008 loss)
I0514 12:46:51.050601 12912 sgd_solver.cpp:106] Iteration 5950, lr = 0.0005
I0514 12:47:28.717432 12912 solver.cpp:454] Snapshotting to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_6000.caffemodel
I0514 12:47:28.913377 12912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_6000.solverstate
I0514 12:47:28.994037 12912 solver.cpp:337] Iteration 6000, Testing net (#0)
I0514 12:47:28.994101 12912 net.cpp:685] Ignoring source layer loss
I0514 12:49:13.111347 12912 solver.cpp:404]     Test net output #0: accuracy = 0.461618
I0514 12:49:13.402509 12912 solver.cpp:228] Iteration 6000, loss = 0.916345
I0514 12:49:13.402565 12912 solver.cpp:244]     Train net output #0: loss = 0.916345 (* 1 = 0.916345 loss)
I0514 12:49:13.402576 12912 sgd_solver.cpp:106] Iteration 6000, lr = 0.0005
I0514 12:49:51.409158 12912 solver.cpp:228] Iteration 6050, loss = 1.41065
I0514 12:49:51.409401 12912 solver.cpp:244]     Train net output #0: loss = 1.41065 (* 1 = 1.41065 loss)
I0514 12:49:51.409417 12912 sgd_solver.cpp:106] Iteration 6050, lr = 0.0005
I0514 12:50:29.422282 12912 solver.cpp:228] Iteration 6100, loss = 1.25085
I0514 12:50:29.422451 12912 solver.cpp:244]     Train net output #0: loss = 1.25085 (* 1 = 1.25085 loss)
I0514 12:50:29.422463 12912 sgd_solver.cpp:106] Iteration 6100, lr = 0.0005
I0514 12:51:07.419067 12912 solver.cpp:228] Iteration 6150, loss = 1.54052
I0514 12:51:07.419201 12912 solver.cpp:244]     Train net output #0: loss = 1.54052 (* 1 = 1.54052 loss)
I0514 12:51:07.419214 12912 sgd_solver.cpp:106] Iteration 6150, lr = 0.0005
I0514 12:51:45.428408 12912 solver.cpp:228] Iteration 6200, loss = 2.07389
I0514 12:51:45.428566 12912 solver.cpp:244]     Train net output #0: loss = 2.07389 (* 1 = 2.07389 loss)
I0514 12:51:45.428580 12912 sgd_solver.cpp:106] Iteration 6200, lr = 0.0005
I0514 12:52:23.444453 12912 solver.cpp:228] Iteration 6250, loss = 1.74537
I0514 12:52:23.444586 12912 solver.cpp:244]     Train net output #0: loss = 1.74537 (* 1 = 1.74537 loss)
I0514 12:52:23.444641 12912 sgd_solver.cpp:106] Iteration 6250, lr = 0.0005
I0514 12:53:01.490898 12912 solver.cpp:228] Iteration 6300, loss = 1.34032
I0514 12:53:01.491024 12912 solver.cpp:244]     Train net output #0: loss = 1.34032 (* 1 = 1.34032 loss)
I0514 12:53:01.491041 12912 sgd_solver.cpp:106] Iteration 6300, lr = 0.0005
I0514 12:53:39.503639 12912 solver.cpp:228] Iteration 6350, loss = 1.80823
I0514 12:53:39.503733 12912 solver.cpp:244]     Train net output #0: loss = 1.80823 (* 1 = 1.80823 loss)
I0514 12:53:39.503751 12912 sgd_solver.cpp:106] Iteration 6350, lr = 0.0005
I0514 12:54:17.498816 12912 solver.cpp:228] Iteration 6400, loss = 1.1476
I0514 12:54:17.498910 12912 solver.cpp:244]     Train net output #0: loss = 1.1476 (* 1 = 1.1476 loss)
I0514 12:54:17.498922 12912 sgd_solver.cpp:106] Iteration 6400, lr = 0.0005
I0514 12:54:55.485837 12912 solver.cpp:228] Iteration 6450, loss = 1.10051
I0514 12:54:55.485941 12912 solver.cpp:244]     Train net output #0: loss = 1.10051 (* 1 = 1.10051 loss)
I0514 12:54:55.485954 12912 sgd_solver.cpp:106] Iteration 6450, lr = 0.0005
I0514 12:55:33.481564 12912 solver.cpp:228] Iteration 6500, loss = 1.38539
I0514 12:55:33.481705 12912 solver.cpp:244]     Train net output #0: loss = 1.38539 (* 1 = 1.38539 loss)
I0514 12:55:33.481719 12912 sgd_solver.cpp:106] Iteration 6500, lr = 0.0005
I0514 12:56:11.492934 12912 solver.cpp:228] Iteration 6550, loss = 1.57281
I0514 12:56:11.493062 12912 solver.cpp:244]     Train net output #0: loss = 1.57281 (* 1 = 1.57281 loss)
I0514 12:56:11.493079 12912 sgd_solver.cpp:106] Iteration 6550, lr = 0.0005
I0514 12:56:49.505457 12912 solver.cpp:228] Iteration 6600, loss = 1.21174
I0514 12:56:49.505571 12912 solver.cpp:244]     Train net output #0: loss = 1.21174 (* 1 = 1.21174 loss)
I0514 12:56:49.505584 12912 sgd_solver.cpp:106] Iteration 6600, lr = 0.0005
I0514 12:57:27.517565 12912 solver.cpp:228] Iteration 6650, loss = 1.39023
I0514 12:57:27.517758 12912 solver.cpp:244]     Train net output #0: loss = 1.39023 (* 1 = 1.39023 loss)
I0514 12:57:27.517779 12912 sgd_solver.cpp:106] Iteration 6650, lr = 0.0005
I0514 12:58:05.571190 12912 solver.cpp:228] Iteration 6700, loss = 1.97976
I0514 12:58:05.571341 12912 solver.cpp:244]     Train net output #0: loss = 1.97976 (* 1 = 1.97976 loss)
I0514 12:58:05.571355 12912 sgd_solver.cpp:106] Iteration 6700, lr = 0.0005
I0514 12:58:43.580499 12912 solver.cpp:228] Iteration 6750, loss = 1.30299
I0514 12:58:43.580698 12912 solver.cpp:244]     Train net output #0: loss = 1.30299 (* 1 = 1.30299 loss)
I0514 12:58:43.580737 12912 sgd_solver.cpp:106] Iteration 6750, lr = 0.0005
I0514 12:59:21.593624 12912 solver.cpp:228] Iteration 6800, loss = 2.12922
I0514 12:59:21.593739 12912 solver.cpp:244]     Train net output #0: loss = 2.12922 (* 1 = 2.12922 loss)
I0514 12:59:21.593755 12912 sgd_solver.cpp:106] Iteration 6800, lr = 0.0005
I0514 12:59:59.609360 12912 solver.cpp:228] Iteration 6850, loss = 1.42772
I0514 12:59:59.609515 12912 solver.cpp:244]     Train net output #0: loss = 1.42772 (* 1 = 1.42772 loss)
I0514 12:59:59.609534 12912 sgd_solver.cpp:106] Iteration 6850, lr = 0.0005
I0514 13:00:37.623632 12912 solver.cpp:228] Iteration 6900, loss = 1.42677
I0514 13:00:37.623780 12912 solver.cpp:244]     Train net output #0: loss = 1.42677 (* 1 = 1.42677 loss)
I0514 13:00:37.623795 12912 sgd_solver.cpp:106] Iteration 6900, lr = 0.0005
I0514 13:01:15.645808 12912 solver.cpp:228] Iteration 6950, loss = 1.70925
I0514 13:01:15.645954 12912 solver.cpp:244]     Train net output #0: loss = 1.70925 (* 1 = 1.70925 loss)
I0514 13:01:15.645977 12912 sgd_solver.cpp:106] Iteration 6950, lr = 0.0005
I0514 13:01:53.355239 12912 solver.cpp:454] Snapshotting to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_7000.caffemodel
I0514 13:01:54.188133 12912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_7000.solverstate
I0514 13:01:54.331449 12912 solver.cpp:337] Iteration 7000, Testing net (#0)
I0514 13:01:54.331526 12912 net.cpp:685] Ignoring source layer loss
I0514 13:03:38.260375 12912 solver.cpp:404]     Test net output #0: accuracy = 0.406324
I0514 13:03:38.550889 12912 solver.cpp:228] Iteration 7000, loss = 1.25913
I0514 13:03:38.550938 12912 solver.cpp:244]     Train net output #0: loss = 1.25913 (* 1 = 1.25913 loss)
I0514 13:03:38.550953 12912 sgd_solver.cpp:106] Iteration 7000, lr = 0.0005
I0514 13:04:16.540740 12912 solver.cpp:228] Iteration 7050, loss = 0.815722
I0514 13:04:16.540946 12912 solver.cpp:244]     Train net output #0: loss = 0.815722 (* 1 = 0.815722 loss)
I0514 13:04:16.540959 12912 sgd_solver.cpp:106] Iteration 7050, lr = 0.0005
I0514 13:04:54.515604 12912 solver.cpp:228] Iteration 7100, loss = 1.36894
I0514 13:04:54.515708 12912 solver.cpp:244]     Train net output #0: loss = 1.36894 (* 1 = 1.36894 loss)
I0514 13:04:54.515720 12912 sgd_solver.cpp:106] Iteration 7100, lr = 0.0005
I0514 13:05:32.469372 12912 solver.cpp:228] Iteration 7150, loss = 1.45172
I0514 13:05:32.469493 12912 solver.cpp:244]     Train net output #0: loss = 1.45172 (* 1 = 1.45172 loss)
I0514 13:05:32.469508 12912 sgd_solver.cpp:106] Iteration 7150, lr = 0.0005
I0514 13:06:10.440631 12912 solver.cpp:228] Iteration 7200, loss = 1.28488
I0514 13:06:10.440831 12912 solver.cpp:244]     Train net output #0: loss = 1.28488 (* 1 = 1.28488 loss)
I0514 13:06:10.440855 12912 sgd_solver.cpp:106] Iteration 7200, lr = 0.0005
I0514 13:06:48.425614 12912 solver.cpp:228] Iteration 7250, loss = 0.896823
I0514 13:06:48.425736 12912 solver.cpp:244]     Train net output #0: loss = 0.896823 (* 1 = 0.896823 loss)
I0514 13:06:48.425750 12912 sgd_solver.cpp:106] Iteration 7250, lr = 0.0005
I0514 13:07:26.436457 12912 solver.cpp:228] Iteration 7300, loss = 0.861006
I0514 13:07:26.436583 12912 solver.cpp:244]     Train net output #0: loss = 0.861006 (* 1 = 0.861006 loss)
I0514 13:07:26.436600 12912 sgd_solver.cpp:106] Iteration 7300, lr = 0.0005
I0514 13:08:04.462057 12912 solver.cpp:228] Iteration 7350, loss = 1.03074
I0514 13:08:04.462160 12912 solver.cpp:244]     Train net output #0: loss = 1.03074 (* 1 = 1.03074 loss)
I0514 13:08:04.462177 12912 sgd_solver.cpp:106] Iteration 7350, lr = 0.0005
I0514 13:08:42.469694 12912 solver.cpp:228] Iteration 7400, loss = 1.47081
I0514 13:08:42.469838 12912 solver.cpp:244]     Train net output #0: loss = 1.47081 (* 1 = 1.47081 loss)
I0514 13:08:42.469856 12912 sgd_solver.cpp:106] Iteration 7400, lr = 0.0005
I0514 13:09:20.474673 12912 solver.cpp:228] Iteration 7450, loss = 1.24035
I0514 13:09:20.474995 12912 solver.cpp:244]     Train net output #0: loss = 1.24035 (* 1 = 1.24035 loss)
I0514 13:09:20.475013 12912 sgd_solver.cpp:106] Iteration 7450, lr = 0.0005
I0514 13:09:58.481889 12912 solver.cpp:228] Iteration 7500, loss = 1.32595
I0514 13:09:58.482002 12912 solver.cpp:244]     Train net output #0: loss = 1.32595 (* 1 = 1.32595 loss)
I0514 13:09:58.482020 12912 sgd_solver.cpp:106] Iteration 7500, lr = 0.0005
I0514 13:10:36.480342 12912 solver.cpp:228] Iteration 7550, loss = 1.40178
I0514 13:10:36.480504 12912 solver.cpp:244]     Train net output #0: loss = 1.40178 (* 1 = 1.40178 loss)
I0514 13:10:36.480520 12912 sgd_solver.cpp:106] Iteration 7550, lr = 0.0005
I0514 13:11:14.485904 12912 solver.cpp:228] Iteration 7600, loss = 1.25266
I0514 13:11:14.486120 12912 solver.cpp:244]     Train net output #0: loss = 1.25266 (* 1 = 1.25266 loss)
I0514 13:11:14.486142 12912 sgd_solver.cpp:106] Iteration 7600, lr = 0.0005
I0514 13:11:52.521806 12912 solver.cpp:228] Iteration 7650, loss = 1.94348
I0514 13:11:52.521903 12912 solver.cpp:244]     Train net output #0: loss = 1.94348 (* 1 = 1.94348 loss)
I0514 13:11:52.521914 12912 sgd_solver.cpp:106] Iteration 7650, lr = 0.0005
I0514 13:12:30.549932 12912 solver.cpp:228] Iteration 7700, loss = 1.09714
I0514 13:12:30.550053 12912 solver.cpp:244]     Train net output #0: loss = 1.09714 (* 1 = 1.09714 loss)
I0514 13:12:30.550066 12912 sgd_solver.cpp:106] Iteration 7700, lr = 0.0005
I0514 13:13:08.543493 12912 solver.cpp:228] Iteration 7750, loss = 1.44785
I0514 13:13:08.543596 12912 solver.cpp:244]     Train net output #0: loss = 1.44785 (* 1 = 1.44785 loss)
I0514 13:13:08.543613 12912 sgd_solver.cpp:106] Iteration 7750, lr = 0.0005
I0514 13:13:46.577769 12912 solver.cpp:228] Iteration 7800, loss = 0.922959
I0514 13:13:46.577880 12912 solver.cpp:244]     Train net output #0: loss = 0.922959 (* 1 = 0.922959 loss)
I0514 13:13:46.577898 12912 sgd_solver.cpp:106] Iteration 7800, lr = 0.0005
I0514 13:14:24.603760 12912 solver.cpp:228] Iteration 7850, loss = 1.09314
I0514 13:14:24.603919 12912 solver.cpp:244]     Train net output #0: loss = 1.09314 (* 1 = 1.09314 loss)
I0514 13:14:24.603935 12912 sgd_solver.cpp:106] Iteration 7850, lr = 0.0005
I0514 13:15:02.625075 12912 solver.cpp:228] Iteration 7900, loss = 1.07479
I0514 13:15:02.625195 12912 solver.cpp:244]     Train net output #0: loss = 1.07479 (* 1 = 1.07479 loss)
I0514 13:15:02.625210 12912 sgd_solver.cpp:106] Iteration 7900, lr = 0.0005
I0514 13:15:40.615667 12912 solver.cpp:228] Iteration 7950, loss = 0.443545
I0514 13:15:40.615793 12912 solver.cpp:244]     Train net output #0: loss = 0.443545 (* 1 = 0.443545 loss)
I0514 13:15:40.615810 12912 sgd_solver.cpp:106] Iteration 7950, lr = 0.0005
I0514 13:16:18.359962 12912 solver.cpp:454] Snapshotting to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_8000.caffemodel
I0514 13:16:18.884022 12912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_8000.solverstate
I0514 13:16:19.030951 12912 solver.cpp:337] Iteration 8000, Testing net (#0)
I0514 13:16:19.031059 12912 net.cpp:685] Ignoring source layer loss
I0514 13:18:03.274883 12912 solver.cpp:404]     Test net output #0: accuracy = 0.425441
I0514 13:18:03.565140 12912 solver.cpp:228] Iteration 8000, loss = 0.741264
I0514 13:18:03.565191 12912 solver.cpp:244]     Train net output #0: loss = 0.741264 (* 1 = 0.741264 loss)
I0514 13:18:03.565201 12912 sgd_solver.cpp:106] Iteration 8000, lr = 0.0005
I0514 13:18:41.578384 12912 solver.cpp:228] Iteration 8050, loss = 1.21324
I0514 13:18:41.578577 12912 solver.cpp:244]     Train net output #0: loss = 1.21324 (* 1 = 1.21324 loss)
I0514 13:18:41.578596 12912 sgd_solver.cpp:106] Iteration 8050, lr = 0.0005
I0514 13:19:19.568073 12912 solver.cpp:228] Iteration 8100, loss = 0.778858
I0514 13:19:19.568225 12912 solver.cpp:244]     Train net output #0: loss = 0.778858 (* 1 = 0.778858 loss)
I0514 13:19:19.568240 12912 sgd_solver.cpp:106] Iteration 8100, lr = 0.0005
I0514 13:19:57.584075 12912 solver.cpp:228] Iteration 8150, loss = 0.939549
I0514 13:19:57.584260 12912 solver.cpp:244]     Train net output #0: loss = 0.939549 (* 1 = 0.939549 loss)
I0514 13:19:57.584295 12912 sgd_solver.cpp:106] Iteration 8150, lr = 0.0005
I0514 13:20:35.595010 12912 solver.cpp:228] Iteration 8200, loss = 1.37343
I0514 13:20:35.595206 12912 solver.cpp:244]     Train net output #0: loss = 1.37343 (* 1 = 1.37343 loss)
I0514 13:20:35.595245 12912 sgd_solver.cpp:106] Iteration 8200, lr = 0.0005
I0514 13:21:13.617450 12912 solver.cpp:228] Iteration 8250, loss = 0.905022
I0514 13:21:13.617571 12912 solver.cpp:244]     Train net output #0: loss = 0.905022 (* 1 = 0.905022 loss)
I0514 13:21:13.617589 12912 sgd_solver.cpp:106] Iteration 8250, lr = 0.0005
I0514 13:21:51.651084 12912 solver.cpp:228] Iteration 8300, loss = 0.703255
I0514 13:21:51.651288 12912 solver.cpp:244]     Train net output #0: loss = 0.703255 (* 1 = 0.703255 loss)
I0514 13:21:51.651305 12912 sgd_solver.cpp:106] Iteration 8300, lr = 0.0005
I0514 13:22:29.640940 12912 solver.cpp:228] Iteration 8350, loss = 1.28056
I0514 13:22:29.641065 12912 solver.cpp:244]     Train net output #0: loss = 1.28056 (* 1 = 1.28056 loss)
I0514 13:22:29.641077 12912 sgd_solver.cpp:106] Iteration 8350, lr = 0.0005
I0514 13:23:07.649168 12912 solver.cpp:228] Iteration 8400, loss = 0.812409
I0514 13:23:07.649317 12912 solver.cpp:244]     Train net output #0: loss = 0.812409 (* 1 = 0.812409 loss)
I0514 13:23:07.649336 12912 sgd_solver.cpp:106] Iteration 8400, lr = 0.0005
I0514 13:23:45.621208 12912 solver.cpp:228] Iteration 8450, loss = 1.13819
I0514 13:23:45.621383 12912 solver.cpp:244]     Train net output #0: loss = 1.13819 (* 1 = 1.13819 loss)
I0514 13:23:45.621423 12912 sgd_solver.cpp:106] Iteration 8450, lr = 0.0005
I0514 13:24:23.580453 12912 solver.cpp:228] Iteration 8500, loss = 0.45239
I0514 13:24:23.580590 12912 solver.cpp:244]     Train net output #0: loss = 0.45239 (* 1 = 0.45239 loss)
I0514 13:24:23.580606 12912 sgd_solver.cpp:106] Iteration 8500, lr = 0.0005
I0514 13:25:01.548990 12912 solver.cpp:228] Iteration 8550, loss = 1.04189
I0514 13:25:01.549078 12912 solver.cpp:244]     Train net output #0: loss = 1.04189 (* 1 = 1.04189 loss)
I0514 13:25:01.549089 12912 sgd_solver.cpp:106] Iteration 8550, lr = 0.0005
I0514 13:25:39.530027 12912 solver.cpp:228] Iteration 8600, loss = 1.13694
I0514 13:25:39.530139 12912 solver.cpp:244]     Train net output #0: loss = 1.13694 (* 1 = 1.13694 loss)
I0514 13:25:39.530151 12912 sgd_solver.cpp:106] Iteration 8600, lr = 0.0005
I0514 13:26:17.529014 12912 solver.cpp:228] Iteration 8650, loss = 1.30619
I0514 13:26:17.529163 12912 solver.cpp:244]     Train net output #0: loss = 1.30619 (* 1 = 1.30619 loss)
I0514 13:26:17.529183 12912 sgd_solver.cpp:106] Iteration 8650, lr = 0.0005
I0514 13:26:55.566231 12912 solver.cpp:228] Iteration 8700, loss = 1.04416
I0514 13:26:55.566408 12912 solver.cpp:244]     Train net output #0: loss = 1.04416 (* 1 = 1.04416 loss)
I0514 13:26:55.566426 12912 sgd_solver.cpp:106] Iteration 8700, lr = 0.0005
I0514 13:27:33.582247 12912 solver.cpp:228] Iteration 8750, loss = 0.570865
I0514 13:27:33.582442 12912 solver.cpp:244]     Train net output #0: loss = 0.570864 (* 1 = 0.570864 loss)
I0514 13:27:33.582484 12912 sgd_solver.cpp:106] Iteration 8750, lr = 0.0005
I0514 13:28:11.601626 12912 solver.cpp:228] Iteration 8800, loss = 0.840186
I0514 13:28:11.601830 12912 solver.cpp:244]     Train net output #0: loss = 0.840185 (* 1 = 0.840185 loss)
I0514 13:28:11.601874 12912 sgd_solver.cpp:106] Iteration 8800, lr = 0.0005
I0514 13:28:49.609078 12912 solver.cpp:228] Iteration 8850, loss = 1.04826
I0514 13:28:49.609192 12912 solver.cpp:244]     Train net output #0: loss = 1.04826 (* 1 = 1.04826 loss)
I0514 13:28:49.609205 12912 sgd_solver.cpp:106] Iteration 8850, lr = 0.0005
I0514 13:29:27.616099 12912 solver.cpp:228] Iteration 8900, loss = 0.639234
I0514 13:29:27.616246 12912 solver.cpp:244]     Train net output #0: loss = 0.639233 (* 1 = 0.639233 loss)
I0514 13:29:27.616260 12912 sgd_solver.cpp:106] Iteration 8900, lr = 0.0005
I0514 13:30:05.644114 12912 solver.cpp:228] Iteration 8950, loss = 1.06151
I0514 13:30:05.644387 12912 solver.cpp:244]     Train net output #0: loss = 1.06151 (* 1 = 1.06151 loss)
I0514 13:30:05.644408 12912 sgd_solver.cpp:106] Iteration 8950, lr = 0.0005
I0514 13:30:43.374640 12912 solver.cpp:454] Snapshotting to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_9000.caffemodel
I0514 13:30:44.127884 12912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_9000.solverstate
I0514 13:30:44.275199 12912 solver.cpp:337] Iteration 9000, Testing net (#0)
I0514 13:30:44.275279 12912 net.cpp:685] Ignoring source layer loss
I0514 13:32:27.286813 12912 solver.cpp:404]     Test net output #0: accuracy = 0.511912
I0514 13:32:27.577862 12912 solver.cpp:228] Iteration 9000, loss = 1.0973
I0514 13:32:27.577918 12912 solver.cpp:244]     Train net output #0: loss = 1.0973 (* 1 = 1.0973 loss)
I0514 13:32:27.577932 12912 sgd_solver.cpp:106] Iteration 9000, lr = 0.0005
I0514 13:33:05.603735 12912 solver.cpp:228] Iteration 9050, loss = 1.02674
I0514 13:33:05.603839 12912 solver.cpp:244]     Train net output #0: loss = 1.02674 (* 1 = 1.02674 loss)
I0514 13:33:05.603857 12912 sgd_solver.cpp:106] Iteration 9050, lr = 0.0005
I0514 13:33:43.634183 12912 solver.cpp:228] Iteration 9100, loss = 0.818627
I0514 13:33:43.634299 12912 solver.cpp:244]     Train net output #0: loss = 0.818627 (* 1 = 0.818627 loss)
I0514 13:33:43.634317 12912 sgd_solver.cpp:106] Iteration 9100, lr = 0.0005
I0514 13:34:21.656075 12912 solver.cpp:228] Iteration 9150, loss = 0.95938
I0514 13:34:21.656287 12912 solver.cpp:244]     Train net output #0: loss = 0.959379 (* 1 = 0.959379 loss)
I0514 13:34:21.656306 12912 sgd_solver.cpp:106] Iteration 9150, lr = 0.0005
I0514 13:34:59.677253 12912 solver.cpp:228] Iteration 9200, loss = 0.471233
I0514 13:34:59.677428 12912 solver.cpp:244]     Train net output #0: loss = 0.471233 (* 1 = 0.471233 loss)
I0514 13:34:59.677467 12912 sgd_solver.cpp:106] Iteration 9200, lr = 0.0005
I0514 13:35:37.703289 12912 solver.cpp:228] Iteration 9250, loss = 0.928773
I0514 13:35:37.703451 12912 solver.cpp:244]     Train net output #0: loss = 0.928772 (* 1 = 0.928772 loss)
I0514 13:35:37.703470 12912 sgd_solver.cpp:106] Iteration 9250, lr = 0.0005
I0514 13:36:15.712543 12912 solver.cpp:228] Iteration 9300, loss = 1.03613
I0514 13:36:15.712669 12912 solver.cpp:244]     Train net output #0: loss = 1.03613 (* 1 = 1.03613 loss)
I0514 13:36:15.712682 12912 sgd_solver.cpp:106] Iteration 9300, lr = 0.0005
I0514 13:36:53.720499 12912 solver.cpp:228] Iteration 9350, loss = 0.487973
I0514 13:36:53.720695 12912 solver.cpp:244]     Train net output #0: loss = 0.487973 (* 1 = 0.487973 loss)
I0514 13:36:53.720712 12912 sgd_solver.cpp:106] Iteration 9350, lr = 0.0005
I0514 13:37:31.745405 12912 solver.cpp:228] Iteration 9400, loss = 0.481594
I0514 13:37:31.745543 12912 solver.cpp:244]     Train net output #0: loss = 0.481593 (* 1 = 0.481593 loss)
I0514 13:37:31.745556 12912 sgd_solver.cpp:106] Iteration 9400, lr = 0.0005
I0514 13:38:09.748906 12912 solver.cpp:228] Iteration 9450, loss = 0.696556
I0514 13:38:09.749006 12912 solver.cpp:244]     Train net output #0: loss = 0.696556 (* 1 = 0.696556 loss)
I0514 13:38:09.749023 12912 sgd_solver.cpp:106] Iteration 9450, lr = 0.0005
I0514 13:38:47.745744 12912 solver.cpp:228] Iteration 9500, loss = 0.603477
I0514 13:38:47.745879 12912 solver.cpp:244]     Train net output #0: loss = 0.603477 (* 1 = 0.603477 loss)
I0514 13:38:47.745893 12912 sgd_solver.cpp:106] Iteration 9500, lr = 0.0005
I0514 13:39:25.753445 12912 solver.cpp:228] Iteration 9550, loss = 1.2565
I0514 13:39:25.753629 12912 solver.cpp:244]     Train net output #0: loss = 1.25649 (* 1 = 1.25649 loss)
I0514 13:39:25.753648 12912 sgd_solver.cpp:106] Iteration 9550, lr = 0.0005
I0514 13:40:03.786804 12912 solver.cpp:228] Iteration 9600, loss = 0.536786
I0514 13:40:03.786969 12912 solver.cpp:244]     Train net output #0: loss = 0.536785 (* 1 = 0.536785 loss)
I0514 13:40:03.786990 12912 sgd_solver.cpp:106] Iteration 9600, lr = 0.0005
I0514 13:40:41.808254 12912 solver.cpp:228] Iteration 9650, loss = 0.671107
I0514 13:40:41.808411 12912 solver.cpp:244]     Train net output #0: loss = 0.671106 (* 1 = 0.671106 loss)
I0514 13:40:41.808459 12912 sgd_solver.cpp:106] Iteration 9650, lr = 0.0005
I0514 13:41:19.834542 12912 solver.cpp:228] Iteration 9700, loss = 0.867436
I0514 13:41:19.834698 12912 solver.cpp:244]     Train net output #0: loss = 0.867435 (* 1 = 0.867435 loss)
I0514 13:41:19.834714 12912 sgd_solver.cpp:106] Iteration 9700, lr = 0.0005
I0514 13:41:57.904333 12912 solver.cpp:228] Iteration 9750, loss = 0.543631
I0514 13:41:57.904474 12912 solver.cpp:244]     Train net output #0: loss = 0.543631 (* 1 = 0.543631 loss)
I0514 13:41:57.904491 12912 sgd_solver.cpp:106] Iteration 9750, lr = 0.0005
I0514 13:42:35.878550 12912 solver.cpp:228] Iteration 9800, loss = 0.845699
I0514 13:42:35.878734 12912 solver.cpp:244]     Train net output #0: loss = 0.845698 (* 1 = 0.845698 loss)
I0514 13:42:35.878773 12912 sgd_solver.cpp:106] Iteration 9800, lr = 0.0005
I0514 13:43:13.848074 12912 solver.cpp:228] Iteration 9850, loss = 0.820903
I0514 13:43:13.848208 12912 solver.cpp:244]     Train net output #0: loss = 0.820903 (* 1 = 0.820903 loss)
I0514 13:43:13.848225 12912 sgd_solver.cpp:106] Iteration 9850, lr = 0.0005
I0514 13:43:51.823860 12912 solver.cpp:228] Iteration 9900, loss = 0.780929
I0514 13:43:51.823956 12912 solver.cpp:244]     Train net output #0: loss = 0.780928 (* 1 = 0.780928 loss)
I0514 13:43:51.823973 12912 sgd_solver.cpp:106] Iteration 9900, lr = 0.0005
I0514 13:44:29.806063 12912 solver.cpp:228] Iteration 9950, loss = 0.78364
I0514 13:44:29.806249 12912 solver.cpp:244]     Train net output #0: loss = 0.783639 (* 1 = 0.783639 loss)
I0514 13:44:29.806289 12912 sgd_solver.cpp:106] Iteration 9950, lr = 0.0005
I0514 13:45:07.536427 12912 solver.cpp:454] Snapshotting to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_10000.caffemodel
I0514 13:45:08.258013 12912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_10000.solverstate
I0514 13:45:08.397892 12912 solver.cpp:337] Iteration 10000, Testing net (#0)
I0514 13:45:08.397972 12912 net.cpp:685] Ignoring source layer loss
I0514 13:46:52.470677 12912 solver.cpp:404]     Test net output #0: accuracy = 0.445147
I0514 13:46:52.761754 12912 solver.cpp:228] Iteration 10000, loss = 0.661882
I0514 13:46:52.761885 12912 solver.cpp:244]     Train net output #0: loss = 0.661881 (* 1 = 0.661881 loss)
I0514 13:46:52.761921 12912 sgd_solver.cpp:106] Iteration 10000, lr = 0.0005
I0514 13:47:30.797513 12912 solver.cpp:228] Iteration 10050, loss = 1.22672
I0514 13:47:30.797715 12912 solver.cpp:244]     Train net output #0: loss = 1.22672 (* 1 = 1.22672 loss)
I0514 13:47:30.797776 12912 sgd_solver.cpp:106] Iteration 10050, lr = 0.0005
I0514 13:48:08.819253 12912 solver.cpp:228] Iteration 10100, loss = 0.779678
I0514 13:48:08.819489 12912 solver.cpp:244]     Train net output #0: loss = 0.779677 (* 1 = 0.779677 loss)
I0514 13:48:08.819530 12912 sgd_solver.cpp:106] Iteration 10100, lr = 0.0005
I0514 13:48:46.896433 12912 solver.cpp:228] Iteration 10150, loss = 0.476926
I0514 13:48:46.896625 12912 solver.cpp:244]     Train net output #0: loss = 0.476925 (* 1 = 0.476925 loss)
I0514 13:48:46.896646 12912 sgd_solver.cpp:106] Iteration 10150, lr = 0.0005
I0514 13:49:24.923270 12912 solver.cpp:228] Iteration 10200, loss = 0.507717
I0514 13:49:24.923436 12912 solver.cpp:244]     Train net output #0: loss = 0.507716 (* 1 = 0.507716 loss)
I0514 13:49:24.923454 12912 sgd_solver.cpp:106] Iteration 10200, lr = 0.0005
I0514 13:50:02.951349 12912 solver.cpp:228] Iteration 10250, loss = 0.431259
I0514 13:50:02.951485 12912 solver.cpp:244]     Train net output #0: loss = 0.431258 (* 1 = 0.431258 loss)
I0514 13:50:02.951503 12912 sgd_solver.cpp:106] Iteration 10250, lr = 0.0005
I0514 13:50:40.984632 12912 solver.cpp:228] Iteration 10300, loss = 0.680587
I0514 13:50:40.984742 12912 solver.cpp:244]     Train net output #0: loss = 0.680586 (* 1 = 0.680586 loss)
I0514 13:50:40.984755 12912 sgd_solver.cpp:106] Iteration 10300, lr = 0.0005
I0514 13:51:19.014598 12912 solver.cpp:228] Iteration 10350, loss = 0.920542
I0514 13:51:19.014703 12912 solver.cpp:244]     Train net output #0: loss = 0.920541 (* 1 = 0.920541 loss)
I0514 13:51:19.014715 12912 sgd_solver.cpp:106] Iteration 10350, lr = 0.0005
I0514 13:51:57.028375 12912 solver.cpp:228] Iteration 10400, loss = 1.16074
I0514 13:51:57.028491 12912 solver.cpp:244]     Train net output #0: loss = 1.16074 (* 1 = 1.16074 loss)
I0514 13:51:57.028507 12912 sgd_solver.cpp:106] Iteration 10400, lr = 0.0005
I0514 13:52:35.051933 12912 solver.cpp:228] Iteration 10450, loss = 0.891322
I0514 13:52:35.052049 12912 solver.cpp:244]     Train net output #0: loss = 0.891321 (* 1 = 0.891321 loss)
I0514 13:52:35.052064 12912 sgd_solver.cpp:106] Iteration 10450, lr = 0.0005
I0514 13:53:13.072484 12912 solver.cpp:228] Iteration 10500, loss = 0.710217
I0514 13:53:13.072695 12912 solver.cpp:244]     Train net output #0: loss = 0.710216 (* 1 = 0.710216 loss)
I0514 13:53:13.072723 12912 sgd_solver.cpp:106] Iteration 10500, lr = 0.0005
I0514 13:53:51.092051 12912 solver.cpp:228] Iteration 10550, loss = 0.789004
I0514 13:53:51.092294 12912 solver.cpp:244]     Train net output #0: loss = 0.789004 (* 1 = 0.789004 loss)
I0514 13:53:51.092311 12912 sgd_solver.cpp:106] Iteration 10550, lr = 0.0005
I0514 13:54:29.129849 12912 solver.cpp:228] Iteration 10600, loss = 0.900932
I0514 13:54:29.129940 12912 solver.cpp:244]     Train net output #0: loss = 0.900931 (* 1 = 0.900931 loss)
I0514 13:54:29.129952 12912 sgd_solver.cpp:106] Iteration 10600, lr = 0.0005
I0514 13:55:07.169368 12912 solver.cpp:228] Iteration 10650, loss = 0.698303
I0514 13:55:07.169482 12912 solver.cpp:244]     Train net output #0: loss = 0.698302 (* 1 = 0.698302 loss)
I0514 13:55:07.169495 12912 sgd_solver.cpp:106] Iteration 10650, lr = 0.0005
I0514 13:55:45.181027 12912 solver.cpp:228] Iteration 10700, loss = 0.859511
I0514 13:55:45.181216 12912 solver.cpp:244]     Train net output #0: loss = 0.859511 (* 1 = 0.859511 loss)
I0514 13:55:45.181255 12912 sgd_solver.cpp:106] Iteration 10700, lr = 0.0005
I0514 13:56:23.225679 12912 solver.cpp:228] Iteration 10750, loss = 0.376879
I0514 13:56:23.225826 12912 solver.cpp:244]     Train net output #0: loss = 0.376879 (* 1 = 0.376879 loss)
I0514 13:56:23.225842 12912 sgd_solver.cpp:106] Iteration 10750, lr = 0.0005
I0514 13:57:01.269333 12912 solver.cpp:228] Iteration 10800, loss = 1.06753
I0514 13:57:01.269438 12912 solver.cpp:244]     Train net output #0: loss = 1.06753 (* 1 = 1.06753 loss)
I0514 13:57:01.269450 12912 sgd_solver.cpp:106] Iteration 10800, lr = 0.0005
I0514 13:57:39.320021 12912 solver.cpp:228] Iteration 10850, loss = 0.709538
I0514 13:57:39.320133 12912 solver.cpp:244]     Train net output #0: loss = 0.709537 (* 1 = 0.709537 loss)
I0514 13:57:39.320147 12912 sgd_solver.cpp:106] Iteration 10850, lr = 0.0005
I0514 13:58:17.344930 12912 solver.cpp:228] Iteration 10900, loss = 0.67553
I0514 13:58:17.345043 12912 solver.cpp:244]     Train net output #0: loss = 0.67553 (* 1 = 0.67553 loss)
I0514 13:58:17.345062 12912 sgd_solver.cpp:106] Iteration 10900, lr = 0.0005
I0514 13:58:55.362282 12912 solver.cpp:228] Iteration 10950, loss = 0.654248
I0514 13:58:55.362426 12912 solver.cpp:244]     Train net output #0: loss = 0.654248 (* 1 = 0.654248 loss)
I0514 13:58:55.362438 12912 sgd_solver.cpp:106] Iteration 10950, lr = 0.0005
I0514 13:59:33.081223 12912 solver.cpp:454] Snapshotting to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_11000.caffemodel
I0514 13:59:33.932605 12912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_11000.solverstate
I0514 13:59:34.015010 12912 solver.cpp:337] Iteration 11000, Testing net (#0)
I0514 13:59:34.015071 12912 net.cpp:685] Ignoring source layer loss
I0514 14:01:17.825534 12912 solver.cpp:404]     Test net output #0: accuracy = 0.499853
I0514 14:01:18.115870 12912 solver.cpp:228] Iteration 11000, loss = 0.82744
I0514 14:01:18.115914 12912 solver.cpp:244]     Train net output #0: loss = 0.82744 (* 1 = 0.82744 loss)
I0514 14:01:18.115928 12912 sgd_solver.cpp:106] Iteration 11000, lr = 0.0005
I0514 14:01:56.074383 12912 solver.cpp:228] Iteration 11050, loss = 0.283957
I0514 14:01:56.074506 12912 solver.cpp:244]     Train net output #0: loss = 0.283957 (* 1 = 0.283957 loss)
I0514 14:01:56.074524 12912 sgd_solver.cpp:106] Iteration 11050, lr = 0.0005
I0514 14:02:34.038619 12912 solver.cpp:228] Iteration 11100, loss = 0.34529
I0514 14:02:34.038733 12912 solver.cpp:244]     Train net output #0: loss = 0.34529 (* 1 = 0.34529 loss)
I0514 14:02:34.038744 12912 sgd_solver.cpp:106] Iteration 11100, lr = 0.0005
I0514 14:03:12.019335 12912 solver.cpp:228] Iteration 11150, loss = 0.659676
I0514 14:03:12.019461 12912 solver.cpp:244]     Train net output #0: loss = 0.659676 (* 1 = 0.659676 loss)
I0514 14:03:12.019472 12912 sgd_solver.cpp:106] Iteration 11150, lr = 0.0005
I0514 14:03:50.048470 12912 solver.cpp:228] Iteration 11200, loss = 0.526143
I0514 14:03:50.048622 12912 solver.cpp:244]     Train net output #0: loss = 0.526143 (* 1 = 0.526143 loss)
I0514 14:03:50.048640 12912 sgd_solver.cpp:106] Iteration 11200, lr = 0.0005
I0514 14:04:28.074321 12912 solver.cpp:228] Iteration 11250, loss = 0.40028
I0514 14:04:28.074514 12912 solver.cpp:244]     Train net output #0: loss = 0.400279 (* 1 = 0.400279 loss)
I0514 14:04:28.074556 12912 sgd_solver.cpp:106] Iteration 11250, lr = 0.0005
I0514 14:05:06.087429 12912 solver.cpp:228] Iteration 11300, loss = 0.708731
I0514 14:05:06.087537 12912 solver.cpp:244]     Train net output #0: loss = 0.70873 (* 1 = 0.70873 loss)
I0514 14:05:06.087556 12912 sgd_solver.cpp:106] Iteration 11300, lr = 0.0005
I0514 14:05:44.116881 12912 solver.cpp:228] Iteration 11350, loss = 0.603114
I0514 14:05:44.117002 12912 solver.cpp:244]     Train net output #0: loss = 0.603113 (* 1 = 0.603113 loss)
I0514 14:05:44.117020 12912 sgd_solver.cpp:106] Iteration 11350, lr = 0.0005
I0514 14:06:22.141948 12912 solver.cpp:228] Iteration 11400, loss = 0.436967
I0514 14:06:22.142071 12912 solver.cpp:244]     Train net output #0: loss = 0.436967 (* 1 = 0.436967 loss)
I0514 14:06:22.142083 12912 sgd_solver.cpp:106] Iteration 11400, lr = 0.0005
I0514 14:07:00.146920 12912 solver.cpp:228] Iteration 11450, loss = 0.354023
I0514 14:07:00.147045 12912 solver.cpp:244]     Train net output #0: loss = 0.354023 (* 1 = 0.354023 loss)
I0514 14:07:00.147059 12912 sgd_solver.cpp:106] Iteration 11450, lr = 0.0005
I0514 14:07:38.169111 12912 solver.cpp:228] Iteration 11500, loss = 0.870076
I0514 14:07:38.169266 12912 solver.cpp:244]     Train net output #0: loss = 0.870076 (* 1 = 0.870076 loss)
I0514 14:07:38.169284 12912 sgd_solver.cpp:106] Iteration 11500, lr = 0.0005
I0514 14:08:16.190296 12912 solver.cpp:228] Iteration 11550, loss = 0.520812
I0514 14:08:16.190474 12912 solver.cpp:244]     Train net output #0: loss = 0.520812 (* 1 = 0.520812 loss)
I0514 14:08:16.190511 12912 sgd_solver.cpp:106] Iteration 11550, lr = 0.0005
I0514 14:08:54.190553 12912 solver.cpp:228] Iteration 11600, loss = 0.744634
I0514 14:08:54.190657 12912 solver.cpp:244]     Train net output #0: loss = 0.744634 (* 1 = 0.744634 loss)
I0514 14:08:54.190671 12912 sgd_solver.cpp:106] Iteration 11600, lr = 0.0005
I0514 14:09:32.205878 12912 solver.cpp:228] Iteration 11650, loss = 0.70626
I0514 14:09:32.205976 12912 solver.cpp:244]     Train net output #0: loss = 0.70626 (* 1 = 0.70626 loss)
I0514 14:09:32.205994 12912 sgd_solver.cpp:106] Iteration 11650, lr = 0.0005
I0514 14:10:10.217923 12912 solver.cpp:228] Iteration 11700, loss = 0.832408
I0514 14:10:10.218071 12912 solver.cpp:244]     Train net output #0: loss = 0.832408 (* 1 = 0.832408 loss)
I0514 14:10:10.218089 12912 sgd_solver.cpp:106] Iteration 11700, lr = 0.0005
I0514 14:10:48.268049 12912 solver.cpp:228] Iteration 11750, loss = 0.482295
I0514 14:10:48.268213 12912 solver.cpp:244]     Train net output #0: loss = 0.482295 (* 1 = 0.482295 loss)
I0514 14:10:48.268229 12912 sgd_solver.cpp:106] Iteration 11750, lr = 0.0005
I0514 14:11:26.291033 12912 solver.cpp:228] Iteration 11800, loss = 0.681497
I0514 14:11:26.291229 12912 solver.cpp:244]     Train net output #0: loss = 0.681496 (* 1 = 0.681496 loss)
I0514 14:11:26.291266 12912 sgd_solver.cpp:106] Iteration 11800, lr = 0.0005
I0514 14:12:04.320072 12912 solver.cpp:228] Iteration 11850, loss = 0.493799
I0514 14:12:04.320193 12912 solver.cpp:244]     Train net output #0: loss = 0.493798 (* 1 = 0.493798 loss)
I0514 14:12:04.320209 12912 sgd_solver.cpp:106] Iteration 11850, lr = 0.0005
I0514 14:12:42.344729 12912 solver.cpp:228] Iteration 11900, loss = 0.400488
I0514 14:12:42.344889 12912 solver.cpp:244]     Train net output #0: loss = 0.400487 (* 1 = 0.400487 loss)
I0514 14:12:42.344908 12912 sgd_solver.cpp:106] Iteration 11900, lr = 0.0005
I0514 14:13:20.379242 12912 solver.cpp:228] Iteration 11950, loss = 0.562604
I0514 14:13:20.379384 12912 solver.cpp:244]     Train net output #0: loss = 0.562604 (* 1 = 0.562604 loss)
I0514 14:13:20.379397 12912 sgd_solver.cpp:106] Iteration 11950, lr = 0.0005
I0514 14:13:58.116667 12912 solver.cpp:454] Snapshotting to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_12000.caffemodel
I0514 14:13:58.572262 12912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_12000.solverstate
I0514 14:13:58.656103 12912 solver.cpp:337] Iteration 12000, Testing net (#0)
I0514 14:13:58.656154 12912 net.cpp:685] Ignoring source layer loss
I0514 14:15:42.873090 12912 solver.cpp:404]     Test net output #0: accuracy = 0.5925
I0514 14:15:43.163697 12912 solver.cpp:228] Iteration 12000, loss = 0.567588
I0514 14:15:43.163879 12912 solver.cpp:244]     Train net output #0: loss = 0.567588 (* 1 = 0.567588 loss)
I0514 14:15:43.163918 12912 sgd_solver.cpp:106] Iteration 12000, lr = 0.0005
I0514 14:16:21.205644 12912 solver.cpp:228] Iteration 12050, loss = 0.445667
I0514 14:16:21.205812 12912 solver.cpp:244]     Train net output #0: loss = 0.445666 (* 1 = 0.445666 loss)
I0514 14:16:21.205853 12912 sgd_solver.cpp:106] Iteration 12050, lr = 0.0005
I0514 14:16:59.244535 12912 solver.cpp:228] Iteration 12100, loss = 0.763628
I0514 14:16:59.244707 12912 solver.cpp:244]     Train net output #0: loss = 0.763628 (* 1 = 0.763628 loss)
I0514 14:16:59.244745 12912 sgd_solver.cpp:106] Iteration 12100, lr = 0.0005
I0514 14:17:37.289573 12912 solver.cpp:228] Iteration 12150, loss = 0.635392
I0514 14:17:37.289775 12912 solver.cpp:244]     Train net output #0: loss = 0.635392 (* 1 = 0.635392 loss)
I0514 14:17:37.289813 12912 sgd_solver.cpp:106] Iteration 12150, lr = 0.0005
I0514 14:18:15.337893 12912 solver.cpp:228] Iteration 12200, loss = 0.407027
I0514 14:18:15.338004 12912 solver.cpp:244]     Train net output #0: loss = 0.407027 (* 1 = 0.407027 loss)
I0514 14:18:15.338022 12912 sgd_solver.cpp:106] Iteration 12200, lr = 0.0005
I0514 14:18:53.366488 12912 solver.cpp:228] Iteration 12250, loss = 0.729336
I0514 14:18:53.366614 12912 solver.cpp:244]     Train net output #0: loss = 0.729336 (* 1 = 0.729336 loss)
I0514 14:18:53.366631 12912 sgd_solver.cpp:106] Iteration 12250, lr = 0.0005
I0514 14:19:31.403450 12912 solver.cpp:228] Iteration 12300, loss = 0.400541
I0514 14:19:31.403583 12912 solver.cpp:244]     Train net output #0: loss = 0.400541 (* 1 = 0.400541 loss)
I0514 14:19:31.403599 12912 sgd_solver.cpp:106] Iteration 12300, lr = 0.0005
I0514 14:20:09.419183 12912 solver.cpp:228] Iteration 12350, loss = 0.428239
I0514 14:20:09.419293 12912 solver.cpp:244]     Train net output #0: loss = 0.428239 (* 1 = 0.428239 loss)
I0514 14:20:09.419312 12912 sgd_solver.cpp:106] Iteration 12350, lr = 0.0005
I0514 14:20:47.388995 12912 solver.cpp:228] Iteration 12400, loss = 0.558336
I0514 14:20:47.389158 12912 solver.cpp:244]     Train net output #0: loss = 0.558336 (* 1 = 0.558336 loss)
I0514 14:20:47.389179 12912 sgd_solver.cpp:106] Iteration 12400, lr = 0.0005
I0514 14:21:25.359843 12912 solver.cpp:228] Iteration 12450, loss = 0.522022
I0514 14:21:25.359948 12912 solver.cpp:244]     Train net output #0: loss = 0.522022 (* 1 = 0.522022 loss)
I0514 14:21:25.359961 12912 sgd_solver.cpp:106] Iteration 12450, lr = 0.0005
I0514 14:22:03.327399 12912 solver.cpp:228] Iteration 12500, loss = 0.555975
I0514 14:22:03.327518 12912 solver.cpp:244]     Train net output #0: loss = 0.555975 (* 1 = 0.555975 loss)
I0514 14:22:03.327532 12912 sgd_solver.cpp:106] Iteration 12500, lr = 0.0005
I0514 14:22:41.361632 12912 solver.cpp:228] Iteration 12550, loss = 0.570075
I0514 14:22:41.361770 12912 solver.cpp:244]     Train net output #0: loss = 0.570075 (* 1 = 0.570075 loss)
I0514 14:22:41.361790 12912 sgd_solver.cpp:106] Iteration 12550, lr = 0.0005
I0514 14:23:19.376633 12912 solver.cpp:228] Iteration 12600, loss = 0.644883
I0514 14:23:19.376812 12912 solver.cpp:244]     Train net output #0: loss = 0.644882 (* 1 = 0.644882 loss)
I0514 14:23:19.376847 12912 sgd_solver.cpp:106] Iteration 12600, lr = 0.0005
I0514 14:23:57.416191 12912 solver.cpp:228] Iteration 12650, loss = 0.329731
I0514 14:23:57.416292 12912 solver.cpp:244]     Train net output #0: loss = 0.329731 (* 1 = 0.329731 loss)
I0514 14:23:57.416304 12912 sgd_solver.cpp:106] Iteration 12650, lr = 0.0005
I0514 14:24:35.437649 12912 solver.cpp:228] Iteration 12700, loss = 0.532717
I0514 14:24:35.437785 12912 solver.cpp:244]     Train net output #0: loss = 0.532716 (* 1 = 0.532716 loss)
I0514 14:24:35.437834 12912 sgd_solver.cpp:106] Iteration 12700, lr = 0.0005
I0514 14:25:13.460639 12912 solver.cpp:228] Iteration 12750, loss = 0.385672
I0514 14:25:13.460743 12912 solver.cpp:244]     Train net output #0: loss = 0.385672 (* 1 = 0.385672 loss)
I0514 14:25:13.460762 12912 sgd_solver.cpp:106] Iteration 12750, lr = 0.0005
I0514 14:25:51.495931 12912 solver.cpp:228] Iteration 12800, loss = 0.613128
I0514 14:25:51.496103 12912 solver.cpp:244]     Train net output #0: loss = 0.613128 (* 1 = 0.613128 loss)
I0514 14:25:51.496143 12912 sgd_solver.cpp:106] Iteration 12800, lr = 0.0005
I0514 14:26:29.517813 12912 solver.cpp:228] Iteration 12850, loss = 0.376485
I0514 14:26:29.517982 12912 solver.cpp:244]     Train net output #0: loss = 0.376484 (* 1 = 0.376484 loss)
I0514 14:26:29.518019 12912 sgd_solver.cpp:106] Iteration 12850, lr = 0.0005
I0514 14:27:07.534741 12912 solver.cpp:228] Iteration 12900, loss = 0.22024
I0514 14:27:07.534870 12912 solver.cpp:244]     Train net output #0: loss = 0.22024 (* 1 = 0.22024 loss)
I0514 14:27:07.534889 12912 sgd_solver.cpp:106] Iteration 12900, lr = 0.0005
I0514 14:27:45.556538 12912 solver.cpp:228] Iteration 12950, loss = 0.438008
I0514 14:27:45.556747 12912 solver.cpp:244]     Train net output #0: loss = 0.438007 (* 1 = 0.438007 loss)
I0514 14:27:45.556768 12912 sgd_solver.cpp:106] Iteration 12950, lr = 0.0005
I0514 14:28:23.280951 12912 solver.cpp:454] Snapshotting to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_13000.caffemodel
I0514 14:28:24.115389 12912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_13000.solverstate
I0514 14:28:24.260854 12912 solver.cpp:337] Iteration 13000, Testing net (#0)
I0514 14:28:24.260922 12912 net.cpp:685] Ignoring source layer loss
I0514 14:30:08.320204 12912 solver.cpp:404]     Test net output #0: accuracy = 0.493235
I0514 14:30:08.610502 12912 solver.cpp:228] Iteration 13000, loss = 0.270702
I0514 14:30:08.610554 12912 solver.cpp:244]     Train net output #0: loss = 0.270702 (* 1 = 0.270702 loss)
I0514 14:30:08.610569 12912 sgd_solver.cpp:106] Iteration 13000, lr = 0.0005
I0514 14:30:46.619251 12912 solver.cpp:228] Iteration 13050, loss = 0.333767
I0514 14:30:46.619400 12912 solver.cpp:244]     Train net output #0: loss = 0.333767 (* 1 = 0.333767 loss)
I0514 14:30:46.619417 12912 sgd_solver.cpp:106] Iteration 13050, lr = 0.0005
I0514 14:31:24.657486 12912 solver.cpp:228] Iteration 13100, loss = 0.548188
I0514 14:31:24.657649 12912 solver.cpp:244]     Train net output #0: loss = 0.548187 (* 1 = 0.548187 loss)
I0514 14:31:24.657662 12912 sgd_solver.cpp:106] Iteration 13100, lr = 0.0005
I0514 14:32:02.688885 12912 solver.cpp:228] Iteration 13150, loss = 0.186088
I0514 14:32:02.689003 12912 solver.cpp:244]     Train net output #0: loss = 0.186088 (* 1 = 0.186088 loss)
I0514 14:32:02.689015 12912 sgd_solver.cpp:106] Iteration 13150, lr = 0.0005
I0514 14:32:40.729701 12912 solver.cpp:228] Iteration 13200, loss = 0.457136
I0514 14:32:40.729904 12912 solver.cpp:244]     Train net output #0: loss = 0.457136 (* 1 = 0.457136 loss)
I0514 14:32:40.729925 12912 sgd_solver.cpp:106] Iteration 13200, lr = 0.0005
I0514 14:33:18.763425 12912 solver.cpp:228] Iteration 13250, loss = 0.417816
I0514 14:33:18.763550 12912 solver.cpp:244]     Train net output #0: loss = 0.417816 (* 1 = 0.417816 loss)
I0514 14:33:18.763567 12912 sgd_solver.cpp:106] Iteration 13250, lr = 0.0005
I0514 14:33:56.779459 12912 solver.cpp:228] Iteration 13300, loss = 0.940956
I0514 14:33:56.779633 12912 solver.cpp:244]     Train net output #0: loss = 0.940956 (* 1 = 0.940956 loss)
I0514 14:33:56.779671 12912 sgd_solver.cpp:106] Iteration 13300, lr = 0.0005
I0514 14:34:34.804904 12912 solver.cpp:228] Iteration 13350, loss = 0.389039
I0514 14:34:34.805053 12912 solver.cpp:244]     Train net output #0: loss = 0.389039 (* 1 = 0.389039 loss)
I0514 14:34:34.805070 12912 sgd_solver.cpp:106] Iteration 13350, lr = 0.0005
I0514 14:35:12.842607 12912 solver.cpp:228] Iteration 13400, loss = 0.581364
I0514 14:35:12.843495 12912 solver.cpp:244]     Train net output #0: loss = 0.581364 (* 1 = 0.581364 loss)
I0514 14:35:12.843521 12912 sgd_solver.cpp:106] Iteration 13400, lr = 0.0005
I0514 14:35:50.869549 12912 solver.cpp:228] Iteration 13450, loss = 0.234288
I0514 14:35:50.869738 12912 solver.cpp:244]     Train net output #0: loss = 0.234288 (* 1 = 0.234288 loss)
I0514 14:35:50.869781 12912 sgd_solver.cpp:106] Iteration 13450, lr = 0.0005
I0514 14:36:28.884354 12912 solver.cpp:228] Iteration 13500, loss = 0.519341
I0514 14:36:28.884474 12912 solver.cpp:244]     Train net output #0: loss = 0.519341 (* 1 = 0.519341 loss)
I0514 14:36:28.884490 12912 sgd_solver.cpp:106] Iteration 13500, lr = 0.0005
I0514 14:37:06.917215 12912 solver.cpp:228] Iteration 13550, loss = 0.0772793
I0514 14:37:06.917398 12912 solver.cpp:244]     Train net output #0: loss = 0.077279 (* 1 = 0.077279 loss)
I0514 14:37:06.917443 12912 sgd_solver.cpp:106] Iteration 13550, lr = 0.0005
I0514 14:37:44.956720 12912 solver.cpp:228] Iteration 13600, loss = 0.319266
I0514 14:37:44.957005 12912 solver.cpp:244]     Train net output #0: loss = 0.319266 (* 1 = 0.319266 loss)
I0514 14:37:44.957047 12912 sgd_solver.cpp:106] Iteration 13600, lr = 0.0005
I0514 14:38:22.991823 12912 solver.cpp:228] Iteration 13650, loss = 0.198208
I0514 14:38:22.991996 12912 solver.cpp:244]     Train net output #0: loss = 0.198208 (* 1 = 0.198208 loss)
I0514 14:38:22.992013 12912 sgd_solver.cpp:106] Iteration 13650, lr = 0.0005
I0514 14:39:00.984565 12912 solver.cpp:228] Iteration 13700, loss = 0.264462
I0514 14:39:00.984792 12912 solver.cpp:244]     Train net output #0: loss = 0.264462 (* 1 = 0.264462 loss)
I0514 14:39:00.984853 12912 sgd_solver.cpp:106] Iteration 13700, lr = 0.0005
I0514 14:39:38.944203 12912 solver.cpp:228] Iteration 13750, loss = 0.249418
I0514 14:39:38.944353 12912 solver.cpp:244]     Train net output #0: loss = 0.249417 (* 1 = 0.249417 loss)
I0514 14:39:38.944397 12912 sgd_solver.cpp:106] Iteration 13750, lr = 0.0005
I0514 14:40:16.902365 12912 solver.cpp:228] Iteration 13800, loss = 0.239142
I0514 14:40:16.902478 12912 solver.cpp:244]     Train net output #0: loss = 0.239142 (* 1 = 0.239142 loss)
I0514 14:40:16.902493 12912 sgd_solver.cpp:106] Iteration 13800, lr = 0.0005
I0514 14:40:54.863544 12912 solver.cpp:228] Iteration 13850, loss = 0.436765
I0514 14:40:54.863674 12912 solver.cpp:244]     Train net output #0: loss = 0.436765 (* 1 = 0.436765 loss)
I0514 14:40:54.863692 12912 sgd_solver.cpp:106] Iteration 13850, lr = 0.0005
I0514 14:41:32.877944 12912 solver.cpp:228] Iteration 13900, loss = 0.513551
I0514 14:41:32.878082 12912 solver.cpp:244]     Train net output #0: loss = 0.513551 (* 1 = 0.513551 loss)
I0514 14:41:32.878100 12912 sgd_solver.cpp:106] Iteration 13900, lr = 0.0005
I0514 14:42:10.899595 12912 solver.cpp:228] Iteration 13950, loss = 0.27019
I0514 14:42:10.899739 12912 solver.cpp:244]     Train net output #0: loss = 0.27019 (* 1 = 0.27019 loss)
I0514 14:42:10.899756 12912 sgd_solver.cpp:106] Iteration 13950, lr = 0.0005
I0514 14:42:48.619993 12912 solver.cpp:454] Snapshotting to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_14000.caffemodel
I0514 14:42:49.414620 12912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_14000.solverstate
I0514 14:42:49.557656 12912 solver.cpp:337] Iteration 14000, Testing net (#0)
I0514 14:42:49.557734 12912 net.cpp:685] Ignoring source layer loss
I0514 14:44:33.276973 12912 solver.cpp:404]     Test net output #0: accuracy = 0.499559
I0514 14:44:33.567111 12912 solver.cpp:228] Iteration 14000, loss = 0.434473
I0514 14:44:33.567173 12912 solver.cpp:244]     Train net output #0: loss = 0.434473 (* 1 = 0.434473 loss)
I0514 14:44:33.567188 12912 sgd_solver.cpp:106] Iteration 14000, lr = 0.0005
I0514 14:45:11.584619 12912 solver.cpp:228] Iteration 14050, loss = 0.133767
I0514 14:45:11.584741 12912 solver.cpp:244]     Train net output #0: loss = 0.133767 (* 1 = 0.133767 loss)
I0514 14:45:11.584760 12912 sgd_solver.cpp:106] Iteration 14050, lr = 0.0005
I0514 14:45:49.596782 12912 solver.cpp:228] Iteration 14100, loss = 0.356907
I0514 14:45:49.596945 12912 solver.cpp:244]     Train net output #0: loss = 0.356906 (* 1 = 0.356906 loss)
I0514 14:45:49.596982 12912 sgd_solver.cpp:106] Iteration 14100, lr = 0.0005
I0514 14:46:27.622412 12912 solver.cpp:228] Iteration 14150, loss = 0.121152
I0514 14:46:27.622547 12912 solver.cpp:244]     Train net output #0: loss = 0.121152 (* 1 = 0.121152 loss)
I0514 14:46:27.622566 12912 sgd_solver.cpp:106] Iteration 14150, lr = 0.0005
I0514 14:47:05.633170 12912 solver.cpp:228] Iteration 14200, loss = 0.36048
I0514 14:47:05.633294 12912 solver.cpp:244]     Train net output #0: loss = 0.36048 (* 1 = 0.36048 loss)
I0514 14:47:05.633307 12912 sgd_solver.cpp:106] Iteration 14200, lr = 0.0005
I0514 14:47:43.694991 12912 solver.cpp:228] Iteration 14250, loss = 0.285502
I0514 14:47:43.695168 12912 solver.cpp:244]     Train net output #0: loss = 0.285502 (* 1 = 0.285502 loss)
I0514 14:47:43.695207 12912 sgd_solver.cpp:106] Iteration 14250, lr = 0.0005
I0514 14:48:21.751272 12912 solver.cpp:228] Iteration 14300, loss = 0.317348
I0514 14:48:21.751425 12912 solver.cpp:244]     Train net output #0: loss = 0.317348 (* 1 = 0.317348 loss)
I0514 14:48:21.751438 12912 sgd_solver.cpp:106] Iteration 14300, lr = 0.0005
I0514 14:48:59.777365 12912 solver.cpp:228] Iteration 14350, loss = 0.346902
I0514 14:48:59.777483 12912 solver.cpp:244]     Train net output #0: loss = 0.346902 (* 1 = 0.346902 loss)
I0514 14:48:59.777498 12912 sgd_solver.cpp:106] Iteration 14350, lr = 0.0005
I0514 14:49:37.802172 12912 solver.cpp:228] Iteration 14400, loss = 0.252569
I0514 14:49:37.802278 12912 solver.cpp:244]     Train net output #0: loss = 0.252569 (* 1 = 0.252569 loss)
I0514 14:49:37.802295 12912 sgd_solver.cpp:106] Iteration 14400, lr = 0.0005
I0514 14:50:15.822623 12912 solver.cpp:228] Iteration 14450, loss = 0.352772
I0514 14:50:15.822737 12912 solver.cpp:244]     Train net output #0: loss = 0.352772 (* 1 = 0.352772 loss)
I0514 14:50:15.822757 12912 sgd_solver.cpp:106] Iteration 14450, lr = 0.0005
I0514 14:50:53.829848 12912 solver.cpp:228] Iteration 14500, loss = 0.231276
I0514 14:50:53.830103 12912 solver.cpp:244]     Train net output #0: loss = 0.231276 (* 1 = 0.231276 loss)
I0514 14:50:53.830157 12912 sgd_solver.cpp:106] Iteration 14500, lr = 0.0005
I0514 14:51:31.857318 12912 solver.cpp:228] Iteration 14550, loss = 0.339861
I0514 14:51:31.857520 12912 solver.cpp:244]     Train net output #0: loss = 0.339861 (* 1 = 0.339861 loss)
I0514 14:51:31.857555 12912 sgd_solver.cpp:106] Iteration 14550, lr = 0.0005
I0514 14:52:09.868899 12912 solver.cpp:228] Iteration 14600, loss = 0.319257
I0514 14:52:09.869058 12912 solver.cpp:244]     Train net output #0: loss = 0.319257 (* 1 = 0.319257 loss)
I0514 14:52:09.869079 12912 sgd_solver.cpp:106] Iteration 14600, lr = 0.0005
I0514 14:52:47.896848 12912 solver.cpp:228] Iteration 14650, loss = 0.167359
I0514 14:52:47.896962 12912 solver.cpp:244]     Train net output #0: loss = 0.167359 (* 1 = 0.167359 loss)
I0514 14:52:47.896981 12912 sgd_solver.cpp:106] Iteration 14650, lr = 0.0005
I0514 14:53:25.924098 12912 solver.cpp:228] Iteration 14700, loss = 0.210846
I0514 14:53:25.924248 12912 solver.cpp:244]     Train net output #0: loss = 0.210846 (* 1 = 0.210846 loss)
I0514 14:53:25.924270 12912 sgd_solver.cpp:106] Iteration 14700, lr = 0.0005
I0514 14:54:03.968152 12912 solver.cpp:228] Iteration 14750, loss = 0.153654
I0514 14:54:03.968261 12912 solver.cpp:244]     Train net output #0: loss = 0.153654 (* 1 = 0.153654 loss)
I0514 14:54:03.968274 12912 sgd_solver.cpp:106] Iteration 14750, lr = 0.0005
I0514 14:54:41.955502 12912 solver.cpp:228] Iteration 14800, loss = 0.382245
I0514 14:54:41.955621 12912 solver.cpp:244]     Train net output #0: loss = 0.382245 (* 1 = 0.382245 loss)
I0514 14:54:41.955634 12912 sgd_solver.cpp:106] Iteration 14800, lr = 0.0005
I0514 14:55:19.977469 12912 solver.cpp:228] Iteration 14850, loss = 0.0718255
I0514 14:55:19.977596 12912 solver.cpp:244]     Train net output #0: loss = 0.0718255 (* 1 = 0.0718255 loss)
I0514 14:55:19.977614 12912 sgd_solver.cpp:106] Iteration 14850, lr = 0.0005
I0514 14:55:57.969867 12912 solver.cpp:228] Iteration 14900, loss = 0.37847
I0514 14:55:57.970052 12912 solver.cpp:244]     Train net output #0: loss = 0.37847 (* 1 = 0.37847 loss)
I0514 14:55:57.970074 12912 sgd_solver.cpp:106] Iteration 14900, lr = 0.0005
I0514 14:56:35.993791 12912 solver.cpp:228] Iteration 14950, loss = 0.239758
I0514 14:56:35.993985 12912 solver.cpp:244]     Train net output #0: loss = 0.239757 (* 1 = 0.239757 loss)
I0514 14:56:35.994045 12912 sgd_solver.cpp:106] Iteration 14950, lr = 0.0005
I0514 14:57:13.733935 12912 solver.cpp:454] Snapshotting to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_15000.caffemodel
I0514 14:57:13.929428 12912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_15000.solverstate
I0514 14:57:14.016806 12912 solver.cpp:337] Iteration 15000, Testing net (#0)
I0514 14:57:14.016862 12912 net.cpp:685] Ignoring source layer loss
I0514 14:58:56.962733 12912 solver.cpp:404]     Test net output #0: accuracy = 0.500441
I0514 14:58:57.252398 12912 solver.cpp:228] Iteration 15000, loss = 0.506822
I0514 14:58:57.252444 12912 solver.cpp:244]     Train net output #0: loss = 0.506821 (* 1 = 0.506821 loss)
I0514 14:58:57.252459 12912 sgd_solver.cpp:106] Iteration 15000, lr = 0.0005
I0514 14:59:35.204627 12912 solver.cpp:228] Iteration 15050, loss = 0.301864
I0514 14:59:35.204733 12912 solver.cpp:244]     Train net output #0: loss = 0.301864 (* 1 = 0.301864 loss)
I0514 14:59:35.204746 12912 sgd_solver.cpp:106] Iteration 15050, lr = 0.0005
I0514 15:00:13.247980 12912 solver.cpp:228] Iteration 15100, loss = 0.304707
I0514 15:00:13.248113 12912 solver.cpp:244]     Train net output #0: loss = 0.304707 (* 1 = 0.304707 loss)
I0514 15:00:13.248126 12912 sgd_solver.cpp:106] Iteration 15100, lr = 0.0005
I0514 15:00:51.313088 12912 solver.cpp:228] Iteration 15150, loss = 0.665516
I0514 15:00:51.313285 12912 solver.cpp:244]     Train net output #0: loss = 0.665516 (* 1 = 0.665516 loss)
I0514 15:00:51.313328 12912 sgd_solver.cpp:106] Iteration 15150, lr = 0.0005
I0514 15:01:29.364922 12912 solver.cpp:228] Iteration 15200, loss = 0.290099
I0514 15:01:29.365103 12912 solver.cpp:244]     Train net output #0: loss = 0.290099 (* 1 = 0.290099 loss)
I0514 15:01:29.365149 12912 sgd_solver.cpp:106] Iteration 15200, lr = 0.0005
I0514 15:02:07.387300 12912 solver.cpp:228] Iteration 15250, loss = 0.151061
I0514 15:02:07.387444 12912 solver.cpp:244]     Train net output #0: loss = 0.151061 (* 1 = 0.151061 loss)
I0514 15:02:07.387459 12912 sgd_solver.cpp:106] Iteration 15250, lr = 0.0005
I0514 15:02:45.416321 12912 solver.cpp:228] Iteration 15300, loss = 0.0969777
I0514 15:02:45.416466 12912 solver.cpp:244]     Train net output #0: loss = 0.0969777 (* 1 = 0.0969777 loss)
I0514 15:02:45.416484 12912 sgd_solver.cpp:106] Iteration 15300, lr = 0.0005
I0514 15:03:23.426443 12912 solver.cpp:228] Iteration 15350, loss = 0.382199
I0514 15:03:23.426553 12912 solver.cpp:244]     Train net output #0: loss = 0.382199 (* 1 = 0.382199 loss)
I0514 15:03:23.426570 12912 sgd_solver.cpp:106] Iteration 15350, lr = 0.0005
I0514 15:04:01.460883 12912 solver.cpp:228] Iteration 15400, loss = 0.352022
I0514 15:04:01.461042 12912 solver.cpp:244]     Train net output #0: loss = 0.352022 (* 1 = 0.352022 loss)
I0514 15:04:01.461061 12912 sgd_solver.cpp:106] Iteration 15400, lr = 0.0005
I0514 15:04:39.476960 12912 solver.cpp:228] Iteration 15450, loss = 0.252018
I0514 15:04:39.477143 12912 solver.cpp:244]     Train net output #0: loss = 0.252018 (* 1 = 0.252018 loss)
I0514 15:04:39.477161 12912 sgd_solver.cpp:106] Iteration 15450, lr = 0.0005
I0514 15:05:17.498962 12912 solver.cpp:228] Iteration 15500, loss = 0.267851
I0514 15:05:17.499068 12912 solver.cpp:244]     Train net output #0: loss = 0.267851 (* 1 = 0.267851 loss)
I0514 15:05:17.499080 12912 sgd_solver.cpp:106] Iteration 15500, lr = 0.0005
I0514 15:05:55.532646 12912 solver.cpp:228] Iteration 15550, loss = 0.156085
I0514 15:05:55.532755 12912 solver.cpp:244]     Train net output #0: loss = 0.156085 (* 1 = 0.156085 loss)
I0514 15:05:55.532773 12912 sgd_solver.cpp:106] Iteration 15550, lr = 0.0005
I0514 15:06:33.546566 12912 solver.cpp:228] Iteration 15600, loss = 0.0587751
I0514 15:06:33.546684 12912 solver.cpp:244]     Train net output #0: loss = 0.0587752 (* 1 = 0.0587752 loss)
I0514 15:06:33.546696 12912 sgd_solver.cpp:106] Iteration 15600, lr = 0.0005
I0514 15:07:11.567562 12912 solver.cpp:228] Iteration 15650, loss = 0.163583
I0514 15:07:11.567662 12912 solver.cpp:244]     Train net output #0: loss = 0.163583 (* 1 = 0.163583 loss)
I0514 15:07:11.567675 12912 sgd_solver.cpp:106] Iteration 15650, lr = 0.0005
I0514 15:07:49.609163 12912 solver.cpp:228] Iteration 15700, loss = 0.124569
I0514 15:07:49.609345 12912 solver.cpp:244]     Train net output #0: loss = 0.124569 (* 1 = 0.124569 loss)
I0514 15:07:49.609387 12912 sgd_solver.cpp:106] Iteration 15700, lr = 0.0005
I0514 15:08:27.655741 12912 solver.cpp:228] Iteration 15750, loss = 0.0857929
I0514 15:08:27.655882 12912 solver.cpp:244]     Train net output #0: loss = 0.085793 (* 1 = 0.085793 loss)
I0514 15:08:27.655900 12912 sgd_solver.cpp:106] Iteration 15750, lr = 0.0005
I0514 15:09:05.683234 12912 solver.cpp:228] Iteration 15800, loss = 0.288397
I0514 15:09:05.683384 12912 solver.cpp:244]     Train net output #0: loss = 0.288398 (* 1 = 0.288398 loss)
I0514 15:09:05.683398 12912 sgd_solver.cpp:106] Iteration 15800, lr = 0.0005
I0514 15:09:43.690798 12912 solver.cpp:228] Iteration 15850, loss = 0.227889
I0514 15:09:43.690932 12912 solver.cpp:244]     Train net output #0: loss = 0.22789 (* 1 = 0.22789 loss)
I0514 15:09:43.690953 12912 sgd_solver.cpp:106] Iteration 15850, lr = 0.0005
I0514 15:10:21.694222 12912 solver.cpp:228] Iteration 15900, loss = 0.222547
I0514 15:10:21.694396 12912 solver.cpp:244]     Train net output #0: loss = 0.222547 (* 1 = 0.222547 loss)
I0514 15:10:21.694432 12912 sgd_solver.cpp:106] Iteration 15900, lr = 0.0005
I0514 15:10:59.724370 12912 solver.cpp:228] Iteration 15950, loss = 0.110929
I0514 15:10:59.724469 12912 solver.cpp:244]     Train net output #0: loss = 0.110929 (* 1 = 0.110929 loss)
I0514 15:10:59.724486 12912 sgd_solver.cpp:106] Iteration 15950, lr = 0.0005
I0514 15:11:37.437305 12912 solver.cpp:454] Snapshotting to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_16000.caffemodel
I0514 15:11:38.068763 12912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_16000.solverstate
I0514 15:11:38.206753 12912 solver.cpp:337] Iteration 16000, Testing net (#0)
I0514 15:11:38.206858 12912 net.cpp:685] Ignoring source layer loss
I0514 15:13:22.435866 12912 solver.cpp:404]     Test net output #0: accuracy = 0.617647
I0514 15:13:22.739820 12912 solver.cpp:228] Iteration 16000, loss = 0.0999544
I0514 15:13:22.739891 12912 solver.cpp:244]     Train net output #0: loss = 0.0999546 (* 1 = 0.0999546 loss)
I0514 15:13:22.739909 12912 sgd_solver.cpp:106] Iteration 16000, lr = 0.0005
I0514 15:14:00.774181 12912 solver.cpp:228] Iteration 16050, loss = 0.265709
I0514 15:14:00.774365 12912 solver.cpp:244]     Train net output #0: loss = 0.26571 (* 1 = 0.26571 loss)
I0514 15:14:00.774406 12912 sgd_solver.cpp:106] Iteration 16050, lr = 0.0005
I0514 15:14:38.808502 12912 solver.cpp:228] Iteration 16100, loss = 0.116807
I0514 15:14:38.808609 12912 solver.cpp:244]     Train net output #0: loss = 0.116807 (* 1 = 0.116807 loss)
I0514 15:14:38.808627 12912 sgd_solver.cpp:106] Iteration 16100, lr = 0.0005
I0514 15:15:16.810667 12912 solver.cpp:228] Iteration 16150, loss = 0.242609
I0514 15:15:16.810813 12912 solver.cpp:244]     Train net output #0: loss = 0.242609 (* 1 = 0.242609 loss)
I0514 15:15:16.810830 12912 sgd_solver.cpp:106] Iteration 16150, lr = 0.0005
I0514 15:15:54.818564 12912 solver.cpp:228] Iteration 16200, loss = 0.306455
I0514 15:15:54.818691 12912 solver.cpp:244]     Train net output #0: loss = 0.306455 (* 1 = 0.306455 loss)
I0514 15:15:54.818708 12912 sgd_solver.cpp:106] Iteration 16200, lr = 0.0005
I0514 15:16:32.786537 12912 solver.cpp:228] Iteration 16250, loss = 0.450889
I0514 15:16:32.786659 12912 solver.cpp:244]     Train net output #0: loss = 0.450889 (* 1 = 0.450889 loss)
I0514 15:16:32.786671 12912 sgd_solver.cpp:106] Iteration 16250, lr = 0.0005
I0514 15:17:10.727210 12912 solver.cpp:228] Iteration 16300, loss = 0.116362
I0514 15:17:10.727298 12912 solver.cpp:244]     Train net output #0: loss = 0.116362 (* 1 = 0.116362 loss)
I0514 15:17:10.727315 12912 sgd_solver.cpp:106] Iteration 16300, lr = 0.0005
I0514 15:17:48.691031 12912 solver.cpp:228] Iteration 16350, loss = 0.234039
I0514 15:17:48.691171 12912 solver.cpp:244]     Train net output #0: loss = 0.234039 (* 1 = 0.234039 loss)
I0514 15:17:48.691190 12912 sgd_solver.cpp:106] Iteration 16350, lr = 0.0005
I0514 15:18:26.680318 12912 solver.cpp:228] Iteration 16400, loss = 0.285889
I0514 15:18:26.680454 12912 solver.cpp:244]     Train net output #0: loss = 0.28589 (* 1 = 0.28589 loss)
I0514 15:18:26.680466 12912 sgd_solver.cpp:106] Iteration 16400, lr = 0.0005
I0514 15:19:04.694766 12912 solver.cpp:228] Iteration 16450, loss = 0.467327
I0514 15:19:04.694872 12912 solver.cpp:244]     Train net output #0: loss = 0.467327 (* 1 = 0.467327 loss)
I0514 15:19:04.694885 12912 sgd_solver.cpp:106] Iteration 16450, lr = 0.0005
I0514 15:19:42.715606 12912 solver.cpp:228] Iteration 16500, loss = 0.141213
I0514 15:19:42.715708 12912 solver.cpp:244]     Train net output #0: loss = 0.141213 (* 1 = 0.141213 loss)
I0514 15:19:42.715721 12912 sgd_solver.cpp:106] Iteration 16500, lr = 0.0005
I0514 15:20:20.726284 12912 solver.cpp:228] Iteration 16550, loss = 0.044881
I0514 15:20:20.726443 12912 solver.cpp:244]     Train net output #0: loss = 0.044881 (* 1 = 0.044881 loss)
I0514 15:20:20.726454 12912 sgd_solver.cpp:106] Iteration 16550, lr = 0.0005
I0514 15:20:58.752547 12912 solver.cpp:228] Iteration 16600, loss = 0.135669
I0514 15:20:58.752694 12912 solver.cpp:244]     Train net output #0: loss = 0.135669 (* 1 = 0.135669 loss)
I0514 15:20:58.752710 12912 sgd_solver.cpp:106] Iteration 16600, lr = 0.0005
I0514 15:21:36.787075 12912 solver.cpp:228] Iteration 16650, loss = 0.117928
I0514 15:21:36.787190 12912 solver.cpp:244]     Train net output #0: loss = 0.117928 (* 1 = 0.117928 loss)
I0514 15:21:36.787204 12912 sgd_solver.cpp:106] Iteration 16650, lr = 0.0005
I0514 15:22:14.800618 12912 solver.cpp:228] Iteration 16700, loss = 0.398485
I0514 15:22:14.800770 12912 solver.cpp:244]     Train net output #0: loss = 0.398485 (* 1 = 0.398485 loss)
I0514 15:22:14.800789 12912 sgd_solver.cpp:106] Iteration 16700, lr = 0.0005
I0514 15:22:52.809803 12912 solver.cpp:228] Iteration 16750, loss = 0.0779723
I0514 15:22:52.809994 12912 solver.cpp:244]     Train net output #0: loss = 0.0779724 (* 1 = 0.0779724 loss)
I0514 15:22:52.810012 12912 sgd_solver.cpp:106] Iteration 16750, lr = 0.0005
I0514 15:23:30.867852 12912 solver.cpp:228] Iteration 16800, loss = 0.118522
I0514 15:23:30.867949 12912 solver.cpp:244]     Train net output #0: loss = 0.118522 (* 1 = 0.118522 loss)
I0514 15:23:30.867961 12912 sgd_solver.cpp:106] Iteration 16800, lr = 0.0005
I0514 15:24:08.890453 12912 solver.cpp:228] Iteration 16850, loss = 0.0904253
I0514 15:24:08.890563 12912 solver.cpp:244]     Train net output #0: loss = 0.0904254 (* 1 = 0.0904254 loss)
I0514 15:24:08.890576 12912 sgd_solver.cpp:106] Iteration 16850, lr = 0.0005
I0514 15:24:46.902779 12912 solver.cpp:228] Iteration 16900, loss = 0.104212
I0514 15:24:46.902922 12912 solver.cpp:244]     Train net output #0: loss = 0.104212 (* 1 = 0.104212 loss)
I0514 15:24:46.902941 12912 sgd_solver.cpp:106] Iteration 16900, lr = 0.0005
I0514 15:25:24.938709 12912 solver.cpp:228] Iteration 16950, loss = 0.401619
I0514 15:25:24.938817 12912 solver.cpp:244]     Train net output #0: loss = 0.401619 (* 1 = 0.401619 loss)
I0514 15:25:24.938834 12912 sgd_solver.cpp:106] Iteration 16950, lr = 0.0005
I0514 15:26:02.705159 12912 solver.cpp:454] Snapshotting to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_17000.caffemodel
I0514 15:26:03.310966 12912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_17000.solverstate
I0514 15:26:03.410444 12912 solver.cpp:337] Iteration 17000, Testing net (#0)
I0514 15:26:03.410506 12912 net.cpp:685] Ignoring source layer loss
I0514 15:27:47.731133 12912 solver.cpp:404]     Test net output #0: accuracy = 0.605735
I0514 15:27:48.035112 12912 solver.cpp:228] Iteration 17000, loss = 0.281411
I0514 15:27:48.035169 12912 solver.cpp:244]     Train net output #0: loss = 0.281411 (* 1 = 0.281411 loss)
I0514 15:27:48.035182 12912 sgd_solver.cpp:106] Iteration 17000, lr = 0.0005
I0514 15:28:26.064939 12912 solver.cpp:228] Iteration 17050, loss = 0.122653
I0514 15:28:26.065107 12912 solver.cpp:244]     Train net output #0: loss = 0.122653 (* 1 = 0.122653 loss)
I0514 15:28:26.065146 12912 sgd_solver.cpp:106] Iteration 17050, lr = 0.0005
I0514 15:29:04.107913 12912 solver.cpp:228] Iteration 17100, loss = 0.177176
I0514 15:29:04.108044 12912 solver.cpp:244]     Train net output #0: loss = 0.177176 (* 1 = 0.177176 loss)
I0514 15:29:04.108062 12912 sgd_solver.cpp:106] Iteration 17100, lr = 0.0005
I0514 15:29:42.111755 12912 solver.cpp:228] Iteration 17150, loss = 0.056258
I0514 15:29:42.111871 12912 solver.cpp:244]     Train net output #0: loss = 0.056258 (* 1 = 0.056258 loss)
I0514 15:29:42.111884 12912 sgd_solver.cpp:106] Iteration 17150, lr = 0.0005
I0514 15:30:20.130750 12912 solver.cpp:228] Iteration 17200, loss = 0.294864
I0514 15:30:20.130872 12912 solver.cpp:244]     Train net output #0: loss = 0.294864 (* 1 = 0.294864 loss)
I0514 15:30:20.130892 12912 sgd_solver.cpp:106] Iteration 17200, lr = 0.0005
I0514 15:30:58.143451 12912 solver.cpp:228] Iteration 17250, loss = 0.17434
I0514 15:30:58.143642 12912 solver.cpp:244]     Train net output #0: loss = 0.17434 (* 1 = 0.17434 loss)
I0514 15:30:58.143682 12912 sgd_solver.cpp:106] Iteration 17250, lr = 0.0005
I0514 15:31:36.147156 12912 solver.cpp:228] Iteration 17300, loss = 0.0605955
I0514 15:31:36.147377 12912 solver.cpp:244]     Train net output #0: loss = 0.0605956 (* 1 = 0.0605956 loss)
I0514 15:31:36.147399 12912 sgd_solver.cpp:106] Iteration 17300, lr = 0.0005
I0514 15:32:14.162511 12912 solver.cpp:228] Iteration 17350, loss = 0.0649305
I0514 15:32:14.162669 12912 solver.cpp:244]     Train net output #0: loss = 0.0649306 (* 1 = 0.0649306 loss)
I0514 15:32:14.162690 12912 sgd_solver.cpp:106] Iteration 17350, lr = 0.0005
I0514 15:32:52.197497 12912 solver.cpp:228] Iteration 17400, loss = 0.0904812
I0514 15:32:52.197700 12912 solver.cpp:244]     Train net output #0: loss = 0.0904813 (* 1 = 0.0904813 loss)
I0514 15:32:52.197718 12912 sgd_solver.cpp:106] Iteration 17400, lr = 0.0005
I0514 15:33:30.222923 12912 solver.cpp:228] Iteration 17450, loss = 0.0671891
I0514 15:33:30.223024 12912 solver.cpp:244]     Train net output #0: loss = 0.0671892 (* 1 = 0.0671892 loss)
I0514 15:33:30.223037 12912 sgd_solver.cpp:106] Iteration 17450, lr = 0.0005
I0514 15:34:08.260694 12912 solver.cpp:228] Iteration 17500, loss = 0.0324377
I0514 15:34:08.260824 12912 solver.cpp:244]     Train net output #0: loss = 0.0324377 (* 1 = 0.0324377 loss)
I0514 15:34:08.260843 12912 sgd_solver.cpp:106] Iteration 17500, lr = 0.0005
I0514 15:34:46.273522 12912 solver.cpp:228] Iteration 17550, loss = 0.0952883
I0514 15:34:46.273639 12912 solver.cpp:244]     Train net output #0: loss = 0.0952883 (* 1 = 0.0952883 loss)
I0514 15:34:46.273656 12912 sgd_solver.cpp:106] Iteration 17550, lr = 0.0005
I0514 15:35:24.252799 12912 solver.cpp:228] Iteration 17600, loss = 0.128514
I0514 15:35:24.252900 12912 solver.cpp:244]     Train net output #0: loss = 0.128514 (* 1 = 0.128514 loss)
I0514 15:35:24.252918 12912 sgd_solver.cpp:106] Iteration 17600, lr = 0.0005
I0514 15:36:02.223989 12912 solver.cpp:228] Iteration 17650, loss = 0.262598
I0514 15:36:02.224182 12912 solver.cpp:244]     Train net output #0: loss = 0.262598 (* 1 = 0.262598 loss)
I0514 15:36:02.224220 12912 sgd_solver.cpp:106] Iteration 17650, lr = 0.0005
I0514 15:36:40.187086 12912 solver.cpp:228] Iteration 17700, loss = 0.253796
I0514 15:36:40.187248 12912 solver.cpp:244]     Train net output #0: loss = 0.253796 (* 1 = 0.253796 loss)
I0514 15:36:40.187283 12912 sgd_solver.cpp:106] Iteration 17700, lr = 0.0005
I0514 15:37:18.199069 12912 solver.cpp:228] Iteration 17750, loss = 0.30594
I0514 15:37:18.199262 12912 solver.cpp:244]     Train net output #0: loss = 0.305939 (* 1 = 0.305939 loss)
I0514 15:37:18.199304 12912 sgd_solver.cpp:106] Iteration 17750, lr = 0.0005
I0514 15:37:56.218941 12912 solver.cpp:228] Iteration 17800, loss = 0.0333594
I0514 15:37:56.219048 12912 solver.cpp:244]     Train net output #0: loss = 0.0333594 (* 1 = 0.0333594 loss)
I0514 15:37:56.219065 12912 sgd_solver.cpp:106] Iteration 17800, lr = 0.0005
I0514 15:38:34.266105 12912 solver.cpp:228] Iteration 17850, loss = 0.0907978
I0514 15:38:34.266312 12912 solver.cpp:244]     Train net output #0: loss = 0.0907978 (* 1 = 0.0907978 loss)
I0514 15:38:34.266355 12912 sgd_solver.cpp:106] Iteration 17850, lr = 0.0005
I0514 15:39:12.290664 12912 solver.cpp:228] Iteration 17900, loss = 0.0843784
I0514 15:39:12.290849 12912 solver.cpp:244]     Train net output #0: loss = 0.0843784 (* 1 = 0.0843784 loss)
I0514 15:39:12.290889 12912 sgd_solver.cpp:106] Iteration 17900, lr = 0.0005
I0514 15:39:50.305771 12912 solver.cpp:228] Iteration 17950, loss = 0.14872
I0514 15:39:50.305896 12912 solver.cpp:244]     Train net output #0: loss = 0.14872 (* 1 = 0.14872 loss)
I0514 15:39:50.305912 12912 sgd_solver.cpp:106] Iteration 17950, lr = 0.0005
I0514 15:40:28.030814 12912 solver.cpp:454] Snapshotting to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_18000.caffemodel
I0514 15:40:28.771163 12912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_18000.solverstate
I0514 15:40:28.853672 12912 solver.cpp:337] Iteration 18000, Testing net (#0)
I0514 15:40:28.853724 12912 net.cpp:685] Ignoring source layer loss
I0514 15:42:12.840701 12912 solver.cpp:404]     Test net output #0: accuracy = 0.589559
I0514 15:42:13.131861 12912 solver.cpp:228] Iteration 18000, loss = 0.187189
I0514 15:42:13.131921 12912 solver.cpp:244]     Train net output #0: loss = 0.187189 (* 1 = 0.187189 loss)
I0514 15:42:13.131933 12912 sgd_solver.cpp:106] Iteration 18000, lr = 0.0005
I0514 15:42:51.155746 12912 solver.cpp:228] Iteration 18050, loss = 0.0913629
I0514 15:42:51.155853 12912 solver.cpp:244]     Train net output #0: loss = 0.091363 (* 1 = 0.091363 loss)
I0514 15:42:51.155865 12912 sgd_solver.cpp:106] Iteration 18050, lr = 0.0005
I0514 15:43:29.221232 12912 solver.cpp:228] Iteration 18100, loss = 0.129534
I0514 15:43:29.221359 12912 solver.cpp:244]     Train net output #0: loss = 0.129534 (* 1 = 0.129534 loss)
I0514 15:43:29.221372 12912 sgd_solver.cpp:106] Iteration 18100, lr = 0.0005
I0514 15:44:07.248971 12912 solver.cpp:228] Iteration 18150, loss = 0.125115
I0514 15:44:07.249089 12912 solver.cpp:244]     Train net output #0: loss = 0.125115 (* 1 = 0.125115 loss)
I0514 15:44:07.249102 12912 sgd_solver.cpp:106] Iteration 18150, lr = 0.0005
I0514 15:44:45.264150 12912 solver.cpp:228] Iteration 18200, loss = 0.0985249
I0514 15:44:45.264256 12912 solver.cpp:244]     Train net output #0: loss = 0.0985249 (* 1 = 0.0985249 loss)
I0514 15:44:45.264273 12912 sgd_solver.cpp:106] Iteration 18200, lr = 0.0005
I0514 15:45:23.281534 12912 solver.cpp:228] Iteration 18250, loss = 0.349415
I0514 15:45:23.282073 12912 solver.cpp:244]     Train net output #0: loss = 0.349415 (* 1 = 0.349415 loss)
I0514 15:45:23.282122 12912 sgd_solver.cpp:106] Iteration 18250, lr = 0.0005
I0514 15:46:01.282045 12912 solver.cpp:228] Iteration 18300, loss = 0.253871
I0514 15:46:01.282140 12912 solver.cpp:244]     Train net output #0: loss = 0.253871 (* 1 = 0.253871 loss)
I0514 15:46:01.282152 12912 sgd_solver.cpp:106] Iteration 18300, lr = 0.0005
I0514 15:46:39.327059 12912 solver.cpp:228] Iteration 18350, loss = 0.36879
I0514 15:46:39.327235 12912 solver.cpp:244]     Train net output #0: loss = 0.36879 (* 1 = 0.36879 loss)
I0514 15:46:39.327275 12912 sgd_solver.cpp:106] Iteration 18350, lr = 0.0005
I0514 15:47:17.403921 12912 solver.cpp:228] Iteration 18400, loss = 0.0663146
I0514 15:47:17.404058 12912 solver.cpp:244]     Train net output #0: loss = 0.0663146 (* 1 = 0.0663146 loss)
I0514 15:47:17.404075 12912 sgd_solver.cpp:106] Iteration 18400, lr = 0.0005
I0514 15:47:55.420220 12912 solver.cpp:228] Iteration 18450, loss = 0.278232
I0514 15:47:55.420344 12912 solver.cpp:244]     Train net output #0: loss = 0.278232 (* 1 = 0.278232 loss)
I0514 15:47:55.420362 12912 sgd_solver.cpp:106] Iteration 18450, lr = 0.0005
I0514 15:48:33.479791 12912 solver.cpp:228] Iteration 18500, loss = 0.0716101
I0514 15:48:33.479928 12912 solver.cpp:244]     Train net output #0: loss = 0.0716102 (* 1 = 0.0716102 loss)
I0514 15:48:33.479946 12912 sgd_solver.cpp:106] Iteration 18500, lr = 0.0005
I0514 15:49:11.479502 12912 solver.cpp:228] Iteration 18550, loss = 0.416158
I0514 15:49:11.479643 12912 solver.cpp:244]     Train net output #0: loss = 0.416158 (* 1 = 0.416158 loss)
I0514 15:49:11.479658 12912 sgd_solver.cpp:106] Iteration 18550, lr = 0.0005
I0514 15:49:49.495023 12912 solver.cpp:228] Iteration 18600, loss = 0.10607
I0514 15:49:49.495164 12912 solver.cpp:244]     Train net output #0: loss = 0.10607 (* 1 = 0.10607 loss)
I0514 15:49:49.495180 12912 sgd_solver.cpp:106] Iteration 18600, lr = 0.0005
I0514 15:50:27.502089 12912 solver.cpp:228] Iteration 18650, loss = 0.125569
I0514 15:50:27.502223 12912 solver.cpp:244]     Train net output #0: loss = 0.125569 (* 1 = 0.125569 loss)
I0514 15:50:27.502236 12912 sgd_solver.cpp:106] Iteration 18650, lr = 0.0005
I0514 15:51:05.574570 12912 solver.cpp:228] Iteration 18700, loss = 0.138111
I0514 15:51:05.574690 12912 solver.cpp:244]     Train net output #0: loss = 0.138111 (* 1 = 0.138111 loss)
I0514 15:51:05.574707 12912 sgd_solver.cpp:106] Iteration 18700, lr = 0.0005
I0514 15:51:43.596402 12912 solver.cpp:228] Iteration 18750, loss = 0.0667358
I0514 15:51:43.596544 12912 solver.cpp:244]     Train net output #0: loss = 0.0667358 (* 1 = 0.0667358 loss)
I0514 15:51:43.596561 12912 sgd_solver.cpp:106] Iteration 18750, lr = 0.0005
I0514 15:52:21.619992 12912 solver.cpp:228] Iteration 18800, loss = 0.319246
I0514 15:52:21.620162 12912 solver.cpp:244]     Train net output #0: loss = 0.319246 (* 1 = 0.319246 loss)
I0514 15:52:21.620183 12912 sgd_solver.cpp:106] Iteration 18800, lr = 0.0005
I0514 15:52:59.653026 12912 solver.cpp:228] Iteration 18850, loss = 0.0839538
I0514 15:52:59.653187 12912 solver.cpp:244]     Train net output #0: loss = 0.083954 (* 1 = 0.083954 loss)
I0514 15:52:59.653201 12912 sgd_solver.cpp:106] Iteration 18850, lr = 0.0005
I0514 15:53:37.656564 12912 solver.cpp:228] Iteration 18900, loss = 0.058635
I0514 15:53:37.656697 12912 solver.cpp:244]     Train net output #0: loss = 0.0586351 (* 1 = 0.0586351 loss)
I0514 15:53:37.656716 12912 sgd_solver.cpp:106] Iteration 18900, lr = 0.0005
I0514 15:54:15.614446 12912 solver.cpp:228] Iteration 18950, loss = 0.0990071
I0514 15:54:15.614547 12912 solver.cpp:244]     Train net output #0: loss = 0.0990072 (* 1 = 0.0990072 loss)
I0514 15:54:15.614559 12912 sgd_solver.cpp:106] Iteration 18950, lr = 0.0005
I0514 15:54:53.289965 12912 solver.cpp:454] Snapshotting to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_19000.caffemodel
I0514 15:54:53.820338 12912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_19000.solverstate
I0514 15:54:53.914202 12912 solver.cpp:337] Iteration 19000, Testing net (#0)
I0514 15:54:53.914258 12912 net.cpp:685] Ignoring source layer loss
I0514 15:56:37.537252 12912 solver.cpp:404]     Test net output #0: accuracy = 0.675294
I0514 15:56:37.828786 12912 solver.cpp:228] Iteration 19000, loss = 0.109278
I0514 15:56:37.828871 12912 solver.cpp:244]     Train net output #0: loss = 0.109278 (* 1 = 0.109278 loss)
I0514 15:56:37.828891 12912 sgd_solver.cpp:106] Iteration 19000, lr = 0.0005
I0514 15:57:15.872426 12912 solver.cpp:228] Iteration 19050, loss = 0.0318325
I0514 15:57:15.872545 12912 solver.cpp:244]     Train net output #0: loss = 0.0318326 (* 1 = 0.0318326 loss)
I0514 15:57:15.872558 12912 sgd_solver.cpp:106] Iteration 19050, lr = 0.0005
I0514 15:57:53.911697 12912 solver.cpp:228] Iteration 19100, loss = 0.0444777
I0514 15:57:53.911852 12912 solver.cpp:244]     Train net output #0: loss = 0.0444779 (* 1 = 0.0444779 loss)
I0514 15:57:53.911872 12912 sgd_solver.cpp:106] Iteration 19100, lr = 0.0005
I0514 15:58:31.928652 12912 solver.cpp:228] Iteration 19150, loss = 0.0368697
I0514 15:58:31.928813 12912 solver.cpp:244]     Train net output #0: loss = 0.0368699 (* 1 = 0.0368699 loss)
I0514 15:58:31.928848 12912 sgd_solver.cpp:106] Iteration 19150, lr = 0.0005
I0514 15:59:09.942811 12912 solver.cpp:228] Iteration 19200, loss = 0.0290466
I0514 15:59:09.942950 12912 solver.cpp:244]     Train net output #0: loss = 0.0290468 (* 1 = 0.0290468 loss)
I0514 15:59:09.942968 12912 sgd_solver.cpp:106] Iteration 19200, lr = 0.0005
I0514 15:59:47.951954 12912 solver.cpp:228] Iteration 19250, loss = 0.149223
I0514 15:59:47.962116 12912 solver.cpp:244]     Train net output #0: loss = 0.149223 (* 1 = 0.149223 loss)
I0514 15:59:47.962152 12912 sgd_solver.cpp:106] Iteration 19250, lr = 0.0005
I0514 16:00:25.977810 12912 solver.cpp:228] Iteration 19300, loss = 0.16865
I0514 16:00:25.977916 12912 solver.cpp:244]     Train net output #0: loss = 0.16865 (* 1 = 0.16865 loss)
I0514 16:00:25.977934 12912 sgd_solver.cpp:106] Iteration 19300, lr = 0.0005
I0514 16:01:03.972365 12912 solver.cpp:228] Iteration 19350, loss = 0.060098
I0514 16:01:03.972470 12912 solver.cpp:244]     Train net output #0: loss = 0.0600981 (* 1 = 0.0600981 loss)
I0514 16:01:03.972486 12912 sgd_solver.cpp:106] Iteration 19350, lr = 0.0005
I0514 16:01:41.973628 12912 solver.cpp:228] Iteration 19400, loss = 0.133437
I0514 16:01:41.973832 12912 solver.cpp:244]     Train net output #0: loss = 0.133437 (* 1 = 0.133437 loss)
I0514 16:01:41.973875 12912 sgd_solver.cpp:106] Iteration 19400, lr = 0.0005
I0514 16:02:20.000447 12912 solver.cpp:228] Iteration 19450, loss = 0.0872381
I0514 16:02:20.000558 12912 solver.cpp:244]     Train net output #0: loss = 0.0872381 (* 1 = 0.0872381 loss)
I0514 16:02:20.000576 12912 sgd_solver.cpp:106] Iteration 19450, lr = 0.0005
I0514 16:02:58.031080 12912 solver.cpp:228] Iteration 19500, loss = 0.0740155
I0514 16:02:58.031270 12912 solver.cpp:244]     Train net output #0: loss = 0.0740156 (* 1 = 0.0740156 loss)
I0514 16:02:58.031308 12912 sgd_solver.cpp:106] Iteration 19500, lr = 0.0005
I0514 16:03:36.044379 12912 solver.cpp:228] Iteration 19550, loss = 0.530151
I0514 16:03:36.044534 12912 solver.cpp:244]     Train net output #0: loss = 0.530151 (* 1 = 0.530151 loss)
I0514 16:03:36.044553 12912 sgd_solver.cpp:106] Iteration 19550, lr = 0.0005
I0514 16:04:14.054287 12912 solver.cpp:228] Iteration 19600, loss = 0.159875
I0514 16:04:14.054451 12912 solver.cpp:244]     Train net output #0: loss = 0.159875 (* 1 = 0.159875 loss)
I0514 16:04:14.054471 12912 sgd_solver.cpp:106] Iteration 19600, lr = 0.0005
I0514 16:04:52.080792 12912 solver.cpp:228] Iteration 19650, loss = 0.135406
I0514 16:04:52.080884 12912 solver.cpp:244]     Train net output #0: loss = 0.135407 (* 1 = 0.135407 loss)
I0514 16:04:52.080896 12912 sgd_solver.cpp:106] Iteration 19650, lr = 0.0005
I0514 16:05:30.098188 12912 solver.cpp:228] Iteration 19700, loss = 0.123167
I0514 16:05:30.098289 12912 solver.cpp:244]     Train net output #0: loss = 0.123167 (* 1 = 0.123167 loss)
I0514 16:05:30.098301 12912 sgd_solver.cpp:106] Iteration 19700, lr = 0.0005
I0514 16:06:08.102581 12912 solver.cpp:228] Iteration 19750, loss = 0.103976
I0514 16:06:08.102723 12912 solver.cpp:244]     Train net output #0: loss = 0.103976 (* 1 = 0.103976 loss)
I0514 16:06:08.102736 12912 sgd_solver.cpp:106] Iteration 19750, lr = 0.0005
I0514 16:06:46.106648 12912 solver.cpp:228] Iteration 19800, loss = 0.0317658
I0514 16:06:46.106767 12912 solver.cpp:244]     Train net output #0: loss = 0.0317659 (* 1 = 0.0317659 loss)
I0514 16:06:46.106781 12912 sgd_solver.cpp:106] Iteration 19800, lr = 0.0005
I0514 16:07:24.120237 12912 solver.cpp:228] Iteration 19850, loss = 0.326747
I0514 16:07:24.120393 12912 solver.cpp:244]     Train net output #0: loss = 0.326747 (* 1 = 0.326747 loss)
I0514 16:07:24.120410 12912 sgd_solver.cpp:106] Iteration 19850, lr = 0.0005
I0514 16:08:02.122383 12912 solver.cpp:228] Iteration 19900, loss = 0.128938
I0514 16:08:02.122570 12912 solver.cpp:244]     Train net output #0: loss = 0.128939 (* 1 = 0.128939 loss)
I0514 16:08:02.122586 12912 sgd_solver.cpp:106] Iteration 19900, lr = 0.0005
I0514 16:08:40.127868 12912 solver.cpp:228] Iteration 19950, loss = 0.0511154
I0514 16:08:40.127981 12912 solver.cpp:244]     Train net output #0: loss = 0.0511156 (* 1 = 0.0511156 loss)
I0514 16:08:40.127995 12912 sgd_solver.cpp:106] Iteration 19950, lr = 0.0005
I0514 16:09:17.843971 12912 solver.cpp:454] Snapshotting to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_20000.caffemodel
I0514 16:09:18.366578 12912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_20000.solverstate
I0514 16:09:18.449795 12912 solver.cpp:337] Iteration 20000, Testing net (#0)
I0514 16:09:18.449856 12912 net.cpp:685] Ignoring source layer loss
I0514 16:11:02.390386 12912 solver.cpp:404]     Test net output #0: accuracy = 0.670882
I0514 16:11:02.679594 12912 solver.cpp:228] Iteration 20000, loss = 0.106554
I0514 16:11:02.679659 12912 solver.cpp:244]     Train net output #0: loss = 0.106554 (* 1 = 0.106554 loss)
I0514 16:11:02.679673 12912 sgd_solver.cpp:106] Iteration 20000, lr = 0.0005
I0514 16:11:40.712348 12912 solver.cpp:228] Iteration 20050, loss = 0.0877629
I0514 16:11:40.712535 12912 solver.cpp:244]     Train net output #0: loss = 0.087763 (* 1 = 0.087763 loss)
I0514 16:11:40.712553 12912 sgd_solver.cpp:106] Iteration 20050, lr = 0.0005
I0514 16:12:18.698002 12912 solver.cpp:228] Iteration 20100, loss = 0.440237
I0514 16:12:18.698101 12912 solver.cpp:244]     Train net output #0: loss = 0.440237 (* 1 = 0.440237 loss)
I0514 16:12:18.698113 12912 sgd_solver.cpp:106] Iteration 20100, lr = 0.0005
I0514 16:12:56.653702 12912 solver.cpp:228] Iteration 20150, loss = 0.0322927
I0514 16:12:56.653801 12912 solver.cpp:244]     Train net output #0: loss = 0.0322928 (* 1 = 0.0322928 loss)
I0514 16:12:56.653818 12912 sgd_solver.cpp:106] Iteration 20150, lr = 0.0005
I0514 16:13:34.619674 12912 solver.cpp:228] Iteration 20200, loss = 0.0610822
I0514 16:13:34.619819 12912 solver.cpp:244]     Train net output #0: loss = 0.0610823 (* 1 = 0.0610823 loss)
I0514 16:13:34.619833 12912 sgd_solver.cpp:106] Iteration 20200, lr = 0.0005
I0514 16:14:12.566402 12912 solver.cpp:228] Iteration 20250, loss = 0.0262564
I0514 16:14:12.566535 12912 solver.cpp:244]     Train net output #0: loss = 0.0262565 (* 1 = 0.0262565 loss)
I0514 16:14:12.566553 12912 sgd_solver.cpp:106] Iteration 20250, lr = 0.0005
I0514 16:14:50.581979 12912 solver.cpp:228] Iteration 20300, loss = 0.0450796
I0514 16:14:50.582093 12912 solver.cpp:244]     Train net output #0: loss = 0.0450797 (* 1 = 0.0450797 loss)
I0514 16:14:50.582113 12912 sgd_solver.cpp:106] Iteration 20300, lr = 0.0005
I0514 16:15:28.584532 12912 solver.cpp:228] Iteration 20350, loss = 0.0378186
I0514 16:15:28.584637 12912 solver.cpp:244]     Train net output #0: loss = 0.0378186 (* 1 = 0.0378186 loss)
I0514 16:15:28.584650 12912 sgd_solver.cpp:106] Iteration 20350, lr = 0.0005
I0514 16:16:06.607513 12912 solver.cpp:228] Iteration 20400, loss = 0.0632727
I0514 16:16:06.607677 12912 solver.cpp:244]     Train net output #0: loss = 0.0632728 (* 1 = 0.0632728 loss)
I0514 16:16:06.607717 12912 sgd_solver.cpp:106] Iteration 20400, lr = 0.0005
I0514 16:16:44.621774 12912 solver.cpp:228] Iteration 20450, loss = 0.0966394
I0514 16:16:44.621909 12912 solver.cpp:244]     Train net output #0: loss = 0.0966395 (* 1 = 0.0966395 loss)
I0514 16:16:44.621922 12912 sgd_solver.cpp:106] Iteration 20450, lr = 0.0005
I0514 16:17:22.665240 12912 solver.cpp:228] Iteration 20500, loss = 0.0631201
I0514 16:17:22.665355 12912 solver.cpp:244]     Train net output #0: loss = 0.0631202 (* 1 = 0.0631202 loss)
I0514 16:17:22.665369 12912 sgd_solver.cpp:106] Iteration 20500, lr = 0.0005
I0514 16:18:00.663859 12912 solver.cpp:228] Iteration 20550, loss = 0.11043
I0514 16:18:00.663976 12912 solver.cpp:244]     Train net output #0: loss = 0.11043 (* 1 = 0.11043 loss)
I0514 16:18:00.663995 12912 sgd_solver.cpp:106] Iteration 20550, lr = 0.0005
I0514 16:18:38.671888 12912 solver.cpp:228] Iteration 20600, loss = 0.105247
I0514 16:18:38.672019 12912 solver.cpp:244]     Train net output #0: loss = 0.105247 (* 1 = 0.105247 loss)
I0514 16:18:38.672031 12912 sgd_solver.cpp:106] Iteration 20600, lr = 0.0005
I0514 16:19:16.680044 12912 solver.cpp:228] Iteration 20650, loss = 0.0275904
I0514 16:19:16.680212 12912 solver.cpp:244]     Train net output #0: loss = 0.0275906 (* 1 = 0.0275906 loss)
I0514 16:19:16.680249 12912 sgd_solver.cpp:106] Iteration 20650, lr = 0.0005
I0514 16:19:54.687765 12912 solver.cpp:228] Iteration 20700, loss = 0.21351
I0514 16:19:54.687989 12912 solver.cpp:244]     Train net output #0: loss = 0.21351 (* 1 = 0.21351 loss)
I0514 16:19:54.688029 12912 sgd_solver.cpp:106] Iteration 20700, lr = 0.0005
I0514 16:20:32.686274 12912 solver.cpp:228] Iteration 20750, loss = 0.157524
I0514 16:20:32.686373 12912 solver.cpp:244]     Train net output #0: loss = 0.157524 (* 1 = 0.157524 loss)
I0514 16:20:32.686389 12912 sgd_solver.cpp:106] Iteration 20750, lr = 0.0005
I0514 16:21:10.724717 12912 solver.cpp:228] Iteration 20800, loss = 0.0652759
I0514 16:21:10.724846 12912 solver.cpp:244]     Train net output #0: loss = 0.065276 (* 1 = 0.065276 loss)
I0514 16:21:10.724863 12912 sgd_solver.cpp:106] Iteration 20800, lr = 0.0005
I0514 16:21:48.748721 12912 solver.cpp:228] Iteration 20850, loss = 0.183229
I0514 16:21:48.748893 12912 solver.cpp:244]     Train net output #0: loss = 0.183229 (* 1 = 0.183229 loss)
I0514 16:21:48.748908 12912 sgd_solver.cpp:106] Iteration 20850, lr = 0.0005
I0514 16:22:26.766505 12912 solver.cpp:228] Iteration 20900, loss = 0.0365412
I0514 16:22:26.766652 12912 solver.cpp:244]     Train net output #0: loss = 0.0365413 (* 1 = 0.0365413 loss)
I0514 16:22:26.766670 12912 sgd_solver.cpp:106] Iteration 20900, lr = 0.0005
I0514 16:23:04.770001 12912 solver.cpp:228] Iteration 20950, loss = 0.0324859
I0514 16:23:04.770120 12912 solver.cpp:244]     Train net output #0: loss = 0.032486 (* 1 = 0.032486 loss)
I0514 16:23:04.770133 12912 sgd_solver.cpp:106] Iteration 20950, lr = 0.0005
I0514 16:23:42.493604 12912 solver.cpp:454] Snapshotting to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_21000.caffemodel
I0514 16:23:43.070559 12912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_21000.solverstate
I0514 16:23:43.160944 12912 solver.cpp:337] Iteration 21000, Testing net (#0)
I0514 16:23:43.161008 12912 net.cpp:685] Ignoring source layer loss
I0514 16:25:27.331426 12912 solver.cpp:404]     Test net output #0: accuracy = 0.640147
I0514 16:25:27.620857 12912 solver.cpp:228] Iteration 21000, loss = 0.078506
I0514 16:25:27.620985 12912 solver.cpp:244]     Train net output #0: loss = 0.0785061 (* 1 = 0.0785061 loss)
I0514 16:25:27.621028 12912 sgd_solver.cpp:106] Iteration 21000, lr = 0.0005
I0514 16:26:05.637681 12912 solver.cpp:228] Iteration 21050, loss = 0.0849641
I0514 16:26:05.637845 12912 solver.cpp:244]     Train net output #0: loss = 0.0849642 (* 1 = 0.0849642 loss)
I0514 16:26:05.637879 12912 sgd_solver.cpp:106] Iteration 21050, lr = 0.0005
I0514 16:26:43.657727 12912 solver.cpp:228] Iteration 21100, loss = 0.0692244
I0514 16:26:43.657820 12912 solver.cpp:244]     Train net output #0: loss = 0.0692245 (* 1 = 0.0692245 loss)
I0514 16:26:43.657832 12912 sgd_solver.cpp:106] Iteration 21100, lr = 0.0005
I0514 16:27:21.660737 12912 solver.cpp:228] Iteration 21150, loss = 0.182807
I0514 16:27:21.660852 12912 solver.cpp:244]     Train net output #0: loss = 0.182807 (* 1 = 0.182807 loss)
I0514 16:27:21.660866 12912 sgd_solver.cpp:106] Iteration 21150, lr = 0.0005
I0514 16:27:59.659919 12912 solver.cpp:228] Iteration 21200, loss = 0.0538896
I0514 16:27:59.660030 12912 solver.cpp:244]     Train net output #0: loss = 0.0538897 (* 1 = 0.0538897 loss)
I0514 16:27:59.660048 12912 sgd_solver.cpp:106] Iteration 21200, lr = 0.0005
I0514 16:28:37.671973 12912 solver.cpp:228] Iteration 21250, loss = 0.162073
I0514 16:28:37.672104 12912 solver.cpp:244]     Train net output #0: loss = 0.162073 (* 1 = 0.162073 loss)
I0514 16:28:37.672119 12912 sgd_solver.cpp:106] Iteration 21250, lr = 0.0005
I0514 16:29:15.669545 12912 solver.cpp:228] Iteration 21300, loss = 0.0816559
I0514 16:29:15.669766 12912 solver.cpp:244]     Train net output #0: loss = 0.081656 (* 1 = 0.081656 loss)
I0514 16:29:15.669791 12912 sgd_solver.cpp:106] Iteration 21300, lr = 0.0005
I0514 16:29:53.673483 12912 solver.cpp:228] Iteration 21350, loss = 0.035259
I0514 16:29:53.673657 12912 solver.cpp:244]     Train net output #0: loss = 0.0352591 (* 1 = 0.0352591 loss)
I0514 16:29:53.673703 12912 sgd_solver.cpp:106] Iteration 21350, lr = 0.0005
I0514 16:30:31.673151 12912 solver.cpp:228] Iteration 21400, loss = 0.0938384
I0514 16:30:31.673308 12912 solver.cpp:244]     Train net output #0: loss = 0.0938385 (* 1 = 0.0938385 loss)
I0514 16:30:31.673321 12912 sgd_solver.cpp:106] Iteration 21400, lr = 0.0005
I0514 16:31:09.661649 12912 solver.cpp:228] Iteration 21450, loss = 0.0594128
I0514 16:31:09.661773 12912 solver.cpp:244]     Train net output #0: loss = 0.0594129 (* 1 = 0.0594129 loss)
I0514 16:31:09.661790 12912 sgd_solver.cpp:106] Iteration 21450, lr = 0.0005
I0514 16:31:47.616580 12912 solver.cpp:228] Iteration 21500, loss = 0.0584457
I0514 16:31:47.616785 12912 solver.cpp:244]     Train net output #0: loss = 0.0584458 (* 1 = 0.0584458 loss)
I0514 16:31:47.616827 12912 sgd_solver.cpp:106] Iteration 21500, lr = 0.0005
I0514 16:32:25.575776 12912 solver.cpp:228] Iteration 21550, loss = 0.0788688
I0514 16:32:25.575920 12912 solver.cpp:244]     Train net output #0: loss = 0.078869 (* 1 = 0.078869 loss)
I0514 16:32:25.575938 12912 sgd_solver.cpp:106] Iteration 21550, lr = 0.0005
I0514 16:33:03.522781 12912 solver.cpp:228] Iteration 21600, loss = 0.03537
I0514 16:33:03.522984 12912 solver.cpp:244]     Train net output #0: loss = 0.0353702 (* 1 = 0.0353702 loss)
I0514 16:33:03.522997 12912 sgd_solver.cpp:106] Iteration 21600, lr = 0.0005
I0514 16:33:41.465034 12912 solver.cpp:228] Iteration 21650, loss = 0.063401
I0514 16:33:41.465152 12912 solver.cpp:244]     Train net output #0: loss = 0.0634012 (* 1 = 0.0634012 loss)
I0514 16:33:41.465165 12912 sgd_solver.cpp:106] Iteration 21650, lr = 0.0005
I0514 16:34:19.413799 12912 solver.cpp:228] Iteration 21700, loss = 0.0281095
I0514 16:34:19.413970 12912 solver.cpp:244]     Train net output #0: loss = 0.0281096 (* 1 = 0.0281096 loss)
I0514 16:34:19.413985 12912 sgd_solver.cpp:106] Iteration 21700, lr = 0.0005
I0514 16:34:57.355312 12912 solver.cpp:228] Iteration 21750, loss = 0.138554
I0514 16:34:57.355430 12912 solver.cpp:244]     Train net output #0: loss = 0.138554 (* 1 = 0.138554 loss)
I0514 16:34:57.355443 12912 sgd_solver.cpp:106] Iteration 21750, lr = 0.0005
I0514 16:35:35.299037 12912 solver.cpp:228] Iteration 21800, loss = 0.0967689
I0514 16:35:35.299161 12912 solver.cpp:244]     Train net output #0: loss = 0.0967691 (* 1 = 0.0967691 loss)
I0514 16:35:35.299182 12912 sgd_solver.cpp:106] Iteration 21800, lr = 0.0005
I0514 16:36:13.251242 12912 solver.cpp:228] Iteration 21850, loss = 0.0270225
I0514 16:36:13.251351 12912 solver.cpp:244]     Train net output #0: loss = 0.0270227 (* 1 = 0.0270227 loss)
I0514 16:36:13.251369 12912 sgd_solver.cpp:106] Iteration 21850, lr = 0.0005
I0514 16:36:51.190656 12912 solver.cpp:228] Iteration 21900, loss = 0.0453474
I0514 16:36:51.190789 12912 solver.cpp:244]     Train net output #0: loss = 0.0453475 (* 1 = 0.0453475 loss)
I0514 16:36:51.190811 12912 sgd_solver.cpp:106] Iteration 21900, lr = 0.0005
I0514 16:37:29.133721 12912 solver.cpp:228] Iteration 21950, loss = 0.116251
I0514 16:37:29.133831 12912 solver.cpp:244]     Train net output #0: loss = 0.116251 (* 1 = 0.116251 loss)
I0514 16:37:29.133848 12912 sgd_solver.cpp:106] Iteration 21950, lr = 0.0005
I0514 16:38:06.776433 12912 solver.cpp:454] Snapshotting to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_22000.caffemodel
I0514 16:38:07.301908 12912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_22000.solverstate
I0514 16:38:07.382074 12912 solver.cpp:337] Iteration 22000, Testing net (#0)
I0514 16:38:07.382128 12912 net.cpp:685] Ignoring source layer loss
I0514 16:39:49.594768 12912 solver.cpp:404]     Test net output #0: accuracy = 0.551618
I0514 16:39:49.884707 12912 solver.cpp:228] Iteration 22000, loss = 0.0302393
I0514 16:39:49.884783 12912 solver.cpp:244]     Train net output #0: loss = 0.0302394 (* 1 = 0.0302394 loss)
I0514 16:39:49.884796 12912 sgd_solver.cpp:106] Iteration 22000, lr = 0.0005
I0514 16:40:27.827392 12912 solver.cpp:228] Iteration 22050, loss = 0.070127
I0514 16:40:27.827543 12912 solver.cpp:244]     Train net output #0: loss = 0.0701271 (* 1 = 0.0701271 loss)
I0514 16:40:27.827560 12912 sgd_solver.cpp:106] Iteration 22050, lr = 0.0005
I0514 16:41:05.767223 12912 solver.cpp:228] Iteration 22100, loss = 0.0579471
I0514 16:41:05.767350 12912 solver.cpp:244]     Train net output #0: loss = 0.0579473 (* 1 = 0.0579473 loss)
I0514 16:41:05.767369 12912 sgd_solver.cpp:106] Iteration 22100, lr = 0.0005
I0514 16:41:43.696650 12912 solver.cpp:228] Iteration 22150, loss = 0.0942654
I0514 16:41:43.696825 12912 solver.cpp:244]     Train net output #0: loss = 0.0942656 (* 1 = 0.0942656 loss)
I0514 16:41:43.696838 12912 sgd_solver.cpp:106] Iteration 22150, lr = 0.0005
I0514 16:42:21.634450 12912 solver.cpp:228] Iteration 22200, loss = 0.0529428
I0514 16:42:21.634598 12912 solver.cpp:244]     Train net output #0: loss = 0.052943 (* 1 = 0.052943 loss)
I0514 16:42:21.634611 12912 sgd_solver.cpp:106] Iteration 22200, lr = 0.0005
I0514 16:42:59.572007 12912 solver.cpp:228] Iteration 22250, loss = 0.0698804
I0514 16:42:59.572178 12912 solver.cpp:244]     Train net output #0: loss = 0.0698806 (* 1 = 0.0698806 loss)
I0514 16:42:59.572196 12912 sgd_solver.cpp:106] Iteration 22250, lr = 0.0005
I0514 16:43:37.507128 12912 solver.cpp:228] Iteration 22300, loss = 0.106291
I0514 16:43:37.507277 12912 solver.cpp:244]     Train net output #0: loss = 0.106291 (* 1 = 0.106291 loss)
I0514 16:43:37.507292 12912 sgd_solver.cpp:106] Iteration 22300, lr = 0.0005
I0514 16:44:15.441059 12912 solver.cpp:228] Iteration 22350, loss = 0.0218179
I0514 16:44:15.441232 12912 solver.cpp:244]     Train net output #0: loss = 0.0218181 (* 1 = 0.0218181 loss)
I0514 16:44:15.441246 12912 sgd_solver.cpp:106] Iteration 22350, lr = 0.0005
I0514 16:44:53.368526 12912 solver.cpp:228] Iteration 22400, loss = 0.0130529
I0514 16:44:53.368630 12912 solver.cpp:244]     Train net output #0: loss = 0.0130531 (* 1 = 0.0130531 loss)
I0514 16:44:53.368643 12912 sgd_solver.cpp:106] Iteration 22400, lr = 0.0005
I0514 16:45:31.303194 12912 solver.cpp:228] Iteration 22450, loss = 0.0632433
I0514 16:45:31.303311 12912 solver.cpp:244]     Train net output #0: loss = 0.0632436 (* 1 = 0.0632436 loss)
I0514 16:45:31.303329 12912 sgd_solver.cpp:106] Iteration 22450, lr = 0.0005
I0514 16:46:09.238378 12912 solver.cpp:228] Iteration 22500, loss = 0.103645
I0514 16:46:09.238574 12912 solver.cpp:244]     Train net output #0: loss = 0.103646 (* 1 = 0.103646 loss)
I0514 16:46:09.238589 12912 sgd_solver.cpp:106] Iteration 22500, lr = 0.0005
I0514 16:46:47.170794 12912 solver.cpp:228] Iteration 22550, loss = 0.106996
I0514 16:46:47.170946 12912 solver.cpp:244]     Train net output #0: loss = 0.106996 (* 1 = 0.106996 loss)
I0514 16:46:47.170958 12912 sgd_solver.cpp:106] Iteration 22550, lr = 0.0005
I0514 16:47:25.105687 12912 solver.cpp:228] Iteration 22600, loss = 0.100722
I0514 16:47:25.105794 12912 solver.cpp:244]     Train net output #0: loss = 0.100722 (* 1 = 0.100722 loss)
I0514 16:47:25.105813 12912 sgd_solver.cpp:106] Iteration 22600, lr = 0.0005
I0514 16:48:03.063707 12912 solver.cpp:228] Iteration 22650, loss = 0.106636
I0514 16:48:03.063838 12912 solver.cpp:244]     Train net output #0: loss = 0.106636 (* 1 = 0.106636 loss)
I0514 16:48:03.063853 12912 sgd_solver.cpp:106] Iteration 22650, lr = 0.0005
I0514 16:48:41.040545 12912 solver.cpp:228] Iteration 22700, loss = 0.063676
I0514 16:48:41.040732 12912 solver.cpp:244]     Train net output #0: loss = 0.0636765 (* 1 = 0.0636765 loss)
I0514 16:48:41.040750 12912 sgd_solver.cpp:106] Iteration 22700, lr = 0.0005
I0514 16:49:18.997521 12912 solver.cpp:228] Iteration 22750, loss = 0.133507
I0514 16:49:18.997633 12912 solver.cpp:244]     Train net output #0: loss = 0.133507 (* 1 = 0.133507 loss)
I0514 16:49:18.997647 12912 sgd_solver.cpp:106] Iteration 22750, lr = 0.0005
I0514 16:49:56.947525 12912 solver.cpp:228] Iteration 22800, loss = 0.0331407
I0514 16:49:56.947629 12912 solver.cpp:244]     Train net output #0: loss = 0.0331412 (* 1 = 0.0331412 loss)
I0514 16:49:56.947643 12912 sgd_solver.cpp:106] Iteration 22800, lr = 0.0005
I0514 16:50:34.886838 12912 solver.cpp:228] Iteration 22850, loss = 0.0331663
I0514 16:50:34.887022 12912 solver.cpp:244]     Train net output #0: loss = 0.0331667 (* 1 = 0.0331667 loss)
I0514 16:50:34.887040 12912 sgd_solver.cpp:106] Iteration 22850, lr = 0.0005
I0514 16:51:12.828876 12912 solver.cpp:228] Iteration 22900, loss = 0.149099
I0514 16:51:12.829001 12912 solver.cpp:244]     Train net output #0: loss = 0.1491 (* 1 = 0.1491 loss)
I0514 16:51:12.829025 12912 sgd_solver.cpp:106] Iteration 22900, lr = 0.0005
I0514 16:51:50.773964 12912 solver.cpp:228] Iteration 22950, loss = 0.218801
I0514 16:51:50.774116 12912 solver.cpp:244]     Train net output #0: loss = 0.218802 (* 1 = 0.218802 loss)
I0514 16:51:50.774130 12912 sgd_solver.cpp:106] Iteration 22950, lr = 0.0005
I0514 16:52:28.440608 12912 solver.cpp:454] Snapshotting to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_23000.caffemodel
I0514 16:52:28.999218 12912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_23000.solverstate
I0514 16:52:29.079727 12912 solver.cpp:337] Iteration 23000, Testing net (#0)
I0514 16:52:29.079787 12912 net.cpp:685] Ignoring source layer loss
I0514 16:54:12.240370 12912 solver.cpp:404]     Test net output #0: accuracy = 0.62
I0514 16:54:12.529443 12912 solver.cpp:228] Iteration 23000, loss = 0.037776
I0514 16:54:12.529510 12912 solver.cpp:244]     Train net output #0: loss = 0.0377765 (* 1 = 0.0377765 loss)
I0514 16:54:12.529525 12912 sgd_solver.cpp:106] Iteration 23000, lr = 0.0005
I0514 16:54:50.482630 12912 solver.cpp:228] Iteration 23050, loss = 0.138002
I0514 16:54:50.482798 12912 solver.cpp:244]     Train net output #0: loss = 0.138003 (* 1 = 0.138003 loss)
I0514 16:54:50.482820 12912 sgd_solver.cpp:106] Iteration 23050, lr = 0.0005
I0514 16:55:28.444728 12912 solver.cpp:228] Iteration 23100, loss = 0.0673655
I0514 16:55:28.444831 12912 solver.cpp:244]     Train net output #0: loss = 0.0673661 (* 1 = 0.0673661 loss)
I0514 16:55:28.444844 12912 sgd_solver.cpp:106] Iteration 23100, lr = 0.0005
I0514 16:56:06.402498 12912 solver.cpp:228] Iteration 23150, loss = 0.0494307
I0514 16:56:06.402673 12912 solver.cpp:244]     Train net output #0: loss = 0.0494312 (* 1 = 0.0494312 loss)
I0514 16:56:06.402714 12912 sgd_solver.cpp:106] Iteration 23150, lr = 0.0005
I0514 16:56:44.367794 12912 solver.cpp:228] Iteration 23200, loss = 0.0222633
I0514 16:56:44.367897 12912 solver.cpp:244]     Train net output #0: loss = 0.0222638 (* 1 = 0.0222638 loss)
I0514 16:56:44.367909 12912 sgd_solver.cpp:106] Iteration 23200, lr = 0.0005
I0514 16:57:22.326648 12912 solver.cpp:228] Iteration 23250, loss = 0.063708
I0514 16:57:22.326776 12912 solver.cpp:244]     Train net output #0: loss = 0.0637085 (* 1 = 0.0637085 loss)
I0514 16:57:22.326793 12912 sgd_solver.cpp:106] Iteration 23250, lr = 0.0005
I0514 16:58:00.306216 12912 solver.cpp:228] Iteration 23300, loss = 0.0328133
I0514 16:58:00.306350 12912 solver.cpp:244]     Train net output #0: loss = 0.0328138 (* 1 = 0.0328138 loss)
I0514 16:58:00.306367 12912 sgd_solver.cpp:106] Iteration 23300, lr = 0.0005
I0514 16:58:38.259215 12912 solver.cpp:228] Iteration 23350, loss = 0.309744
I0514 16:58:38.259321 12912 solver.cpp:244]     Train net output #0: loss = 0.309744 (* 1 = 0.309744 loss)
I0514 16:58:38.259333 12912 sgd_solver.cpp:106] Iteration 23350, lr = 0.0005
I0514 16:59:16.213343 12912 solver.cpp:228] Iteration 23400, loss = 0.0331463
I0514 16:59:16.213451 12912 solver.cpp:244]     Train net output #0: loss = 0.0331467 (* 1 = 0.0331467 loss)
I0514 16:59:16.213464 12912 sgd_solver.cpp:106] Iteration 23400, lr = 0.0005
I0514 16:59:54.169562 12912 solver.cpp:228] Iteration 23450, loss = 0.0550539
I0514 16:59:54.169685 12912 solver.cpp:244]     Train net output #0: loss = 0.0550544 (* 1 = 0.0550544 loss)
I0514 16:59:54.169703 12912 sgd_solver.cpp:106] Iteration 23450, lr = 0.0005
I0514 17:00:32.141607 12912 solver.cpp:228] Iteration 23500, loss = 0.0270669
I0514 17:00:32.141716 12912 solver.cpp:244]     Train net output #0: loss = 0.0270674 (* 1 = 0.0270674 loss)
I0514 17:00:32.141732 12912 sgd_solver.cpp:106] Iteration 23500, lr = 0.0005
I0514 17:01:10.109617 12912 solver.cpp:228] Iteration 23550, loss = 0.059533
I0514 17:01:10.109727 12912 solver.cpp:244]     Train net output #0: loss = 0.0595335 (* 1 = 0.0595335 loss)
I0514 17:01:10.109745 12912 sgd_solver.cpp:106] Iteration 23550, lr = 0.0005
I0514 17:01:48.070446 12912 solver.cpp:228] Iteration 23600, loss = 0.0434093
I0514 17:01:48.070619 12912 solver.cpp:244]     Train net output #0: loss = 0.0434098 (* 1 = 0.0434098 loss)
I0514 17:01:48.070636 12912 sgd_solver.cpp:106] Iteration 23600, lr = 0.0005
I0514 17:02:26.024814 12912 solver.cpp:228] Iteration 23650, loss = 0.0190654
I0514 17:02:26.024971 12912 solver.cpp:244]     Train net output #0: loss = 0.0190659 (* 1 = 0.0190659 loss)
I0514 17:02:26.024987 12912 sgd_solver.cpp:106] Iteration 23650, lr = 0.0005
I0514 17:03:03.983247 12912 solver.cpp:228] Iteration 23700, loss = 0.00960156
I0514 17:03:03.983352 12912 solver.cpp:244]     Train net output #0: loss = 0.00960203 (* 1 = 0.00960203 loss)
I0514 17:03:03.983364 12912 sgd_solver.cpp:106] Iteration 23700, lr = 0.0005
I0514 17:03:41.942304 12912 solver.cpp:228] Iteration 23750, loss = 0.0205892
I0514 17:03:41.942451 12912 solver.cpp:244]     Train net output #0: loss = 0.0205896 (* 1 = 0.0205896 loss)
I0514 17:03:41.942467 12912 sgd_solver.cpp:106] Iteration 23750, lr = 0.0005
I0514 17:04:19.910097 12912 solver.cpp:228] Iteration 23800, loss = 0.0527186
I0514 17:04:19.910236 12912 solver.cpp:244]     Train net output #0: loss = 0.052719 (* 1 = 0.052719 loss)
I0514 17:04:19.910255 12912 sgd_solver.cpp:106] Iteration 23800, lr = 0.0005
I0514 17:04:57.866050 12912 solver.cpp:228] Iteration 23850, loss = 0.0155693
I0514 17:04:57.866163 12912 solver.cpp:244]     Train net output #0: loss = 0.0155697 (* 1 = 0.0155697 loss)
I0514 17:04:57.866179 12912 sgd_solver.cpp:106] Iteration 23850, lr = 0.0005
I0514 17:05:35.833381 12912 solver.cpp:228] Iteration 23900, loss = 0.0147
I0514 17:05:35.833643 12912 solver.cpp:244]     Train net output #0: loss = 0.0147004 (* 1 = 0.0147004 loss)
I0514 17:05:35.833686 12912 sgd_solver.cpp:106] Iteration 23900, lr = 0.0005
I0514 17:06:13.791784 12912 solver.cpp:228] Iteration 23950, loss = 0.0330406
I0514 17:06:13.791913 12912 solver.cpp:244]     Train net output #0: loss = 0.033041 (* 1 = 0.033041 loss)
I0514 17:06:13.791925 12912 sgd_solver.cpp:106] Iteration 23950, lr = 0.0005
I0514 17:06:51.461536 12912 solver.cpp:454] Snapshotting to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_24000.caffemodel
I0514 17:06:51.658104 12912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_24000.solverstate
I0514 17:06:51.736640 12912 solver.cpp:337] Iteration 24000, Testing net (#0)
I0514 17:06:51.736701 12912 net.cpp:685] Ignoring source layer loss
I0514 17:08:34.094184 12912 solver.cpp:404]     Test net output #0: accuracy = 0.695294
I0514 17:08:34.383780 12912 solver.cpp:228] Iteration 24000, loss = 0.0130406
I0514 17:08:34.383827 12912 solver.cpp:244]     Train net output #0: loss = 0.013041 (* 1 = 0.013041 loss)
I0514 17:08:34.383836 12912 sgd_solver.cpp:106] Iteration 24000, lr = 0.0005
I0514 17:09:12.349776 12912 solver.cpp:228] Iteration 24050, loss = 0.0515758
I0514 17:09:12.349912 12912 solver.cpp:244]     Train net output #0: loss = 0.0515762 (* 1 = 0.0515762 loss)
I0514 17:09:12.349931 12912 sgd_solver.cpp:106] Iteration 24050, lr = 0.0005
I0514 17:09:50.326840 12912 solver.cpp:228] Iteration 24100, loss = 0.0218997
I0514 17:09:50.326992 12912 solver.cpp:244]     Train net output #0: loss = 0.0219001 (* 1 = 0.0219001 loss)
I0514 17:09:50.327009 12912 sgd_solver.cpp:106] Iteration 24100, lr = 0.0005
I0514 17:10:28.298640 12912 solver.cpp:228] Iteration 24150, loss = 0.0498057
I0514 17:10:28.298805 12912 solver.cpp:244]     Train net output #0: loss = 0.0498062 (* 1 = 0.0498062 loss)
I0514 17:10:28.298825 12912 sgd_solver.cpp:106] Iteration 24150, lr = 0.0005
I0514 17:11:06.254770 12912 solver.cpp:228] Iteration 24200, loss = 0.0984177
I0514 17:11:06.254953 12912 solver.cpp:244]     Train net output #0: loss = 0.0984181 (* 1 = 0.0984181 loss)
I0514 17:11:06.255002 12912 sgd_solver.cpp:106] Iteration 24200, lr = 0.0005
I0514 17:11:44.223815 12912 solver.cpp:228] Iteration 24250, loss = 0.0394404
I0514 17:11:44.223914 12912 solver.cpp:244]     Train net output #0: loss = 0.0394409 (* 1 = 0.0394409 loss)
I0514 17:11:44.223927 12912 sgd_solver.cpp:106] Iteration 24250, lr = 0.0005
I0514 17:12:22.173321 12912 solver.cpp:228] Iteration 24300, loss = 0.0901643
I0514 17:12:22.173423 12912 solver.cpp:244]     Train net output #0: loss = 0.0901647 (* 1 = 0.0901647 loss)
I0514 17:12:22.173434 12912 sgd_solver.cpp:106] Iteration 24300, lr = 0.0005
I0514 17:13:00.133262 12912 solver.cpp:228] Iteration 24350, loss = 0.0305947
I0514 17:13:00.133381 12912 solver.cpp:244]     Train net output #0: loss = 0.0305951 (* 1 = 0.0305951 loss)
I0514 17:13:00.133401 12912 sgd_solver.cpp:106] Iteration 24350, lr = 0.0005
I0514 17:13:38.095105 12912 solver.cpp:228] Iteration 24400, loss = 0.0833394
I0514 17:13:38.095219 12912 solver.cpp:244]     Train net output #0: loss = 0.0833398 (* 1 = 0.0833398 loss)
I0514 17:13:38.095239 12912 sgd_solver.cpp:106] Iteration 24400, lr = 0.0005
I0514 17:14:16.106416 12912 solver.cpp:228] Iteration 24450, loss = 0.0157232
I0514 17:14:16.106540 12912 solver.cpp:244]     Train net output #0: loss = 0.0157235 (* 1 = 0.0157235 loss)
I0514 17:14:16.106554 12912 sgd_solver.cpp:106] Iteration 24450, lr = 0.0005
I0514 17:14:54.098410 12912 solver.cpp:228] Iteration 24500, loss = 0.0684971
I0514 17:14:54.098593 12912 solver.cpp:244]     Train net output #0: loss = 0.0684974 (* 1 = 0.0684974 loss)
I0514 17:14:54.098664 12912 sgd_solver.cpp:106] Iteration 24500, lr = 0.0005
I0514 17:15:32.087858 12912 solver.cpp:228] Iteration 24550, loss = 0.0841849
I0514 17:15:32.088049 12912 solver.cpp:244]     Train net output #0: loss = 0.0841852 (* 1 = 0.0841852 loss)
I0514 17:15:32.088090 12912 sgd_solver.cpp:106] Iteration 24550, lr = 0.0005
I0514 17:16:10.041839 12912 solver.cpp:228] Iteration 24600, loss = 0.054414
I0514 17:16:10.041951 12912 solver.cpp:244]     Train net output #0: loss = 0.0544143 (* 1 = 0.0544143 loss)
I0514 17:16:10.041970 12912 sgd_solver.cpp:106] Iteration 24600, lr = 0.0005
I0514 17:16:47.993234 12912 solver.cpp:228] Iteration 24650, loss = 0.0172441
I0514 17:16:47.993382 12912 solver.cpp:244]     Train net output #0: loss = 0.0172444 (* 1 = 0.0172444 loss)
I0514 17:16:47.993394 12912 sgd_solver.cpp:106] Iteration 24650, lr = 0.0005
I0514 17:17:25.969281 12912 solver.cpp:228] Iteration 24700, loss = 0.0489206
I0514 17:17:25.969395 12912 solver.cpp:244]     Train net output #0: loss = 0.0489209 (* 1 = 0.0489209 loss)
I0514 17:17:25.969413 12912 sgd_solver.cpp:106] Iteration 24700, lr = 0.0005
I0514 17:18:03.922523 12912 solver.cpp:228] Iteration 24750, loss = 0.0410852
I0514 17:18:03.922698 12912 solver.cpp:244]     Train net output #0: loss = 0.0410855 (* 1 = 0.0410855 loss)
I0514 17:18:03.922718 12912 sgd_solver.cpp:106] Iteration 24750, lr = 0.0005
I0514 17:18:41.897615 12912 solver.cpp:228] Iteration 24800, loss = 0.0215857
I0514 17:18:41.897748 12912 solver.cpp:244]     Train net output #0: loss = 0.021586 (* 1 = 0.021586 loss)
I0514 17:18:41.897766 12912 sgd_solver.cpp:106] Iteration 24800, lr = 0.0005
I0514 17:19:19.863716 12912 solver.cpp:228] Iteration 24850, loss = 0.0236334
I0514 17:19:19.863869 12912 solver.cpp:244]     Train net output #0: loss = 0.0236337 (* 1 = 0.0236337 loss)
I0514 17:19:19.863891 12912 sgd_solver.cpp:106] Iteration 24850, lr = 0.0005
I0514 17:19:57.828094 12912 solver.cpp:228] Iteration 24900, loss = 0.0873364
I0514 17:19:57.828268 12912 solver.cpp:244]     Train net output #0: loss = 0.0873366 (* 1 = 0.0873366 loss)
I0514 17:19:57.828313 12912 sgd_solver.cpp:106] Iteration 24900, lr = 0.0005
I0514 17:20:35.800202 12912 solver.cpp:228] Iteration 24950, loss = 0.0848218
I0514 17:20:35.800391 12912 solver.cpp:244]     Train net output #0: loss = 0.084822 (* 1 = 0.084822 loss)
I0514 17:20:35.800410 12912 sgd_solver.cpp:106] Iteration 24950, lr = 0.0005
I0514 17:21:13.621870 12912 solver.cpp:454] Snapshotting to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_25000.caffemodel
I0514 17:21:13.889281 12912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_25000.solverstate
I0514 17:21:13.985858 12912 solver.cpp:337] Iteration 25000, Testing net (#0)
I0514 17:21:13.986443 12912 net.cpp:685] Ignoring source layer loss
I0514 17:23:03.885047 12912 solver.cpp:404]     Test net output #0: accuracy = 0.693382
I0514 17:23:04.175202 12912 solver.cpp:228] Iteration 25000, loss = 0.0149021
I0514 17:23:04.175249 12912 solver.cpp:244]     Train net output #0: loss = 0.0149023 (* 1 = 0.0149023 loss)
I0514 17:23:04.175261 12912 sgd_solver.cpp:106] Iteration 25000, lr = 0.0005
I0514 17:23:42.123432 12912 solver.cpp:228] Iteration 25050, loss = 0.013219
I0514 17:23:42.123589 12912 solver.cpp:244]     Train net output #0: loss = 0.0132192 (* 1 = 0.0132192 loss)
I0514 17:23:42.123608 12912 sgd_solver.cpp:106] Iteration 25050, lr = 0.0005
I0514 17:24:20.102149 12912 solver.cpp:228] Iteration 25100, loss = 0.0875942
I0514 17:24:20.102334 12912 solver.cpp:244]     Train net output #0: loss = 0.0875944 (* 1 = 0.0875944 loss)
I0514 17:24:20.102375 12912 sgd_solver.cpp:106] Iteration 25100, lr = 0.0005
I0514 17:24:58.073647 12912 solver.cpp:228] Iteration 25150, loss = 0.0275664
I0514 17:24:58.073807 12912 solver.cpp:244]     Train net output #0: loss = 0.0275666 (* 1 = 0.0275666 loss)
I0514 17:24:58.073832 12912 sgd_solver.cpp:106] Iteration 25150, lr = 0.0005
I0514 17:25:36.044380 12912 solver.cpp:228] Iteration 25200, loss = 0.0213076
I0514 17:25:36.044621 12912 solver.cpp:244]     Train net output #0: loss = 0.0213078 (* 1 = 0.0213078 loss)
I0514 17:25:36.044648 12912 sgd_solver.cpp:106] Iteration 25200, lr = 0.0005
I0514 17:26:13.993968 12912 solver.cpp:228] Iteration 25250, loss = 0.0638201
I0514 17:26:13.994123 12912 solver.cpp:244]     Train net output #0: loss = 0.0638203 (* 1 = 0.0638203 loss)
I0514 17:26:13.994150 12912 sgd_solver.cpp:106] Iteration 25250, lr = 0.0005
I0514 17:26:51.941413 12912 solver.cpp:228] Iteration 25300, loss = 0.0173821
I0514 17:26:51.941526 12912 solver.cpp:244]     Train net output #0: loss = 0.0173824 (* 1 = 0.0173824 loss)
I0514 17:26:51.941539 12912 sgd_solver.cpp:106] Iteration 25300, lr = 0.0005
I0514 17:27:29.902217 12912 solver.cpp:228] Iteration 25350, loss = 0.0538777
I0514 17:27:29.902365 12912 solver.cpp:244]     Train net output #0: loss = 0.0538779 (* 1 = 0.0538779 loss)
I0514 17:27:29.902384 12912 sgd_solver.cpp:106] Iteration 25350, lr = 0.0005
I0514 17:28:07.867842 12912 solver.cpp:228] Iteration 25400, loss = 0.0311913
I0514 17:28:07.867979 12912 solver.cpp:244]     Train net output #0: loss = 0.0311915 (* 1 = 0.0311915 loss)
I0514 17:28:07.867995 12912 sgd_solver.cpp:106] Iteration 25400, lr = 0.0005
I0514 17:28:45.831135 12912 solver.cpp:228] Iteration 25450, loss = 0.0360365
I0514 17:28:45.838141 12912 solver.cpp:244]     Train net output #0: loss = 0.0360367 (* 1 = 0.0360367 loss)
I0514 17:28:45.838174 12912 sgd_solver.cpp:106] Iteration 25450, lr = 0.0005
I0514 17:29:23.788836 12912 solver.cpp:228] Iteration 25500, loss = 0.0446616
I0514 17:29:23.789049 12912 solver.cpp:244]     Train net output #0: loss = 0.0446618 (* 1 = 0.0446618 loss)
I0514 17:29:23.789070 12912 sgd_solver.cpp:106] Iteration 25500, lr = 0.0005
I0514 17:30:01.769279 12912 solver.cpp:228] Iteration 25550, loss = 0.0248046
I0514 17:30:01.770257 12912 solver.cpp:244]     Train net output #0: loss = 0.0248048 (* 1 = 0.0248048 loss)
I0514 17:30:01.770292 12912 sgd_solver.cpp:106] Iteration 25550, lr = 0.0005
I0514 17:30:39.730134 12912 solver.cpp:228] Iteration 25600, loss = 0.0283396
I0514 17:30:39.730284 12912 solver.cpp:244]     Train net output #0: loss = 0.0283399 (* 1 = 0.0283399 loss)
I0514 17:30:39.730301 12912 sgd_solver.cpp:106] Iteration 25600, lr = 0.0005
I0514 17:31:17.690485 12912 solver.cpp:228] Iteration 25650, loss = 0.0358331
I0514 17:31:17.690593 12912 solver.cpp:244]     Train net output #0: loss = 0.0358334 (* 1 = 0.0358334 loss)
I0514 17:31:17.690606 12912 sgd_solver.cpp:106] Iteration 25650, lr = 0.0005
I0514 17:31:55.646401 12912 solver.cpp:228] Iteration 25700, loss = 0.0202453
I0514 17:31:55.646549 12912 solver.cpp:244]     Train net output #0: loss = 0.0202455 (* 1 = 0.0202455 loss)
I0514 17:31:55.646564 12912 sgd_solver.cpp:106] Iteration 25700, lr = 0.0005
I0514 17:32:33.597410 12912 solver.cpp:228] Iteration 25750, loss = 0.0143927
I0514 17:32:33.597563 12912 solver.cpp:244]     Train net output #0: loss = 0.0143929 (* 1 = 0.0143929 loss)
I0514 17:32:33.597575 12912 sgd_solver.cpp:106] Iteration 25750, lr = 0.0005
I0514 17:33:11.561154 12912 solver.cpp:228] Iteration 25800, loss = 0.0310414
I0514 17:33:11.561305 12912 solver.cpp:244]     Train net output #0: loss = 0.0310417 (* 1 = 0.0310417 loss)
I0514 17:33:11.561326 12912 sgd_solver.cpp:106] Iteration 25800, lr = 0.0005
I0514 17:33:49.541594 12912 solver.cpp:228] Iteration 25850, loss = 0.0570187
I0514 17:33:49.541731 12912 solver.cpp:244]     Train net output #0: loss = 0.057019 (* 1 = 0.057019 loss)
I0514 17:33:49.541745 12912 sgd_solver.cpp:106] Iteration 25850, lr = 0.0005
I0514 17:34:27.497795 12912 solver.cpp:228] Iteration 25900, loss = 0.218926
I0514 17:34:27.497911 12912 solver.cpp:244]     Train net output #0: loss = 0.218926 (* 1 = 0.218926 loss)
I0514 17:34:27.497931 12912 sgd_solver.cpp:106] Iteration 25900, lr = 0.0005
I0514 17:35:05.460760 12912 solver.cpp:228] Iteration 25950, loss = 0.231477
I0514 17:35:05.460919 12912 solver.cpp:244]     Train net output #0: loss = 0.231477 (* 1 = 0.231477 loss)
I0514 17:35:05.460940 12912 sgd_solver.cpp:106] Iteration 25950, lr = 0.0005
I0514 17:35:43.115914 12912 solver.cpp:454] Snapshotting to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_26000.caffemodel
I0514 17:35:43.902384 12912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_26000.solverstate
I0514 17:35:44.043421 12912 solver.cpp:337] Iteration 26000, Testing net (#0)
I0514 17:35:44.044584 12912 net.cpp:685] Ignoring source layer loss
I0514 17:37:33.265750 12912 solver.cpp:404]     Test net output #0: accuracy = 0.623529
I0514 17:37:33.555387 12912 solver.cpp:228] Iteration 26000, loss = 0.0352833
I0514 17:37:33.555443 12912 solver.cpp:244]     Train net output #0: loss = 0.0352836 (* 1 = 0.0352836 loss)
I0514 17:37:33.555459 12912 sgd_solver.cpp:106] Iteration 26000, lr = 0.0005
I0514 17:38:11.514464 12912 solver.cpp:228] Iteration 26050, loss = 0.174053
I0514 17:38:11.514633 12912 solver.cpp:244]     Train net output #0: loss = 0.174053 (* 1 = 0.174053 loss)
I0514 17:38:11.514647 12912 sgd_solver.cpp:106] Iteration 26050, lr = 0.0005
I0514 17:38:49.473078 12912 solver.cpp:228] Iteration 26100, loss = 0.0207305
I0514 17:38:49.473203 12912 solver.cpp:244]     Train net output #0: loss = 0.0207307 (* 1 = 0.0207307 loss)
I0514 17:38:49.473217 12912 sgd_solver.cpp:106] Iteration 26100, lr = 0.0005
I0514 17:39:27.443630 12912 solver.cpp:228] Iteration 26150, loss = 0.0230314
I0514 17:39:27.443815 12912 solver.cpp:244]     Train net output #0: loss = 0.0230317 (* 1 = 0.0230317 loss)
I0514 17:39:27.443833 12912 sgd_solver.cpp:106] Iteration 26150, lr = 0.0005
I0514 17:40:05.420334 12912 solver.cpp:228] Iteration 26200, loss = 0.0245397
I0514 17:40:05.420475 12912 solver.cpp:244]     Train net output #0: loss = 0.02454 (* 1 = 0.02454 loss)
I0514 17:40:05.420491 12912 sgd_solver.cpp:106] Iteration 26200, lr = 0.0005
I0514 17:40:43.373879 12912 solver.cpp:228] Iteration 26250, loss = 0.0220222
I0514 17:40:43.374001 12912 solver.cpp:244]     Train net output #0: loss = 0.0220224 (* 1 = 0.0220224 loss)
I0514 17:40:43.374014 12912 sgd_solver.cpp:106] Iteration 26250, lr = 0.0005
I0514 17:41:21.318191 12912 solver.cpp:228] Iteration 26300, loss = 0.0410758
I0514 17:41:21.318333 12912 solver.cpp:244]     Train net output #0: loss = 0.0410761 (* 1 = 0.0410761 loss)
I0514 17:41:21.318351 12912 sgd_solver.cpp:106] Iteration 26300, lr = 0.0005
I0514 17:41:59.286463 12912 solver.cpp:228] Iteration 26350, loss = 0.0326106
I0514 17:41:59.287386 12912 solver.cpp:244]     Train net output #0: loss = 0.0326108 (* 1 = 0.0326108 loss)
I0514 17:41:59.287400 12912 sgd_solver.cpp:106] Iteration 26350, lr = 0.0005
I0514 17:42:37.238384 12912 solver.cpp:228] Iteration 26400, loss = 0.0560758
I0514 17:42:37.238584 12912 solver.cpp:244]     Train net output #0: loss = 0.056076 (* 1 = 0.056076 loss)
I0514 17:42:37.238598 12912 sgd_solver.cpp:106] Iteration 26400, lr = 0.0005
I0514 17:43:15.174901 12912 solver.cpp:228] Iteration 26450, loss = 0.0220099
I0514 17:43:15.175034 12912 solver.cpp:244]     Train net output #0: loss = 0.0220102 (* 1 = 0.0220102 loss)
I0514 17:43:15.175047 12912 sgd_solver.cpp:106] Iteration 26450, lr = 0.0005
I0514 17:43:53.131649 12912 solver.cpp:228] Iteration 26500, loss = 0.064392
I0514 17:43:53.131768 12912 solver.cpp:244]     Train net output #0: loss = 0.0643922 (* 1 = 0.0643922 loss)
I0514 17:43:53.131780 12912 sgd_solver.cpp:106] Iteration 26500, lr = 0.0005
I0514 17:44:31.089622 12912 solver.cpp:228] Iteration 26550, loss = 0.0342004
I0514 17:44:31.089920 12912 solver.cpp:244]     Train net output #0: loss = 0.0342007 (* 1 = 0.0342007 loss)
I0514 17:44:31.089943 12912 sgd_solver.cpp:106] Iteration 26550, lr = 0.0005
I0514 17:45:09.037169 12912 solver.cpp:228] Iteration 26600, loss = 0.0540816
I0514 17:45:09.037286 12912 solver.cpp:244]     Train net output #0: loss = 0.0540818 (* 1 = 0.0540818 loss)
I0514 17:45:09.037299 12912 sgd_solver.cpp:106] Iteration 26600, lr = 0.0005
I0514 17:45:46.999176 12912 solver.cpp:228] Iteration 26650, loss = 0.0240174
I0514 17:45:46.999348 12912 solver.cpp:244]     Train net output #0: loss = 0.0240176 (* 1 = 0.0240176 loss)
I0514 17:45:46.999363 12912 sgd_solver.cpp:106] Iteration 26650, lr = 0.0005
I0514 17:46:24.966526 12912 solver.cpp:228] Iteration 26700, loss = 0.0673934
I0514 17:46:24.966642 12912 solver.cpp:244]     Train net output #0: loss = 0.0673936 (* 1 = 0.0673936 loss)
I0514 17:46:24.966656 12912 sgd_solver.cpp:106] Iteration 26700, lr = 0.0005
I0514 17:47:02.926878 12912 solver.cpp:228] Iteration 26750, loss = 0.0142649
I0514 17:47:02.926982 12912 solver.cpp:244]     Train net output #0: loss = 0.0142651 (* 1 = 0.0142651 loss)
I0514 17:47:02.926995 12912 sgd_solver.cpp:106] Iteration 26750, lr = 0.0005
I0514 17:47:40.850855 12912 solver.cpp:228] Iteration 26800, loss = 0.0299902
I0514 17:47:40.851032 12912 solver.cpp:244]     Train net output #0: loss = 0.0299904 (* 1 = 0.0299904 loss)
I0514 17:47:40.851044 12912 sgd_solver.cpp:106] Iteration 26800, lr = 0.0005
I0514 17:48:17.746733 12912 solver.cpp:228] Iteration 26850, loss = 0.0448356
I0514 17:48:17.746850 12912 solver.cpp:244]     Train net output #0: loss = 0.0448359 (* 1 = 0.0448359 loss)
I0514 17:48:17.746861 12912 sgd_solver.cpp:106] Iteration 26850, lr = 0.0005
I0514 17:48:55.278448 12912 solver.cpp:228] Iteration 26900, loss = 0.0203123
I0514 17:48:55.278554 12912 solver.cpp:244]     Train net output #0: loss = 0.0203125 (* 1 = 0.0203125 loss)
I0514 17:48:55.278573 12912 sgd_solver.cpp:106] Iteration 26900, lr = 0.0005
I0514 17:49:33.230617 12912 solver.cpp:228] Iteration 26950, loss = 0.0205939
I0514 17:49:33.230747 12912 solver.cpp:244]     Train net output #0: loss = 0.0205942 (* 1 = 0.0205942 loss)
I0514 17:49:33.230761 12912 sgd_solver.cpp:106] Iteration 26950, lr = 0.0005
I0514 17:50:10.902170 12912 solver.cpp:454] Snapshotting to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_27000.caffemodel
I0514 17:50:11.241705 12912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_27000.solverstate
I0514 17:50:11.380132 12912 solver.cpp:337] Iteration 27000, Testing net (#0)
I0514 17:50:11.381000 12912 net.cpp:685] Ignoring source layer loss
I0514 17:51:54.324434 12912 solver.cpp:404]     Test net output #0: accuracy = 0.690882
I0514 17:51:54.614231 12912 solver.cpp:228] Iteration 27000, loss = 0.0309295
I0514 17:51:54.614300 12912 solver.cpp:244]     Train net output #0: loss = 0.0309297 (* 1 = 0.0309297 loss)
I0514 17:51:54.614310 12912 sgd_solver.cpp:106] Iteration 27000, lr = 0.0005
I0514 17:52:32.573570 12912 solver.cpp:228] Iteration 27050, loss = 0.0272582
I0514 17:52:32.573757 12912 solver.cpp:244]     Train net output #0: loss = 0.0272584 (* 1 = 0.0272584 loss)
I0514 17:52:32.573772 12912 sgd_solver.cpp:106] Iteration 27050, lr = 0.0005
I0514 17:53:10.530238 12912 solver.cpp:228] Iteration 27100, loss = 0.0301787
I0514 17:53:10.530395 12912 solver.cpp:244]     Train net output #0: loss = 0.0301789 (* 1 = 0.0301789 loss)
I0514 17:53:10.530406 12912 sgd_solver.cpp:106] Iteration 27100, lr = 0.0005
I0514 17:53:48.480903 12912 solver.cpp:228] Iteration 27150, loss = 0.0610662
I0514 17:53:48.481061 12912 solver.cpp:244]     Train net output #0: loss = 0.0610664 (* 1 = 0.0610664 loss)
I0514 17:53:48.481075 12912 sgd_solver.cpp:106] Iteration 27150, lr = 0.0005
I0514 17:54:26.433629 12912 solver.cpp:228] Iteration 27200, loss = 0.0613072
I0514 17:54:26.433773 12912 solver.cpp:244]     Train net output #0: loss = 0.0613074 (* 1 = 0.0613074 loss)
I0514 17:54:26.433784 12912 sgd_solver.cpp:106] Iteration 27200, lr = 0.0005
I0514 17:55:04.393204 12912 solver.cpp:228] Iteration 27250, loss = 0.00790843
I0514 17:55:04.393352 12912 solver.cpp:244]     Train net output #0: loss = 0.00790867 (* 1 = 0.00790867 loss)
I0514 17:55:04.393364 12912 sgd_solver.cpp:106] Iteration 27250, lr = 0.0005
I0514 17:55:42.361057 12912 solver.cpp:228] Iteration 27300, loss = 0.0499529
I0514 17:55:42.361233 12912 solver.cpp:244]     Train net output #0: loss = 0.0499531 (* 1 = 0.0499531 loss)
I0514 17:55:42.361248 12912 sgd_solver.cpp:106] Iteration 27300, lr = 0.0005
I0514 17:56:20.321768 12912 solver.cpp:228] Iteration 27350, loss = 0.0123281
I0514 17:56:20.321900 12912 solver.cpp:244]     Train net output #0: loss = 0.0123284 (* 1 = 0.0123284 loss)
I0514 17:56:20.321913 12912 sgd_solver.cpp:106] Iteration 27350, lr = 0.0005
I0514 17:56:58.282110 12912 solver.cpp:228] Iteration 27400, loss = 0.0140134
I0514 17:56:58.282228 12912 solver.cpp:244]     Train net output #0: loss = 0.0140136 (* 1 = 0.0140136 loss)
I0514 17:56:58.282240 12912 sgd_solver.cpp:106] Iteration 27400, lr = 0.0005
I0514 17:57:36.233315 12912 solver.cpp:228] Iteration 27450, loss = 0.0382135
I0514 17:57:36.233461 12912 solver.cpp:244]     Train net output #0: loss = 0.0382137 (* 1 = 0.0382137 loss)
I0514 17:57:36.233474 12912 sgd_solver.cpp:106] Iteration 27450, lr = 0.0005
I0514 17:58:14.175994 12912 solver.cpp:228] Iteration 27500, loss = 0.0285651
I0514 17:58:14.176116 12912 solver.cpp:244]     Train net output #0: loss = 0.0285653 (* 1 = 0.0285653 loss)
I0514 17:58:14.176129 12912 sgd_solver.cpp:106] Iteration 27500, lr = 0.0005
I0514 17:58:52.123659 12912 solver.cpp:228] Iteration 27550, loss = 0.0156375
I0514 17:58:52.123826 12912 solver.cpp:244]     Train net output #0: loss = 0.0156378 (* 1 = 0.0156378 loss)
I0514 17:58:52.123841 12912 sgd_solver.cpp:106] Iteration 27550, lr = 0.0005
I0514 17:59:30.081959 12912 solver.cpp:228] Iteration 27600, loss = 0.0420791
I0514 17:59:30.082087 12912 solver.cpp:244]     Train net output #0: loss = 0.0420794 (* 1 = 0.0420794 loss)
I0514 17:59:30.082100 12912 sgd_solver.cpp:106] Iteration 27600, lr = 0.0005
I0514 18:00:08.026006 12912 solver.cpp:228] Iteration 27650, loss = 0.0234329
I0514 18:00:08.026154 12912 solver.cpp:244]     Train net output #0: loss = 0.0234331 (* 1 = 0.0234331 loss)
I0514 18:00:08.026166 12912 sgd_solver.cpp:106] Iteration 27650, lr = 0.0005
I0514 18:00:45.994607 12912 solver.cpp:228] Iteration 27700, loss = 0.216799
I0514 18:00:45.994771 12912 solver.cpp:244]     Train net output #0: loss = 0.216799 (* 1 = 0.216799 loss)
I0514 18:00:45.994784 12912 sgd_solver.cpp:106] Iteration 27700, lr = 0.0005
I0514 18:01:23.967133 12912 solver.cpp:228] Iteration 27750, loss = 0.0159767
I0514 18:01:23.967308 12912 solver.cpp:244]     Train net output #0: loss = 0.0159769 (* 1 = 0.0159769 loss)
I0514 18:01:23.967325 12912 sgd_solver.cpp:106] Iteration 27750, lr = 0.0005
I0514 18:02:01.926901 12912 solver.cpp:228] Iteration 27800, loss = 0.0176262
I0514 18:02:01.927048 12912 solver.cpp:244]     Train net output #0: loss = 0.0176265 (* 1 = 0.0176265 loss)
I0514 18:02:01.927062 12912 sgd_solver.cpp:106] Iteration 27800, lr = 0.0005
I0514 18:02:39.878489 12912 solver.cpp:228] Iteration 27850, loss = 0.0722743
I0514 18:02:39.878592 12912 solver.cpp:244]     Train net output #0: loss = 0.0722745 (* 1 = 0.0722745 loss)
I0514 18:02:39.878604 12912 sgd_solver.cpp:106] Iteration 27850, lr = 0.0005
I0514 18:03:17.831889 12912 solver.cpp:228] Iteration 27900, loss = 0.0103551
I0514 18:03:17.832010 12912 solver.cpp:244]     Train net output #0: loss = 0.0103553 (* 1 = 0.0103553 loss)
I0514 18:03:17.832023 12912 sgd_solver.cpp:106] Iteration 27900, lr = 0.0005
I0514 18:03:55.787577 12912 solver.cpp:228] Iteration 27950, loss = 0.00785352
I0514 18:03:55.787686 12912 solver.cpp:244]     Train net output #0: loss = 0.00785376 (* 1 = 0.00785376 loss)
I0514 18:03:55.787698 12912 sgd_solver.cpp:106] Iteration 27950, lr = 0.0005
I0514 18:04:33.451676 12912 solver.cpp:454] Snapshotting to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_28000.caffemodel
I0514 18:04:33.648794 12912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_28000.solverstate
I0514 18:04:33.736666 12912 solver.cpp:337] Iteration 28000, Testing net (#0)
I0514 18:04:33.736733 12912 net.cpp:685] Ignoring source layer loss
I0514 18:06:15.938416 12912 solver.cpp:404]     Test net output #0: accuracy = 0.644853
I0514 18:06:16.228601 12912 solver.cpp:228] Iteration 28000, loss = 0.0127736
I0514 18:06:16.228653 12912 solver.cpp:244]     Train net output #0: loss = 0.0127739 (* 1 = 0.0127739 loss)
I0514 18:06:16.228668 12912 sgd_solver.cpp:106] Iteration 28000, lr = 0.0005
I0514 18:06:54.181463 12912 solver.cpp:228] Iteration 28050, loss = 0.0238642
I0514 18:06:54.181591 12912 solver.cpp:244]     Train net output #0: loss = 0.0238645 (* 1 = 0.0238645 loss)
I0514 18:06:54.181602 12912 sgd_solver.cpp:106] Iteration 28050, lr = 0.0005
I0514 18:07:32.130429 12912 solver.cpp:228] Iteration 28100, loss = 0.0119878
I0514 18:07:32.130548 12912 solver.cpp:244]     Train net output #0: loss = 0.0119881 (* 1 = 0.0119881 loss)
I0514 18:07:32.130559 12912 sgd_solver.cpp:106] Iteration 28100, lr = 0.0005
I0514 18:08:10.097039 12912 solver.cpp:228] Iteration 28150, loss = 0.0395169
I0514 18:08:10.097172 12912 solver.cpp:244]     Train net output #0: loss = 0.0395172 (* 1 = 0.0395172 loss)
I0514 18:08:10.097184 12912 sgd_solver.cpp:106] Iteration 28150, lr = 0.0005
I0514 18:08:48.050623 12912 solver.cpp:228] Iteration 28200, loss = 0.0861336
I0514 18:08:48.050803 12912 solver.cpp:244]     Train net output #0: loss = 0.0861339 (* 1 = 0.0861339 loss)
I0514 18:08:48.050819 12912 sgd_solver.cpp:106] Iteration 28200, lr = 0.0005
I0514 18:09:26.001420 12912 solver.cpp:228] Iteration 28250, loss = 0.10864
I0514 18:09:26.001572 12912 solver.cpp:244]     Train net output #0: loss = 0.10864 (* 1 = 0.10864 loss)
I0514 18:09:26.001583 12912 sgd_solver.cpp:106] Iteration 28250, lr = 0.0005
I0514 18:10:03.950176 12912 solver.cpp:228] Iteration 28300, loss = 0.0212879
I0514 18:10:03.950300 12912 solver.cpp:244]     Train net output #0: loss = 0.0212881 (* 1 = 0.0212881 loss)
I0514 18:10:03.950314 12912 sgd_solver.cpp:106] Iteration 28300, lr = 0.0005
I0514 18:10:41.889269 12912 solver.cpp:228] Iteration 28350, loss = 0.0181654
I0514 18:10:41.889410 12912 solver.cpp:244]     Train net output #0: loss = 0.0181656 (* 1 = 0.0181656 loss)
I0514 18:10:41.889423 12912 sgd_solver.cpp:106] Iteration 28350, lr = 0.0005
I0514 18:11:19.837235 12912 solver.cpp:228] Iteration 28400, loss = 0.00880204
I0514 18:11:19.837383 12912 solver.cpp:244]     Train net output #0: loss = 0.0088023 (* 1 = 0.0088023 loss)
I0514 18:11:19.837398 12912 sgd_solver.cpp:106] Iteration 28400, lr = 0.0005
I0514 18:11:57.798378 12912 solver.cpp:228] Iteration 28450, loss = 0.012998
I0514 18:11:57.798612 12912 solver.cpp:244]     Train net output #0: loss = 0.0129983 (* 1 = 0.0129983 loss)
I0514 18:11:57.798655 12912 sgd_solver.cpp:106] Iteration 28450, lr = 0.0005
I0514 18:12:35.732585 12912 solver.cpp:228] Iteration 28500, loss = 0.0227596
I0514 18:12:35.732703 12912 solver.cpp:244]     Train net output #0: loss = 0.0227598 (* 1 = 0.0227598 loss)
I0514 18:12:35.732720 12912 sgd_solver.cpp:106] Iteration 28500, lr = 0.0005
I0514 18:13:13.686954 12912 solver.cpp:228] Iteration 28550, loss = 0.00860284
I0514 18:13:13.687120 12912 solver.cpp:244]     Train net output #0: loss = 0.00860309 (* 1 = 0.00860309 loss)
I0514 18:13:13.687140 12912 sgd_solver.cpp:106] Iteration 28550, lr = 0.0005
I0514 18:13:51.633646 12912 solver.cpp:228] Iteration 28600, loss = 0.0235924
I0514 18:13:51.633790 12912 solver.cpp:244]     Train net output #0: loss = 0.0235926 (* 1 = 0.0235926 loss)
I0514 18:13:51.633801 12912 sgd_solver.cpp:106] Iteration 28600, lr = 0.0005
I0514 18:14:29.591075 12912 solver.cpp:228] Iteration 28650, loss = 0.0293004
I0514 18:14:29.591222 12912 solver.cpp:244]     Train net output #0: loss = 0.0293007 (* 1 = 0.0293007 loss)
I0514 18:14:29.591235 12912 sgd_solver.cpp:106] Iteration 28650, lr = 0.0005
I0514 18:15:07.548014 12912 solver.cpp:228] Iteration 28700, loss = 0.0550487
I0514 18:15:07.548123 12912 solver.cpp:244]     Train net output #0: loss = 0.055049 (* 1 = 0.055049 loss)
I0514 18:15:07.548142 12912 sgd_solver.cpp:106] Iteration 28700, lr = 0.0005
I0514 18:15:45.507374 12912 solver.cpp:228] Iteration 28750, loss = 0.00739569
I0514 18:15:45.507513 12912 solver.cpp:244]     Train net output #0: loss = 0.00739594 (* 1 = 0.00739594 loss)
I0514 18:15:45.507532 12912 sgd_solver.cpp:106] Iteration 28750, lr = 0.0005
I0514 18:16:23.470537 12912 solver.cpp:228] Iteration 28800, loss = 0.0296432
I0514 18:16:23.470675 12912 solver.cpp:244]     Train net output #0: loss = 0.0296434 (* 1 = 0.0296434 loss)
I0514 18:16:23.470688 12912 sgd_solver.cpp:106] Iteration 28800, lr = 0.0005
I0514 18:17:01.422016 12912 solver.cpp:228] Iteration 28850, loss = 0.0205295
I0514 18:17:01.422147 12912 solver.cpp:244]     Train net output #0: loss = 0.0205298 (* 1 = 0.0205298 loss)
I0514 18:17:01.422160 12912 sgd_solver.cpp:106] Iteration 28850, lr = 0.0005
I0514 18:17:39.378610 12912 solver.cpp:228] Iteration 28900, loss = 0.0406339
I0514 18:17:39.378723 12912 solver.cpp:244]     Train net output #0: loss = 0.0406342 (* 1 = 0.0406342 loss)
I0514 18:17:39.378737 12912 sgd_solver.cpp:106] Iteration 28900, lr = 0.0005
I0514 18:18:17.323586 12912 solver.cpp:228] Iteration 28950, loss = 0.0345704
I0514 18:18:17.323715 12912 solver.cpp:244]     Train net output #0: loss = 0.0345707 (* 1 = 0.0345707 loss)
I0514 18:18:17.323729 12912 sgd_solver.cpp:106] Iteration 28950, lr = 0.0005
I0514 18:18:55.003219 12912 solver.cpp:454] Snapshotting to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_29000.caffemodel
I0514 18:18:55.512662 12912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_29000.solverstate
I0514 18:18:55.595391 12912 solver.cpp:337] Iteration 29000, Testing net (#0)
I0514 18:18:55.595450 12912 net.cpp:685] Ignoring source layer loss
I0514 18:20:37.958765 12912 solver.cpp:404]     Test net output #0: accuracy = 0.720588
I0514 18:20:38.248544 12912 solver.cpp:228] Iteration 29000, loss = 0.0144966
I0514 18:20:38.248625 12912 solver.cpp:244]     Train net output #0: loss = 0.0144969 (* 1 = 0.0144969 loss)
I0514 18:20:38.248644 12912 sgd_solver.cpp:106] Iteration 29000, lr = 0.0005
I0514 18:21:16.206703 12912 solver.cpp:228] Iteration 29050, loss = 0.0251727
I0514 18:21:16.206835 12912 solver.cpp:244]     Train net output #0: loss = 0.025173 (* 1 = 0.025173 loss)
I0514 18:21:16.206852 12912 sgd_solver.cpp:106] Iteration 29050, lr = 0.0005
I0514 18:21:54.167574 12912 solver.cpp:228] Iteration 29100, loss = 0.0671546
I0514 18:21:54.167697 12912 solver.cpp:244]     Train net output #0: loss = 0.0671548 (* 1 = 0.0671548 loss)
I0514 18:21:54.167716 12912 sgd_solver.cpp:106] Iteration 29100, lr = 0.0005
I0514 18:22:32.127842 12912 solver.cpp:228] Iteration 29150, loss = 0.0422377
I0514 18:22:32.127951 12912 solver.cpp:244]     Train net output #0: loss = 0.042238 (* 1 = 0.042238 loss)
I0514 18:22:32.127964 12912 sgd_solver.cpp:106] Iteration 29150, lr = 0.0005
I0514 18:23:10.084318 12912 solver.cpp:228] Iteration 29200, loss = 0.0165597
I0514 18:23:10.084439 12912 solver.cpp:244]     Train net output #0: loss = 0.01656 (* 1 = 0.01656 loss)
I0514 18:23:10.084450 12912 sgd_solver.cpp:106] Iteration 29200, lr = 0.0005
I0514 18:23:48.029819 12912 solver.cpp:228] Iteration 29250, loss = 0.0228953
I0514 18:23:48.029932 12912 solver.cpp:244]     Train net output #0: loss = 0.0228955 (* 1 = 0.0228955 loss)
I0514 18:23:48.029949 12912 sgd_solver.cpp:106] Iteration 29250, lr = 0.0005
I0514 18:24:25.969568 12912 solver.cpp:228] Iteration 29300, loss = 0.00543193
I0514 18:24:25.969691 12912 solver.cpp:244]     Train net output #0: loss = 0.00543221 (* 1 = 0.00543221 loss)
I0514 18:24:25.969704 12912 sgd_solver.cpp:106] Iteration 29300, lr = 0.0005
I0514 18:25:03.915990 12912 solver.cpp:228] Iteration 29350, loss = 0.0548445
I0514 18:25:03.916131 12912 solver.cpp:244]     Train net output #0: loss = 0.0548448 (* 1 = 0.0548448 loss)
I0514 18:25:03.916144 12912 sgd_solver.cpp:106] Iteration 29350, lr = 0.0005
I0514 18:25:41.849788 12912 solver.cpp:228] Iteration 29400, loss = 0.0322071
I0514 18:25:41.849902 12912 solver.cpp:244]     Train net output #0: loss = 0.0322074 (* 1 = 0.0322074 loss)
I0514 18:25:41.849920 12912 sgd_solver.cpp:106] Iteration 29400, lr = 0.0005
I0514 18:26:19.806722 12912 solver.cpp:228] Iteration 29450, loss = 0.0277898
I0514 18:26:19.806869 12912 solver.cpp:244]     Train net output #0: loss = 0.0277901 (* 1 = 0.0277901 loss)
I0514 18:26:19.806888 12912 sgd_solver.cpp:106] Iteration 29450, lr = 0.0005
I0514 18:26:57.760085 12912 solver.cpp:228] Iteration 29500, loss = 0.0312762
I0514 18:26:57.760227 12912 solver.cpp:244]     Train net output #0: loss = 0.0312765 (* 1 = 0.0312765 loss)
I0514 18:26:57.760241 12912 sgd_solver.cpp:106] Iteration 29500, lr = 0.0005
I0514 18:27:35.717483 12912 solver.cpp:228] Iteration 29550, loss = 0.00599438
I0514 18:27:35.717615 12912 solver.cpp:244]     Train net output #0: loss = 0.00599465 (* 1 = 0.00599465 loss)
I0514 18:27:35.717628 12912 sgd_solver.cpp:106] Iteration 29550, lr = 0.0005
I0514 18:28:13.683701 12912 solver.cpp:228] Iteration 29600, loss = 0.0081923
I0514 18:28:13.683894 12912 solver.cpp:244]     Train net output #0: loss = 0.00819257 (* 1 = 0.00819257 loss)
I0514 18:28:13.683907 12912 sgd_solver.cpp:106] Iteration 29600, lr = 0.0005
I0514 18:28:51.637919 12912 solver.cpp:228] Iteration 29650, loss = 0.0135774
I0514 18:28:51.638068 12912 solver.cpp:244]     Train net output #0: loss = 0.0135776 (* 1 = 0.0135776 loss)
I0514 18:28:51.638082 12912 sgd_solver.cpp:106] Iteration 29650, lr = 0.0005
I0514 18:29:29.589653 12912 solver.cpp:228] Iteration 29700, loss = 0.0460183
I0514 18:29:29.589830 12912 solver.cpp:244]     Train net output #0: loss = 0.0460186 (* 1 = 0.0460186 loss)
I0514 18:29:29.589853 12912 sgd_solver.cpp:106] Iteration 29700, lr = 0.0005
I0514 18:30:07.543869 12912 solver.cpp:228] Iteration 29750, loss = 0.0145427
I0514 18:30:07.543989 12912 solver.cpp:244]     Train net output #0: loss = 0.0145429 (* 1 = 0.0145429 loss)
I0514 18:30:07.544003 12912 sgd_solver.cpp:106] Iteration 29750, lr = 0.0005
I0514 18:30:45.495682 12912 solver.cpp:228] Iteration 29800, loss = 0.0369057
I0514 18:30:45.495859 12912 solver.cpp:244]     Train net output #0: loss = 0.036906 (* 1 = 0.036906 loss)
I0514 18:30:45.495877 12912 sgd_solver.cpp:106] Iteration 29800, lr = 0.0005
I0514 18:31:23.425374 12912 solver.cpp:228] Iteration 29850, loss = 0.0295556
I0514 18:31:23.425478 12912 solver.cpp:244]     Train net output #0: loss = 0.0295559 (* 1 = 0.0295559 loss)
I0514 18:31:23.425496 12912 sgd_solver.cpp:106] Iteration 29850, lr = 0.0005
I0514 18:32:01.373105 12912 solver.cpp:228] Iteration 29900, loss = 0.0309314
I0514 18:32:01.373224 12912 solver.cpp:244]     Train net output #0: loss = 0.0309317 (* 1 = 0.0309317 loss)
I0514 18:32:01.373237 12912 sgd_solver.cpp:106] Iteration 29900, lr = 0.0005
I0514 18:32:39.307593 12912 solver.cpp:228] Iteration 29950, loss = 0.032002
I0514 18:32:39.307724 12912 solver.cpp:244]     Train net output #0: loss = 0.0320023 (* 1 = 0.0320023 loss)
I0514 18:32:39.307745 12912 sgd_solver.cpp:106] Iteration 29950, lr = 0.0005
I0514 18:33:16.962286 12912 solver.cpp:454] Snapshotting to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_30000.caffemodel
I0514 18:33:17.488311 12912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_30000.solverstate
I0514 18:33:17.570381 12912 solver.cpp:337] Iteration 30000, Testing net (#0)
I0514 18:33:17.570442 12912 net.cpp:685] Ignoring source layer loss
I0514 18:34:59.865032 12912 solver.cpp:404]     Test net output #0: accuracy = 0.718382
I0514 18:35:00.154332 12912 solver.cpp:228] Iteration 30000, loss = 0.0136722
I0514 18:35:00.154386 12912 solver.cpp:244]     Train net output #0: loss = 0.0136725 (* 1 = 0.0136725 loss)
I0514 18:35:00.154397 12912 sgd_solver.cpp:106] Iteration 30000, lr = 0.0005
I0514 18:35:38.107208 12912 solver.cpp:228] Iteration 30050, loss = 0.0133623
I0514 18:35:38.107339 12912 solver.cpp:244]     Train net output #0: loss = 0.0133626 (* 1 = 0.0133626 loss)
I0514 18:35:38.107357 12912 sgd_solver.cpp:106] Iteration 30050, lr = 0.0005
I0514 18:36:16.052296 12912 solver.cpp:228] Iteration 30100, loss = 0.0612866
I0514 18:36:16.052425 12912 solver.cpp:244]     Train net output #0: loss = 0.0612869 (* 1 = 0.0612869 loss)
I0514 18:36:16.052439 12912 sgd_solver.cpp:106] Iteration 30100, lr = 0.0005
I0514 18:36:54.005347 12912 solver.cpp:228] Iteration 30150, loss = 0.0122323
I0514 18:36:54.005477 12912 solver.cpp:244]     Train net output #0: loss = 0.0122325 (* 1 = 0.0122325 loss)
I0514 18:36:54.005496 12912 sgd_solver.cpp:106] Iteration 30150, lr = 0.0005
I0514 18:37:31.942903 12912 solver.cpp:228] Iteration 30200, loss = 0.0241716
I0514 18:37:31.943076 12912 solver.cpp:244]     Train net output #0: loss = 0.0241719 (* 1 = 0.0241719 loss)
I0514 18:37:31.943119 12912 sgd_solver.cpp:106] Iteration 30200, lr = 0.0005
I0514 18:38:09.900106 12912 solver.cpp:228] Iteration 30250, loss = 0.0108008
I0514 18:38:09.900229 12912 solver.cpp:244]     Train net output #0: loss = 0.0108011 (* 1 = 0.0108011 loss)
I0514 18:38:09.900249 12912 sgd_solver.cpp:106] Iteration 30250, lr = 0.0005
I0514 18:38:47.851904 12912 solver.cpp:228] Iteration 30300, loss = 0.132747
I0514 18:38:47.852041 12912 solver.cpp:244]     Train net output #0: loss = 0.132748 (* 1 = 0.132748 loss)
I0514 18:38:47.852059 12912 sgd_solver.cpp:106] Iteration 30300, lr = 0.0005
I0514 18:39:25.778677 12912 solver.cpp:228] Iteration 30350, loss = 0.0341535
I0514 18:39:25.778787 12912 solver.cpp:244]     Train net output #0: loss = 0.0341538 (* 1 = 0.0341538 loss)
I0514 18:39:25.778800 12912 sgd_solver.cpp:106] Iteration 30350, lr = 0.0005
I0514 18:40:03.729306 12912 solver.cpp:228] Iteration 30400, loss = 0.0269156
I0514 18:40:03.729457 12912 solver.cpp:244]     Train net output #0: loss = 0.0269158 (* 1 = 0.0269158 loss)
I0514 18:40:03.729470 12912 sgd_solver.cpp:106] Iteration 30400, lr = 0.0005
I0514 18:40:41.693960 12912 solver.cpp:228] Iteration 30450, loss = 0.0410791
I0514 18:40:41.694082 12912 solver.cpp:244]     Train net output #0: loss = 0.0410793 (* 1 = 0.0410793 loss)
I0514 18:40:41.694102 12912 sgd_solver.cpp:106] Iteration 30450, lr = 0.0005
I0514 18:41:19.633965 12912 solver.cpp:228] Iteration 30500, loss = 0.00971121
I0514 18:41:19.634100 12912 solver.cpp:244]     Train net output #0: loss = 0.00971149 (* 1 = 0.00971149 loss)
I0514 18:41:19.634114 12912 sgd_solver.cpp:106] Iteration 30500, lr = 0.0005
I0514 18:41:57.575772 12912 solver.cpp:228] Iteration 30550, loss = 0.141595
I0514 18:41:57.575920 12912 solver.cpp:244]     Train net output #0: loss = 0.141596 (* 1 = 0.141596 loss)
I0514 18:41:57.575935 12912 sgd_solver.cpp:106] Iteration 30550, lr = 0.0005
I0514 18:42:35.513799 12912 solver.cpp:228] Iteration 30600, loss = 0.0189436
I0514 18:42:35.513954 12912 solver.cpp:244]     Train net output #0: loss = 0.0189438 (* 1 = 0.0189438 loss)
I0514 18:42:35.513967 12912 sgd_solver.cpp:106] Iteration 30600, lr = 0.0005
I0514 18:43:13.453737 12912 solver.cpp:228] Iteration 30650, loss = 0.00709196
I0514 18:43:13.453840 12912 solver.cpp:244]     Train net output #0: loss = 0.00709224 (* 1 = 0.00709224 loss)
I0514 18:43:13.453853 12912 sgd_solver.cpp:106] Iteration 30650, lr = 0.0005
I0514 18:43:51.405407 12912 solver.cpp:228] Iteration 30700, loss = 0.024599
I0514 18:43:51.405525 12912 solver.cpp:244]     Train net output #0: loss = 0.0245992 (* 1 = 0.0245992 loss)
I0514 18:43:51.405544 12912 sgd_solver.cpp:106] Iteration 30700, lr = 0.0005
I0514 18:44:29.344771 12912 solver.cpp:228] Iteration 30750, loss = 0.0611722
I0514 18:44:29.344939 12912 solver.cpp:244]     Train net output #0: loss = 0.0611725 (* 1 = 0.0611725 loss)
I0514 18:44:29.344991 12912 sgd_solver.cpp:106] Iteration 30750, lr = 0.0005
I0514 18:45:07.305258 12912 solver.cpp:228] Iteration 30800, loss = 0.0145863
I0514 18:45:07.305445 12912 solver.cpp:244]     Train net output #0: loss = 0.0145866 (* 1 = 0.0145866 loss)
I0514 18:45:07.305459 12912 sgd_solver.cpp:106] Iteration 30800, lr = 0.0005
I0514 18:45:45.261044 12912 solver.cpp:228] Iteration 30850, loss = 0.00896133
I0514 18:45:45.261198 12912 solver.cpp:244]     Train net output #0: loss = 0.00896161 (* 1 = 0.00896161 loss)
I0514 18:45:45.261212 12912 sgd_solver.cpp:106] Iteration 30850, lr = 0.0005
I0514 18:46:23.218313 12912 solver.cpp:228] Iteration 30900, loss = 0.0137778
I0514 18:46:23.218461 12912 solver.cpp:244]     Train net output #0: loss = 0.0137781 (* 1 = 0.0137781 loss)
I0514 18:46:23.218479 12912 sgd_solver.cpp:106] Iteration 30900, lr = 0.0005
I0514 18:47:01.174306 12912 solver.cpp:228] Iteration 30950, loss = 0.00920569
I0514 18:47:01.174432 12912 solver.cpp:244]     Train net output #0: loss = 0.00920597 (* 1 = 0.00920597 loss)
I0514 18:47:01.174445 12912 sgd_solver.cpp:106] Iteration 30950, lr = 0.0005
I0514 18:47:38.843739 12912 solver.cpp:454] Snapshotting to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_31000.caffemodel
I0514 18:47:39.380606 12912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_31000.solverstate
I0514 18:47:39.530062 12912 solver.cpp:337] Iteration 31000, Testing net (#0)
I0514 18:47:39.530133 12912 net.cpp:685] Ignoring source layer loss
I0514 18:49:21.955596 12912 solver.cpp:404]     Test net output #0: accuracy = 0.664559
I0514 18:49:22.244762 12912 solver.cpp:228] Iteration 31000, loss = 0.0206567
I0514 18:49:22.244822 12912 solver.cpp:244]     Train net output #0: loss = 0.020657 (* 1 = 0.020657 loss)
I0514 18:49:22.244832 12912 sgd_solver.cpp:106] Iteration 31000, lr = 0.0005
I0514 18:50:00.189705 12912 solver.cpp:228] Iteration 31050, loss = 0.0300106
I0514 18:50:00.189826 12912 solver.cpp:244]     Train net output #0: loss = 0.0300109 (* 1 = 0.0300109 loss)
I0514 18:50:00.189838 12912 sgd_solver.cpp:106] Iteration 31050, lr = 0.0005
I0514 18:50:38.133810 12912 solver.cpp:228] Iteration 31100, loss = 0.00832864
I0514 18:50:38.133924 12912 solver.cpp:244]     Train net output #0: loss = 0.00832891 (* 1 = 0.00832891 loss)
I0514 18:50:38.133942 12912 sgd_solver.cpp:106] Iteration 31100, lr = 0.0005
I0514 18:51:16.068611 12912 solver.cpp:228] Iteration 31150, loss = 0.0364101
I0514 18:51:16.068738 12912 solver.cpp:244]     Train net output #0: loss = 0.0364103 (* 1 = 0.0364103 loss)
I0514 18:51:16.068752 12912 sgd_solver.cpp:106] Iteration 31150, lr = 0.0005
I0514 18:51:54.019455 12912 solver.cpp:228] Iteration 31200, loss = 0.0130588
I0514 18:51:54.019562 12912 solver.cpp:244]     Train net output #0: loss = 0.0130591 (* 1 = 0.0130591 loss)
I0514 18:51:54.019579 12912 sgd_solver.cpp:106] Iteration 31200, lr = 0.0005
I0514 18:52:31.995282 12912 solver.cpp:228] Iteration 31250, loss = 0.0479508
I0514 18:52:31.996251 12912 solver.cpp:244]     Train net output #0: loss = 0.0479511 (* 1 = 0.0479511 loss)
I0514 18:52:31.996275 12912 sgd_solver.cpp:106] Iteration 31250, lr = 0.0005
I0514 18:53:09.943716 12912 solver.cpp:228] Iteration 31300, loss = 0.0115402
I0514 18:53:09.943842 12912 solver.cpp:244]     Train net output #0: loss = 0.0115405 (* 1 = 0.0115405 loss)
I0514 18:53:09.943857 12912 sgd_solver.cpp:106] Iteration 31300, lr = 0.0005
I0514 18:53:47.888109 12912 solver.cpp:228] Iteration 31350, loss = 0.0103038
I0514 18:53:47.888222 12912 solver.cpp:244]     Train net output #0: loss = 0.0103041 (* 1 = 0.0103041 loss)
I0514 18:53:47.888236 12912 sgd_solver.cpp:106] Iteration 31350, lr = 0.0005
I0514 18:54:25.855932 12912 solver.cpp:228] Iteration 31400, loss = 0.0471284
I0514 18:54:25.856046 12912 solver.cpp:244]     Train net output #0: loss = 0.0471287 (* 1 = 0.0471287 loss)
I0514 18:54:25.856065 12912 sgd_solver.cpp:106] Iteration 31400, lr = 0.0005
I0514 18:55:03.818743 12912 solver.cpp:228] Iteration 31450, loss = 0.0271754
I0514 18:55:03.818862 12912 solver.cpp:244]     Train net output #0: loss = 0.0271757 (* 1 = 0.0271757 loss)
I0514 18:55:03.818876 12912 sgd_solver.cpp:106] Iteration 31450, lr = 0.0005
I0514 18:55:41.781651 12912 solver.cpp:228] Iteration 31500, loss = 0.0386476
I0514 18:55:41.781833 12912 solver.cpp:244]     Train net output #0: loss = 0.0386479 (* 1 = 0.0386479 loss)
I0514 18:55:41.781852 12912 sgd_solver.cpp:106] Iteration 31500, lr = 0.0005
I0514 18:56:19.728480 12912 solver.cpp:228] Iteration 31550, loss = 0.0121372
I0514 18:56:19.728659 12912 solver.cpp:244]     Train net output #0: loss = 0.0121374 (* 1 = 0.0121374 loss)
I0514 18:56:19.728672 12912 sgd_solver.cpp:106] Iteration 31550, lr = 0.0005
I0514 18:56:57.686506 12912 solver.cpp:228] Iteration 31600, loss = 0.0245401
I0514 18:56:57.686625 12912 solver.cpp:244]     Train net output #0: loss = 0.0245403 (* 1 = 0.0245403 loss)
I0514 18:56:57.686638 12912 sgd_solver.cpp:106] Iteration 31600, lr = 0.0005
I0514 18:57:35.647145 12912 solver.cpp:228] Iteration 31650, loss = 0.0167123
I0514 18:57:35.647280 12912 solver.cpp:244]     Train net output #0: loss = 0.0167125 (* 1 = 0.0167125 loss)
I0514 18:57:35.647294 12912 sgd_solver.cpp:106] Iteration 31650, lr = 0.0005
I0514 18:58:13.584564 12912 solver.cpp:228] Iteration 31700, loss = 0.0212215
I0514 18:58:13.584681 12912 solver.cpp:244]     Train net output #0: loss = 0.0212218 (* 1 = 0.0212218 loss)
I0514 18:58:13.584693 12912 sgd_solver.cpp:106] Iteration 31700, lr = 0.0005
I0514 18:58:51.536792 12912 solver.cpp:228] Iteration 31750, loss = 0.0406429
I0514 18:58:51.536907 12912 solver.cpp:244]     Train net output #0: loss = 0.0406431 (* 1 = 0.0406431 loss)
I0514 18:58:51.536926 12912 sgd_solver.cpp:106] Iteration 31750, lr = 0.0005
I0514 18:59:29.475548 12912 solver.cpp:228] Iteration 31800, loss = 0.012965
I0514 18:59:29.475702 12912 solver.cpp:244]     Train net output #0: loss = 0.0129652 (* 1 = 0.0129652 loss)
I0514 18:59:29.475716 12912 sgd_solver.cpp:106] Iteration 31800, lr = 0.0005
I0514 19:00:07.407488 12912 solver.cpp:228] Iteration 31850, loss = 0.0472584
I0514 19:00:07.407652 12912 solver.cpp:244]     Train net output #0: loss = 0.0472586 (* 1 = 0.0472586 loss)
I0514 19:00:07.407673 12912 sgd_solver.cpp:106] Iteration 31850, lr = 0.0005
I0514 19:00:45.357221 12912 solver.cpp:228] Iteration 31900, loss = 0.0114378
I0514 19:00:45.357339 12912 solver.cpp:244]     Train net output #0: loss = 0.011438 (* 1 = 0.011438 loss)
I0514 19:00:45.357357 12912 sgd_solver.cpp:106] Iteration 31900, lr = 0.0005
I0514 19:01:23.315438 12912 solver.cpp:228] Iteration 31950, loss = 0.0231984
I0514 19:01:23.315588 12912 solver.cpp:244]     Train net output #0: loss = 0.0231987 (* 1 = 0.0231987 loss)
I0514 19:01:23.315608 12912 sgd_solver.cpp:106] Iteration 31950, lr = 0.0005
I0514 19:02:00.961503 12912 solver.cpp:454] Snapshotting to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_32000.caffemodel
I0514 19:02:01.489913 12912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_32000.solverstate
I0514 19:02:01.572250 12912 solver.cpp:337] Iteration 32000, Testing net (#0)
I0514 19:02:01.572311 12912 net.cpp:685] Ignoring source layer loss
I0514 19:03:44.423591 12912 solver.cpp:404]     Test net output #0: accuracy = 0.695294
I0514 19:03:44.714046 12912 solver.cpp:228] Iteration 32000, loss = 0.0211999
I0514 19:03:44.714104 12912 solver.cpp:244]     Train net output #0: loss = 0.0212001 (* 1 = 0.0212001 loss)
I0514 19:03:44.714119 12912 sgd_solver.cpp:106] Iteration 32000, lr = 0.0005
I0514 19:04:22.679404 12912 solver.cpp:228] Iteration 32050, loss = 0.00879845
I0514 19:04:22.679519 12912 solver.cpp:244]     Train net output #0: loss = 0.00879875 (* 1 = 0.00879875 loss)
I0514 19:04:22.679535 12912 sgd_solver.cpp:106] Iteration 32050, lr = 0.0005
I0514 19:05:00.638753 12912 solver.cpp:228] Iteration 32100, loss = 0.0502831
I0514 19:05:00.638861 12912 solver.cpp:244]     Train net output #0: loss = 0.0502834 (* 1 = 0.0502834 loss)
I0514 19:05:00.638875 12912 sgd_solver.cpp:106] Iteration 32100, lr = 0.0005
I0514 19:05:38.592589 12912 solver.cpp:228] Iteration 32150, loss = 0.0436839
I0514 19:05:38.592694 12912 solver.cpp:244]     Train net output #0: loss = 0.0436842 (* 1 = 0.0436842 loss)
I0514 19:05:38.592711 12912 sgd_solver.cpp:106] Iteration 32150, lr = 0.0005
I0514 19:06:16.566498 12912 solver.cpp:228] Iteration 32200, loss = 0.0460046
I0514 19:06:16.566656 12912 solver.cpp:244]     Train net output #0: loss = 0.0460049 (* 1 = 0.0460049 loss)
I0514 19:06:16.566674 12912 sgd_solver.cpp:106] Iteration 32200, lr = 0.0005
I0514 19:06:54.527250 12912 solver.cpp:228] Iteration 32250, loss = 0.0597209
I0514 19:06:54.527464 12912 solver.cpp:244]     Train net output #0: loss = 0.0597212 (* 1 = 0.0597212 loss)
I0514 19:06:54.527484 12912 sgd_solver.cpp:106] Iteration 32250, lr = 0.0005
I0514 19:07:32.487124 12912 solver.cpp:228] Iteration 32300, loss = 0.00983969
I0514 19:07:32.487272 12912 solver.cpp:244]     Train net output #0: loss = 0.00983999 (* 1 = 0.00983999 loss)
I0514 19:07:32.487289 12912 sgd_solver.cpp:106] Iteration 32300, lr = 0.0005
I0514 19:08:10.440776 12912 solver.cpp:228] Iteration 32350, loss = 0.017697
I0514 19:08:10.440892 12912 solver.cpp:244]     Train net output #0: loss = 0.0176973 (* 1 = 0.0176973 loss)
I0514 19:08:10.440906 12912 sgd_solver.cpp:106] Iteration 32350, lr = 0.0005
I0514 19:08:48.399191 12912 solver.cpp:228] Iteration 32400, loss = 0.171572
I0514 19:08:48.399302 12912 solver.cpp:244]     Train net output #0: loss = 0.171572 (* 1 = 0.171572 loss)
I0514 19:08:48.399314 12912 sgd_solver.cpp:106] Iteration 32400, lr = 0.0005
I0514 19:09:26.359797 12912 solver.cpp:228] Iteration 32450, loss = 0.0153688
I0514 19:09:26.360020 12912 solver.cpp:244]     Train net output #0: loss = 0.0153692 (* 1 = 0.0153692 loss)
I0514 19:09:26.360060 12912 sgd_solver.cpp:106] Iteration 32450, lr = 0.0005
I0514 19:10:04.313652 12912 solver.cpp:228] Iteration 32500, loss = 0.0118399
I0514 19:10:04.313907 12912 solver.cpp:244]     Train net output #0: loss = 0.0118402 (* 1 = 0.0118402 loss)
I0514 19:10:04.313971 12912 sgd_solver.cpp:106] Iteration 32500, lr = 0.0005
I0514 19:10:42.275148 12912 solver.cpp:228] Iteration 32550, loss = 0.0425652
I0514 19:10:42.275308 12912 solver.cpp:244]     Train net output #0: loss = 0.0425655 (* 1 = 0.0425655 loss)
I0514 19:10:42.275323 12912 sgd_solver.cpp:106] Iteration 32550, lr = 0.0005
I0514 19:11:20.233984 12912 solver.cpp:228] Iteration 32600, loss = 0.0168007
I0514 19:11:20.234088 12912 solver.cpp:244]     Train net output #0: loss = 0.0168011 (* 1 = 0.0168011 loss)
I0514 19:11:20.234102 12912 sgd_solver.cpp:106] Iteration 32600, lr = 0.0005
I0514 19:11:58.202553 12912 solver.cpp:228] Iteration 32650, loss = 0.0164121
I0514 19:11:58.202672 12912 solver.cpp:244]     Train net output #0: loss = 0.0164124 (* 1 = 0.0164124 loss)
I0514 19:11:58.202692 12912 sgd_solver.cpp:106] Iteration 32650, lr = 0.0005
I0514 19:12:36.162032 12912 solver.cpp:228] Iteration 32700, loss = 0.0146316
I0514 19:12:36.162144 12912 solver.cpp:244]     Train net output #0: loss = 0.014632 (* 1 = 0.014632 loss)
I0514 19:12:36.162163 12912 sgd_solver.cpp:106] Iteration 32700, lr = 0.0005
I0514 19:13:14.126272 12912 solver.cpp:228] Iteration 32750, loss = 0.0430736
I0514 19:13:14.126380 12912 solver.cpp:244]     Train net output #0: loss = 0.043074 (* 1 = 0.043074 loss)
I0514 19:13:14.126397 12912 sgd_solver.cpp:106] Iteration 32750, lr = 0.0005
I0514 19:13:52.080319 12912 solver.cpp:228] Iteration 32800, loss = 0.0313449
I0514 19:13:52.080446 12912 solver.cpp:244]     Train net output #0: loss = 0.0313452 (* 1 = 0.0313452 loss)
I0514 19:13:52.080459 12912 sgd_solver.cpp:106] Iteration 32800, lr = 0.0005
I0514 19:14:30.018924 12912 solver.cpp:228] Iteration 32850, loss = 0.0381831
I0514 19:14:30.019106 12912 solver.cpp:244]     Train net output #0: loss = 0.0381835 (* 1 = 0.0381835 loss)
I0514 19:14:30.019124 12912 sgd_solver.cpp:106] Iteration 32850, lr = 0.0005
I0514 19:15:07.997172 12912 solver.cpp:228] Iteration 32900, loss = 0.0117553
I0514 19:15:07.997275 12912 solver.cpp:244]     Train net output #0: loss = 0.0117557 (* 1 = 0.0117557 loss)
I0514 19:15:07.997293 12912 sgd_solver.cpp:106] Iteration 32900, lr = 0.0005
I0514 19:15:45.940769 12912 solver.cpp:228] Iteration 32950, loss = 0.0189904
I0514 19:15:45.940903 12912 solver.cpp:244]     Train net output #0: loss = 0.0189908 (* 1 = 0.0189908 loss)
I0514 19:15:45.940920 12912 sgd_solver.cpp:106] Iteration 32950, lr = 0.0005
I0514 19:16:23.621755 12912 solver.cpp:454] Snapshotting to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_33000.caffemodel
I0514 19:16:23.822221 12912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_33000.solverstate
I0514 19:16:23.903228 12912 solver.cpp:337] Iteration 33000, Testing net (#0)
I0514 19:16:23.903291 12912 net.cpp:685] Ignoring source layer loss
I0514 19:18:06.794178 12912 solver.cpp:404]     Test net output #0: accuracy = 0.748088
I0514 19:18:07.084558 12912 solver.cpp:228] Iteration 33000, loss = 0.0116272
I0514 19:18:07.084612 12912 solver.cpp:244]     Train net output #0: loss = 0.0116275 (* 1 = 0.0116275 loss)
I0514 19:18:07.084627 12912 sgd_solver.cpp:106] Iteration 33000, lr = 0.0005
I0514 19:18:45.035818 12912 solver.cpp:228] Iteration 33050, loss = 0.00690526
I0514 19:18:45.035966 12912 solver.cpp:244]     Train net output #0: loss = 0.0069056 (* 1 = 0.0069056 loss)
I0514 19:18:45.035992 12912 sgd_solver.cpp:106] Iteration 33050, lr = 0.0005
I0514 19:19:22.976845 12912 solver.cpp:228] Iteration 33100, loss = 0.0440126
I0514 19:19:22.976963 12912 solver.cpp:244]     Train net output #0: loss = 0.044013 (* 1 = 0.044013 loss)
I0514 19:19:22.976980 12912 sgd_solver.cpp:106] Iteration 33100, lr = 0.0005
I0514 19:20:00.948464 12912 solver.cpp:228] Iteration 33150, loss = 0.00502931
I0514 19:20:00.948560 12912 solver.cpp:244]     Train net output #0: loss = 0.00502965 (* 1 = 0.00502965 loss)
I0514 19:20:00.948578 12912 sgd_solver.cpp:106] Iteration 33150, lr = 0.0005
I0514 19:20:38.904624 12912 solver.cpp:228] Iteration 33200, loss = 0.0129724
I0514 19:20:38.904884 12912 solver.cpp:244]     Train net output #0: loss = 0.0129728 (* 1 = 0.0129728 loss)
I0514 19:20:38.904912 12912 sgd_solver.cpp:106] Iteration 33200, lr = 0.0005
I0514 19:21:16.840109 12912 solver.cpp:228] Iteration 33250, loss = 0.0124784
I0514 19:21:16.840306 12912 solver.cpp:244]     Train net output #0: loss = 0.0124787 (* 1 = 0.0124787 loss)
I0514 19:21:16.840325 12912 sgd_solver.cpp:106] Iteration 33250, lr = 0.0005
I0514 19:21:54.800782 12912 solver.cpp:228] Iteration 33300, loss = 0.0122145
I0514 19:21:54.800890 12912 solver.cpp:244]     Train net output #0: loss = 0.0122148 (* 1 = 0.0122148 loss)
I0514 19:21:54.800909 12912 sgd_solver.cpp:106] Iteration 33300, lr = 0.0005
I0514 19:22:32.759397 12912 solver.cpp:228] Iteration 33350, loss = 0.00722693
I0514 19:22:32.759497 12912 solver.cpp:244]     Train net output #0: loss = 0.00722727 (* 1 = 0.00722727 loss)
I0514 19:22:32.759510 12912 sgd_solver.cpp:106] Iteration 33350, lr = 0.0005
I0514 19:23:10.713212 12912 solver.cpp:228] Iteration 33400, loss = 0.0163089
I0514 19:23:10.713321 12912 solver.cpp:244]     Train net output #0: loss = 0.0163092 (* 1 = 0.0163092 loss)
I0514 19:23:10.713340 12912 sgd_solver.cpp:106] Iteration 33400, lr = 0.0005
I0514 19:23:48.666309 12912 solver.cpp:228] Iteration 33450, loss = 0.00643847
I0514 19:23:48.666481 12912 solver.cpp:244]     Train net output #0: loss = 0.0064388 (* 1 = 0.0064388 loss)
I0514 19:23:48.666522 12912 sgd_solver.cpp:106] Iteration 33450, lr = 0.0005
I0514 19:24:26.610281 12912 solver.cpp:228] Iteration 33500, loss = 0.0222876
I0514 19:24:26.610484 12912 solver.cpp:244]     Train net output #0: loss = 0.0222879 (* 1 = 0.0222879 loss)
I0514 19:24:26.610529 12912 sgd_solver.cpp:106] Iteration 33500, lr = 0.0005
I0514 19:25:04.566664 12912 solver.cpp:228] Iteration 33550, loss = 0.0266563
I0514 19:25:04.566767 12912 solver.cpp:244]     Train net output #0: loss = 0.0266566 (* 1 = 0.0266566 loss)
I0514 19:25:04.566786 12912 sgd_solver.cpp:106] Iteration 33550, lr = 0.0005
I0514 19:25:42.512876 12912 solver.cpp:228] Iteration 33600, loss = 0.0344544
I0514 19:25:42.513044 12912 solver.cpp:244]     Train net output #0: loss = 0.0344547 (* 1 = 0.0344547 loss)
I0514 19:25:42.513063 12912 sgd_solver.cpp:106] Iteration 33600, lr = 0.0005
I0514 19:26:20.474071 12912 solver.cpp:228] Iteration 33650, loss = 0.0123968
I0514 19:26:20.474208 12912 solver.cpp:244]     Train net output #0: loss = 0.012397 (* 1 = 0.012397 loss)
I0514 19:26:20.474228 12912 sgd_solver.cpp:106] Iteration 33650, lr = 0.0005
I0514 19:26:58.417773 12912 solver.cpp:228] Iteration 33700, loss = 0.0104222
I0514 19:26:58.417937 12912 solver.cpp:244]     Train net output #0: loss = 0.0104225 (* 1 = 0.0104225 loss)
I0514 19:26:58.417956 12912 sgd_solver.cpp:106] Iteration 33700, lr = 0.0005
I0514 19:27:36.368358 12912 solver.cpp:228] Iteration 33750, loss = 0.020975
I0514 19:27:36.368475 12912 solver.cpp:244]     Train net output #0: loss = 0.0209753 (* 1 = 0.0209753 loss)
I0514 19:27:36.368494 12912 sgd_solver.cpp:106] Iteration 33750, lr = 0.0005
I0514 19:28:14.356768 12912 solver.cpp:228] Iteration 33800, loss = 0.0151938
I0514 19:28:14.356925 12912 solver.cpp:244]     Train net output #0: loss = 0.0151941 (* 1 = 0.0151941 loss)
I0514 19:28:14.356945 12912 sgd_solver.cpp:106] Iteration 33800, lr = 0.0005
I0514 19:28:52.320997 12912 solver.cpp:228] Iteration 33850, loss = 0.0133958
I0514 19:28:52.321168 12912 solver.cpp:244]     Train net output #0: loss = 0.0133961 (* 1 = 0.0133961 loss)
I0514 19:28:52.321187 12912 sgd_solver.cpp:106] Iteration 33850, lr = 0.0005
I0514 19:29:30.267261 12912 solver.cpp:228] Iteration 33900, loss = 0.0537669
I0514 19:29:30.267366 12912 solver.cpp:244]     Train net output #0: loss = 0.0537672 (* 1 = 0.0537672 loss)
I0514 19:29:30.267379 12912 sgd_solver.cpp:106] Iteration 33900, lr = 0.0005
I0514 19:30:08.227474 12912 solver.cpp:228] Iteration 33950, loss = 0.0068419
I0514 19:30:08.227672 12912 solver.cpp:244]     Train net output #0: loss = 0.00684222 (* 1 = 0.00684222 loss)
I0514 19:30:08.227721 12912 sgd_solver.cpp:106] Iteration 33950, lr = 0.0005
I0514 19:30:45.888900 12912 solver.cpp:454] Snapshotting to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_34000.caffemodel
I0514 19:30:46.388679 12912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_34000.solverstate
I0514 19:30:46.472178 12912 solver.cpp:337] Iteration 34000, Testing net (#0)
I0514 19:30:46.472229 12912 net.cpp:685] Ignoring source layer loss
I0514 19:32:29.300133 12912 solver.cpp:404]     Test net output #0: accuracy = 0.662647
I0514 19:32:29.589848 12912 solver.cpp:228] Iteration 34000, loss = 0.0248215
I0514 19:32:29.589901 12912 solver.cpp:244]     Train net output #0: loss = 0.0248218 (* 1 = 0.0248218 loss)
I0514 19:32:29.589916 12912 sgd_solver.cpp:106] Iteration 34000, lr = 0.0005
I0514 19:33:07.543401 12912 solver.cpp:228] Iteration 34050, loss = 0.0350503
I0514 19:33:07.543516 12912 solver.cpp:244]     Train net output #0: loss = 0.0350507 (* 1 = 0.0350507 loss)
I0514 19:33:07.543535 12912 sgd_solver.cpp:106] Iteration 34050, lr = 0.0005
I0514 19:33:45.507287 12912 solver.cpp:228] Iteration 34100, loss = 0.0221755
I0514 19:33:45.507416 12912 solver.cpp:244]     Train net output #0: loss = 0.0221758 (* 1 = 0.0221758 loss)
I0514 19:33:45.507429 12912 sgd_solver.cpp:106] Iteration 34100, lr = 0.0005
I0514 19:34:23.458276 12912 solver.cpp:228] Iteration 34150, loss = 0.0157188
I0514 19:34:23.458420 12912 solver.cpp:244]     Train net output #0: loss = 0.0157191 (* 1 = 0.0157191 loss)
I0514 19:34:23.458433 12912 sgd_solver.cpp:106] Iteration 34150, lr = 0.0005
I0514 19:35:01.434914 12912 solver.cpp:228] Iteration 34200, loss = 0.0245596
I0514 19:35:01.435026 12912 solver.cpp:244]     Train net output #0: loss = 0.02456 (* 1 = 0.02456 loss)
I0514 19:35:01.435045 12912 sgd_solver.cpp:106] Iteration 34200, lr = 0.0005
I0514 19:35:39.385252 12912 solver.cpp:228] Iteration 34250, loss = 0.0143337
I0514 19:35:39.385367 12912 solver.cpp:244]     Train net output #0: loss = 0.0143341 (* 1 = 0.0143341 loss)
I0514 19:35:39.385380 12912 sgd_solver.cpp:106] Iteration 34250, lr = 0.0005
I0514 19:36:17.344377 12912 solver.cpp:228] Iteration 34300, loss = 0.0430448
I0514 19:36:17.344513 12912 solver.cpp:244]     Train net output #0: loss = 0.0430451 (* 1 = 0.0430451 loss)
I0514 19:36:17.344530 12912 sgd_solver.cpp:106] Iteration 34300, lr = 0.0005
I0514 19:36:55.310358 12912 solver.cpp:228] Iteration 34350, loss = 0.0111467
I0514 19:36:55.310534 12912 solver.cpp:244]     Train net output #0: loss = 0.011147 (* 1 = 0.011147 loss)
I0514 19:36:55.310554 12912 sgd_solver.cpp:106] Iteration 34350, lr = 0.0005
I0514 19:37:33.269788 12912 solver.cpp:228] Iteration 34400, loss = 0.0111456
I0514 19:37:33.269891 12912 solver.cpp:244]     Train net output #0: loss = 0.011146 (* 1 = 0.011146 loss)
I0514 19:37:33.269909 12912 sgd_solver.cpp:106] Iteration 34400, lr = 0.0005
I0514 19:38:11.224238 12912 solver.cpp:228] Iteration 34450, loss = 0.0103651
I0514 19:38:11.224349 12912 solver.cpp:244]     Train net output #0: loss = 0.0103654 (* 1 = 0.0103654 loss)
I0514 19:38:11.224361 12912 sgd_solver.cpp:106] Iteration 34450, lr = 0.0005
I0514 19:38:49.174263 12912 solver.cpp:228] Iteration 34500, loss = 0.0300396
I0514 19:38:49.174437 12912 solver.cpp:244]     Train net output #0: loss = 0.0300399 (* 1 = 0.0300399 loss)
I0514 19:38:49.174453 12912 sgd_solver.cpp:106] Iteration 34500, lr = 0.0005
I0514 19:39:27.133605 12912 solver.cpp:228] Iteration 34550, loss = 0.0104021
I0514 19:39:27.133810 12912 solver.cpp:244]     Train net output #0: loss = 0.0104024 (* 1 = 0.0104024 loss)
I0514 19:39:27.133832 12912 sgd_solver.cpp:106] Iteration 34550, lr = 0.0005
I0514 19:40:05.081190 12912 solver.cpp:228] Iteration 34600, loss = 0.0215628
I0514 19:40:05.081315 12912 solver.cpp:244]     Train net output #0: loss = 0.0215632 (* 1 = 0.0215632 loss)
I0514 19:40:05.081329 12912 sgd_solver.cpp:106] Iteration 34600, lr = 0.0005
I0514 19:40:43.036417 12912 solver.cpp:228] Iteration 34650, loss = 0.02607
I0514 19:40:43.036658 12912 solver.cpp:244]     Train net output #0: loss = 0.0260704 (* 1 = 0.0260704 loss)
I0514 19:40:43.036720 12912 sgd_solver.cpp:106] Iteration 34650, lr = 0.0005
I0514 19:41:20.991593 12912 solver.cpp:228] Iteration 34700, loss = 0.065078
I0514 19:41:20.991781 12912 solver.cpp:244]     Train net output #0: loss = 0.0650783 (* 1 = 0.0650783 loss)
I0514 19:41:20.991825 12912 sgd_solver.cpp:106] Iteration 34700, lr = 0.0005
I0514 19:41:58.958235 12912 solver.cpp:228] Iteration 34750, loss = 0.0100665
I0514 19:41:58.958354 12912 solver.cpp:244]     Train net output #0: loss = 0.0100668 (* 1 = 0.0100668 loss)
I0514 19:41:58.958367 12912 sgd_solver.cpp:106] Iteration 34750, lr = 0.0005
I0514 19:42:36.921551 12912 solver.cpp:228] Iteration 34800, loss = 0.013848
I0514 19:42:36.921671 12912 solver.cpp:244]     Train net output #0: loss = 0.0138483 (* 1 = 0.0138483 loss)
I0514 19:42:36.921684 12912 sgd_solver.cpp:106] Iteration 34800, lr = 0.0005
I0514 19:43:14.880947 12912 solver.cpp:228] Iteration 34850, loss = 0.010708
I0514 19:43:14.882102 12912 solver.cpp:244]     Train net output #0: loss = 0.0107083 (* 1 = 0.0107083 loss)
I0514 19:43:14.882122 12912 sgd_solver.cpp:106] Iteration 34850, lr = 0.0005
I0514 19:43:52.830229 12912 solver.cpp:228] Iteration 34900, loss = 0.0145619
I0514 19:43:52.830422 12912 solver.cpp:244]     Train net output #0: loss = 0.0145622 (* 1 = 0.0145622 loss)
I0514 19:43:52.830461 12912 sgd_solver.cpp:106] Iteration 34900, lr = 0.0005
I0514 19:44:30.803707 12912 solver.cpp:228] Iteration 34950, loss = 0.0214894
I0514 19:44:30.803853 12912 solver.cpp:244]     Train net output #0: loss = 0.0214898 (* 1 = 0.0214898 loss)
I0514 19:44:30.803869 12912 sgd_solver.cpp:106] Iteration 34950, lr = 0.0005
I0514 19:45:08.451998 12912 solver.cpp:454] Snapshotting to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_35000.caffemodel
I0514 19:45:09.121332 12912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_35000.solverstate
I0514 19:45:09.202291 12912 solver.cpp:337] Iteration 35000, Testing net (#0)
I0514 19:45:09.202342 12912 net.cpp:685] Ignoring source layer loss
I0514 19:46:52.214680 12912 solver.cpp:404]     Test net output #0: accuracy = 0.705735
I0514 19:46:52.504444 12912 solver.cpp:228] Iteration 35000, loss = 0.0312433
I0514 19:46:52.504494 12912 solver.cpp:244]     Train net output #0: loss = 0.0312436 (* 1 = 0.0312436 loss)
I0514 19:46:52.504509 12912 sgd_solver.cpp:106] Iteration 35000, lr = 0.0005
I0514 19:47:30.459218 12912 solver.cpp:228] Iteration 35050, loss = 0.0109807
I0514 19:47:30.459393 12912 solver.cpp:244]     Train net output #0: loss = 0.010981 (* 1 = 0.010981 loss)
I0514 19:47:30.459408 12912 sgd_solver.cpp:106] Iteration 35050, lr = 0.0005
I0514 19:48:08.435442 12912 solver.cpp:228] Iteration 35100, loss = 0.0189085
I0514 19:48:08.435580 12912 solver.cpp:244]     Train net output #0: loss = 0.0189088 (* 1 = 0.0189088 loss)
I0514 19:48:08.435613 12912 sgd_solver.cpp:106] Iteration 35100, lr = 0.0005
I0514 19:48:46.405514 12912 solver.cpp:228] Iteration 35150, loss = 0.0177954
I0514 19:48:46.405637 12912 solver.cpp:244]     Train net output #0: loss = 0.0177957 (* 1 = 0.0177957 loss)
I0514 19:48:46.405653 12912 sgd_solver.cpp:106] Iteration 35150, lr = 0.0005
I0514 19:49:24.364823 12912 solver.cpp:228] Iteration 35200, loss = 0.0103741
I0514 19:49:24.364933 12912 solver.cpp:244]     Train net output #0: loss = 0.0103744 (* 1 = 0.0103744 loss)
I0514 19:49:24.364953 12912 sgd_solver.cpp:106] Iteration 35200, lr = 0.0005
I0514 19:50:02.331645 12912 solver.cpp:228] Iteration 35250, loss = 0.0217155
I0514 19:50:02.331785 12912 solver.cpp:244]     Train net output #0: loss = 0.0217158 (* 1 = 0.0217158 loss)
I0514 19:50:02.331802 12912 sgd_solver.cpp:106] Iteration 35250, lr = 0.0005
I0514 19:50:40.281141 12912 solver.cpp:228] Iteration 35300, loss = 0.0258113
I0514 19:50:40.281246 12912 solver.cpp:244]     Train net output #0: loss = 0.0258116 (* 1 = 0.0258116 loss)
I0514 19:50:40.281265 12912 sgd_solver.cpp:106] Iteration 35300, lr = 0.0005
I0514 19:51:18.243489 12912 solver.cpp:228] Iteration 35350, loss = 0.0415367
I0514 19:51:18.243664 12912 solver.cpp:244]     Train net output #0: loss = 0.041537 (* 1 = 0.041537 loss)
I0514 19:51:18.243701 12912 sgd_solver.cpp:106] Iteration 35350, lr = 0.0005
I0514 19:51:56.211199 12912 solver.cpp:228] Iteration 35400, loss = 0.0203535
I0514 19:51:56.211416 12912 solver.cpp:244]     Train net output #0: loss = 0.0203538 (* 1 = 0.0203538 loss)
I0514 19:51:56.211431 12912 sgd_solver.cpp:106] Iteration 35400, lr = 0.0005
I0514 19:52:34.168387 12912 solver.cpp:228] Iteration 35450, loss = 0.0215953
I0514 19:52:34.168499 12912 solver.cpp:244]     Train net output #0: loss = 0.0215957 (* 1 = 0.0215957 loss)
I0514 19:52:34.168516 12912 sgd_solver.cpp:106] Iteration 35450, lr = 0.0005
I0514 19:53:12.131526 12912 solver.cpp:228] Iteration 35500, loss = 0.0208042
I0514 19:53:12.131644 12912 solver.cpp:244]     Train net output #0: loss = 0.0208045 (* 1 = 0.0208045 loss)
I0514 19:53:12.131662 12912 sgd_solver.cpp:106] Iteration 35500, lr = 0.0005
I0514 19:53:50.088976 12912 solver.cpp:228] Iteration 35550, loss = 0.0125933
I0514 19:53:50.089118 12912 solver.cpp:244]     Train net output #0: loss = 0.0125937 (* 1 = 0.0125937 loss)
I0514 19:53:50.089136 12912 sgd_solver.cpp:106] Iteration 35550, lr = 0.0005
I0514 19:54:28.076644 12912 solver.cpp:228] Iteration 35600, loss = 0.0246995
I0514 19:54:28.076817 12912 solver.cpp:244]     Train net output #0: loss = 0.0246999 (* 1 = 0.0246999 loss)
I0514 19:54:28.076844 12912 sgd_solver.cpp:106] Iteration 35600, lr = 0.0005
I0514 19:55:06.052644 12912 solver.cpp:228] Iteration 35650, loss = 0.0112583
I0514 19:55:06.052762 12912 solver.cpp:244]     Train net output #0: loss = 0.0112587 (* 1 = 0.0112587 loss)
I0514 19:55:06.052775 12912 sgd_solver.cpp:106] Iteration 35650, lr = 0.0005
I0514 19:55:44.039754 12912 solver.cpp:228] Iteration 35700, loss = 0.00815413
I0514 19:55:44.039891 12912 solver.cpp:244]     Train net output #0: loss = 0.00815446 (* 1 = 0.00815446 loss)
I0514 19:55:44.039908 12912 sgd_solver.cpp:106] Iteration 35700, lr = 0.0005
I0514 19:56:22.001333 12912 solver.cpp:228] Iteration 35750, loss = 0.0102902
I0514 19:56:22.001526 12912 solver.cpp:244]     Train net output #0: loss = 0.0102906 (* 1 = 0.0102906 loss)
I0514 19:56:22.001569 12912 sgd_solver.cpp:106] Iteration 35750, lr = 0.0005
I0514 19:56:59.962641 12912 solver.cpp:228] Iteration 35800, loss = 0.00826652
I0514 19:56:59.962781 12912 solver.cpp:244]     Train net output #0: loss = 0.00826686 (* 1 = 0.00826686 loss)
I0514 19:56:59.962800 12912 sgd_solver.cpp:106] Iteration 35800, lr = 0.0005
I0514 19:57:37.937693 12912 solver.cpp:228] Iteration 35850, loss = 0.00908664
I0514 19:57:37.937816 12912 solver.cpp:244]     Train net output #0: loss = 0.00908697 (* 1 = 0.00908697 loss)
I0514 19:57:37.937834 12912 sgd_solver.cpp:106] Iteration 35850, lr = 0.0005
I0514 19:58:15.894217 12912 solver.cpp:228] Iteration 35900, loss = 0.0402408
I0514 19:58:15.894323 12912 solver.cpp:244]     Train net output #0: loss = 0.0402411 (* 1 = 0.0402411 loss)
I0514 19:58:15.894343 12912 sgd_solver.cpp:106] Iteration 35900, lr = 0.0005
I0514 19:58:53.859756 12912 solver.cpp:228] Iteration 35950, loss = 0.00643866
I0514 19:58:53.859943 12912 solver.cpp:244]     Train net output #0: loss = 0.00643899 (* 1 = 0.00643899 loss)
I0514 19:58:53.859983 12912 sgd_solver.cpp:106] Iteration 35950, lr = 0.0005
I0514 19:59:31.547417 12912 solver.cpp:454] Snapshotting to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_36000.caffemodel
I0514 19:59:32.109344 12912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_36000.solverstate
I0514 19:59:32.196867 12912 solver.cpp:337] Iteration 36000, Testing net (#0)
I0514 19:59:32.196920 12912 net.cpp:685] Ignoring source layer loss
I0514 20:01:15.115223 12912 solver.cpp:404]     Test net output #0: accuracy = 0.738971
I0514 20:01:15.405702 12912 solver.cpp:228] Iteration 36000, loss = 0.0126258
I0514 20:01:15.405752 12912 solver.cpp:244]     Train net output #0: loss = 0.0126261 (* 1 = 0.0126261 loss)
I0514 20:01:15.405762 12912 sgd_solver.cpp:106] Iteration 36000, lr = 0.0005
I0514 20:01:53.359243 12912 solver.cpp:228] Iteration 36050, loss = 0.0122772
I0514 20:01:53.366111 12912 solver.cpp:244]     Train net output #0: loss = 0.0122775 (* 1 = 0.0122775 loss)
I0514 20:01:53.366168 12912 sgd_solver.cpp:106] Iteration 36050, lr = 0.0005
I0514 20:02:31.312705 12912 solver.cpp:228] Iteration 36100, loss = 0.0250063
I0514 20:02:31.312844 12912 solver.cpp:244]     Train net output #0: loss = 0.0250066 (* 1 = 0.0250066 loss)
I0514 20:02:31.312861 12912 sgd_solver.cpp:106] Iteration 36100, lr = 0.0005
I0514 20:03:09.275146 12912 solver.cpp:228] Iteration 36150, loss = 0.0111812
I0514 20:03:09.275277 12912 solver.cpp:244]     Train net output #0: loss = 0.0111816 (* 1 = 0.0111816 loss)
I0514 20:03:09.275291 12912 sgd_solver.cpp:106] Iteration 36150, lr = 0.0005
I0514 20:03:47.244285 12912 solver.cpp:228] Iteration 36200, loss = 0.00367387
I0514 20:03:47.244401 12912 solver.cpp:244]     Train net output #0: loss = 0.00367423 (* 1 = 0.00367423 loss)
I0514 20:03:47.244415 12912 sgd_solver.cpp:106] Iteration 36200, lr = 0.0005
I0514 20:04:25.212050 12912 solver.cpp:228] Iteration 36250, loss = 0.0269458
I0514 20:04:25.212193 12912 solver.cpp:244]     Train net output #0: loss = 0.0269461 (* 1 = 0.0269461 loss)
I0514 20:04:25.212210 12912 sgd_solver.cpp:106] Iteration 36250, lr = 0.0005
I0514 20:05:03.177502 12912 solver.cpp:228] Iteration 36300, loss = 0.00843108
I0514 20:05:03.177621 12912 solver.cpp:244]     Train net output #0: loss = 0.00843145 (* 1 = 0.00843145 loss)
I0514 20:05:03.177633 12912 sgd_solver.cpp:106] Iteration 36300, lr = 0.0005
I0514 20:05:41.128443 12912 solver.cpp:228] Iteration 36350, loss = 0.0199029
I0514 20:05:41.128558 12912 solver.cpp:244]     Train net output #0: loss = 0.0199033 (* 1 = 0.0199033 loss)
I0514 20:05:41.128571 12912 sgd_solver.cpp:106] Iteration 36350, lr = 0.0005
I0514 20:06:19.099287 12912 solver.cpp:228] Iteration 36400, loss = 0.0516549
I0514 20:06:19.099433 12912 solver.cpp:244]     Train net output #0: loss = 0.0516552 (* 1 = 0.0516552 loss)
I0514 20:06:19.099452 12912 sgd_solver.cpp:106] Iteration 36400, lr = 0.0005
I0514 20:06:57.061712 12912 solver.cpp:228] Iteration 36450, loss = 0.0158175
I0514 20:06:57.061982 12912 solver.cpp:244]     Train net output #0: loss = 0.0158179 (* 1 = 0.0158179 loss)
I0514 20:06:57.062003 12912 sgd_solver.cpp:106] Iteration 36450, lr = 0.0005
I0514 20:07:35.014262 12912 solver.cpp:228] Iteration 36500, loss = 0.175817
I0514 20:07:35.022119 12912 solver.cpp:244]     Train net output #0: loss = 0.175818 (* 1 = 0.175818 loss)
I0514 20:07:35.022151 12912 sgd_solver.cpp:106] Iteration 36500, lr = 0.0005
I0514 20:08:12.962858 12912 solver.cpp:228] Iteration 36550, loss = 0.0109206
I0514 20:08:12.963034 12912 solver.cpp:244]     Train net output #0: loss = 0.0109209 (* 1 = 0.0109209 loss)
I0514 20:08:12.963074 12912 sgd_solver.cpp:106] Iteration 36550, lr = 0.0005
I0514 20:08:50.912755 12912 solver.cpp:228] Iteration 36600, loss = 0.0050512
I0514 20:08:50.912889 12912 solver.cpp:244]     Train net output #0: loss = 0.00505159 (* 1 = 0.00505159 loss)
I0514 20:08:50.912904 12912 sgd_solver.cpp:106] Iteration 36600, lr = 0.0005
I0514 20:09:28.860855 12912 solver.cpp:228] Iteration 36650, loss = 0.0279546
I0514 20:09:28.860996 12912 solver.cpp:244]     Train net output #0: loss = 0.0279549 (* 1 = 0.0279549 loss)
I0514 20:09:28.861016 12912 sgd_solver.cpp:106] Iteration 36650, lr = 0.0005
I0514 20:10:06.816107 12912 solver.cpp:228] Iteration 36700, loss = 0.0107792
I0514 20:10:06.816236 12912 solver.cpp:244]     Train net output #0: loss = 0.0107796 (* 1 = 0.0107796 loss)
I0514 20:10:06.816256 12912 sgd_solver.cpp:106] Iteration 36700, lr = 0.0005
I0514 20:10:44.790379 12912 solver.cpp:228] Iteration 36750, loss = 0.00880713
I0514 20:10:44.790477 12912 solver.cpp:244]     Train net output #0: loss = 0.00880749 (* 1 = 0.00880749 loss)
I0514 20:10:44.790490 12912 sgd_solver.cpp:106] Iteration 36750, lr = 0.0005
I0514 20:11:22.719621 12912 solver.cpp:228] Iteration 36800, loss = 0.0575221
I0514 20:11:22.719764 12912 solver.cpp:244]     Train net output #0: loss = 0.0575225 (* 1 = 0.0575225 loss)
I0514 20:11:22.719781 12912 sgd_solver.cpp:106] Iteration 36800, lr = 0.0005
I0514 20:12:00.687731 12912 solver.cpp:228] Iteration 36850, loss = 0.0333726
I0514 20:12:00.687942 12912 solver.cpp:244]     Train net output #0: loss = 0.033373 (* 1 = 0.033373 loss)
I0514 20:12:00.687985 12912 sgd_solver.cpp:106] Iteration 36850, lr = 0.0005
I0514 20:12:38.640103 12912 solver.cpp:228] Iteration 36900, loss = 0.0375188
I0514 20:12:38.640218 12912 solver.cpp:244]     Train net output #0: loss = 0.0375192 (* 1 = 0.0375192 loss)
I0514 20:12:38.640235 12912 sgd_solver.cpp:106] Iteration 36900, lr = 0.0005
I0514 20:13:16.608700 12912 solver.cpp:228] Iteration 36950, loss = 0.00928016
I0514 20:13:16.608825 12912 solver.cpp:244]     Train net output #0: loss = 0.00928054 (* 1 = 0.00928054 loss)
I0514 20:13:16.608844 12912 sgd_solver.cpp:106] Iteration 36950, lr = 0.0005
I0514 20:13:54.259927 12912 solver.cpp:454] Snapshotting to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_37000.caffemodel
I0514 20:13:54.470975 12912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_37000.solverstate
I0514 20:13:54.550907 12912 solver.cpp:337] Iteration 37000, Testing net (#0)
I0514 20:13:54.550972 12912 net.cpp:685] Ignoring source layer loss
I0514 20:15:37.524330 12912 solver.cpp:404]     Test net output #0: accuracy = 0.694265
I0514 20:15:37.814640 12912 solver.cpp:228] Iteration 37000, loss = 0.00852714
I0514 20:15:37.814688 12912 solver.cpp:244]     Train net output #0: loss = 0.00852752 (* 1 = 0.00852752 loss)
I0514 20:15:37.814698 12912 sgd_solver.cpp:106] Iteration 37000, lr = 0.0005
I0514 20:16:15.780094 12912 solver.cpp:228] Iteration 37050, loss = 0.0121707
I0514 20:16:15.780195 12912 solver.cpp:244]     Train net output #0: loss = 0.0121711 (* 1 = 0.0121711 loss)
I0514 20:16:15.780208 12912 sgd_solver.cpp:106] Iteration 37050, lr = 0.0005
I0514 20:16:53.755728 12912 solver.cpp:228] Iteration 37100, loss = 0.0134597
I0514 20:16:53.755846 12912 solver.cpp:244]     Train net output #0: loss = 0.01346 (* 1 = 0.01346 loss)
I0514 20:16:53.755858 12912 sgd_solver.cpp:106] Iteration 37100, lr = 0.0005
I0514 20:17:31.717188 12912 solver.cpp:228] Iteration 37150, loss = 0.0147648
I0514 20:17:31.717363 12912 solver.cpp:244]     Train net output #0: loss = 0.0147652 (* 1 = 0.0147652 loss)
I0514 20:17:31.717383 12912 sgd_solver.cpp:106] Iteration 37150, lr = 0.0005
I0514 20:18:09.674386 12912 solver.cpp:228] Iteration 37200, loss = 0.0200545
I0514 20:18:09.674499 12912 solver.cpp:244]     Train net output #0: loss = 0.0200549 (* 1 = 0.0200549 loss)
I0514 20:18:09.674512 12912 sgd_solver.cpp:106] Iteration 37200, lr = 0.0005
I0514 20:18:47.629523 12912 solver.cpp:228] Iteration 37250, loss = 0.0128489
I0514 20:18:47.629626 12912 solver.cpp:244]     Train net output #0: loss = 0.0128492 (* 1 = 0.0128492 loss)
I0514 20:18:47.629639 12912 sgd_solver.cpp:106] Iteration 37250, lr = 0.0005
I0514 20:19:25.588781 12912 solver.cpp:228] Iteration 37300, loss = 0.010858
I0514 20:19:25.588887 12912 solver.cpp:244]     Train net output #0: loss = 0.0108584 (* 1 = 0.0108584 loss)
I0514 20:19:25.588901 12912 sgd_solver.cpp:106] Iteration 37300, lr = 0.0005
I0514 20:20:03.536470 12912 solver.cpp:228] Iteration 37350, loss = 0.00710136
I0514 20:20:03.536623 12912 solver.cpp:244]     Train net output #0: loss = 0.00710173 (* 1 = 0.00710173 loss)
I0514 20:20:03.536640 12912 sgd_solver.cpp:106] Iteration 37350, lr = 0.0005
I0514 20:20:41.496071 12912 solver.cpp:228] Iteration 37400, loss = 0.0157821
I0514 20:20:41.496203 12912 solver.cpp:244]     Train net output #0: loss = 0.0157825 (* 1 = 0.0157825 loss)
I0514 20:20:41.496245 12912 sgd_solver.cpp:106] Iteration 37400, lr = 0.0005
I0514 20:21:19.451871 12912 solver.cpp:228] Iteration 37450, loss = 0.0091335
I0514 20:21:19.451977 12912 solver.cpp:244]     Train net output #0: loss = 0.00913386 (* 1 = 0.00913386 loss)
I0514 20:21:19.451994 12912 sgd_solver.cpp:106] Iteration 37450, lr = 0.0005
I0514 20:21:57.405755 12912 solver.cpp:228] Iteration 37500, loss = 0.0634831
I0514 20:21:57.405874 12912 solver.cpp:244]     Train net output #0: loss = 0.0634835 (* 1 = 0.0634835 loss)
I0514 20:21:57.405886 12912 sgd_solver.cpp:106] Iteration 37500, lr = 0.0005
I0514 20:22:35.364809 12912 solver.cpp:228] Iteration 37550, loss = 0.00551479
I0514 20:22:35.365002 12912 solver.cpp:244]     Train net output #0: loss = 0.00551515 (* 1 = 0.00551515 loss)
I0514 20:22:35.365021 12912 sgd_solver.cpp:106] Iteration 37550, lr = 0.0005
I0514 20:23:13.334827 12912 solver.cpp:228] Iteration 37600, loss = 0.0115389
I0514 20:23:13.335000 12912 solver.cpp:244]     Train net output #0: loss = 0.0115392 (* 1 = 0.0115392 loss)
I0514 20:23:13.335014 12912 sgd_solver.cpp:106] Iteration 37600, lr = 0.0005
I0514 20:23:51.305536 12912 solver.cpp:228] Iteration 37650, loss = 0.0533393
I0514 20:23:51.305713 12912 solver.cpp:244]     Train net output #0: loss = 0.0533396 (* 1 = 0.0533396 loss)
I0514 20:23:51.305783 12912 sgd_solver.cpp:106] Iteration 37650, lr = 0.0005
I0514 20:24:29.289419 12912 solver.cpp:228] Iteration 37700, loss = 0.0163416
I0514 20:24:29.289572 12912 solver.cpp:244]     Train net output #0: loss = 0.0163419 (* 1 = 0.0163419 loss)
I0514 20:24:29.289592 12912 sgd_solver.cpp:106] Iteration 37700, lr = 0.0005
I0514 20:25:07.260663 12912 solver.cpp:228] Iteration 37750, loss = 0.0255311
I0514 20:25:07.260795 12912 solver.cpp:244]     Train net output #0: loss = 0.0255315 (* 1 = 0.0255315 loss)
I0514 20:25:07.260810 12912 sgd_solver.cpp:106] Iteration 37750, lr = 0.0005
I0514 20:25:45.244717 12912 solver.cpp:228] Iteration 37800, loss = 0.0263388
I0514 20:25:45.244822 12912 solver.cpp:244]     Train net output #0: loss = 0.0263392 (* 1 = 0.0263392 loss)
I0514 20:25:45.244835 12912 sgd_solver.cpp:106] Iteration 37800, lr = 0.0005
I0514 20:26:23.208348 12912 solver.cpp:228] Iteration 37850, loss = 0.0141563
I0514 20:26:23.208454 12912 solver.cpp:244]     Train net output #0: loss = 0.0141567 (* 1 = 0.0141567 loss)
I0514 20:26:23.208472 12912 sgd_solver.cpp:106] Iteration 37850, lr = 0.0005
I0514 20:27:01.151070 12912 solver.cpp:228] Iteration 37900, loss = 0.0107799
I0514 20:27:01.151244 12912 solver.cpp:244]     Train net output #0: loss = 0.0107804 (* 1 = 0.0107804 loss)
I0514 20:27:01.151283 12912 sgd_solver.cpp:106] Iteration 37900, lr = 0.0005
I0514 20:27:39.109763 12912 solver.cpp:228] Iteration 37950, loss = 0.0122807
I0514 20:27:39.109923 12912 solver.cpp:244]     Train net output #0: loss = 0.0122811 (* 1 = 0.0122811 loss)
I0514 20:27:39.109942 12912 sgd_solver.cpp:106] Iteration 37950, lr = 0.0005
I0514 20:28:16.759548 12912 solver.cpp:454] Snapshotting to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_38000.caffemodel
I0514 20:28:17.392184 12912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_38000.solverstate
I0514 20:28:17.475288 12912 solver.cpp:337] Iteration 38000, Testing net (#0)
I0514 20:28:17.475347 12912 net.cpp:685] Ignoring source layer loss
I0514 20:30:00.444811 12912 solver.cpp:404]     Test net output #0: accuracy = 0.735588
I0514 20:30:00.734876 12912 solver.cpp:228] Iteration 38000, loss = 0.012243
I0514 20:30:00.734946 12912 solver.cpp:244]     Train net output #0: loss = 0.0122434 (* 1 = 0.0122434 loss)
I0514 20:30:00.734961 12912 sgd_solver.cpp:106] Iteration 38000, lr = 0.0005
I0514 20:30:38.690922 12912 solver.cpp:228] Iteration 38050, loss = 0.00901718
I0514 20:30:38.691072 12912 solver.cpp:244]     Train net output #0: loss = 0.00901758 (* 1 = 0.00901758 loss)
I0514 20:30:38.691089 12912 sgd_solver.cpp:106] Iteration 38050, lr = 0.0005
I0514 20:31:16.661263 12912 solver.cpp:228] Iteration 38100, loss = 0.018223
I0514 20:31:16.661367 12912 solver.cpp:244]     Train net output #0: loss = 0.0182234 (* 1 = 0.0182234 loss)
I0514 20:31:16.661386 12912 sgd_solver.cpp:106] Iteration 38100, lr = 0.0005
I0514 20:31:54.618681 12912 solver.cpp:228] Iteration 38150, loss = 0.00855931
I0514 20:31:54.618788 12912 solver.cpp:244]     Train net output #0: loss = 0.0085597 (* 1 = 0.0085597 loss)
I0514 20:31:54.618805 12912 sgd_solver.cpp:106] Iteration 38150, lr = 0.0005
I0514 20:32:32.570695 12912 solver.cpp:228] Iteration 38200, loss = 0.00999812
I0514 20:32:32.570837 12912 solver.cpp:244]     Train net output #0: loss = 0.00999852 (* 1 = 0.00999852 loss)
I0514 20:32:32.570850 12912 sgd_solver.cpp:106] Iteration 38200, lr = 0.0005
I0514 20:33:10.521910 12912 solver.cpp:228] Iteration 38250, loss = 0.0127006
I0514 20:33:10.522058 12912 solver.cpp:244]     Train net output #0: loss = 0.012701 (* 1 = 0.012701 loss)
I0514 20:33:10.522076 12912 sgd_solver.cpp:106] Iteration 38250, lr = 0.0005
I0514 20:33:48.507058 12912 solver.cpp:228] Iteration 38300, loss = 0.0152943
I0514 20:33:48.507165 12912 solver.cpp:244]     Train net output #0: loss = 0.0152947 (* 1 = 0.0152947 loss)
I0514 20:33:48.507184 12912 sgd_solver.cpp:106] Iteration 38300, lr = 0.0005
I0514 20:34:26.458035 12912 solver.cpp:228] Iteration 38350, loss = 0.090947
I0514 20:34:26.458143 12912 solver.cpp:244]     Train net output #0: loss = 0.0909474 (* 1 = 0.0909474 loss)
I0514 20:34:26.458161 12912 sgd_solver.cpp:106] Iteration 38350, lr = 0.0005
I0514 20:35:04.414983 12912 solver.cpp:228] Iteration 38400, loss = 0.0244483
I0514 20:35:04.415099 12912 solver.cpp:244]     Train net output #0: loss = 0.0244487 (* 1 = 0.0244487 loss)
I0514 20:35:04.415112 12912 sgd_solver.cpp:106] Iteration 38400, lr = 0.0005
I0514 20:35:42.360050 12912 solver.cpp:228] Iteration 38450, loss = 0.0217599
I0514 20:35:42.360167 12912 solver.cpp:244]     Train net output #0: loss = 0.0217603 (* 1 = 0.0217603 loss)
I0514 20:35:42.360182 12912 sgd_solver.cpp:106] Iteration 38450, lr = 0.0005
I0514 20:36:20.328433 12912 solver.cpp:228] Iteration 38500, loss = 0.0188621
I0514 20:36:20.328536 12912 solver.cpp:244]     Train net output #0: loss = 0.0188624 (* 1 = 0.0188624 loss)
I0514 20:36:20.328554 12912 sgd_solver.cpp:106] Iteration 38500, lr = 0.0005
I0514 20:36:58.290169 12912 solver.cpp:228] Iteration 38550, loss = 0.0126988
I0514 20:36:58.290352 12912 solver.cpp:244]     Train net output #0: loss = 0.0126992 (* 1 = 0.0126992 loss)
I0514 20:36:58.290388 12912 sgd_solver.cpp:106] Iteration 38550, lr = 0.0005
I0514 20:37:36.239596 12912 solver.cpp:228] Iteration 38600, loss = 0.0186474
I0514 20:37:36.239742 12912 solver.cpp:244]     Train net output #0: loss = 0.0186478 (* 1 = 0.0186478 loss)
I0514 20:37:36.239754 12912 sgd_solver.cpp:106] Iteration 38600, lr = 0.0005
I0514 20:38:14.188560 12912 solver.cpp:228] Iteration 38650, loss = 0.0295201
I0514 20:38:14.188779 12912 solver.cpp:244]     Train net output #0: loss = 0.0295204 (* 1 = 0.0295204 loss)
I0514 20:38:14.188825 12912 sgd_solver.cpp:106] Iteration 38650, lr = 0.0005
I0514 20:38:52.123425 12912 solver.cpp:228] Iteration 38700, loss = 0.0148426
I0514 20:38:52.123543 12912 solver.cpp:244]     Train net output #0: loss = 0.014843 (* 1 = 0.014843 loss)
I0514 20:38:52.123560 12912 sgd_solver.cpp:106] Iteration 38700, lr = 0.0005
I0514 20:39:30.063096 12912 solver.cpp:228] Iteration 38750, loss = 0.00898121
I0514 20:39:30.063217 12912 solver.cpp:244]     Train net output #0: loss = 0.00898156 (* 1 = 0.00898156 loss)
I0514 20:39:30.063230 12912 sgd_solver.cpp:106] Iteration 38750, lr = 0.0005
I0514 20:40:08.003011 12912 solver.cpp:228] Iteration 38800, loss = 0.041657
I0514 20:40:08.003131 12912 solver.cpp:244]     Train net output #0: loss = 0.0416573 (* 1 = 0.0416573 loss)
I0514 20:40:08.003144 12912 sgd_solver.cpp:106] Iteration 38800, lr = 0.0005
I0514 20:40:45.950860 12912 solver.cpp:228] Iteration 38850, loss = 0.047949
I0514 20:40:45.950981 12912 solver.cpp:244]     Train net output #0: loss = 0.0479494 (* 1 = 0.0479494 loss)
I0514 20:40:45.950994 12912 sgd_solver.cpp:106] Iteration 38850, lr = 0.0005
I0514 20:41:23.896651 12912 solver.cpp:228] Iteration 38900, loss = 0.0248674
I0514 20:41:23.896770 12912 solver.cpp:244]     Train net output #0: loss = 0.0248678 (* 1 = 0.0248678 loss)
I0514 20:41:23.896788 12912 sgd_solver.cpp:106] Iteration 38900, lr = 0.0005
I0514 20:42:01.848436 12912 solver.cpp:228] Iteration 38950, loss = 0.0166768
I0514 20:42:01.848620 12912 solver.cpp:244]     Train net output #0: loss = 0.0166772 (* 1 = 0.0166772 loss)
I0514 20:42:01.848659 12912 sgd_solver.cpp:106] Iteration 38950, lr = 0.0005
I0514 20:42:39.506484 12912 solver.cpp:454] Snapshotting to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_39000.caffemodel
I0514 20:42:40.036708 12912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_39000.solverstate
I0514 20:42:40.118353 12912 solver.cpp:337] Iteration 39000, Testing net (#0)
I0514 20:42:40.118403 12912 net.cpp:685] Ignoring source layer loss
I0514 20:44:23.085579 12912 solver.cpp:404]     Test net output #0: accuracy = 0.741324
I0514 20:44:23.377018 12912 solver.cpp:228] Iteration 39000, loss = 0.0222479
I0514 20:44:23.377094 12912 solver.cpp:244]     Train net output #0: loss = 0.0222482 (* 1 = 0.0222482 loss)
I0514 20:44:23.377116 12912 sgd_solver.cpp:106] Iteration 39000, lr = 0.0005
I0514 20:45:01.359263 12912 solver.cpp:228] Iteration 39050, loss = 0.0191018
I0514 20:45:01.359421 12912 solver.cpp:244]     Train net output #0: loss = 0.0191022 (* 1 = 0.0191022 loss)
I0514 20:45:01.359438 12912 sgd_solver.cpp:106] Iteration 39050, lr = 0.0005
I0514 20:45:39.346966 12912 solver.cpp:228] Iteration 39100, loss = 0.00393822
I0514 20:45:39.347187 12912 solver.cpp:244]     Train net output #0: loss = 0.00393859 (* 1 = 0.00393859 loss)
I0514 20:45:39.347237 12912 sgd_solver.cpp:106] Iteration 39100, lr = 0.0005
I0514 20:46:17.326879 12912 solver.cpp:228] Iteration 39150, loss = 0.00692858
I0514 20:46:17.327028 12912 solver.cpp:244]     Train net output #0: loss = 0.00692896 (* 1 = 0.00692896 loss)
I0514 20:46:17.327045 12912 sgd_solver.cpp:106] Iteration 39150, lr = 0.0005
I0514 20:46:55.288739 12912 solver.cpp:228] Iteration 39200, loss = 0.00630177
I0514 20:46:55.288875 12912 solver.cpp:244]     Train net output #0: loss = 0.00630215 (* 1 = 0.00630215 loss)
I0514 20:46:55.288892 12912 sgd_solver.cpp:106] Iteration 39200, lr = 0.0005
I0514 20:47:33.266340 12912 solver.cpp:228] Iteration 39250, loss = 0.00473744
I0514 20:47:33.266443 12912 solver.cpp:244]     Train net output #0: loss = 0.00473782 (* 1 = 0.00473782 loss)
I0514 20:47:33.266456 12912 sgd_solver.cpp:106] Iteration 39250, lr = 0.0005
I0514 20:48:11.238859 12912 solver.cpp:228] Iteration 39300, loss = 0.0105984
I0514 20:48:11.239028 12912 solver.cpp:244]     Train net output #0: loss = 0.0105988 (* 1 = 0.0105988 loss)
I0514 20:48:11.239048 12912 sgd_solver.cpp:106] Iteration 39300, lr = 0.0005
I0514 20:48:49.200068 12912 solver.cpp:228] Iteration 39350, loss = 0.00582077
I0514 20:48:49.200206 12912 solver.cpp:244]     Train net output #0: loss = 0.00582116 (* 1 = 0.00582116 loss)
I0514 20:48:49.200220 12912 sgd_solver.cpp:106] Iteration 39350, lr = 0.0005
I0514 20:49:27.171908 12912 solver.cpp:228] Iteration 39400, loss = 0.00802412
I0514 20:49:27.172065 12912 solver.cpp:244]     Train net output #0: loss = 0.00802451 (* 1 = 0.00802451 loss)
I0514 20:49:27.172111 12912 sgd_solver.cpp:106] Iteration 39400, lr = 0.0005
I0514 20:50:05.135751 12912 solver.cpp:228] Iteration 39450, loss = 0.00886899
I0514 20:50:05.135864 12912 solver.cpp:244]     Train net output #0: loss = 0.00886938 (* 1 = 0.00886938 loss)
I0514 20:50:05.135881 12912 sgd_solver.cpp:106] Iteration 39450, lr = 0.0005
I0514 20:50:43.097643 12912 solver.cpp:228] Iteration 39500, loss = 0.00546154
I0514 20:50:43.097744 12912 solver.cpp:244]     Train net output #0: loss = 0.00546194 (* 1 = 0.00546194 loss)
I0514 20:50:43.097761 12912 sgd_solver.cpp:106] Iteration 39500, lr = 0.0005
I0514 20:51:21.053319 12912 solver.cpp:228] Iteration 39550, loss = 0.00753419
I0514 20:51:21.053450 12912 solver.cpp:244]     Train net output #0: loss = 0.00753458 (* 1 = 0.00753458 loss)
I0514 20:51:21.053467 12912 sgd_solver.cpp:106] Iteration 39550, lr = 0.0005
I0514 20:51:59.009266 12912 solver.cpp:228] Iteration 39600, loss = 0.0244653
I0514 20:51:59.009485 12912 solver.cpp:244]     Train net output #0: loss = 0.0244657 (* 1 = 0.0244657 loss)
I0514 20:51:59.009506 12912 sgd_solver.cpp:106] Iteration 39600, lr = 0.0005
I0514 20:52:36.963774 12912 solver.cpp:228] Iteration 39650, loss = 0.0499274
I0514 20:52:36.963913 12912 solver.cpp:244]     Train net output #0: loss = 0.0499278 (* 1 = 0.0499278 loss)
I0514 20:52:36.963932 12912 sgd_solver.cpp:106] Iteration 39650, lr = 0.0005
I0514 20:53:14.924093 12912 solver.cpp:228] Iteration 39700, loss = 0.00689761
I0514 20:53:14.924196 12912 solver.cpp:244]     Train net output #0: loss = 0.00689801 (* 1 = 0.00689801 loss)
I0514 20:53:14.924208 12912 sgd_solver.cpp:106] Iteration 39700, lr = 0.0005
I0514 20:53:52.891836 12912 solver.cpp:228] Iteration 39750, loss = 0.00605644
I0514 20:53:52.891943 12912 solver.cpp:244]     Train net output #0: loss = 0.00605684 (* 1 = 0.00605684 loss)
I0514 20:53:52.891957 12912 sgd_solver.cpp:106] Iteration 39750, lr = 0.0005
I0514 20:54:30.873229 12912 solver.cpp:228] Iteration 39800, loss = 0.00344291
I0514 20:54:30.873452 12912 solver.cpp:244]     Train net output #0: loss = 0.00344331 (* 1 = 0.00344331 loss)
I0514 20:54:30.873495 12912 sgd_solver.cpp:106] Iteration 39800, lr = 0.0005
I0514 20:55:08.838281 12912 solver.cpp:228] Iteration 39850, loss = 0.00506993
I0514 20:55:08.838461 12912 solver.cpp:244]     Train net output #0: loss = 0.00507034 (* 1 = 0.00507034 loss)
I0514 20:55:08.838479 12912 sgd_solver.cpp:106] Iteration 39850, lr = 0.0005
I0514 20:55:46.800384 12912 solver.cpp:228] Iteration 39900, loss = 0.00667634
I0514 20:55:46.800493 12912 solver.cpp:244]     Train net output #0: loss = 0.00667675 (* 1 = 0.00667675 loss)
I0514 20:55:46.800513 12912 sgd_solver.cpp:106] Iteration 39900, lr = 0.0005
I0514 20:56:24.770766 12912 solver.cpp:228] Iteration 39950, loss = 0.0176331
I0514 20:56:24.770938 12912 solver.cpp:244]     Train net output #0: loss = 0.0176335 (* 1 = 0.0176335 loss)
I0514 20:56:24.770956 12912 sgd_solver.cpp:106] Iteration 39950, lr = 0.0005
I0514 20:57:02.445142 12912 solver.cpp:454] Snapshotting to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_40000.caffemodel
I0514 20:57:03.031241 12912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_40000.solverstate
I0514 20:57:03.176383 12912 solver.cpp:337] Iteration 40000, Testing net (#0)
I0514 20:57:03.176496 12912 net.cpp:685] Ignoring source layer loss
I0514 20:58:46.007851 12912 solver.cpp:404]     Test net output #0: accuracy = 0.755588
I0514 20:58:46.297552 12912 solver.cpp:228] Iteration 40000, loss = 0.0104584
I0514 20:58:46.297623 12912 solver.cpp:244]     Train net output #0: loss = 0.0104588 (* 1 = 0.0104588 loss)
I0514 20:58:46.297638 12912 sgd_solver.cpp:106] Iteration 40000, lr = 0.0005
I0514 20:59:24.272122 12912 solver.cpp:228] Iteration 40050, loss = 0.0117145
I0514 20:59:24.272316 12912 solver.cpp:244]     Train net output #0: loss = 0.0117149 (* 1 = 0.0117149 loss)
I0514 20:59:24.272336 12912 sgd_solver.cpp:106] Iteration 40050, lr = 0.0005
I0514 21:00:02.241567 12912 solver.cpp:228] Iteration 40100, loss = 0.0161521
I0514 21:00:02.241705 12912 solver.cpp:244]     Train net output #0: loss = 0.0161525 (* 1 = 0.0161525 loss)
I0514 21:00:02.241721 12912 sgd_solver.cpp:106] Iteration 40100, lr = 0.0005
I0514 21:00:40.211761 12912 solver.cpp:228] Iteration 40150, loss = 0.0089371
I0514 21:00:40.211884 12912 solver.cpp:244]     Train net output #0: loss = 0.00893751 (* 1 = 0.00893751 loss)
I0514 21:00:40.211902 12912 sgd_solver.cpp:106] Iteration 40150, lr = 0.0005
I0514 21:01:18.164327 12912 solver.cpp:228] Iteration 40200, loss = 0.0406194
I0514 21:01:18.164469 12912 solver.cpp:244]     Train net output #0: loss = 0.0406199 (* 1 = 0.0406199 loss)
I0514 21:01:18.164511 12912 sgd_solver.cpp:106] Iteration 40200, lr = 0.0005
I0514 21:01:56.138759 12912 solver.cpp:228] Iteration 40250, loss = 0.0138388
I0514 21:01:56.138860 12912 solver.cpp:244]     Train net output #0: loss = 0.0138392 (* 1 = 0.0138392 loss)
I0514 21:01:56.138873 12912 sgd_solver.cpp:106] Iteration 40250, lr = 0.0005
I0514 21:02:34.093247 12912 solver.cpp:228] Iteration 40300, loss = 0.0179513
I0514 21:02:34.093405 12912 solver.cpp:244]     Train net output #0: loss = 0.0179518 (* 1 = 0.0179518 loss)
I0514 21:02:34.093423 12912 sgd_solver.cpp:106] Iteration 40300, lr = 0.0005
I0514 21:03:12.069195 12912 solver.cpp:228] Iteration 40350, loss = 0.0226184
I0514 21:03:12.069382 12912 solver.cpp:244]     Train net output #0: loss = 0.0226189 (* 1 = 0.0226189 loss)
I0514 21:03:12.069422 12912 sgd_solver.cpp:106] Iteration 40350, lr = 0.0005
I0514 21:03:50.037027 12912 solver.cpp:228] Iteration 40400, loss = 0.0109925
I0514 21:03:50.037158 12912 solver.cpp:244]     Train net output #0: loss = 0.0109929 (* 1 = 0.0109929 loss)
I0514 21:03:50.037171 12912 sgd_solver.cpp:106] Iteration 40400, lr = 0.0005
I0514 21:04:28.005417 12912 solver.cpp:228] Iteration 40450, loss = 0.0038764
I0514 21:04:28.005568 12912 solver.cpp:244]     Train net output #0: loss = 0.00387681 (* 1 = 0.00387681 loss)
I0514 21:04:28.005586 12912 sgd_solver.cpp:106] Iteration 40450, lr = 0.0005
I0514 21:05:05.963860 12912 solver.cpp:228] Iteration 40500, loss = 0.0254629
I0514 21:05:05.964016 12912 solver.cpp:244]     Train net output #0: loss = 0.0254632 (* 1 = 0.0254632 loss)
I0514 21:05:05.964031 12912 sgd_solver.cpp:106] Iteration 40500, lr = 0.0005
I0514 21:05:43.967145 12912 solver.cpp:228] Iteration 40550, loss = 0.0249783
I0514 21:05:43.967249 12912 solver.cpp:244]     Train net output #0: loss = 0.0249787 (* 1 = 0.0249787 loss)
I0514 21:05:43.967267 12912 sgd_solver.cpp:106] Iteration 40550, lr = 0.0005
I0514 21:06:21.919703 12912 solver.cpp:228] Iteration 40600, loss = 0.00586018
I0514 21:06:21.919993 12912 solver.cpp:244]     Train net output #0: loss = 0.00586058 (* 1 = 0.00586058 loss)
I0514 21:06:21.920058 12912 sgd_solver.cpp:106] Iteration 40600, lr = 0.0005
I0514 21:06:59.896425 12912 solver.cpp:228] Iteration 40650, loss = 0.00157835
I0514 21:06:59.896587 12912 solver.cpp:244]     Train net output #0: loss = 0.00157875 (* 1 = 0.00157875 loss)
I0514 21:06:59.896603 12912 sgd_solver.cpp:106] Iteration 40650, lr = 0.0005
I0514 21:07:37.869091 12912 solver.cpp:228] Iteration 40700, loss = 0.00367247
I0514 21:07:37.869225 12912 solver.cpp:244]     Train net output #0: loss = 0.00367287 (* 1 = 0.00367287 loss)
I0514 21:07:37.869246 12912 sgd_solver.cpp:106] Iteration 40700, lr = 0.0005
I0514 21:08:15.831085 12912 solver.cpp:228] Iteration 40750, loss = 0.011664
I0514 21:08:15.831264 12912 solver.cpp:244]     Train net output #0: loss = 0.0116644 (* 1 = 0.0116644 loss)
I0514 21:08:15.831285 12912 sgd_solver.cpp:106] Iteration 40750, lr = 0.0005
I0514 21:08:53.783126 12912 solver.cpp:228] Iteration 40800, loss = 0.0182012
I0514 21:08:53.783236 12912 solver.cpp:244]     Train net output #0: loss = 0.0182016 (* 1 = 0.0182016 loss)
I0514 21:08:53.783254 12912 sgd_solver.cpp:106] Iteration 40800, lr = 0.0005
I0514 21:09:31.748920 12912 solver.cpp:228] Iteration 40850, loss = 0.00998799
I0514 21:09:31.749096 12912 solver.cpp:244]     Train net output #0: loss = 0.0099884 (* 1 = 0.0099884 loss)
I0514 21:09:31.749114 12912 sgd_solver.cpp:106] Iteration 40850, lr = 0.0005
I0514 21:10:09.707952 12912 solver.cpp:228] Iteration 40900, loss = 0.00529136
I0514 21:10:09.708081 12912 solver.cpp:244]     Train net output #0: loss = 0.00529179 (* 1 = 0.00529179 loss)
I0514 21:10:09.708099 12912 sgd_solver.cpp:106] Iteration 40900, lr = 0.0005
I0514 21:10:47.657450 12912 solver.cpp:228] Iteration 40950, loss = 0.0100014
I0514 21:10:47.657552 12912 solver.cpp:244]     Train net output #0: loss = 0.0100019 (* 1 = 0.0100019 loss)
I0514 21:10:47.657567 12912 sgd_solver.cpp:106] Iteration 40950, lr = 0.0005
I0514 21:11:25.307055 12912 solver.cpp:454] Snapshotting to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_41000.caffemodel
I0514 21:11:25.803805 12912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_41000.solverstate
I0514 21:11:25.886412 12912 solver.cpp:337] Iteration 41000, Testing net (#0)
I0514 21:11:25.886471 12912 net.cpp:685] Ignoring source layer loss
I0514 21:13:08.626647 12912 solver.cpp:404]     Test net output #0: accuracy = 0.723235
I0514 21:13:08.916223 12912 solver.cpp:228] Iteration 41000, loss = 0.0265012
I0514 21:13:08.916291 12912 solver.cpp:244]     Train net output #0: loss = 0.0265016 (* 1 = 0.0265016 loss)
I0514 21:13:08.916306 12912 sgd_solver.cpp:106] Iteration 41000, lr = 0.0005
I0514 21:13:46.864356 12912 solver.cpp:228] Iteration 41050, loss = 0.00345579
I0514 21:13:46.864456 12912 solver.cpp:244]     Train net output #0: loss = 0.00345623 (* 1 = 0.00345623 loss)
I0514 21:13:46.864475 12912 sgd_solver.cpp:106] Iteration 41050, lr = 0.0005
I0514 21:14:24.829491 12912 solver.cpp:228] Iteration 41100, loss = 0.0142854
I0514 21:14:24.829625 12912 solver.cpp:244]     Train net output #0: loss = 0.0142858 (* 1 = 0.0142858 loss)
I0514 21:14:24.829643 12912 sgd_solver.cpp:106] Iteration 41100, lr = 0.0005
I0514 21:15:02.765372 12912 solver.cpp:228] Iteration 41150, loss = 0.00366279
I0514 21:15:02.765501 12912 solver.cpp:244]     Train net output #0: loss = 0.00366323 (* 1 = 0.00366323 loss)
I0514 21:15:02.765514 12912 sgd_solver.cpp:106] Iteration 41150, lr = 0.0005
I0514 21:15:40.730448 12912 solver.cpp:228] Iteration 41200, loss = 0.00378557
I0514 21:15:40.730593 12912 solver.cpp:244]     Train net output #0: loss = 0.00378602 (* 1 = 0.00378602 loss)
I0514 21:15:40.730612 12912 sgd_solver.cpp:106] Iteration 41200, lr = 0.0005
I0514 21:16:18.674566 12912 solver.cpp:228] Iteration 41250, loss = 0.00591543
I0514 21:16:18.674731 12912 solver.cpp:244]     Train net output #0: loss = 0.00591587 (* 1 = 0.00591587 loss)
I0514 21:16:18.674768 12912 sgd_solver.cpp:106] Iteration 41250, lr = 0.0005
I0514 21:16:56.627988 12912 solver.cpp:228] Iteration 41300, loss = 0.00812124
I0514 21:16:56.628094 12912 solver.cpp:244]     Train net output #0: loss = 0.00812168 (* 1 = 0.00812168 loss)
I0514 21:16:56.628111 12912 sgd_solver.cpp:106] Iteration 41300, lr = 0.0005
I0514 21:17:34.590389 12912 solver.cpp:228] Iteration 41350, loss = 0.0170538
I0514 21:17:34.590517 12912 solver.cpp:244]     Train net output #0: loss = 0.0170543 (* 1 = 0.0170543 loss)
I0514 21:17:34.590540 12912 sgd_solver.cpp:106] Iteration 41350, lr = 0.0005
I0514 21:18:12.532732 12912 solver.cpp:228] Iteration 41400, loss = 0.00668001
I0514 21:18:12.533005 12912 solver.cpp:244]     Train net output #0: loss = 0.00668046 (* 1 = 0.00668046 loss)
I0514 21:18:12.533052 12912 sgd_solver.cpp:106] Iteration 41400, lr = 0.0005
I0514 21:18:50.476848 12912 solver.cpp:228] Iteration 41450, loss = 0.00596952
I0514 21:18:50.476996 12912 solver.cpp:244]     Train net output #0: loss = 0.00596996 (* 1 = 0.00596996 loss)
I0514 21:18:50.477010 12912 sgd_solver.cpp:106] Iteration 41450, lr = 0.0005
I0514 21:19:28.435892 12912 solver.cpp:228] Iteration 41500, loss = 0.00771491
I0514 21:19:28.436002 12912 solver.cpp:244]     Train net output #0: loss = 0.00771535 (* 1 = 0.00771535 loss)
I0514 21:19:28.436020 12912 sgd_solver.cpp:106] Iteration 41500, lr = 0.0005
I0514 21:20:06.398775 12912 solver.cpp:228] Iteration 41550, loss = 0.00500913
I0514 21:20:06.398938 12912 solver.cpp:244]     Train net output #0: loss = 0.00500956 (* 1 = 0.00500956 loss)
I0514 21:20:06.398957 12912 sgd_solver.cpp:106] Iteration 41550, lr = 0.0005
I0514 21:20:44.336340 12912 solver.cpp:228] Iteration 41600, loss = 0.00593885
I0514 21:20:44.336500 12912 solver.cpp:244]     Train net output #0: loss = 0.00593928 (* 1 = 0.00593928 loss)
I0514 21:20:44.336519 12912 sgd_solver.cpp:106] Iteration 41600, lr = 0.0005
I0514 21:21:22.290570 12912 solver.cpp:228] Iteration 41650, loss = 0.00561939
I0514 21:21:22.290683 12912 solver.cpp:244]     Train net output #0: loss = 0.00561982 (* 1 = 0.00561982 loss)
I0514 21:21:22.290696 12912 sgd_solver.cpp:106] Iteration 41650, lr = 0.0005
I0514 21:22:00.232630 12912 solver.cpp:228] Iteration 41700, loss = 0.041111
I0514 21:22:00.232741 12912 solver.cpp:244]     Train net output #0: loss = 0.0411114 (* 1 = 0.0411114 loss)
I0514 21:22:00.232759 12912 sgd_solver.cpp:106] Iteration 41700, lr = 0.0005
I0514 21:22:38.177342 12912 solver.cpp:228] Iteration 41750, loss = 0.00776459
I0514 21:22:38.177484 12912 solver.cpp:244]     Train net output #0: loss = 0.00776502 (* 1 = 0.00776502 loss)
I0514 21:22:38.177496 12912 sgd_solver.cpp:106] Iteration 41750, lr = 0.0005
I0514 21:23:16.132027 12912 solver.cpp:228] Iteration 41800, loss = 0.00640082
I0514 21:23:16.132154 12912 solver.cpp:244]     Train net output #0: loss = 0.00640124 (* 1 = 0.00640124 loss)
I0514 21:23:16.132172 12912 sgd_solver.cpp:106] Iteration 41800, lr = 0.0005
I0514 21:23:54.086225 12912 solver.cpp:228] Iteration 41850, loss = 0.00886166
I0514 21:23:54.086354 12912 solver.cpp:244]     Train net output #0: loss = 0.00886208 (* 1 = 0.00886208 loss)
I0514 21:23:54.086366 12912 sgd_solver.cpp:106] Iteration 41850, lr = 0.0005
I0514 21:24:32.038995 12912 solver.cpp:228] Iteration 41900, loss = 0.0218174
I0514 21:24:32.039192 12912 solver.cpp:244]     Train net output #0: loss = 0.0218178 (* 1 = 0.0218178 loss)
I0514 21:24:32.039253 12912 sgd_solver.cpp:106] Iteration 41900, lr = 0.0005
I0514 21:25:09.986246 12912 solver.cpp:228] Iteration 41950, loss = 0.0166715
I0514 21:25:09.986394 12912 solver.cpp:244]     Train net output #0: loss = 0.0166719 (* 1 = 0.0166719 loss)
I0514 21:25:09.986418 12912 sgd_solver.cpp:106] Iteration 41950, lr = 0.0005
I0514 21:25:47.659447 12912 solver.cpp:454] Snapshotting to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_42000.caffemodel
I0514 21:25:48.181056 12912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_42000.solverstate
I0514 21:25:48.262389 12912 solver.cpp:337] Iteration 42000, Testing net (#0)
I0514 21:25:48.262465 12912 net.cpp:685] Ignoring source layer loss
I0514 21:27:31.122078 12912 solver.cpp:404]     Test net output #0: accuracy = 0.699118
I0514 21:27:31.412822 12912 solver.cpp:228] Iteration 42000, loss = 0.00522841
I0514 21:27:31.412873 12912 solver.cpp:244]     Train net output #0: loss = 0.00522883 (* 1 = 0.00522883 loss)
I0514 21:27:31.412886 12912 sgd_solver.cpp:106] Iteration 42000, lr = 0.0005
I0514 21:28:09.389713 12912 solver.cpp:228] Iteration 42050, loss = 0.00524815
I0514 21:28:09.389842 12912 solver.cpp:244]     Train net output #0: loss = 0.00524857 (* 1 = 0.00524857 loss)
I0514 21:28:09.389860 12912 sgd_solver.cpp:106] Iteration 42050, lr = 0.0005
I0514 21:28:47.353171 12912 solver.cpp:228] Iteration 42100, loss = 0.0478436
I0514 21:28:47.353312 12912 solver.cpp:244]     Train net output #0: loss = 0.047844 (* 1 = 0.047844 loss)
I0514 21:28:47.353332 12912 sgd_solver.cpp:106] Iteration 42100, lr = 0.0005
I0514 21:29:25.299641 12912 solver.cpp:228] Iteration 42150, loss = 0.00736594
I0514 21:29:25.299746 12912 solver.cpp:244]     Train net output #0: loss = 0.00736636 (* 1 = 0.00736636 loss)
I0514 21:29:25.299763 12912 sgd_solver.cpp:106] Iteration 42150, lr = 0.0005
I0514 21:30:03.257638 12912 solver.cpp:228] Iteration 42200, loss = 0.00511137
I0514 21:30:03.257807 12912 solver.cpp:244]     Train net output #0: loss = 0.00511179 (* 1 = 0.00511179 loss)
I0514 21:30:03.257853 12912 sgd_solver.cpp:106] Iteration 42200, lr = 0.0005
I0514 21:30:41.196532 12912 solver.cpp:228] Iteration 42250, loss = 0.019478
I0514 21:30:41.196635 12912 solver.cpp:244]     Train net output #0: loss = 0.0194784 (* 1 = 0.0194784 loss)
I0514 21:30:41.196648 12912 sgd_solver.cpp:106] Iteration 42250, lr = 0.0005
I0514 21:31:19.146893 12912 solver.cpp:228] Iteration 42300, loss = 0.00968319
I0514 21:31:19.147035 12912 solver.cpp:244]     Train net output #0: loss = 0.00968362 (* 1 = 0.00968362 loss)
I0514 21:31:19.147050 12912 sgd_solver.cpp:106] Iteration 42300, lr = 0.0005
I0514 21:31:57.084522 12912 solver.cpp:228] Iteration 42350, loss = 0.0416895
I0514 21:31:57.084697 12912 solver.cpp:244]     Train net output #0: loss = 0.0416899 (* 1 = 0.0416899 loss)
I0514 21:31:57.084736 12912 sgd_solver.cpp:106] Iteration 42350, lr = 0.0005
I0514 21:32:35.037029 12912 solver.cpp:228] Iteration 42400, loss = 0.00527927
I0514 21:32:35.037153 12912 solver.cpp:244]     Train net output #0: loss = 0.00527969 (* 1 = 0.00527969 loss)
I0514 21:32:35.037173 12912 sgd_solver.cpp:106] Iteration 42400, lr = 0.0005
I0514 21:33:12.991621 12912 solver.cpp:228] Iteration 42450, loss = 0.00646591
I0514 21:33:12.991724 12912 solver.cpp:244]     Train net output #0: loss = 0.00646633 (* 1 = 0.00646633 loss)
I0514 21:33:12.991741 12912 sgd_solver.cpp:106] Iteration 42450, lr = 0.0005
I0514 21:33:50.939321 12912 solver.cpp:228] Iteration 42500, loss = 0.00241529
I0514 21:33:50.939434 12912 solver.cpp:244]     Train net output #0: loss = 0.00241571 (* 1 = 0.00241571 loss)
I0514 21:33:50.939451 12912 sgd_solver.cpp:106] Iteration 42500, lr = 0.0005
I0514 21:34:28.885171 12912 solver.cpp:228] Iteration 42550, loss = 0.00584419
I0514 21:34:28.885299 12912 solver.cpp:244]     Train net output #0: loss = 0.00584461 (* 1 = 0.00584461 loss)
I0514 21:34:28.885318 12912 sgd_solver.cpp:106] Iteration 42550, lr = 0.0005
I0514 21:35:06.845907 12912 solver.cpp:228] Iteration 42600, loss = 0.0210935
I0514 21:35:06.846010 12912 solver.cpp:244]     Train net output #0: loss = 0.0210939 (* 1 = 0.0210939 loss)
I0514 21:35:06.846037 12912 sgd_solver.cpp:106] Iteration 42600, lr = 0.0005
I0514 21:35:44.791793 12912 solver.cpp:228] Iteration 42650, loss = 0.00791192
I0514 21:35:44.791967 12912 solver.cpp:244]     Train net output #0: loss = 0.00791234 (* 1 = 0.00791234 loss)
I0514 21:35:44.791980 12912 sgd_solver.cpp:106] Iteration 42650, lr = 0.0005
I0514 21:36:22.748729 12912 solver.cpp:228] Iteration 42700, loss = 0.0294441
I0514 21:36:22.748867 12912 solver.cpp:244]     Train net output #0: loss = 0.0294446 (* 1 = 0.0294446 loss)
I0514 21:36:22.748883 12912 sgd_solver.cpp:106] Iteration 42700, lr = 0.0005
I0514 21:37:00.688052 12912 solver.cpp:228] Iteration 42750, loss = 0.00310441
I0514 21:37:00.691197 12912 solver.cpp:244]     Train net output #0: loss = 0.00310485 (* 1 = 0.00310485 loss)
I0514 21:37:00.691227 12912 sgd_solver.cpp:106] Iteration 42750, lr = 0.0005
I0514 21:37:38.642369 12912 solver.cpp:228] Iteration 42800, loss = 0.00600954
I0514 21:37:38.642520 12912 solver.cpp:244]     Train net output #0: loss = 0.00600997 (* 1 = 0.00600997 loss)
I0514 21:37:38.642535 12912 sgd_solver.cpp:106] Iteration 42800, lr = 0.0005
I0514 21:38:16.587008 12912 solver.cpp:228] Iteration 42850, loss = 0.00627335
I0514 21:38:16.587149 12912 solver.cpp:244]     Train net output #0: loss = 0.00627378 (* 1 = 0.00627378 loss)
I0514 21:38:16.587168 12912 sgd_solver.cpp:106] Iteration 42850, lr = 0.0005
I0514 21:38:54.543309 12912 solver.cpp:228] Iteration 42900, loss = 0.00382328
I0514 21:38:54.543496 12912 solver.cpp:244]     Train net output #0: loss = 0.0038237 (* 1 = 0.0038237 loss)
I0514 21:38:54.543536 12912 sgd_solver.cpp:106] Iteration 42900, lr = 0.0005
I0514 21:39:32.490170 12912 solver.cpp:228] Iteration 42950, loss = 0.00374287
I0514 21:39:32.490293 12912 solver.cpp:244]     Train net output #0: loss = 0.0037433 (* 1 = 0.0037433 loss)
I0514 21:39:32.490309 12912 sgd_solver.cpp:106] Iteration 42950, lr = 0.0005
I0514 21:40:10.155971 12912 solver.cpp:454] Snapshotting to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_43000.caffemodel
I0514 21:40:10.687914 12912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_43000.solverstate
I0514 21:40:10.770289 12912 solver.cpp:337] Iteration 43000, Testing net (#0)
I0514 21:40:10.770344 12912 net.cpp:685] Ignoring source layer loss
I0514 21:41:53.724534 12912 solver.cpp:404]     Test net output #0: accuracy = 0.764706
I0514 21:41:54.014034 12912 solver.cpp:228] Iteration 43000, loss = 0.0071439
I0514 21:41:54.014163 12912 solver.cpp:244]     Train net output #0: loss = 0.00714432 (* 1 = 0.00714432 loss)
I0514 21:41:54.014204 12912 sgd_solver.cpp:106] Iteration 43000, lr = 0.0005
I0514 21:42:31.950469 12912 solver.cpp:228] Iteration 43050, loss = 0.0203663
I0514 21:42:31.950567 12912 solver.cpp:244]     Train net output #0: loss = 0.0203668 (* 1 = 0.0203668 loss)
I0514 21:42:31.950579 12912 sgd_solver.cpp:106] Iteration 43050, lr = 0.0005
I0514 21:43:09.889812 12912 solver.cpp:228] Iteration 43100, loss = 0.00946227
I0514 21:43:09.889931 12912 solver.cpp:244]     Train net output #0: loss = 0.00946269 (* 1 = 0.00946269 loss)
I0514 21:43:09.889950 12912 sgd_solver.cpp:106] Iteration 43100, lr = 0.0005
I0514 21:43:47.838891 12912 solver.cpp:228] Iteration 43150, loss = 0.010072
I0514 21:43:47.839035 12912 solver.cpp:244]     Train net output #0: loss = 0.0100724 (* 1 = 0.0100724 loss)
I0514 21:43:47.839047 12912 sgd_solver.cpp:106] Iteration 43150, lr = 0.0005
I0514 21:44:25.802788 12912 solver.cpp:228] Iteration 43200, loss = 0.0113813
I0514 21:44:25.802896 12912 solver.cpp:244]     Train net output #0: loss = 0.0113817 (* 1 = 0.0113817 loss)
I0514 21:44:25.802909 12912 sgd_solver.cpp:106] Iteration 43200, lr = 0.0005
I0514 21:45:03.753790 12912 solver.cpp:228] Iteration 43250, loss = 0.00767847
I0514 21:45:03.753932 12912 solver.cpp:244]     Train net output #0: loss = 0.00767888 (* 1 = 0.00767888 loss)
I0514 21:45:03.753945 12912 sgd_solver.cpp:106] Iteration 43250, lr = 0.0005
I0514 21:45:41.717258 12912 solver.cpp:228] Iteration 43300, loss = 0.015228
I0514 21:45:41.717375 12912 solver.cpp:244]     Train net output #0: loss = 0.0152285 (* 1 = 0.0152285 loss)
I0514 21:45:41.717393 12912 sgd_solver.cpp:106] Iteration 43300, lr = 0.0005
I0514 21:46:19.673671 12912 solver.cpp:228] Iteration 43350, loss = 0.0191567
I0514 21:46:19.673794 12912 solver.cpp:244]     Train net output #0: loss = 0.0191571 (* 1 = 0.0191571 loss)
I0514 21:46:19.673813 12912 sgd_solver.cpp:106] Iteration 43350, lr = 0.0005
I0514 21:46:57.629024 12912 solver.cpp:228] Iteration 43400, loss = 0.00304454
I0514 21:46:57.629161 12912 solver.cpp:244]     Train net output #0: loss = 0.00304496 (* 1 = 0.00304496 loss)
I0514 21:46:57.629179 12912 sgd_solver.cpp:106] Iteration 43400, lr = 0.0005
I0514 21:47:35.572150 12912 solver.cpp:228] Iteration 43450, loss = 0.0403072
I0514 21:47:35.572331 12912 solver.cpp:244]     Train net output #0: loss = 0.0403076 (* 1 = 0.0403076 loss)
I0514 21:47:35.572371 12912 sgd_solver.cpp:106] Iteration 43450, lr = 0.0005
I0514 21:48:13.522096 12912 solver.cpp:228] Iteration 43500, loss = 0.0159776
I0514 21:48:13.522336 12912 solver.cpp:244]     Train net output #0: loss = 0.015978 (* 1 = 0.015978 loss)
I0514 21:48:13.522378 12912 sgd_solver.cpp:106] Iteration 43500, lr = 0.0005
I0514 21:48:51.475309 12912 solver.cpp:228] Iteration 43550, loss = 0.01549
I0514 21:48:51.475411 12912 solver.cpp:244]     Train net output #0: loss = 0.0154904 (* 1 = 0.0154904 loss)
I0514 21:48:51.475424 12912 sgd_solver.cpp:106] Iteration 43550, lr = 0.0005
I0514 21:49:29.438962 12912 solver.cpp:228] Iteration 43600, loss = 0.00364599
I0514 21:49:29.439069 12912 solver.cpp:244]     Train net output #0: loss = 0.00364641 (* 1 = 0.00364641 loss)
I0514 21:49:29.439087 12912 sgd_solver.cpp:106] Iteration 43600, lr = 0.0005
I0514 21:50:07.396808 12912 solver.cpp:228] Iteration 43650, loss = 0.00722267
I0514 21:50:07.396910 12912 solver.cpp:244]     Train net output #0: loss = 0.00722309 (* 1 = 0.00722309 loss)
I0514 21:50:07.396924 12912 sgd_solver.cpp:106] Iteration 43650, lr = 0.0005
I0514 21:50:45.360534 12912 solver.cpp:228] Iteration 43700, loss = 0.0108367
I0514 21:50:45.360718 12912 solver.cpp:244]     Train net output #0: loss = 0.0108371 (* 1 = 0.0108371 loss)
I0514 21:50:45.360765 12912 sgd_solver.cpp:106] Iteration 43700, lr = 0.0005
I0514 21:51:23.327091 12912 solver.cpp:228] Iteration 43750, loss = 0.00889809
I0514 21:51:23.327193 12912 solver.cpp:244]     Train net output #0: loss = 0.00889851 (* 1 = 0.00889851 loss)
I0514 21:51:23.327204 12912 sgd_solver.cpp:106] Iteration 43750, lr = 0.0005
I0514 21:52:01.313295 12912 solver.cpp:228] Iteration 43800, loss = 0.0119827
I0514 21:52:01.313407 12912 solver.cpp:244]     Train net output #0: loss = 0.0119831 (* 1 = 0.0119831 loss)
I0514 21:52:01.313454 12912 sgd_solver.cpp:106] Iteration 43800, lr = 0.0005
I0514 21:52:39.277093 12912 solver.cpp:228] Iteration 43850, loss = 0.00501795
I0514 21:52:39.277206 12912 solver.cpp:244]     Train net output #0: loss = 0.00501835 (* 1 = 0.00501835 loss)
I0514 21:52:39.277220 12912 sgd_solver.cpp:106] Iteration 43850, lr = 0.0005
I0514 21:53:17.229010 12912 solver.cpp:228] Iteration 43900, loss = 0.0133945
I0514 21:53:17.229115 12912 solver.cpp:244]     Train net output #0: loss = 0.0133949 (* 1 = 0.0133949 loss)
I0514 21:53:17.229132 12912 sgd_solver.cpp:106] Iteration 43900, lr = 0.0005
I0514 21:53:55.173280 12912 solver.cpp:228] Iteration 43950, loss = 0.00569101
I0514 21:53:55.173410 12912 solver.cpp:244]     Train net output #0: loss = 0.00569142 (* 1 = 0.00569142 loss)
I0514 21:53:55.173427 12912 sgd_solver.cpp:106] Iteration 43950, lr = 0.0005
I0514 21:54:32.817782 12912 solver.cpp:454] Snapshotting to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_44000.caffemodel
I0514 21:54:33.488418 12912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_44000.solverstate
I0514 21:54:33.572525 12912 solver.cpp:337] Iteration 44000, Testing net (#0)
I0514 21:54:33.572592 12912 net.cpp:685] Ignoring source layer loss
I0514 21:56:16.433145 12912 solver.cpp:404]     Test net output #0: accuracy = 0.724412
I0514 21:56:16.723222 12912 solver.cpp:228] Iteration 44000, loss = 0.0236451
I0514 21:56:16.723270 12912 solver.cpp:244]     Train net output #0: loss = 0.0236455 (* 1 = 0.0236455 loss)
I0514 21:56:16.723284 12912 sgd_solver.cpp:106] Iteration 44000, lr = 0.0005
I0514 21:56:54.679659 12912 solver.cpp:228] Iteration 44050, loss = 0.0351926
I0514 21:56:54.679769 12912 solver.cpp:244]     Train net output #0: loss = 0.035193 (* 1 = 0.035193 loss)
I0514 21:56:54.679787 12912 sgd_solver.cpp:106] Iteration 44050, lr = 0.0005
I0514 21:57:32.641358 12912 solver.cpp:228] Iteration 44100, loss = 0.00189959
I0514 21:57:32.641460 12912 solver.cpp:244]     Train net output #0: loss = 0.00190001 (* 1 = 0.00190001 loss)
I0514 21:57:32.641479 12912 sgd_solver.cpp:106] Iteration 44100, lr = 0.0005
I0514 21:58:10.605307 12912 solver.cpp:228] Iteration 44150, loss = 0.00650107
I0514 21:58:10.605437 12912 solver.cpp:244]     Train net output #0: loss = 0.00650148 (* 1 = 0.00650148 loss)
I0514 21:58:10.605454 12912 sgd_solver.cpp:106] Iteration 44150, lr = 0.0005
I0514 21:58:48.568833 12912 solver.cpp:228] Iteration 44200, loss = 0.00371597
I0514 21:58:48.569054 12912 solver.cpp:244]     Train net output #0: loss = 0.00371638 (* 1 = 0.00371638 loss)
I0514 21:58:48.569098 12912 sgd_solver.cpp:106] Iteration 44200, lr = 0.0005
I0514 21:59:26.539806 12912 solver.cpp:228] Iteration 44250, loss = 0.0103345
I0514 21:59:26.539935 12912 solver.cpp:244]     Train net output #0: loss = 0.0103349 (* 1 = 0.0103349 loss)
I0514 21:59:26.539947 12912 sgd_solver.cpp:106] Iteration 44250, lr = 0.0005
I0514 22:00:04.490905 12912 solver.cpp:228] Iteration 44300, loss = 0.0345738
I0514 22:00:04.491060 12912 solver.cpp:244]     Train net output #0: loss = 0.0345742 (* 1 = 0.0345742 loss)
I0514 22:00:04.491080 12912 sgd_solver.cpp:106] Iteration 44300, lr = 0.0005
I0514 22:00:42.439976 12912 solver.cpp:228] Iteration 44350, loss = 0.0177844
I0514 22:00:42.440073 12912 solver.cpp:244]     Train net output #0: loss = 0.0177848 (* 1 = 0.0177848 loss)
I0514 22:00:42.440090 12912 sgd_solver.cpp:106] Iteration 44350, lr = 0.0005
I0514 22:01:20.406853 12912 solver.cpp:228] Iteration 44400, loss = 0.00600761
I0514 22:01:20.407021 12912 solver.cpp:244]     Train net output #0: loss = 0.00600803 (* 1 = 0.00600803 loss)
I0514 22:01:20.407064 12912 sgd_solver.cpp:106] Iteration 44400, lr = 0.0005
I0514 22:01:58.349840 12912 solver.cpp:228] Iteration 44450, loss = 0.00746496
I0514 22:01:58.349963 12912 solver.cpp:244]     Train net output #0: loss = 0.00746538 (* 1 = 0.00746538 loss)
I0514 22:01:58.349977 12912 sgd_solver.cpp:106] Iteration 44450, lr = 0.0005
I0514 22:02:36.329659 12912 solver.cpp:228] Iteration 44500, loss = 0.0066492
I0514 22:02:36.329782 12912 solver.cpp:244]     Train net output #0: loss = 0.00664962 (* 1 = 0.00664962 loss)
I0514 22:02:36.329795 12912 sgd_solver.cpp:106] Iteration 44500, lr = 0.0005
I0514 22:03:14.273257 12912 solver.cpp:228] Iteration 44550, loss = 0.00346945
I0514 22:03:14.273373 12912 solver.cpp:244]     Train net output #0: loss = 0.00346988 (* 1 = 0.00346988 loss)
I0514 22:03:14.273391 12912 sgd_solver.cpp:106] Iteration 44550, lr = 0.0005
I0514 22:03:52.230806 12912 solver.cpp:228] Iteration 44600, loss = 0.00420275
I0514 22:03:52.230980 12912 solver.cpp:244]     Train net output #0: loss = 0.00420318 (* 1 = 0.00420318 loss)
I0514 22:03:52.231019 12912 sgd_solver.cpp:106] Iteration 44600, lr = 0.0005
I0514 22:04:30.196045 12912 solver.cpp:228] Iteration 44650, loss = 0.00819226
I0514 22:04:30.196173 12912 solver.cpp:244]     Train net output #0: loss = 0.00819269 (* 1 = 0.00819269 loss)
I0514 22:04:30.196192 12912 sgd_solver.cpp:106] Iteration 44650, lr = 0.0005
I0514 22:05:08.148284 12912 solver.cpp:228] Iteration 44700, loss = 0.0334951
I0514 22:05:08.148389 12912 solver.cpp:244]     Train net output #0: loss = 0.0334956 (* 1 = 0.0334956 loss)
I0514 22:05:08.148403 12912 sgd_solver.cpp:106] Iteration 44700, lr = 0.0005
I0514 22:05:46.101507 12912 solver.cpp:228] Iteration 44750, loss = 0.00237062
I0514 22:05:46.101629 12912 solver.cpp:244]     Train net output #0: loss = 0.00237107 (* 1 = 0.00237107 loss)
I0514 22:05:46.101649 12912 sgd_solver.cpp:106] Iteration 44750, lr = 0.0005
I0514 22:06:24.040010 12912 solver.cpp:228] Iteration 44800, loss = 0.00566733
I0514 22:06:24.040181 12912 solver.cpp:244]     Train net output #0: loss = 0.00566778 (* 1 = 0.00566778 loss)
I0514 22:06:24.040200 12912 sgd_solver.cpp:106] Iteration 44800, lr = 0.0005
I0514 22:07:01.978407 12912 solver.cpp:228] Iteration 44850, loss = 0.00575898
I0514 22:07:01.978528 12912 solver.cpp:244]     Train net output #0: loss = 0.00575942 (* 1 = 0.00575942 loss)
I0514 22:07:01.978544 12912 sgd_solver.cpp:106] Iteration 44850, lr = 0.0005
I0514 22:07:39.935855 12912 solver.cpp:228] Iteration 44900, loss = 0.00419918
I0514 22:07:39.936067 12912 solver.cpp:244]     Train net output #0: loss = 0.00419963 (* 1 = 0.00419963 loss)
I0514 22:07:39.936091 12912 sgd_solver.cpp:106] Iteration 44900, lr = 0.0005
I0514 22:08:17.882833 12912 solver.cpp:228] Iteration 44950, loss = 0.0358952
I0514 22:08:17.883016 12912 solver.cpp:244]     Train net output #0: loss = 0.0358957 (* 1 = 0.0358957 loss)
I0514 22:08:17.883033 12912 sgd_solver.cpp:106] Iteration 44950, lr = 0.0005
I0514 22:08:55.547307 12912 solver.cpp:454] Snapshotting to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_45000.caffemodel
I0514 22:08:56.104791 12912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_45000.solverstate
I0514 22:08:56.186763 12912 solver.cpp:337] Iteration 45000, Testing net (#0)
I0514 22:08:56.186822 12912 net.cpp:685] Ignoring source layer loss
I0514 22:10:39.099987 12912 solver.cpp:404]     Test net output #0: accuracy = 0.542059
I0514 22:10:39.390164 12912 solver.cpp:228] Iteration 45000, loss = 0.00666749
I0514 22:10:39.390223 12912 solver.cpp:244]     Train net output #0: loss = 0.00666796 (* 1 = 0.00666796 loss)
I0514 22:10:39.390236 12912 sgd_solver.cpp:106] Iteration 45000, lr = 0.0005
I0514 22:11:17.350411 12912 solver.cpp:228] Iteration 45050, loss = 0.00777169
I0514 22:11:17.350548 12912 solver.cpp:244]     Train net output #0: loss = 0.00777216 (* 1 = 0.00777216 loss)
I0514 22:11:17.350565 12912 sgd_solver.cpp:106] Iteration 45050, lr = 0.0005
I0514 22:11:55.314842 12912 solver.cpp:228] Iteration 45100, loss = 0.0341802
I0514 22:11:55.314957 12912 solver.cpp:244]     Train net output #0: loss = 0.0341807 (* 1 = 0.0341807 loss)
I0514 22:11:55.314981 12912 sgd_solver.cpp:106] Iteration 45100, lr = 0.0005
I0514 22:12:33.274757 12912 solver.cpp:228] Iteration 45150, loss = 0.00862624
I0514 22:12:33.274880 12912 solver.cpp:244]     Train net output #0: loss = 0.00862671 (* 1 = 0.00862671 loss)
I0514 22:12:33.274899 12912 sgd_solver.cpp:106] Iteration 45150, lr = 0.0005
I0514 22:13:11.232437 12912 solver.cpp:228] Iteration 45200, loss = 0.0076078
I0514 22:13:11.232540 12912 solver.cpp:244]     Train net output #0: loss = 0.00760827 (* 1 = 0.00760827 loss)
I0514 22:13:11.232553 12912 sgd_solver.cpp:106] Iteration 45200, lr = 0.0005
I0514 22:13:49.205438 12912 solver.cpp:228] Iteration 45250, loss = 0.00196643
I0514 22:13:49.205549 12912 solver.cpp:244]     Train net output #0: loss = 0.0019669 (* 1 = 0.0019669 loss)
I0514 22:13:49.205567 12912 sgd_solver.cpp:106] Iteration 45250, lr = 0.0005
I0514 22:14:27.174564 12912 solver.cpp:228] Iteration 45300, loss = 0.00489624
I0514 22:14:27.174713 12912 solver.cpp:244]     Train net output #0: loss = 0.00489671 (* 1 = 0.00489671 loss)
I0514 22:14:27.174732 12912 sgd_solver.cpp:106] Iteration 45300, lr = 0.0005
I0514 22:15:05.135464 12912 solver.cpp:228] Iteration 45350, loss = 0.0113815
I0514 22:15:05.135596 12912 solver.cpp:244]     Train net output #0: loss = 0.0113819 (* 1 = 0.0113819 loss)
I0514 22:15:05.135615 12912 sgd_solver.cpp:106] Iteration 45350, lr = 0.0005
I0514 22:15:43.097925 12912 solver.cpp:228] Iteration 45400, loss = 0.00597405
I0514 22:15:43.098039 12912 solver.cpp:244]     Train net output #0: loss = 0.00597452 (* 1 = 0.00597452 loss)
I0514 22:15:43.098054 12912 sgd_solver.cpp:106] Iteration 45400, lr = 0.0005
I0514 22:16:21.065585 12912 solver.cpp:228] Iteration 45450, loss = 0.0458642
I0514 22:16:21.065755 12912 solver.cpp:244]     Train net output #0: loss = 0.0458647 (* 1 = 0.0458647 loss)
I0514 22:16:21.065795 12912 sgd_solver.cpp:106] Iteration 45450, lr = 0.0005
I0514 22:16:59.022121 12912 solver.cpp:228] Iteration 45500, loss = 0.0267045
I0514 22:16:59.022228 12912 solver.cpp:244]     Train net output #0: loss = 0.026705 (* 1 = 0.026705 loss)
I0514 22:16:59.022246 12912 sgd_solver.cpp:106] Iteration 45500, lr = 0.0005
I0514 22:17:36.980125 12912 solver.cpp:228] Iteration 45550, loss = 0.00625913
I0514 22:17:36.980224 12912 solver.cpp:244]     Train net output #0: loss = 0.00625959 (* 1 = 0.00625959 loss)
I0514 22:17:36.980237 12912 sgd_solver.cpp:106] Iteration 45550, lr = 0.0005
I0514 22:18:14.943378 12912 solver.cpp:228] Iteration 45600, loss = 0.00719507
I0514 22:18:14.943500 12912 solver.cpp:244]     Train net output #0: loss = 0.00719553 (* 1 = 0.00719553 loss)
I0514 22:18:14.943555 12912 sgd_solver.cpp:106] Iteration 45600, lr = 0.0005
I0514 22:18:52.882344 12912 solver.cpp:228] Iteration 45650, loss = 0.0050633
I0514 22:18:52.882614 12912 solver.cpp:244]     Train net output #0: loss = 0.00506376 (* 1 = 0.00506376 loss)
I0514 22:18:52.882680 12912 sgd_solver.cpp:106] Iteration 45650, lr = 0.0005
I0514 22:19:30.846825 12912 solver.cpp:228] Iteration 45700, loss = 0.012228
I0514 22:19:30.846985 12912 solver.cpp:244]     Train net output #0: loss = 0.0122284 (* 1 = 0.0122284 loss)
I0514 22:19:30.846998 12912 sgd_solver.cpp:106] Iteration 45700, lr = 0.0005
I0514 22:20:08.795635 12912 solver.cpp:228] Iteration 45750, loss = 0.0699971
I0514 22:20:08.795732 12912 solver.cpp:244]     Train net output #0: loss = 0.0699975 (* 1 = 0.0699975 loss)
I0514 22:20:08.795745 12912 sgd_solver.cpp:106] Iteration 45750, lr = 0.0005
I0514 22:20:46.751219 12912 solver.cpp:228] Iteration 45800, loss = 0.00917179
I0514 22:20:46.751351 12912 solver.cpp:244]     Train net output #0: loss = 0.00917226 (* 1 = 0.00917226 loss)
I0514 22:20:46.751368 12912 sgd_solver.cpp:106] Iteration 45800, lr = 0.0005
I0514 22:21:24.708983 12912 solver.cpp:228] Iteration 45850, loss = 0.00549815
I0514 22:21:24.709157 12912 solver.cpp:244]     Train net output #0: loss = 0.00549861 (* 1 = 0.00549861 loss)
I0514 22:21:24.709203 12912 sgd_solver.cpp:106] Iteration 45850, lr = 0.0005
I0514 22:22:02.664703 12912 solver.cpp:228] Iteration 45900, loss = 0.0304311
I0514 22:22:02.664811 12912 solver.cpp:244]     Train net output #0: loss = 0.0304316 (* 1 = 0.0304316 loss)
I0514 22:22:02.664829 12912 sgd_solver.cpp:106] Iteration 45900, lr = 0.0005
I0514 22:22:40.623721 12912 solver.cpp:228] Iteration 45950, loss = 0.00556276
I0514 22:22:40.623854 12912 solver.cpp:244]     Train net output #0: loss = 0.00556322 (* 1 = 0.00556322 loss)
I0514 22:22:40.623879 12912 sgd_solver.cpp:106] Iteration 45950, lr = 0.0005
I0514 22:23:18.310360 12912 solver.cpp:454] Snapshotting to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_46000.caffemodel
I0514 22:23:18.951298 12912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_46000.solverstate
I0514 22:23:19.075467 12912 solver.cpp:337] Iteration 46000, Testing net (#0)
I0514 22:23:19.075527 12912 net.cpp:685] Ignoring source layer loss
I0514 22:25:01.971691 12912 solver.cpp:404]     Test net output #0: accuracy = 0.767206
I0514 22:25:02.261906 12912 solver.cpp:228] Iteration 46000, loss = 0.0160328
I0514 22:25:02.262001 12912 solver.cpp:244]     Train net output #0: loss = 0.0160333 (* 1 = 0.0160333 loss)
I0514 22:25:02.262019 12912 sgd_solver.cpp:106] Iteration 46000, lr = 0.0005
I0514 22:25:40.232053 12912 solver.cpp:228] Iteration 46050, loss = 0.011943
I0514 22:25:40.232163 12912 solver.cpp:244]     Train net output #0: loss = 0.0119435 (* 1 = 0.0119435 loss)
I0514 22:25:40.232184 12912 sgd_solver.cpp:106] Iteration 46050, lr = 0.0005
I0514 22:26:18.202857 12912 solver.cpp:228] Iteration 46100, loss = 0.00417863
I0514 22:26:18.202972 12912 solver.cpp:244]     Train net output #0: loss = 0.00417909 (* 1 = 0.00417909 loss)
I0514 22:26:18.202991 12912 sgd_solver.cpp:106] Iteration 46100, lr = 0.0005
I0514 22:26:56.180352 12912 solver.cpp:228] Iteration 46150, loss = 0.0261665
I0514 22:26:56.180461 12912 solver.cpp:244]     Train net output #0: loss = 0.026167 (* 1 = 0.026167 loss)
I0514 22:26:56.180474 12912 sgd_solver.cpp:106] Iteration 46150, lr = 0.0005
I0514 22:27:34.146059 12912 solver.cpp:228] Iteration 46200, loss = 0.00806598
I0514 22:27:34.146162 12912 solver.cpp:244]     Train net output #0: loss = 0.00806644 (* 1 = 0.00806644 loss)
I0514 22:27:34.146181 12912 sgd_solver.cpp:106] Iteration 46200, lr = 0.0005
I0514 22:28:12.120908 12912 solver.cpp:228] Iteration 46250, loss = 0.0071536
I0514 22:28:12.121019 12912 solver.cpp:244]     Train net output #0: loss = 0.00715406 (* 1 = 0.00715406 loss)
I0514 22:28:12.121037 12912 sgd_solver.cpp:106] Iteration 46250, lr = 0.0005
I0514 22:28:50.093528 12912 solver.cpp:228] Iteration 46300, loss = 0.00179265
I0514 22:28:50.093667 12912 solver.cpp:244]     Train net output #0: loss = 0.00179311 (* 1 = 0.00179311 loss)
I0514 22:28:50.093686 12912 sgd_solver.cpp:106] Iteration 46300, lr = 0.0005
I0514 22:29:28.075727 12912 solver.cpp:228] Iteration 46350, loss = 0.00718161
I0514 22:29:28.075861 12912 solver.cpp:244]     Train net output #0: loss = 0.00718208 (* 1 = 0.00718208 loss)
I0514 22:29:28.075880 12912 sgd_solver.cpp:106] Iteration 46350, lr = 0.0005
I0514 22:30:06.033146 12912 solver.cpp:228] Iteration 46400, loss = 0.00927891
I0514 22:30:06.033249 12912 solver.cpp:244]     Train net output #0: loss = 0.00927935 (* 1 = 0.00927935 loss)
I0514 22:30:06.033268 12912 sgd_solver.cpp:106] Iteration 46400, lr = 0.0005
I0514 22:30:43.976773 12912 solver.cpp:228] Iteration 46450, loss = 0.0184097
I0514 22:30:43.976876 12912 solver.cpp:244]     Train net output #0: loss = 0.0184101 (* 1 = 0.0184101 loss)
I0514 22:30:43.976889 12912 sgd_solver.cpp:106] Iteration 46450, lr = 0.0005
I0514 22:31:21.926970 12912 solver.cpp:228] Iteration 46500, loss = 0.0164434
I0514 22:31:21.927126 12912 solver.cpp:244]     Train net output #0: loss = 0.0164438 (* 1 = 0.0164438 loss)
I0514 22:31:21.927145 12912 sgd_solver.cpp:106] Iteration 46500, lr = 0.0005
I0514 22:31:59.874511 12912 solver.cpp:228] Iteration 46550, loss = 0.00921296
I0514 22:31:59.874629 12912 solver.cpp:244]     Train net output #0: loss = 0.0092134 (* 1 = 0.0092134 loss)
I0514 22:31:59.874649 12912 sgd_solver.cpp:106] Iteration 46550, lr = 0.0005
I0514 22:32:37.825938 12912 solver.cpp:228] Iteration 46600, loss = 0.0128613
I0514 22:32:37.826148 12912 solver.cpp:244]     Train net output #0: loss = 0.0128617 (* 1 = 0.0128617 loss)
I0514 22:32:37.826185 12912 sgd_solver.cpp:106] Iteration 46600, lr = 0.0005
I0514 22:33:15.784523 12912 solver.cpp:228] Iteration 46650, loss = 0.00329523
I0514 22:33:15.784646 12912 solver.cpp:244]     Train net output #0: loss = 0.00329567 (* 1 = 0.00329567 loss)
I0514 22:33:15.784664 12912 sgd_solver.cpp:106] Iteration 46650, lr = 0.0005
I0514 22:33:53.740675 12912 solver.cpp:228] Iteration 46700, loss = 0.0164949
I0514 22:33:53.740821 12912 solver.cpp:244]     Train net output #0: loss = 0.0164953 (* 1 = 0.0164953 loss)
I0514 22:33:53.740834 12912 sgd_solver.cpp:106] Iteration 46700, lr = 0.0005
I0514 22:34:31.694363 12912 solver.cpp:228] Iteration 46750, loss = 0.00720473
I0514 22:34:31.694478 12912 solver.cpp:244]     Train net output #0: loss = 0.00720518 (* 1 = 0.00720518 loss)
I0514 22:34:31.694490 12912 sgd_solver.cpp:106] Iteration 46750, lr = 0.0005
I0514 22:35:09.673269 12912 solver.cpp:228] Iteration 46800, loss = 0.0159632
I0514 22:35:09.673452 12912 solver.cpp:244]     Train net output #0: loss = 0.0159636 (* 1 = 0.0159636 loss)
I0514 22:35:09.673487 12912 sgd_solver.cpp:106] Iteration 46800, lr = 0.0005
I0514 22:35:47.626741 12912 solver.cpp:228] Iteration 46850, loss = 0.00502621
I0514 22:35:47.626880 12912 solver.cpp:244]     Train net output #0: loss = 0.00502666 (* 1 = 0.00502666 loss)
I0514 22:35:47.626900 12912 sgd_solver.cpp:106] Iteration 46850, lr = 0.0005
I0514 22:36:25.596549 12912 solver.cpp:228] Iteration 46900, loss = 0.00795721
I0514 22:36:25.596734 12912 solver.cpp:244]     Train net output #0: loss = 0.00795766 (* 1 = 0.00795766 loss)
I0514 22:36:25.596758 12912 sgd_solver.cpp:106] Iteration 46900, lr = 0.0005
I0514 22:37:03.552021 12912 solver.cpp:228] Iteration 46950, loss = 0.00391637
I0514 22:37:03.552144 12912 solver.cpp:244]     Train net output #0: loss = 0.00391682 (* 1 = 0.00391682 loss)
I0514 22:37:03.552160 12912 sgd_solver.cpp:106] Iteration 46950, lr = 0.0005
I0514 22:37:41.210367 12912 solver.cpp:454] Snapshotting to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_47000.caffemodel
I0514 22:37:41.768586 12912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_47000.solverstate
I0514 22:37:41.853965 12912 solver.cpp:337] Iteration 47000, Testing net (#0)
I0514 22:37:41.854033 12912 net.cpp:685] Ignoring source layer loss
I0514 22:39:25.057413 12912 solver.cpp:404]     Test net output #0: accuracy = 0.748235
I0514 22:39:25.348561 12912 solver.cpp:228] Iteration 47000, loss = 0.00256872
I0514 22:39:25.348619 12912 solver.cpp:244]     Train net output #0: loss = 0.00256917 (* 1 = 0.00256917 loss)
I0514 22:39:25.348634 12912 sgd_solver.cpp:106] Iteration 47000, lr = 0.0005
I0514 22:40:03.316824 12912 solver.cpp:228] Iteration 47050, loss = 0.00305027
I0514 22:40:03.316928 12912 solver.cpp:244]     Train net output #0: loss = 0.00305072 (* 1 = 0.00305072 loss)
I0514 22:40:03.316941 12912 sgd_solver.cpp:106] Iteration 47050, lr = 0.0005
I0514 22:40:41.269513 12912 solver.cpp:228] Iteration 47100, loss = 0.00657416
I0514 22:40:41.269630 12912 solver.cpp:244]     Train net output #0: loss = 0.00657461 (* 1 = 0.00657461 loss)
I0514 22:40:41.269660 12912 sgd_solver.cpp:106] Iteration 47100, lr = 0.0005
I0514 22:41:19.245426 12912 solver.cpp:228] Iteration 47150, loss = 0.0160725
I0514 22:41:19.245642 12912 solver.cpp:244]     Train net output #0: loss = 0.016073 (* 1 = 0.016073 loss)
I0514 22:41:19.245661 12912 sgd_solver.cpp:106] Iteration 47150, lr = 0.0005
I0514 22:41:57.192821 12912 solver.cpp:228] Iteration 47200, loss = 0.0115987
I0514 22:41:57.192952 12912 solver.cpp:244]     Train net output #0: loss = 0.0115992 (* 1 = 0.0115992 loss)
I0514 22:41:57.192975 12912 sgd_solver.cpp:106] Iteration 47200, lr = 0.0005
I0514 22:42:35.145252 12912 solver.cpp:228] Iteration 47250, loss = 0.01232
I0514 22:42:35.145359 12912 solver.cpp:244]     Train net output #0: loss = 0.0123205 (* 1 = 0.0123205 loss)
I0514 22:42:35.145375 12912 sgd_solver.cpp:106] Iteration 47250, lr = 0.0005
I0514 22:43:13.102478 12912 solver.cpp:228] Iteration 47300, loss = 0.0171028
I0514 22:43:13.102607 12912 solver.cpp:244]     Train net output #0: loss = 0.0171033 (* 1 = 0.0171033 loss)
I0514 22:43:13.102624 12912 sgd_solver.cpp:106] Iteration 47300, lr = 0.0005
I0514 22:43:51.054422 12912 solver.cpp:228] Iteration 47350, loss = 0.0083593
I0514 22:43:51.054538 12912 solver.cpp:244]     Train net output #0: loss = 0.00835976 (* 1 = 0.00835976 loss)
I0514 22:43:51.054558 12912 sgd_solver.cpp:106] Iteration 47350, lr = 0.0005
I0514 22:44:29.016607 12912 solver.cpp:228] Iteration 47400, loss = 0.00283745
I0514 22:44:29.016712 12912 solver.cpp:244]     Train net output #0: loss = 0.00283791 (* 1 = 0.00283791 loss)
I0514 22:44:29.016731 12912 sgd_solver.cpp:106] Iteration 47400, lr = 0.0005
I0514 22:45:06.983464 12912 solver.cpp:228] Iteration 47450, loss = 0.0222097
I0514 22:45:06.983573 12912 solver.cpp:244]     Train net output #0: loss = 0.0222101 (* 1 = 0.0222101 loss)
I0514 22:45:06.983588 12912 sgd_solver.cpp:106] Iteration 47450, lr = 0.0005
I0514 22:45:44.957986 12912 solver.cpp:228] Iteration 47500, loss = 0.0160406
I0514 22:45:44.958097 12912 solver.cpp:244]     Train net output #0: loss = 0.016041 (* 1 = 0.016041 loss)
I0514 22:45:44.958115 12912 sgd_solver.cpp:106] Iteration 47500, lr = 0.0005
I0514 22:46:22.922947 12912 solver.cpp:228] Iteration 47550, loss = 0.0150357
I0514 22:46:22.923063 12912 solver.cpp:244]     Train net output #0: loss = 0.0150362 (* 1 = 0.0150362 loss)
I0514 22:46:22.923081 12912 sgd_solver.cpp:106] Iteration 47550, lr = 0.0005
I0514 22:47:00.868095 12912 solver.cpp:228] Iteration 47600, loss = 0.00556057
I0514 22:47:00.868206 12912 solver.cpp:244]     Train net output #0: loss = 0.00556103 (* 1 = 0.00556103 loss)
I0514 22:47:00.868224 12912 sgd_solver.cpp:106] Iteration 47600, lr = 0.0005
I0514 22:47:38.840968 12912 solver.cpp:228] Iteration 47650, loss = 0.00830109
I0514 22:47:38.841069 12912 solver.cpp:244]     Train net output #0: loss = 0.00830156 (* 1 = 0.00830156 loss)
I0514 22:47:38.841084 12912 sgd_solver.cpp:106] Iteration 47650, lr = 0.0005
I0514 22:48:16.813307 12912 solver.cpp:228] Iteration 47700, loss = 0.00480796
I0514 22:48:16.813405 12912 solver.cpp:244]     Train net output #0: loss = 0.00480843 (* 1 = 0.00480843 loss)
I0514 22:48:16.813423 12912 sgd_solver.cpp:106] Iteration 47700, lr = 0.0005
I0514 22:48:54.766402 12912 solver.cpp:228] Iteration 47750, loss = 0.00725752
I0514 22:48:54.774137 12912 solver.cpp:244]     Train net output #0: loss = 0.00725799 (* 1 = 0.00725799 loss)
I0514 22:48:54.774168 12912 sgd_solver.cpp:106] Iteration 47750, lr = 0.0005
I0514 22:49:32.709130 12912 solver.cpp:228] Iteration 47800, loss = 0.00327463
I0514 22:49:32.709249 12912 solver.cpp:244]     Train net output #0: loss = 0.0032751 (* 1 = 0.0032751 loss)
I0514 22:49:32.709262 12912 sgd_solver.cpp:106] Iteration 47800, lr = 0.0005
I0514 22:50:10.665843 12912 solver.cpp:228] Iteration 47850, loss = 0.00768614
I0514 22:50:10.665948 12912 solver.cpp:244]     Train net output #0: loss = 0.00768661 (* 1 = 0.00768661 loss)
I0514 22:50:10.665967 12912 sgd_solver.cpp:106] Iteration 47850, lr = 0.0005
I0514 22:50:48.639777 12912 solver.cpp:228] Iteration 47900, loss = 0.00467917
I0514 22:50:48.639968 12912 solver.cpp:244]     Train net output #0: loss = 0.00467963 (* 1 = 0.00467963 loss)
I0514 22:50:48.639986 12912 sgd_solver.cpp:106] Iteration 47900, lr = 0.0005
I0514 22:51:26.601646 12912 solver.cpp:228] Iteration 47950, loss = 0.00626267
I0514 22:51:26.601843 12912 solver.cpp:244]     Train net output #0: loss = 0.00626314 (* 1 = 0.00626314 loss)
I0514 22:51:26.601867 12912 sgd_solver.cpp:106] Iteration 47950, lr = 0.0005
I0514 22:52:04.265991 12912 solver.cpp:454] Snapshotting to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_48000.caffemodel
I0514 22:52:04.866371 12912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_48000.solverstate
I0514 22:52:04.948809 12912 solver.cpp:337] Iteration 48000, Testing net (#0)
I0514 22:52:04.948870 12912 net.cpp:685] Ignoring source layer loss
I0514 22:53:47.851630 12912 solver.cpp:404]     Test net output #0: accuracy = 0.729853
I0514 22:53:48.141484 12912 solver.cpp:228] Iteration 48000, loss = 0.00495573
I0514 22:53:48.141546 12912 solver.cpp:244]     Train net output #0: loss = 0.00495619 (* 1 = 0.00495619 loss)
I0514 22:53:48.141561 12912 sgd_solver.cpp:106] Iteration 48000, lr = 0.0005
I0514 22:54:26.106005 12912 solver.cpp:228] Iteration 48050, loss = 0.00953075
I0514 22:54:26.106164 12912 solver.cpp:244]     Train net output #0: loss = 0.00953121 (* 1 = 0.00953121 loss)
I0514 22:54:26.106184 12912 sgd_solver.cpp:106] Iteration 48050, lr = 0.0005
I0514 22:55:04.074409 12912 solver.cpp:228] Iteration 48100, loss = 0.0138956
I0514 22:55:04.074524 12912 solver.cpp:244]     Train net output #0: loss = 0.013896 (* 1 = 0.013896 loss)
I0514 22:55:04.074542 12912 sgd_solver.cpp:106] Iteration 48100, lr = 0.0005
I0514 22:55:42.041232 12912 solver.cpp:228] Iteration 48150, loss = 0.00210165
I0514 22:55:42.041393 12912 solver.cpp:244]     Train net output #0: loss = 0.00210211 (* 1 = 0.00210211 loss)
I0514 22:55:42.041411 12912 sgd_solver.cpp:106] Iteration 48150, lr = 0.0005
I0514 22:56:20.009963 12912 solver.cpp:228] Iteration 48200, loss = 0.0031878
I0514 22:56:20.010087 12912 solver.cpp:244]     Train net output #0: loss = 0.00318826 (* 1 = 0.00318826 loss)
I0514 22:56:20.010100 12912 sgd_solver.cpp:106] Iteration 48200, lr = 0.0005
I0514 22:56:57.985179 12912 solver.cpp:228] Iteration 48250, loss = 0.00232113
I0514 22:56:57.985312 12912 solver.cpp:244]     Train net output #0: loss = 0.00232159 (* 1 = 0.00232159 loss)
I0514 22:56:57.985329 12912 sgd_solver.cpp:106] Iteration 48250, lr = 0.0005
I0514 22:57:35.949573 12912 solver.cpp:228] Iteration 48300, loss = 0.016612
I0514 22:57:35.949677 12912 solver.cpp:244]     Train net output #0: loss = 0.0166124 (* 1 = 0.0166124 loss)
I0514 22:57:35.949690 12912 sgd_solver.cpp:106] Iteration 48300, lr = 0.0005
I0514 22:58:13.906553 12912 solver.cpp:228] Iteration 48350, loss = 0.00544019
I0514 22:58:13.906680 12912 solver.cpp:244]     Train net output #0: loss = 0.00544065 (* 1 = 0.00544065 loss)
I0514 22:58:13.906697 12912 sgd_solver.cpp:106] Iteration 48350, lr = 0.0005
I0514 22:58:51.875845 12912 solver.cpp:228] Iteration 48400, loss = 0.0123047
I0514 22:58:51.875993 12912 solver.cpp:244]     Train net output #0: loss = 0.0123052 (* 1 = 0.0123052 loss)
I0514 22:58:51.876005 12912 sgd_solver.cpp:106] Iteration 48400, lr = 0.0005
I0514 22:59:29.840857 12912 solver.cpp:228] Iteration 48450, loss = 0.00556902
I0514 22:59:29.840975 12912 solver.cpp:244]     Train net output #0: loss = 0.00556948 (* 1 = 0.00556948 loss)
I0514 22:59:29.840988 12912 sgd_solver.cpp:106] Iteration 48450, lr = 0.0005
I0514 23:00:07.816895 12912 solver.cpp:228] Iteration 48500, loss = 0.00469179
I0514 23:00:07.817003 12912 solver.cpp:244]     Train net output #0: loss = 0.00469225 (* 1 = 0.00469225 loss)
I0514 23:00:07.817018 12912 sgd_solver.cpp:106] Iteration 48500, lr = 0.0005
I0514 23:00:45.772281 12912 solver.cpp:228] Iteration 48550, loss = 0.0159989
I0514 23:00:45.772429 12912 solver.cpp:244]     Train net output #0: loss = 0.0159993 (* 1 = 0.0159993 loss)
I0514 23:00:45.772449 12912 sgd_solver.cpp:106] Iteration 48550, lr = 0.0005
I0514 23:01:23.764653 12912 solver.cpp:228] Iteration 48600, loss = 0.00556459
I0514 23:01:23.764837 12912 solver.cpp:244]     Train net output #0: loss = 0.00556504 (* 1 = 0.00556504 loss)
I0514 23:01:23.764855 12912 sgd_solver.cpp:106] Iteration 48600, lr = 0.0005
I0514 23:02:01.725724 12912 solver.cpp:228] Iteration 48650, loss = 0.0148008
I0514 23:02:01.725836 12912 solver.cpp:244]     Train net output #0: loss = 0.0148013 (* 1 = 0.0148013 loss)
I0514 23:02:01.725849 12912 sgd_solver.cpp:106] Iteration 48650, lr = 0.0005
I0514 23:02:39.693400 12912 solver.cpp:228] Iteration 48700, loss = 0.0078146
I0514 23:02:39.693553 12912 solver.cpp:244]     Train net output #0: loss = 0.00781505 (* 1 = 0.00781505 loss)
I0514 23:02:39.693572 12912 sgd_solver.cpp:106] Iteration 48700, lr = 0.0005
I0514 23:03:17.652617 12912 solver.cpp:228] Iteration 48750, loss = 0.00274668
I0514 23:03:17.652752 12912 solver.cpp:244]     Train net output #0: loss = 0.00274713 (* 1 = 0.00274713 loss)
I0514 23:03:17.652766 12912 sgd_solver.cpp:106] Iteration 48750, lr = 0.0005
I0514 23:03:55.608229 12912 solver.cpp:228] Iteration 48800, loss = 0.00268884
I0514 23:03:55.608351 12912 solver.cpp:244]     Train net output #0: loss = 0.00268929 (* 1 = 0.00268929 loss)
I0514 23:03:55.608366 12912 sgd_solver.cpp:106] Iteration 48800, lr = 0.0005
I0514 23:04:33.568704 12912 solver.cpp:228] Iteration 48850, loss = 0.0102681
I0514 23:04:33.568840 12912 solver.cpp:244]     Train net output #0: loss = 0.0102686 (* 1 = 0.0102686 loss)
I0514 23:04:33.568855 12912 sgd_solver.cpp:106] Iteration 48850, lr = 0.0005
I0514 23:05:11.523358 12912 solver.cpp:228] Iteration 48900, loss = 0.0297797
I0514 23:05:11.523463 12912 solver.cpp:244]     Train net output #0: loss = 0.0297801 (* 1 = 0.0297801 loss)
I0514 23:05:11.523475 12912 sgd_solver.cpp:106] Iteration 48900, lr = 0.0005
I0514 23:05:49.460995 12912 solver.cpp:228] Iteration 48950, loss = 0.00415696
I0514 23:05:49.461150 12912 solver.cpp:244]     Train net output #0: loss = 0.00415742 (* 1 = 0.00415742 loss)
I0514 23:05:49.461164 12912 sgd_solver.cpp:106] Iteration 48950, lr = 0.0005
I0514 23:06:27.146589 12912 solver.cpp:454] Snapshotting to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_49000.caffemodel
I0514 23:06:27.395020 12912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_49000.solverstate
I0514 23:06:27.543704 12912 solver.cpp:337] Iteration 49000, Testing net (#0)
I0514 23:06:27.543831 12912 net.cpp:685] Ignoring source layer loss
I0514 23:08:10.534543 12912 solver.cpp:404]     Test net output #0: accuracy = 0.669853
I0514 23:08:10.824959 12912 solver.cpp:228] Iteration 49000, loss = 0.00219219
I0514 23:08:10.825021 12912 solver.cpp:244]     Train net output #0: loss = 0.00219264 (* 1 = 0.00219264 loss)
I0514 23:08:10.825034 12912 sgd_solver.cpp:106] Iteration 49000, lr = 0.0005
I0514 23:08:48.790235 12912 solver.cpp:228] Iteration 49050, loss = 0.0101869
I0514 23:08:48.790360 12912 solver.cpp:244]     Train net output #0: loss = 0.0101874 (* 1 = 0.0101874 loss)
I0514 23:08:48.790379 12912 sgd_solver.cpp:106] Iteration 49050, lr = 0.0005
I0514 23:09:26.749557 12912 solver.cpp:228] Iteration 49100, loss = 0.00615965
I0514 23:09:26.749704 12912 solver.cpp:244]     Train net output #0: loss = 0.0061601 (* 1 = 0.0061601 loss)
I0514 23:09:26.749718 12912 sgd_solver.cpp:106] Iteration 49100, lr = 0.0005
I0514 23:10:04.710945 12912 solver.cpp:228] Iteration 49150, loss = 0.00982872
I0514 23:10:04.711061 12912 solver.cpp:244]     Train net output #0: loss = 0.00982916 (* 1 = 0.00982916 loss)
I0514 23:10:04.711079 12912 sgd_solver.cpp:106] Iteration 49150, lr = 0.0005
I0514 23:10:42.671114 12912 solver.cpp:228] Iteration 49200, loss = 0.0100486
I0514 23:10:42.671283 12912 solver.cpp:244]     Train net output #0: loss = 0.010049 (* 1 = 0.010049 loss)
I0514 23:10:42.671309 12912 sgd_solver.cpp:106] Iteration 49200, lr = 0.0005
I0514 23:11:20.634449 12912 solver.cpp:228] Iteration 49250, loss = 0.0052268
I0514 23:11:20.634578 12912 solver.cpp:244]     Train net output #0: loss = 0.00522724 (* 1 = 0.00522724 loss)
I0514 23:11:20.634598 12912 sgd_solver.cpp:106] Iteration 49250, lr = 0.0005
I0514 23:11:58.594384 12912 solver.cpp:228] Iteration 49300, loss = 0.00358922
I0514 23:11:58.594524 12912 solver.cpp:244]     Train net output #0: loss = 0.00358966 (* 1 = 0.00358966 loss)
I0514 23:11:58.594537 12912 sgd_solver.cpp:106] Iteration 49300, lr = 0.0005
I0514 23:12:36.554375 12912 solver.cpp:228] Iteration 49350, loss = 0.0186004
I0514 23:12:36.554478 12912 solver.cpp:244]     Train net output #0: loss = 0.0186009 (* 1 = 0.0186009 loss)
I0514 23:12:36.554491 12912 sgd_solver.cpp:106] Iteration 49350, lr = 0.0005
I0514 23:13:14.505831 12912 solver.cpp:228] Iteration 49400, loss = 0.0210342
I0514 23:13:14.505944 12912 solver.cpp:244]     Train net output #0: loss = 0.0210347 (* 1 = 0.0210347 loss)
I0514 23:13:14.505960 12912 sgd_solver.cpp:106] Iteration 49400, lr = 0.0005
I0514 23:13:52.478031 12912 solver.cpp:228] Iteration 49450, loss = 0.0100561
I0514 23:13:52.478162 12912 solver.cpp:244]     Train net output #0: loss = 0.0100565 (* 1 = 0.0100565 loss)
I0514 23:13:52.478176 12912 sgd_solver.cpp:106] Iteration 49450, lr = 0.0005
I0514 23:14:30.430389 12912 solver.cpp:228] Iteration 49500, loss = 0.0103631
I0514 23:14:30.430498 12912 solver.cpp:244]     Train net output #0: loss = 0.0103635 (* 1 = 0.0103635 loss)
I0514 23:14:30.430517 12912 sgd_solver.cpp:106] Iteration 49500, lr = 0.0005
I0514 23:15:08.371443 12912 solver.cpp:228] Iteration 49550, loss = 0.00673262
I0514 23:15:08.371611 12912 solver.cpp:244]     Train net output #0: loss = 0.00673306 (* 1 = 0.00673306 loss)
I0514 23:15:08.371649 12912 sgd_solver.cpp:106] Iteration 49550, lr = 0.0005
I0514 23:15:46.324606 12912 solver.cpp:228] Iteration 49600, loss = 0.00387233
I0514 23:15:46.324784 12912 solver.cpp:244]     Train net output #0: loss = 0.00387278 (* 1 = 0.00387278 loss)
I0514 23:15:46.324802 12912 sgd_solver.cpp:106] Iteration 49600, lr = 0.0005
I0514 23:16:24.279660 12912 solver.cpp:228] Iteration 49650, loss = 0.0100718
I0514 23:16:24.279809 12912 solver.cpp:244]     Train net output #0: loss = 0.0100723 (* 1 = 0.0100723 loss)
I0514 23:16:24.279826 12912 sgd_solver.cpp:106] Iteration 49650, lr = 0.0005
I0514 23:17:02.250097 12912 solver.cpp:228] Iteration 49700, loss = 0.00554404
I0514 23:17:02.250216 12912 solver.cpp:244]     Train net output #0: loss = 0.00554448 (* 1 = 0.00554448 loss)
I0514 23:17:02.250236 12912 sgd_solver.cpp:106] Iteration 49700, lr = 0.0005
I0514 23:17:40.207130 12912 solver.cpp:228] Iteration 49750, loss = 0.0102653
I0514 23:17:40.207267 12912 solver.cpp:244]     Train net output #0: loss = 0.0102657 (* 1 = 0.0102657 loss)
I0514 23:17:40.207288 12912 sgd_solver.cpp:106] Iteration 49750, lr = 0.0005
I0514 23:18:18.165674 12912 solver.cpp:228] Iteration 49800, loss = 0.00283368
I0514 23:18:18.165784 12912 solver.cpp:244]     Train net output #0: loss = 0.00283412 (* 1 = 0.00283412 loss)
I0514 23:18:18.165797 12912 sgd_solver.cpp:106] Iteration 49800, lr = 0.0005
I0514 23:18:56.130537 12912 solver.cpp:228] Iteration 49850, loss = 0.00747838
I0514 23:18:56.130684 12912 solver.cpp:244]     Train net output #0: loss = 0.00747883 (* 1 = 0.00747883 loss)
I0514 23:18:56.130703 12912 sgd_solver.cpp:106] Iteration 49850, lr = 0.0005
I0514 23:19:34.101641 12912 solver.cpp:228] Iteration 49900, loss = 0.0043653
I0514 23:19:34.101791 12912 solver.cpp:244]     Train net output #0: loss = 0.00436575 (* 1 = 0.00436575 loss)
I0514 23:19:34.101810 12912 sgd_solver.cpp:106] Iteration 49900, lr = 0.0005
I0514 23:20:12.062088 12912 solver.cpp:228] Iteration 49950, loss = 0.00273197
I0514 23:20:12.062224 12912 solver.cpp:244]     Train net output #0: loss = 0.00273242 (* 1 = 0.00273242 loss)
I0514 23:20:12.062242 12912 sgd_solver.cpp:106] Iteration 49950, lr = 0.0005
I0514 23:20:49.741904 12912 solver.cpp:454] Snapshotting to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_50000.caffemodel
I0514 23:20:50.296176 12912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_50000.solverstate
I0514 23:20:50.442935 12912 solver.cpp:337] Iteration 50000, Testing net (#0)
I0514 23:20:50.443016 12912 net.cpp:685] Ignoring source layer loss
I0514 23:22:33.393019 12912 solver.cpp:404]     Test net output #0: accuracy = 0.762059
I0514 23:22:33.682863 12912 solver.cpp:228] Iteration 50000, loss = 0.0100371
I0514 23:22:33.682911 12912 solver.cpp:244]     Train net output #0: loss = 0.0100376 (* 1 = 0.0100376 loss)
I0514 23:22:33.682925 12912 sgd_solver.cpp:106] Iteration 50000, lr = 0.0005
I0514 23:23:11.641805 12912 solver.cpp:228] Iteration 50050, loss = 0.0123891
I0514 23:23:11.641907 12912 solver.cpp:244]     Train net output #0: loss = 0.0123896 (* 1 = 0.0123896 loss)
I0514 23:23:11.641924 12912 sgd_solver.cpp:106] Iteration 50050, lr = 0.0005
I0514 23:23:49.608361 12912 solver.cpp:228] Iteration 50100, loss = 0.0147252
I0514 23:23:49.608566 12912 solver.cpp:244]     Train net output #0: loss = 0.0147256 (* 1 = 0.0147256 loss)
I0514 23:23:49.608604 12912 sgd_solver.cpp:106] Iteration 50100, lr = 0.0005
I0514 23:24:27.569049 12912 solver.cpp:228] Iteration 50150, loss = 0.00581764
I0514 23:24:27.569154 12912 solver.cpp:244]     Train net output #0: loss = 0.00581809 (* 1 = 0.00581809 loss)
I0514 23:24:27.569167 12912 sgd_solver.cpp:106] Iteration 50150, lr = 0.0005
I0514 23:25:05.537863 12912 solver.cpp:228] Iteration 50200, loss = 0.0314547
I0514 23:25:05.538051 12912 solver.cpp:244]     Train net output #0: loss = 0.0314551 (* 1 = 0.0314551 loss)
I0514 23:25:05.538070 12912 sgd_solver.cpp:106] Iteration 50200, lr = 0.0005
I0514 23:25:43.497125 12912 solver.cpp:228] Iteration 50250, loss = 0.00749553
I0514 23:25:43.497231 12912 solver.cpp:244]     Train net output #0: loss = 0.00749598 (* 1 = 0.00749598 loss)
I0514 23:25:43.497249 12912 sgd_solver.cpp:106] Iteration 50250, lr = 0.0005
I0514 23:26:21.460119 12912 solver.cpp:228] Iteration 50300, loss = 0.0144789
I0514 23:26:21.460248 12912 solver.cpp:244]     Train net output #0: loss = 0.0144794 (* 1 = 0.0144794 loss)
I0514 23:26:21.460261 12912 sgd_solver.cpp:106] Iteration 50300, lr = 0.0005
I0514 23:26:59.429667 12912 solver.cpp:228] Iteration 50350, loss = 0.00998168
I0514 23:26:59.429801 12912 solver.cpp:244]     Train net output #0: loss = 0.00998212 (* 1 = 0.00998212 loss)
I0514 23:26:59.429824 12912 sgd_solver.cpp:106] Iteration 50350, lr = 0.0005
I0514 23:27:37.405287 12912 solver.cpp:228] Iteration 50400, loss = 0.00189422
I0514 23:27:37.405439 12912 solver.cpp:244]     Train net output #0: loss = 0.00189466 (* 1 = 0.00189466 loss)
I0514 23:27:37.405455 12912 sgd_solver.cpp:106] Iteration 50400, lr = 0.0005
I0514 23:28:15.356176 12912 solver.cpp:228] Iteration 50450, loss = 0.00336403
I0514 23:28:15.357352 12912 solver.cpp:244]     Train net output #0: loss = 0.00336448 (* 1 = 0.00336448 loss)
I0514 23:28:15.357400 12912 sgd_solver.cpp:106] Iteration 50450, lr = 0.0005
I0514 23:28:53.301708 12912 solver.cpp:228] Iteration 50500, loss = 0.00462582
I0514 23:28:53.301877 12912 solver.cpp:244]     Train net output #0: loss = 0.00462626 (* 1 = 0.00462626 loss)
I0514 23:28:53.301890 12912 sgd_solver.cpp:106] Iteration 50500, lr = 0.0005
I0514 23:29:31.265132 12912 solver.cpp:228] Iteration 50550, loss = 0.00265192
I0514 23:29:31.265360 12912 solver.cpp:244]     Train net output #0: loss = 0.00265236 (* 1 = 0.00265236 loss)
I0514 23:29:31.265403 12912 sgd_solver.cpp:106] Iteration 50550, lr = 0.0005
I0514 23:30:09.235285 12912 solver.cpp:228] Iteration 50600, loss = 0.0105468
I0514 23:30:09.235406 12912 solver.cpp:244]     Train net output #0: loss = 0.0105473 (* 1 = 0.0105473 loss)
I0514 23:30:09.235420 12912 sgd_solver.cpp:106] Iteration 50600, lr = 0.0005
I0514 23:30:47.192926 12912 solver.cpp:228] Iteration 50650, loss = 0.00218608
I0514 23:30:47.193037 12912 solver.cpp:244]     Train net output #0: loss = 0.00218651 (* 1 = 0.00218651 loss)
I0514 23:30:47.193056 12912 sgd_solver.cpp:106] Iteration 50650, lr = 0.0005
I0514 23:31:25.150557 12912 solver.cpp:228] Iteration 50700, loss = 0.0107364
I0514 23:31:25.150674 12912 solver.cpp:244]     Train net output #0: loss = 0.0107368 (* 1 = 0.0107368 loss)
I0514 23:31:25.150686 12912 sgd_solver.cpp:106] Iteration 50700, lr = 0.0005
I0514 23:32:03.087867 12912 solver.cpp:228] Iteration 50750, loss = 0.00420814
I0514 23:32:03.087978 12912 solver.cpp:244]     Train net output #0: loss = 0.00420857 (* 1 = 0.00420857 loss)
I0514 23:32:03.087996 12912 sgd_solver.cpp:106] Iteration 50750, lr = 0.0005
I0514 23:32:41.059820 12912 solver.cpp:228] Iteration 50800, loss = 0.00696369
I0514 23:32:41.059927 12912 solver.cpp:244]     Train net output #0: loss = 0.00696413 (* 1 = 0.00696413 loss)
I0514 23:32:41.059945 12912 sgd_solver.cpp:106] Iteration 50800, lr = 0.0005
I0514 23:33:19.005069 12912 solver.cpp:228] Iteration 50850, loss = 0.00844801
I0514 23:33:19.005199 12912 solver.cpp:244]     Train net output #0: loss = 0.00844845 (* 1 = 0.00844845 loss)
I0514 23:33:19.005224 12912 sgd_solver.cpp:106] Iteration 50850, lr = 0.0005
I0514 23:33:56.970630 12912 solver.cpp:228] Iteration 50900, loss = 0.0184255
I0514 23:33:56.970814 12912 solver.cpp:244]     Train net output #0: loss = 0.0184259 (* 1 = 0.0184259 loss)
I0514 23:33:56.970834 12912 sgd_solver.cpp:106] Iteration 50900, lr = 0.0005
I0514 23:34:34.934445 12912 solver.cpp:228] Iteration 50950, loss = 0.00850614
I0514 23:34:34.934574 12912 solver.cpp:244]     Train net output #0: loss = 0.00850657 (* 1 = 0.00850657 loss)
I0514 23:34:34.934592 12912 sgd_solver.cpp:106] Iteration 50950, lr = 0.0005
I0514 23:35:12.602962 12912 solver.cpp:454] Snapshotting to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_51000.caffemodel
I0514 23:35:13.132571 12912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_51000.solverstate
I0514 23:35:13.214753 12912 solver.cpp:337] Iteration 51000, Testing net (#0)
I0514 23:35:13.214810 12912 net.cpp:685] Ignoring source layer loss
I0514 23:36:56.105762 12912 solver.cpp:404]     Test net output #0: accuracy = 0.713529
I0514 23:36:56.395923 12912 solver.cpp:228] Iteration 51000, loss = 0.0141787
I0514 23:36:56.395975 12912 solver.cpp:244]     Train net output #0: loss = 0.0141792 (* 1 = 0.0141792 loss)
I0514 23:36:56.395992 12912 sgd_solver.cpp:106] Iteration 51000, lr = 0.0005
I0514 23:37:34.349123 12912 solver.cpp:228] Iteration 51050, loss = 0.0024149
I0514 23:37:34.349241 12912 solver.cpp:244]     Train net output #0: loss = 0.00241532 (* 1 = 0.00241532 loss)
I0514 23:37:34.349254 12912 sgd_solver.cpp:106] Iteration 51050, lr = 0.0005
I0514 23:38:12.326905 12912 solver.cpp:228] Iteration 51100, loss = 0.0274183
I0514 23:38:12.327003 12912 solver.cpp:244]     Train net output #0: loss = 0.0274187 (* 1 = 0.0274187 loss)
I0514 23:38:12.327016 12912 sgd_solver.cpp:106] Iteration 51100, lr = 0.0005
I0514 23:38:50.288930 12912 solver.cpp:228] Iteration 51150, loss = 0.00606722
I0514 23:38:50.289062 12912 solver.cpp:244]     Train net output #0: loss = 0.00606764 (* 1 = 0.00606764 loss)
I0514 23:38:50.289078 12912 sgd_solver.cpp:106] Iteration 51150, lr = 0.0005
I0514 23:39:28.250187 12912 solver.cpp:228] Iteration 51200, loss = 0.00530853
I0514 23:39:28.250326 12912 solver.cpp:244]     Train net output #0: loss = 0.00530895 (* 1 = 0.00530895 loss)
I0514 23:39:28.250346 12912 sgd_solver.cpp:106] Iteration 51200, lr = 0.0005
I0514 23:40:06.215626 12912 solver.cpp:228] Iteration 51250, loss = 0.0138655
I0514 23:40:06.215737 12912 solver.cpp:244]     Train net output #0: loss = 0.0138659 (* 1 = 0.0138659 loss)
I0514 23:40:06.215750 12912 sgd_solver.cpp:106] Iteration 51250, lr = 0.0005
I0514 23:40:44.174428 12912 solver.cpp:228] Iteration 51300, loss = 0.0126808
I0514 23:40:44.174551 12912 solver.cpp:244]     Train net output #0: loss = 0.0126812 (* 1 = 0.0126812 loss)
I0514 23:40:44.174564 12912 sgd_solver.cpp:106] Iteration 51300, lr = 0.0005
I0514 23:41:22.123550 12912 solver.cpp:228] Iteration 51350, loss = 0.015731
I0514 23:41:22.123672 12912 solver.cpp:244]     Train net output #0: loss = 0.0157315 (* 1 = 0.0157315 loss)
I0514 23:41:22.123690 12912 sgd_solver.cpp:106] Iteration 51350, lr = 0.0005
I0514 23:42:00.096675 12912 solver.cpp:228] Iteration 51400, loss = 0.00434261
I0514 23:42:00.096791 12912 solver.cpp:244]     Train net output #0: loss = 0.00434305 (* 1 = 0.00434305 loss)
I0514 23:42:00.096809 12912 sgd_solver.cpp:106] Iteration 51400, lr = 0.0005
I0514 23:42:38.031450 12912 solver.cpp:228] Iteration 51450, loss = 0.0143516
I0514 23:42:38.042068 12912 solver.cpp:244]     Train net output #0: loss = 0.014352 (* 1 = 0.014352 loss)
I0514 23:42:38.042089 12912 sgd_solver.cpp:106] Iteration 51450, lr = 0.0005
I0514 23:43:15.994683 12912 solver.cpp:228] Iteration 51500, loss = 0.00749242
I0514 23:43:15.994812 12912 solver.cpp:244]     Train net output #0: loss = 0.00749286 (* 1 = 0.00749286 loss)
I0514 23:43:15.994830 12912 sgd_solver.cpp:106] Iteration 51500, lr = 0.0005
I0514 23:43:53.968080 12912 solver.cpp:228] Iteration 51550, loss = 0.00950552
I0514 23:43:53.968243 12912 solver.cpp:244]     Train net output #0: loss = 0.00950595 (* 1 = 0.00950595 loss)
I0514 23:43:53.968267 12912 sgd_solver.cpp:106] Iteration 51550, lr = 0.0005
I0514 23:44:31.948005 12912 solver.cpp:228] Iteration 51600, loss = 0.0108819
I0514 23:44:31.948139 12912 solver.cpp:244]     Train net output #0: loss = 0.0108823 (* 1 = 0.0108823 loss)
I0514 23:44:31.948158 12912 sgd_solver.cpp:106] Iteration 51600, lr = 0.0005
I0514 23:45:09.932873 12912 solver.cpp:228] Iteration 51650, loss = 0.00252658
I0514 23:45:09.933008 12912 solver.cpp:244]     Train net output #0: loss = 0.00252701 (* 1 = 0.00252701 loss)
I0514 23:45:09.933028 12912 sgd_solver.cpp:106] Iteration 51650, lr = 0.0005
I0514 23:45:47.902678 12912 solver.cpp:228] Iteration 51700, loss = 0.00580477
I0514 23:45:47.902824 12912 solver.cpp:244]     Train net output #0: loss = 0.00580521 (* 1 = 0.00580521 loss)
I0514 23:45:47.902842 12912 sgd_solver.cpp:106] Iteration 51700, lr = 0.0005
I0514 23:46:25.869561 12912 solver.cpp:228] Iteration 51750, loss = 0.00499451
I0514 23:46:25.869693 12912 solver.cpp:244]     Train net output #0: loss = 0.00499494 (* 1 = 0.00499494 loss)
I0514 23:46:25.869710 12912 sgd_solver.cpp:106] Iteration 51750, lr = 0.0005
I0514 23:47:03.842180 12912 solver.cpp:228] Iteration 51800, loss = 0.0116593
I0514 23:47:03.842304 12912 solver.cpp:244]     Train net output #0: loss = 0.0116598 (* 1 = 0.0116598 loss)
I0514 23:47:03.842324 12912 sgd_solver.cpp:106] Iteration 51800, lr = 0.0005
I0514 23:47:41.797181 12912 solver.cpp:228] Iteration 51850, loss = 0.00360583
I0514 23:47:41.797286 12912 solver.cpp:244]     Train net output #0: loss = 0.00360627 (* 1 = 0.00360627 loss)
I0514 23:47:41.797297 12912 sgd_solver.cpp:106] Iteration 51850, lr = 0.0005
I0514 23:48:19.760180 12912 solver.cpp:228] Iteration 51900, loss = 0.0088942
I0514 23:48:19.760342 12912 solver.cpp:244]     Train net output #0: loss = 0.00889463 (* 1 = 0.00889463 loss)
I0514 23:48:19.760360 12912 sgd_solver.cpp:106] Iteration 51900, lr = 0.0005
I0514 23:48:57.738808 12912 solver.cpp:228] Iteration 51950, loss = 0.0442888
I0514 23:48:57.738914 12912 solver.cpp:244]     Train net output #0: loss = 0.0442893 (* 1 = 0.0442893 loss)
I0514 23:48:57.738926 12912 sgd_solver.cpp:106] Iteration 51950, lr = 0.0005
I0514 23:49:35.424516 12912 solver.cpp:454] Snapshotting to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_52000.caffemodel
I0514 23:49:35.952247 12912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_52000.solverstate
I0514 23:49:36.035145 12912 solver.cpp:337] Iteration 52000, Testing net (#0)
I0514 23:49:36.035194 12912 net.cpp:685] Ignoring source layer loss
I0514 23:51:18.795253 12912 solver.cpp:404]     Test net output #0: accuracy = 0.549118
I0514 23:51:19.085314 12912 solver.cpp:228] Iteration 52000, loss = 0.00483148
I0514 23:51:19.085366 12912 solver.cpp:244]     Train net output #0: loss = 0.00483191 (* 1 = 0.00483191 loss)
I0514 23:51:19.085382 12912 sgd_solver.cpp:106] Iteration 52000, lr = 0.0005
I0514 23:51:57.046922 12912 solver.cpp:228] Iteration 52050, loss = 0.00181559
I0514 23:51:57.047055 12912 solver.cpp:244]     Train net output #0: loss = 0.00181603 (* 1 = 0.00181603 loss)
I0514 23:51:57.047067 12912 sgd_solver.cpp:106] Iteration 52050, lr = 0.0005
I0514 23:52:35.005817 12912 solver.cpp:228] Iteration 52100, loss = 0.00734213
I0514 23:52:35.005928 12912 solver.cpp:244]     Train net output #0: loss = 0.00734257 (* 1 = 0.00734257 loss)
I0514 23:52:35.005946 12912 sgd_solver.cpp:106] Iteration 52100, lr = 0.0005
I0514 23:53:12.956879 12912 solver.cpp:228] Iteration 52150, loss = 0.0063319
I0514 23:53:12.956996 12912 solver.cpp:244]     Train net output #0: loss = 0.00633235 (* 1 = 0.00633235 loss)
I0514 23:53:12.957010 12912 sgd_solver.cpp:106] Iteration 52150, lr = 0.0005
I0514 23:53:50.902109 12912 solver.cpp:228] Iteration 52200, loss = 0.00721977
I0514 23:53:50.902217 12912 solver.cpp:244]     Train net output #0: loss = 0.00722022 (* 1 = 0.00722022 loss)
I0514 23:53:50.902235 12912 sgd_solver.cpp:106] Iteration 52200, lr = 0.0005
I0514 23:54:28.852555 12912 solver.cpp:228] Iteration 52250, loss = 0.00368985
I0514 23:54:28.852715 12912 solver.cpp:244]     Train net output #0: loss = 0.0036903 (* 1 = 0.0036903 loss)
I0514 23:54:28.852735 12912 sgd_solver.cpp:106] Iteration 52250, lr = 0.0005
I0514 23:55:06.811743 12912 solver.cpp:228] Iteration 52300, loss = 0.00372472
I0514 23:55:06.811904 12912 solver.cpp:244]     Train net output #0: loss = 0.00372517 (* 1 = 0.00372517 loss)
I0514 23:55:06.811924 12912 sgd_solver.cpp:106] Iteration 52300, lr = 0.0005
I0514 23:55:44.778990 12912 solver.cpp:228] Iteration 52350, loss = 0.00401023
I0514 23:55:44.779151 12912 solver.cpp:244]     Train net output #0: loss = 0.00401067 (* 1 = 0.00401067 loss)
I0514 23:55:44.779172 12912 sgd_solver.cpp:106] Iteration 52350, lr = 0.0005
I0514 23:56:22.745496 12912 solver.cpp:228] Iteration 52400, loss = 0.00695138
I0514 23:56:22.745595 12912 solver.cpp:244]     Train net output #0: loss = 0.00695182 (* 1 = 0.00695182 loss)
I0514 23:56:22.745612 12912 sgd_solver.cpp:106] Iteration 52400, lr = 0.0005
I0514 23:57:00.716245 12912 solver.cpp:228] Iteration 52450, loss = 0.00576733
I0514 23:57:00.716470 12912 solver.cpp:244]     Train net output #0: loss = 0.00576778 (* 1 = 0.00576778 loss)
I0514 23:57:00.716495 12912 sgd_solver.cpp:106] Iteration 52450, lr = 0.0005
I0514 23:57:38.698150 12912 solver.cpp:228] Iteration 52500, loss = 0.00420006
I0514 23:57:38.698302 12912 solver.cpp:244]     Train net output #0: loss = 0.0042005 (* 1 = 0.0042005 loss)
I0514 23:57:38.698326 12912 sgd_solver.cpp:106] Iteration 52500, lr = 0.0005
I0514 23:58:16.665577 12912 solver.cpp:228] Iteration 52550, loss = 0.0123074
I0514 23:58:16.665756 12912 solver.cpp:244]     Train net output #0: loss = 0.0123079 (* 1 = 0.0123079 loss)
I0514 23:58:16.665783 12912 sgd_solver.cpp:106] Iteration 52550, lr = 0.0005
I0514 23:58:54.631718 12912 solver.cpp:228] Iteration 52600, loss = 0.0057245
I0514 23:58:54.631829 12912 solver.cpp:244]     Train net output #0: loss = 0.00572495 (* 1 = 0.00572495 loss)
I0514 23:58:54.631846 12912 sgd_solver.cpp:106] Iteration 52600, lr = 0.0005
I0514 23:59:32.609092 12912 solver.cpp:228] Iteration 52650, loss = 0.00274699
I0514 23:59:32.609230 12912 solver.cpp:244]     Train net output #0: loss = 0.00274743 (* 1 = 0.00274743 loss)
I0514 23:59:32.609249 12912 sgd_solver.cpp:106] Iteration 52650, lr = 0.0005
I0515 00:00:10.568500 12912 solver.cpp:228] Iteration 52700, loss = 0.0030702
I0515 00:00:10.568636 12912 solver.cpp:244]     Train net output #0: loss = 0.00307065 (* 1 = 0.00307065 loss)
I0515 00:00:10.568655 12912 sgd_solver.cpp:106] Iteration 52700, lr = 0.0005
I0515 00:00:48.530555 12912 solver.cpp:228] Iteration 52750, loss = 0.00563572
I0515 00:00:48.530671 12912 solver.cpp:244]     Train net output #0: loss = 0.00563617 (* 1 = 0.00563617 loss)
I0515 00:00:48.530690 12912 sgd_solver.cpp:106] Iteration 52750, lr = 0.0005
I0515 00:01:26.502514 12912 solver.cpp:228] Iteration 52800, loss = 0.00281998
I0515 00:01:26.502650 12912 solver.cpp:244]     Train net output #0: loss = 0.00282043 (* 1 = 0.00282043 loss)
I0515 00:01:26.502667 12912 sgd_solver.cpp:106] Iteration 52800, lr = 0.0005
I0515 00:02:04.441036 12912 solver.cpp:228] Iteration 52850, loss = 0.0231789
I0515 00:02:04.441241 12912 solver.cpp:244]     Train net output #0: loss = 0.0231794 (* 1 = 0.0231794 loss)
I0515 00:02:04.441283 12912 sgd_solver.cpp:106] Iteration 52850, lr = 0.0005
I0515 00:02:42.414434 12912 solver.cpp:228] Iteration 52900, loss = 0.00702144
I0515 00:02:42.414535 12912 solver.cpp:244]     Train net output #0: loss = 0.00702188 (* 1 = 0.00702188 loss)
I0515 00:02:42.414547 12912 sgd_solver.cpp:106] Iteration 52900, lr = 0.0005
I0515 00:03:20.362921 12912 solver.cpp:228] Iteration 52950, loss = 0.0135956
I0515 00:03:20.363086 12912 solver.cpp:244]     Train net output #0: loss = 0.013596 (* 1 = 0.013596 loss)
I0515 00:03:20.363121 12912 sgd_solver.cpp:106] Iteration 52950, lr = 0.0005
I0515 00:03:58.019413 12912 solver.cpp:454] Snapshotting to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_53000.caffemodel
I0515 00:03:58.231621 12912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_53000.solverstate
I0515 00:03:58.335629 12912 solver.cpp:337] Iteration 53000, Testing net (#0)
I0515 00:03:58.335695 12912 net.cpp:685] Ignoring source layer loss
I0515 00:05:41.351794 12912 solver.cpp:404]     Test net output #0: accuracy = 0.722941
I0515 00:05:41.642086 12912 solver.cpp:228] Iteration 53000, loss = 0.00332335
I0515 00:05:41.642140 12912 solver.cpp:244]     Train net output #0: loss = 0.00332379 (* 1 = 0.00332379 loss)
I0515 00:05:41.642156 12912 sgd_solver.cpp:106] Iteration 53000, lr = 0.0005
I0515 00:06:19.581831 12912 solver.cpp:228] Iteration 53050, loss = 0.00274161
I0515 00:06:19.582005 12912 solver.cpp:244]     Train net output #0: loss = 0.00274205 (* 1 = 0.00274205 loss)
I0515 00:06:19.582021 12912 sgd_solver.cpp:106] Iteration 53050, lr = 0.0005
I0515 00:06:57.546157 12912 solver.cpp:228] Iteration 53100, loss = 0.00428094
I0515 00:06:57.546277 12912 solver.cpp:244]     Train net output #0: loss = 0.00428138 (* 1 = 0.00428138 loss)
I0515 00:06:57.546294 12912 sgd_solver.cpp:106] Iteration 53100, lr = 0.0005
I0515 00:07:35.494532 12912 solver.cpp:228] Iteration 53150, loss = 0.00229339
I0515 00:07:35.494649 12912 solver.cpp:244]     Train net output #0: loss = 0.00229382 (* 1 = 0.00229382 loss)
I0515 00:07:35.494663 12912 sgd_solver.cpp:106] Iteration 53150, lr = 0.0005
I0515 00:08:13.463454 12912 solver.cpp:228] Iteration 53200, loss = 0.00278676
I0515 00:08:13.463572 12912 solver.cpp:244]     Train net output #0: loss = 0.00278719 (* 1 = 0.00278719 loss)
I0515 00:08:13.463590 12912 sgd_solver.cpp:106] Iteration 53200, lr = 0.0005
I0515 00:08:51.436070 12912 solver.cpp:228] Iteration 53250, loss = 0.00809999
I0515 00:08:51.436282 12912 solver.cpp:244]     Train net output #0: loss = 0.00810041 (* 1 = 0.00810041 loss)
I0515 00:08:51.436332 12912 sgd_solver.cpp:106] Iteration 53250, lr = 0.0005
I0515 00:09:29.401926 12912 solver.cpp:228] Iteration 53300, loss = 0.0115252
I0515 00:09:29.402144 12912 solver.cpp:244]     Train net output #0: loss = 0.0115256 (* 1 = 0.0115256 loss)
I0515 00:09:29.402175 12912 sgd_solver.cpp:106] Iteration 53300, lr = 0.0005
I0515 00:10:07.359737 12912 solver.cpp:228] Iteration 53350, loss = 0.00810052
I0515 00:10:07.359865 12912 solver.cpp:244]     Train net output #0: loss = 0.00810096 (* 1 = 0.00810096 loss)
I0515 00:10:07.359881 12912 sgd_solver.cpp:106] Iteration 53350, lr = 0.0005
I0515 00:10:45.321748 12912 solver.cpp:228] Iteration 53400, loss = 0.00541961
I0515 00:10:45.321868 12912 solver.cpp:244]     Train net output #0: loss = 0.00542006 (* 1 = 0.00542006 loss)
I0515 00:10:45.321888 12912 sgd_solver.cpp:106] Iteration 53400, lr = 0.0005
I0515 00:11:23.280333 12912 solver.cpp:228] Iteration 53450, loss = 0.0078317
I0515 00:11:23.280437 12912 solver.cpp:244]     Train net output #0: loss = 0.00783215 (* 1 = 0.00783215 loss)
I0515 00:11:23.280454 12912 sgd_solver.cpp:106] Iteration 53450, lr = 0.0005
I0515 00:12:01.243562 12912 solver.cpp:228] Iteration 53500, loss = 0.0028621
I0515 00:12:01.243744 12912 solver.cpp:244]     Train net output #0: loss = 0.00286254 (* 1 = 0.00286254 loss)
I0515 00:12:01.243762 12912 sgd_solver.cpp:106] Iteration 53500, lr = 0.0005
I0515 00:12:39.219382 12912 solver.cpp:228] Iteration 53550, loss = 0.00709745
I0515 00:12:39.219496 12912 solver.cpp:244]     Train net output #0: loss = 0.0070979 (* 1 = 0.0070979 loss)
I0515 00:12:39.219514 12912 sgd_solver.cpp:106] Iteration 53550, lr = 0.0005
I0515 00:13:17.198746 12912 solver.cpp:228] Iteration 53600, loss = 0.0137816
I0515 00:13:17.198850 12912 solver.cpp:244]     Train net output #0: loss = 0.013782 (* 1 = 0.013782 loss)
I0515 00:13:17.198868 12912 sgd_solver.cpp:106] Iteration 53600, lr = 0.0005
I0515 00:13:55.147430 12912 solver.cpp:228] Iteration 53650, loss = 0.0505251
I0515 00:13:55.147608 12912 solver.cpp:244]     Train net output #0: loss = 0.0505256 (* 1 = 0.0505256 loss)
I0515 00:13:55.147653 12912 sgd_solver.cpp:106] Iteration 53650, lr = 0.0005
I0515 00:14:33.095046 12912 solver.cpp:228] Iteration 53700, loss = 0.00391293
I0515 00:14:33.095147 12912 solver.cpp:244]     Train net output #0: loss = 0.00391338 (* 1 = 0.00391338 loss)
I0515 00:14:33.095160 12912 sgd_solver.cpp:106] Iteration 53700, lr = 0.0005
I0515 00:15:11.065284 12912 solver.cpp:228] Iteration 53750, loss = 0.0110086
I0515 00:15:11.065418 12912 solver.cpp:244]     Train net output #0: loss = 0.0110091 (* 1 = 0.0110091 loss)
I0515 00:15:11.065433 12912 sgd_solver.cpp:106] Iteration 53750, lr = 0.0005
I0515 00:15:49.029800 12912 solver.cpp:228] Iteration 53800, loss = 0.00237762
I0515 00:15:49.029939 12912 solver.cpp:244]     Train net output #0: loss = 0.00237807 (* 1 = 0.00237807 loss)
I0515 00:15:49.029958 12912 sgd_solver.cpp:106] Iteration 53800, lr = 0.0005
I0515 00:16:26.990310 12912 solver.cpp:228] Iteration 53850, loss = 0.0458284
I0515 00:16:26.990437 12912 solver.cpp:244]     Train net output #0: loss = 0.0458289 (* 1 = 0.0458289 loss)
I0515 00:16:26.990456 12912 sgd_solver.cpp:106] Iteration 53850, lr = 0.0005
I0515 00:17:04.942176 12912 solver.cpp:228] Iteration 53900, loss = 0.0121038
I0515 00:17:04.942327 12912 solver.cpp:244]     Train net output #0: loss = 0.0121042 (* 1 = 0.0121042 loss)
I0515 00:17:04.942343 12912 sgd_solver.cpp:106] Iteration 53900, lr = 0.0005
I0515 00:17:42.897378 12912 solver.cpp:228] Iteration 53950, loss = 0.0141766
I0515 00:17:42.897558 12912 solver.cpp:244]     Train net output #0: loss = 0.0141771 (* 1 = 0.0141771 loss)
I0515 00:17:42.897603 12912 sgd_solver.cpp:106] Iteration 53950, lr = 0.0005
I0515 00:18:20.579537 12912 solver.cpp:454] Snapshotting to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_54000.caffemodel
I0515 00:18:21.255398 12912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_54000.solverstate
I0515 00:18:21.401837 12912 solver.cpp:337] Iteration 54000, Testing net (#0)
I0515 00:18:21.401978 12912 net.cpp:685] Ignoring source layer loss
I0515 00:20:04.489040 12912 solver.cpp:404]     Test net output #0: accuracy = 0.687941
I0515 00:20:04.778903 12912 solver.cpp:228] Iteration 54000, loss = 0.0165161
I0515 00:20:04.778964 12912 solver.cpp:244]     Train net output #0: loss = 0.0165166 (* 1 = 0.0165166 loss)
I0515 00:20:04.778980 12912 sgd_solver.cpp:106] Iteration 54000, lr = 0.0005
I0515 00:20:42.733299 12912 solver.cpp:228] Iteration 54050, loss = 0.00263998
I0515 00:20:42.733407 12912 solver.cpp:244]     Train net output #0: loss = 0.00264042 (* 1 = 0.00264042 loss)
I0515 00:20:42.733420 12912 sgd_solver.cpp:106] Iteration 54050, lr = 0.0005
I0515 00:21:20.723115 12912 solver.cpp:228] Iteration 54100, loss = 0.00757022
I0515 00:21:20.723230 12912 solver.cpp:244]     Train net output #0: loss = 0.00757066 (* 1 = 0.00757066 loss)
I0515 00:21:20.723248 12912 sgd_solver.cpp:106] Iteration 54100, lr = 0.0005
I0515 00:21:58.684900 12912 solver.cpp:228] Iteration 54150, loss = 0.00755693
I0515 00:21:58.685003 12912 solver.cpp:244]     Train net output #0: loss = 0.00755738 (* 1 = 0.00755738 loss)
I0515 00:21:58.685021 12912 sgd_solver.cpp:106] Iteration 54150, lr = 0.0005
I0515 00:22:36.645659 12912 solver.cpp:228] Iteration 54200, loss = 0.0022967
I0515 00:22:36.645802 12912 solver.cpp:244]     Train net output #0: loss = 0.00229715 (* 1 = 0.00229715 loss)
I0515 00:22:36.645822 12912 sgd_solver.cpp:106] Iteration 54200, lr = 0.0005
I0515 00:23:14.613184 12912 solver.cpp:228] Iteration 54250, loss = 0.012379
I0515 00:23:14.613294 12912 solver.cpp:244]     Train net output #0: loss = 0.0123795 (* 1 = 0.0123795 loss)
I0515 00:23:14.613313 12912 sgd_solver.cpp:106] Iteration 54250, lr = 0.0005
I0515 00:23:52.584383 12912 solver.cpp:228] Iteration 54300, loss = 0.0021286
I0515 00:23:52.584484 12912 solver.cpp:244]     Train net output #0: loss = 0.00212905 (* 1 = 0.00212905 loss)
I0515 00:23:52.584497 12912 sgd_solver.cpp:106] Iteration 54300, lr = 0.0005
I0515 00:24:30.543818 12912 solver.cpp:228] Iteration 54350, loss = 0.0133868
I0515 00:24:30.543921 12912 solver.cpp:244]     Train net output #0: loss = 0.0133872 (* 1 = 0.0133872 loss)
I0515 00:24:30.543941 12912 sgd_solver.cpp:106] Iteration 54350, lr = 0.0005
I0515 00:25:08.499238 12912 solver.cpp:228] Iteration 54400, loss = 0.00516642
I0515 00:25:08.499344 12912 solver.cpp:244]     Train net output #0: loss = 0.00516687 (* 1 = 0.00516687 loss)
I0515 00:25:08.499362 12912 sgd_solver.cpp:106] Iteration 54400, lr = 0.0005
I0515 00:25:46.478484 12912 solver.cpp:228] Iteration 54450, loss = 0.0023809
I0515 00:25:46.478613 12912 solver.cpp:244]     Train net output #0: loss = 0.00238135 (* 1 = 0.00238135 loss)
I0515 00:25:46.478627 12912 sgd_solver.cpp:106] Iteration 54450, lr = 0.0005
I0515 00:26:24.431717 12912 solver.cpp:228] Iteration 54500, loss = 0.0045362
I0515 00:26:24.431849 12912 solver.cpp:244]     Train net output #0: loss = 0.00453665 (* 1 = 0.00453665 loss)
I0515 00:26:24.431862 12912 sgd_solver.cpp:106] Iteration 54500, lr = 0.0005
I0515 00:27:02.400809 12912 solver.cpp:228] Iteration 54550, loss = 0.00225567
I0515 00:27:02.400949 12912 solver.cpp:244]     Train net output #0: loss = 0.00225612 (* 1 = 0.00225612 loss)
I0515 00:27:02.400974 12912 sgd_solver.cpp:106] Iteration 54550, lr = 0.0005
I0515 00:27:40.351397 12912 solver.cpp:228] Iteration 54600, loss = 0.00502898
I0515 00:27:40.351538 12912 solver.cpp:244]     Train net output #0: loss = 0.00502943 (* 1 = 0.00502943 loss)
I0515 00:27:40.351552 12912 sgd_solver.cpp:106] Iteration 54600, lr = 0.0005
I0515 00:28:18.310658 12912 solver.cpp:228] Iteration 54650, loss = 0.00432398
I0515 00:28:18.310777 12912 solver.cpp:244]     Train net output #0: loss = 0.00432443 (* 1 = 0.00432443 loss)
I0515 00:28:18.310797 12912 sgd_solver.cpp:106] Iteration 54650, lr = 0.0005
I0515 00:28:56.285161 12912 solver.cpp:228] Iteration 54700, loss = 0.00298259
I0515 00:28:56.285266 12912 solver.cpp:244]     Train net output #0: loss = 0.00298304 (* 1 = 0.00298304 loss)
I0515 00:28:56.285284 12912 sgd_solver.cpp:106] Iteration 54700, lr = 0.0005
I0515 00:29:34.247725 12912 solver.cpp:228] Iteration 54750, loss = 0.00936915
I0515 00:29:34.247891 12912 solver.cpp:244]     Train net output #0: loss = 0.00936959 (* 1 = 0.00936959 loss)
I0515 00:29:34.247911 12912 sgd_solver.cpp:106] Iteration 54750, lr = 0.0005
I0515 00:30:12.208708 12912 solver.cpp:228] Iteration 54800, loss = 0.00161039
I0515 00:30:12.208813 12912 solver.cpp:244]     Train net output #0: loss = 0.00161083 (* 1 = 0.00161083 loss)
I0515 00:30:12.208832 12912 sgd_solver.cpp:106] Iteration 54800, lr = 0.0005
I0515 00:30:50.170668 12912 solver.cpp:228] Iteration 54850, loss = 0.00250562
I0515 00:30:50.170807 12912 solver.cpp:244]     Train net output #0: loss = 0.00250605 (* 1 = 0.00250605 loss)
I0515 00:30:50.170820 12912 sgd_solver.cpp:106] Iteration 54850, lr = 0.0005
I0515 00:31:28.128536 12912 solver.cpp:228] Iteration 54900, loss = 0.00277363
I0515 00:31:28.128690 12912 solver.cpp:244]     Train net output #0: loss = 0.00277407 (* 1 = 0.00277407 loss)
I0515 00:31:28.128720 12912 sgd_solver.cpp:106] Iteration 54900, lr = 0.0005
I0515 00:32:06.088645 12912 solver.cpp:228] Iteration 54950, loss = 0.00323471
I0515 00:32:06.088796 12912 solver.cpp:244]     Train net output #0: loss = 0.00323515 (* 1 = 0.00323515 loss)
I0515 00:32:06.088819 12912 sgd_solver.cpp:106] Iteration 54950, lr = 0.0005
I0515 00:32:43.768748 12912 solver.cpp:454] Snapshotting to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_55000.caffemodel
I0515 00:32:44.304525 12912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_55000.solverstate
I0515 00:32:44.387418 12912 solver.cpp:337] Iteration 55000, Testing net (#0)
I0515 00:32:44.387477 12912 net.cpp:685] Ignoring source layer loss
I0515 00:34:27.473104 12912 solver.cpp:404]     Test net output #0: accuracy = 0.773088
I0515 00:34:27.763072 12912 solver.cpp:228] Iteration 55000, loss = 0.00428949
I0515 00:34:27.763144 12912 solver.cpp:244]     Train net output #0: loss = 0.00428993 (* 1 = 0.00428993 loss)
I0515 00:34:27.763157 12912 sgd_solver.cpp:106] Iteration 55000, lr = 0.0005
I0515 00:35:05.729162 12912 solver.cpp:228] Iteration 55050, loss = 0.0779508
I0515 00:35:05.729279 12912 solver.cpp:244]     Train net output #0: loss = 0.0779512 (* 1 = 0.0779512 loss)
I0515 00:35:05.729298 12912 sgd_solver.cpp:106] Iteration 55050, lr = 0.0005
I0515 00:35:43.700723 12912 solver.cpp:228] Iteration 55100, loss = 0.00493591
I0515 00:35:43.700858 12912 solver.cpp:244]     Train net output #0: loss = 0.00493635 (* 1 = 0.00493635 loss)
I0515 00:35:43.700875 12912 sgd_solver.cpp:106] Iteration 55100, lr = 0.0005
I0515 00:36:21.661792 12912 solver.cpp:228] Iteration 55150, loss = 0.0157112
I0515 00:36:21.661934 12912 solver.cpp:244]     Train net output #0: loss = 0.0157116 (* 1 = 0.0157116 loss)
I0515 00:36:21.661952 12912 sgd_solver.cpp:106] Iteration 55150, lr = 0.0005
I0515 00:36:59.603811 12912 solver.cpp:228] Iteration 55200, loss = 0.00658213
I0515 00:36:59.603932 12912 solver.cpp:244]     Train net output #0: loss = 0.00658257 (* 1 = 0.00658257 loss)
I0515 00:36:59.603952 12912 sgd_solver.cpp:106] Iteration 55200, lr = 0.0005
I0515 00:37:37.567172 12912 solver.cpp:228] Iteration 55250, loss = 0.00926385
I0515 00:37:37.567318 12912 solver.cpp:244]     Train net output #0: loss = 0.0092643 (* 1 = 0.0092643 loss)
I0515 00:37:37.567337 12912 sgd_solver.cpp:106] Iteration 55250, lr = 0.0005
I0515 00:38:15.522212 12912 solver.cpp:228] Iteration 55300, loss = 0.00254399
I0515 00:38:15.522377 12912 solver.cpp:244]     Train net output #0: loss = 0.00254443 (* 1 = 0.00254443 loss)
I0515 00:38:15.522394 12912 sgd_solver.cpp:106] Iteration 55300, lr = 0.0005
I0515 00:38:53.486124 12912 solver.cpp:228] Iteration 55350, loss = 0.0136352
I0515 00:38:53.498178 12912 solver.cpp:244]     Train net output #0: loss = 0.0136356 (* 1 = 0.0136356 loss)
I0515 00:38:53.498226 12912 sgd_solver.cpp:106] Iteration 55350, lr = 0.0005
I0515 00:39:31.439852 12912 solver.cpp:228] Iteration 55400, loss = 0.0566539
I0515 00:39:31.439951 12912 solver.cpp:244]     Train net output #0: loss = 0.0566543 (* 1 = 0.0566543 loss)
I0515 00:39:31.439970 12912 sgd_solver.cpp:106] Iteration 55400, lr = 0.0005
I0515 00:40:09.407960 12912 solver.cpp:228] Iteration 55450, loss = 0.00753912
I0515 00:40:09.408098 12912 solver.cpp:244]     Train net output #0: loss = 0.00753956 (* 1 = 0.00753956 loss)
I0515 00:40:09.408118 12912 sgd_solver.cpp:106] Iteration 55450, lr = 0.0005
I0515 00:40:47.358245 12912 solver.cpp:228] Iteration 55500, loss = 0.00397446
I0515 00:40:47.358448 12912 solver.cpp:244]     Train net output #0: loss = 0.0039749 (* 1 = 0.0039749 loss)
I0515 00:40:47.358486 12912 sgd_solver.cpp:106] Iteration 55500, lr = 0.0005
I0515 00:41:25.316519 12912 solver.cpp:228] Iteration 55550, loss = 0.0114129
I0515 00:41:25.316625 12912 solver.cpp:244]     Train net output #0: loss = 0.0114133 (* 1 = 0.0114133 loss)
I0515 00:41:25.316643 12912 sgd_solver.cpp:106] Iteration 55550, lr = 0.0005
I0515 00:42:03.277447 12912 solver.cpp:228] Iteration 55600, loss = 0.00454386
I0515 00:42:03.277586 12912 solver.cpp:244]     Train net output #0: loss = 0.00454431 (* 1 = 0.00454431 loss)
I0515 00:42:03.277603 12912 sgd_solver.cpp:106] Iteration 55600, lr = 0.0005
I0515 00:42:41.249222 12912 solver.cpp:228] Iteration 55650, loss = 0.00537111
I0515 00:42:41.249385 12912 solver.cpp:244]     Train net output #0: loss = 0.00537156 (* 1 = 0.00537156 loss)
I0515 00:42:41.249405 12912 sgd_solver.cpp:106] Iteration 55650, lr = 0.0005
I0515 00:43:19.218901 12912 solver.cpp:228] Iteration 55700, loss = 0.00528324
I0515 00:43:19.219017 12912 solver.cpp:244]     Train net output #0: loss = 0.00528369 (* 1 = 0.00528369 loss)
I0515 00:43:19.219034 12912 sgd_solver.cpp:106] Iteration 55700, lr = 0.0005
I0515 00:43:57.179355 12912 solver.cpp:228] Iteration 55750, loss = 0.0227303
I0515 00:43:57.179461 12912 solver.cpp:244]     Train net output #0: loss = 0.0227308 (* 1 = 0.0227308 loss)
I0515 00:43:57.179474 12912 sgd_solver.cpp:106] Iteration 55750, lr = 0.0005
I0515 00:44:35.140259 12912 solver.cpp:228] Iteration 55800, loss = 0.00371974
I0515 00:44:35.140453 12912 solver.cpp:244]     Train net output #0: loss = 0.00372018 (* 1 = 0.00372018 loss)
I0515 00:44:35.140492 12912 sgd_solver.cpp:106] Iteration 55800, lr = 0.0005
I0515 00:45:13.098219 12912 solver.cpp:228] Iteration 55850, loss = 0.0203155
I0515 00:45:13.098330 12912 solver.cpp:244]     Train net output #0: loss = 0.0203159 (* 1 = 0.0203159 loss)
I0515 00:45:13.098346 12912 sgd_solver.cpp:106] Iteration 55850, lr = 0.0005
I0515 00:45:51.061065 12912 solver.cpp:228] Iteration 55900, loss = 0.0178723
I0515 00:45:51.061168 12912 solver.cpp:244]     Train net output #0: loss = 0.0178727 (* 1 = 0.0178727 loss)
I0515 00:45:51.061185 12912 sgd_solver.cpp:106] Iteration 55900, lr = 0.0005
I0515 00:46:29.013185 12912 solver.cpp:228] Iteration 55950, loss = 0.0133376
I0515 00:46:29.013345 12912 solver.cpp:244]     Train net output #0: loss = 0.013338 (* 1 = 0.013338 loss)
I0515 00:46:29.013384 12912 sgd_solver.cpp:106] Iteration 55950, lr = 0.0005
I0515 00:47:06.676988 12912 solver.cpp:454] Snapshotting to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_56000.caffemodel
I0515 00:47:07.219920 12912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_56000.solverstate
I0515 00:47:07.302227 12912 solver.cpp:337] Iteration 56000, Testing net (#0)
I0515 00:47:07.302284 12912 net.cpp:685] Ignoring source layer loss
I0515 00:48:50.412101 12912 solver.cpp:404]     Test net output #0: accuracy = 0.749853
I0515 00:48:50.702301 12912 solver.cpp:228] Iteration 56000, loss = 0.00874974
I0515 00:48:50.702352 12912 solver.cpp:244]     Train net output #0: loss = 0.0087502 (* 1 = 0.0087502 loss)
I0515 00:48:50.702363 12912 sgd_solver.cpp:106] Iteration 56000, lr = 0.0005
I0515 00:49:28.645819 12912 solver.cpp:228] Iteration 56050, loss = 0.00522499
I0515 00:49:28.645936 12912 solver.cpp:244]     Train net output #0: loss = 0.00522544 (* 1 = 0.00522544 loss)
I0515 00:49:28.645948 12912 sgd_solver.cpp:106] Iteration 56050, lr = 0.0005
I0515 00:50:06.591611 12912 solver.cpp:228] Iteration 56100, loss = 0.00610137
I0515 00:50:06.591753 12912 solver.cpp:244]     Train net output #0: loss = 0.00610182 (* 1 = 0.00610182 loss)
I0515 00:50:06.591773 12912 sgd_solver.cpp:106] Iteration 56100, lr = 0.0005
I0515 00:50:44.556594 12912 solver.cpp:228] Iteration 56150, loss = 0.00681017
I0515 00:50:44.556732 12912 solver.cpp:244]     Train net output #0: loss = 0.00681062 (* 1 = 0.00681062 loss)
I0515 00:50:44.556746 12912 sgd_solver.cpp:106] Iteration 56150, lr = 0.0005
I0515 00:51:22.511950 12912 solver.cpp:228] Iteration 56200, loss = 0.00169715
I0515 00:51:22.512054 12912 solver.cpp:244]     Train net output #0: loss = 0.0016976 (* 1 = 0.0016976 loss)
I0515 00:51:22.512068 12912 sgd_solver.cpp:106] Iteration 56200, lr = 0.0005
I0515 00:52:00.464462 12912 solver.cpp:228] Iteration 56250, loss = 0.00602275
I0515 00:52:00.464607 12912 solver.cpp:244]     Train net output #0: loss = 0.0060232 (* 1 = 0.0060232 loss)
I0515 00:52:00.464625 12912 sgd_solver.cpp:106] Iteration 56250, lr = 0.0005
I0515 00:52:38.417285 12912 solver.cpp:228] Iteration 56300, loss = 0.00492612
I0515 00:52:38.417388 12912 solver.cpp:244]     Train net output #0: loss = 0.00492657 (* 1 = 0.00492657 loss)
I0515 00:52:38.417407 12912 sgd_solver.cpp:106] Iteration 56300, lr = 0.0005
I0515 00:53:16.364106 12912 solver.cpp:228] Iteration 56350, loss = 0.0106342
I0515 00:53:16.364229 12912 solver.cpp:244]     Train net output #0: loss = 0.0106347 (* 1 = 0.0106347 loss)
I0515 00:53:16.364248 12912 sgd_solver.cpp:106] Iteration 56350, lr = 0.0005
I0515 00:53:54.329540 12912 solver.cpp:228] Iteration 56400, loss = 0.00262654
I0515 00:53:54.329644 12912 solver.cpp:244]     Train net output #0: loss = 0.002627 (* 1 = 0.002627 loss)
I0515 00:53:54.329658 12912 sgd_solver.cpp:106] Iteration 56400, lr = 0.0005
I0515 00:54:32.286368 12912 solver.cpp:228] Iteration 56450, loss = 0.00544236
I0515 00:54:32.286479 12912 solver.cpp:244]     Train net output #0: loss = 0.00544282 (* 1 = 0.00544282 loss)
I0515 00:54:32.286499 12912 sgd_solver.cpp:106] Iteration 56450, lr = 0.0005
I0515 00:55:10.249096 12912 solver.cpp:228] Iteration 56500, loss = 0.00786689
I0515 00:55:10.249202 12912 solver.cpp:244]     Train net output #0: loss = 0.00786735 (* 1 = 0.00786735 loss)
I0515 00:55:10.249219 12912 sgd_solver.cpp:106] Iteration 56500, lr = 0.0005
I0515 00:55:48.215832 12912 solver.cpp:228] Iteration 56550, loss = 0.00906868
I0515 00:55:48.215935 12912 solver.cpp:244]     Train net output #0: loss = 0.00906914 (* 1 = 0.00906914 loss)
I0515 00:55:48.215947 12912 sgd_solver.cpp:106] Iteration 56550, lr = 0.0005
I0515 00:56:26.177749 12912 solver.cpp:228] Iteration 56600, loss = 0.013542
I0515 00:56:26.177891 12912 solver.cpp:244]     Train net output #0: loss = 0.0135425 (* 1 = 0.0135425 loss)
I0515 00:56:26.177906 12912 sgd_solver.cpp:106] Iteration 56600, lr = 0.0005
I0515 00:57:04.137204 12912 solver.cpp:228] Iteration 56650, loss = 0.0122957
I0515 00:57:04.137353 12912 solver.cpp:244]     Train net output #0: loss = 0.0122962 (* 1 = 0.0122962 loss)
I0515 00:57:04.137403 12912 sgd_solver.cpp:106] Iteration 56650, lr = 0.0005
I0515 00:57:42.114588 12912 solver.cpp:228] Iteration 56700, loss = 0.00582653
I0515 00:57:42.114688 12912 solver.cpp:244]     Train net output #0: loss = 0.00582699 (* 1 = 0.00582699 loss)
I0515 00:57:42.114701 12912 sgd_solver.cpp:106] Iteration 56700, lr = 0.0005
I0515 00:58:20.079861 12912 solver.cpp:228] Iteration 56750, loss = 0.0118069
I0515 00:58:20.080049 12912 solver.cpp:244]     Train net output #0: loss = 0.0118073 (* 1 = 0.0118073 loss)
I0515 00:58:20.080068 12912 sgd_solver.cpp:106] Iteration 56750, lr = 0.0005
I0515 00:58:58.022934 12912 solver.cpp:228] Iteration 56800, loss = 0.0163918
I0515 00:58:58.023046 12912 solver.cpp:244]     Train net output #0: loss = 0.0163923 (* 1 = 0.0163923 loss)
I0515 00:58:58.023064 12912 sgd_solver.cpp:106] Iteration 56800, lr = 0.0005
I0515 00:59:35.997042 12912 solver.cpp:228] Iteration 56850, loss = 0.00712355
I0515 00:59:35.997215 12912 solver.cpp:244]     Train net output #0: loss = 0.00712401 (* 1 = 0.00712401 loss)
I0515 00:59:35.997233 12912 sgd_solver.cpp:106] Iteration 56850, lr = 0.0005
I0515 01:00:13.964951 12912 solver.cpp:228] Iteration 56900, loss = 0.00312224
I0515 01:00:13.965154 12912 solver.cpp:244]     Train net output #0: loss = 0.00312269 (* 1 = 0.00312269 loss)
I0515 01:00:13.965198 12912 sgd_solver.cpp:106] Iteration 56900, lr = 0.0005
I0515 01:00:51.929275 12912 solver.cpp:228] Iteration 56950, loss = 0.00385772
I0515 01:00:51.929381 12912 solver.cpp:244]     Train net output #0: loss = 0.00385817 (* 1 = 0.00385817 loss)
I0515 01:00:51.929394 12912 sgd_solver.cpp:106] Iteration 56950, lr = 0.0005
I0515 01:01:29.591441 12912 solver.cpp:454] Snapshotting to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_57000.caffemodel
I0515 01:01:30.157867 12912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_57000.solverstate
I0515 01:01:30.253340 12912 solver.cpp:337] Iteration 57000, Testing net (#0)
I0515 01:01:30.253403 12912 net.cpp:685] Ignoring source layer loss
I0515 01:03:13.116226 12912 solver.cpp:404]     Test net output #0: accuracy = 0.744412
I0515 01:03:13.406396 12912 solver.cpp:228] Iteration 57000, loss = 0.00374071
I0515 01:03:13.406510 12912 solver.cpp:244]     Train net output #0: loss = 0.00374117 (* 1 = 0.00374117 loss)
I0515 01:03:13.406529 12912 sgd_solver.cpp:106] Iteration 57000, lr = 0.0005
I0515 01:03:51.371529 12912 solver.cpp:228] Iteration 57050, loss = 0.0222133
I0515 01:03:51.371723 12912 solver.cpp:244]     Train net output #0: loss = 0.0222138 (* 1 = 0.0222138 loss)
I0515 01:03:51.371739 12912 sgd_solver.cpp:106] Iteration 57050, lr = 0.0005
I0515 01:04:29.344802 12912 solver.cpp:228] Iteration 57100, loss = 0.00819169
I0515 01:04:29.344910 12912 solver.cpp:244]     Train net output #0: loss = 0.00819215 (* 1 = 0.00819215 loss)
I0515 01:04:29.344928 12912 sgd_solver.cpp:106] Iteration 57100, lr = 0.0005
I0515 01:05:07.313766 12912 solver.cpp:228] Iteration 57150, loss = 0.00440298
I0515 01:05:07.313871 12912 solver.cpp:244]     Train net output #0: loss = 0.00440344 (* 1 = 0.00440344 loss)
I0515 01:05:07.313884 12912 sgd_solver.cpp:106] Iteration 57150, lr = 0.0005
I0515 01:05:45.284904 12912 solver.cpp:228] Iteration 57200, loss = 0.00626314
I0515 01:05:45.285006 12912 solver.cpp:244]     Train net output #0: loss = 0.0062636 (* 1 = 0.0062636 loss)
I0515 01:05:45.285018 12912 sgd_solver.cpp:106] Iteration 57200, lr = 0.0005
I0515 01:06:23.244701 12912 solver.cpp:228] Iteration 57250, loss = 0.00364363
I0515 01:06:23.244848 12912 solver.cpp:244]     Train net output #0: loss = 0.0036441 (* 1 = 0.0036441 loss)
I0515 01:06:23.244865 12912 sgd_solver.cpp:106] Iteration 57250, lr = 0.0005
I0515 01:07:01.202317 12912 solver.cpp:228] Iteration 57300, loss = 0.00328058
I0515 01:07:01.202456 12912 solver.cpp:244]     Train net output #0: loss = 0.00328104 (* 1 = 0.00328104 loss)
I0515 01:07:01.202474 12912 sgd_solver.cpp:106] Iteration 57300, lr = 0.0005
I0515 01:07:39.167719 12912 solver.cpp:228] Iteration 57350, loss = 0.00524183
I0515 01:07:39.167873 12912 solver.cpp:244]     Train net output #0: loss = 0.0052423 (* 1 = 0.0052423 loss)
I0515 01:07:39.167891 12912 sgd_solver.cpp:106] Iteration 57350, lr = 0.0005
I0515 01:08:17.143776 12912 solver.cpp:228] Iteration 57400, loss = 0.040836
I0515 01:08:17.143905 12912 solver.cpp:244]     Train net output #0: loss = 0.0408365 (* 1 = 0.0408365 loss)
I0515 01:08:17.143919 12912 sgd_solver.cpp:106] Iteration 57400, lr = 0.0005
I0515 01:08:55.101986 12912 solver.cpp:228] Iteration 57450, loss = 0.00407107
I0515 01:08:55.102080 12912 solver.cpp:244]     Train net output #0: loss = 0.00407154 (* 1 = 0.00407154 loss)
I0515 01:08:55.102092 12912 sgd_solver.cpp:106] Iteration 57450, lr = 0.0005
I0515 01:09:33.076823 12912 solver.cpp:228] Iteration 57500, loss = 0.00378819
I0515 01:09:33.076930 12912 solver.cpp:244]     Train net output #0: loss = 0.00378866 (* 1 = 0.00378866 loss)
I0515 01:09:33.076949 12912 sgd_solver.cpp:106] Iteration 57500, lr = 0.0005
I0515 01:10:11.044947 12912 solver.cpp:228] Iteration 57550, loss = 0.00300445
I0515 01:10:11.045164 12912 solver.cpp:244]     Train net output #0: loss = 0.00300492 (* 1 = 0.00300492 loss)
I0515 01:10:11.045181 12912 sgd_solver.cpp:106] Iteration 57550, lr = 0.0005
I0515 01:10:49.012657 12912 solver.cpp:228] Iteration 57600, loss = 0.00947502
I0515 01:10:49.012769 12912 solver.cpp:244]     Train net output #0: loss = 0.00947548 (* 1 = 0.00947548 loss)
I0515 01:10:49.012789 12912 sgd_solver.cpp:106] Iteration 57600, lr = 0.0005
I0515 01:11:26.994729 12912 solver.cpp:228] Iteration 57650, loss = 0.0044232
I0515 01:11:26.994834 12912 solver.cpp:244]     Train net output #0: loss = 0.00442367 (* 1 = 0.00442367 loss)
I0515 01:11:26.994848 12912 sgd_solver.cpp:106] Iteration 57650, lr = 0.0005
I0515 01:12:04.969532 12912 solver.cpp:228] Iteration 57700, loss = 0.00740183
I0515 01:12:04.969650 12912 solver.cpp:244]     Train net output #0: loss = 0.00740229 (* 1 = 0.00740229 loss)
I0515 01:12:04.969662 12912 sgd_solver.cpp:106] Iteration 57700, lr = 0.0005
I0515 01:12:42.949659 12912 solver.cpp:228] Iteration 57750, loss = 0.0105623
I0515 01:12:42.949766 12912 solver.cpp:244]     Train net output #0: loss = 0.0105628 (* 1 = 0.0105628 loss)
I0515 01:12:42.949779 12912 sgd_solver.cpp:106] Iteration 57750, lr = 0.0005
I0515 01:13:20.925945 12912 solver.cpp:228] Iteration 57800, loss = 0.00295345
I0515 01:13:20.926071 12912 solver.cpp:244]     Train net output #0: loss = 0.00295391 (* 1 = 0.00295391 loss)
I0515 01:13:20.926090 12912 sgd_solver.cpp:106] Iteration 57800, lr = 0.0005
I0515 01:13:58.922174 12912 solver.cpp:228] Iteration 57850, loss = 0.00177302
I0515 01:13:58.922284 12912 solver.cpp:244]     Train net output #0: loss = 0.00177348 (* 1 = 0.00177348 loss)
I0515 01:13:58.922297 12912 sgd_solver.cpp:106] Iteration 57850, lr = 0.0005
I0515 01:14:36.916259 12912 solver.cpp:228] Iteration 57900, loss = 0.00905614
I0515 01:14:36.916422 12912 solver.cpp:244]     Train net output #0: loss = 0.0090566 (* 1 = 0.0090566 loss)
I0515 01:14:36.916446 12912 sgd_solver.cpp:106] Iteration 57900, lr = 0.0005
I0515 01:15:14.891203 12912 solver.cpp:228] Iteration 57950, loss = 0.00506727
I0515 01:15:14.891403 12912 solver.cpp:244]     Train net output #0: loss = 0.00506774 (* 1 = 0.00506774 loss)
I0515 01:15:14.891424 12912 sgd_solver.cpp:106] Iteration 57950, lr = 0.0005
I0515 01:15:52.571435 12912 solver.cpp:454] Snapshotting to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_58000.caffemodel
I0515 01:15:53.196782 12912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_58000.solverstate
I0515 01:15:53.278292 12912 solver.cpp:337] Iteration 58000, Testing net (#0)
I0515 01:15:53.278350 12912 net.cpp:685] Ignoring source layer loss
I0515 01:17:36.223536 12912 solver.cpp:404]     Test net output #0: accuracy = 0.711029
I0515 01:17:36.512876 12912 solver.cpp:228] Iteration 58000, loss = 0.00836066
I0515 01:17:36.512929 12912 solver.cpp:244]     Train net output #0: loss = 0.00836113 (* 1 = 0.00836113 loss)
I0515 01:17:36.512944 12912 sgd_solver.cpp:106] Iteration 58000, lr = 0.0005
I0515 01:18:14.477011 12912 solver.cpp:228] Iteration 58050, loss = 0.0107741
I0515 01:18:14.477115 12912 solver.cpp:244]     Train net output #0: loss = 0.0107746 (* 1 = 0.0107746 loss)
I0515 01:18:14.477128 12912 sgd_solver.cpp:106] Iteration 58050, lr = 0.0005
I0515 01:18:52.461841 12912 solver.cpp:228] Iteration 58100, loss = 0.00345164
I0515 01:18:52.462035 12912 solver.cpp:244]     Train net output #0: loss = 0.00345211 (* 1 = 0.00345211 loss)
I0515 01:18:52.462085 12912 sgd_solver.cpp:106] Iteration 58100, lr = 0.0005
I0515 01:19:30.441072 12912 solver.cpp:228] Iteration 58150, loss = 0.00341082
I0515 01:19:30.441176 12912 solver.cpp:244]     Train net output #0: loss = 0.00341129 (* 1 = 0.00341129 loss)
I0515 01:19:30.441195 12912 sgd_solver.cpp:106] Iteration 58150, lr = 0.0005
I0515 01:20:08.430521 12912 solver.cpp:228] Iteration 58200, loss = 0.00308091
I0515 01:20:08.430775 12912 solver.cpp:244]     Train net output #0: loss = 0.00308139 (* 1 = 0.00308139 loss)
I0515 01:20:08.430797 12912 sgd_solver.cpp:106] Iteration 58200, lr = 0.0005
I0515 01:20:46.405649 12912 solver.cpp:228] Iteration 58250, loss = 0.0126989
I0515 01:20:46.406237 12912 solver.cpp:244]     Train net output #0: loss = 0.0126994 (* 1 = 0.0126994 loss)
I0515 01:20:46.406252 12912 sgd_solver.cpp:106] Iteration 58250, lr = 0.0005
I0515 01:21:24.376930 12912 solver.cpp:228] Iteration 58300, loss = 0.00530271
I0515 01:21:24.377094 12912 solver.cpp:244]     Train net output #0: loss = 0.00530319 (* 1 = 0.00530319 loss)
I0515 01:21:24.377110 12912 sgd_solver.cpp:106] Iteration 58300, lr = 0.0005
I0515 01:22:02.342243 12912 solver.cpp:228] Iteration 58350, loss = 0.00300596
I0515 01:22:02.342371 12912 solver.cpp:244]     Train net output #0: loss = 0.00300644 (* 1 = 0.00300644 loss)
I0515 01:22:02.342386 12912 sgd_solver.cpp:106] Iteration 58350, lr = 0.0005
I0515 01:22:40.323077 12912 solver.cpp:228] Iteration 58400, loss = 0.0044944
I0515 01:22:40.323235 12912 solver.cpp:244]     Train net output #0: loss = 0.00449487 (* 1 = 0.00449487 loss)
I0515 01:22:40.323253 12912 sgd_solver.cpp:106] Iteration 58400, lr = 0.0005
I0515 01:23:18.326836 12912 solver.cpp:228] Iteration 58450, loss = 0.00831017
I0515 01:23:18.326941 12912 solver.cpp:244]     Train net output #0: loss = 0.00831063 (* 1 = 0.00831063 loss)
I0515 01:23:18.326954 12912 sgd_solver.cpp:106] Iteration 58450, lr = 0.0005
I0515 01:23:56.302711 12912 solver.cpp:228] Iteration 58500, loss = 0.00388712
I0515 01:23:56.302832 12912 solver.cpp:244]     Train net output #0: loss = 0.00388759 (* 1 = 0.00388759 loss)
I0515 01:23:56.302846 12912 sgd_solver.cpp:106] Iteration 58500, lr = 0.0005
I0515 01:24:34.289577 12912 solver.cpp:228] Iteration 58550, loss = 0.0176307
I0515 01:24:34.289724 12912 solver.cpp:244]     Train net output #0: loss = 0.0176311 (* 1 = 0.0176311 loss)
I0515 01:24:34.289743 12912 sgd_solver.cpp:106] Iteration 58550, lr = 0.0005
I0515 01:25:12.276834 12912 solver.cpp:228] Iteration 58600, loss = 0.00432633
I0515 01:25:12.276943 12912 solver.cpp:244]     Train net output #0: loss = 0.00432679 (* 1 = 0.00432679 loss)
I0515 01:25:12.276962 12912 sgd_solver.cpp:106] Iteration 58600, lr = 0.0005
I0515 01:25:50.243407 12912 solver.cpp:228] Iteration 58650, loss = 0.01349
I0515 01:25:50.243521 12912 solver.cpp:244]     Train net output #0: loss = 0.0134905 (* 1 = 0.0134905 loss)
I0515 01:25:50.243535 12912 sgd_solver.cpp:106] Iteration 58650, lr = 0.0005
I0515 01:26:28.213601 12912 solver.cpp:228] Iteration 58700, loss = 0.00335011
I0515 01:26:28.213704 12912 solver.cpp:244]     Train net output #0: loss = 0.00335058 (* 1 = 0.00335058 loss)
I0515 01:26:28.213722 12912 sgd_solver.cpp:106] Iteration 58700, lr = 0.0005
I0515 01:27:06.178711 12912 solver.cpp:228] Iteration 58750, loss = 0.0117686
I0515 01:27:06.178827 12912 solver.cpp:244]     Train net output #0: loss = 0.0117691 (* 1 = 0.0117691 loss)
I0515 01:27:06.178846 12912 sgd_solver.cpp:106] Iteration 58750, lr = 0.0005
I0515 01:27:44.153023 12912 solver.cpp:228] Iteration 58800, loss = 0.00334179
I0515 01:27:44.153134 12912 solver.cpp:244]     Train net output #0: loss = 0.00334226 (* 1 = 0.00334226 loss)
I0515 01:27:44.153152 12912 sgd_solver.cpp:106] Iteration 58800, lr = 0.0005
I0515 01:28:22.106494 12912 solver.cpp:228] Iteration 58850, loss = 0.0146679
I0515 01:28:22.106608 12912 solver.cpp:244]     Train net output #0: loss = 0.0146684 (* 1 = 0.0146684 loss)
I0515 01:28:22.106626 12912 sgd_solver.cpp:106] Iteration 58850, lr = 0.0005
I0515 01:29:00.083438 12912 solver.cpp:228] Iteration 58900, loss = 0.0116489
I0515 01:29:00.083585 12912 solver.cpp:244]     Train net output #0: loss = 0.0116493 (* 1 = 0.0116493 loss)
I0515 01:29:00.083605 12912 sgd_solver.cpp:106] Iteration 58900, lr = 0.0005
I0515 01:29:38.048908 12912 solver.cpp:228] Iteration 58950, loss = 0.00239227
I0515 01:29:38.049037 12912 solver.cpp:244]     Train net output #0: loss = 0.00239274 (* 1 = 0.00239274 loss)
I0515 01:29:38.049053 12912 sgd_solver.cpp:106] Iteration 58950, lr = 0.0005
I0515 01:30:15.738698 12912 solver.cpp:454] Snapshotting to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_59000.caffemodel
I0515 01:30:16.281985 12912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_59000.solverstate
I0515 01:30:16.376682 12912 solver.cpp:337] Iteration 59000, Testing net (#0)
I0515 01:30:16.376744 12912 net.cpp:685] Ignoring source layer loss
I0515 01:31:59.171416 12912 solver.cpp:404]     Test net output #0: accuracy = 0.730294
I0515 01:31:59.461549 12912 solver.cpp:228] Iteration 59000, loss = 0.0280399
I0515 01:31:59.461601 12912 solver.cpp:244]     Train net output #0: loss = 0.0280404 (* 1 = 0.0280404 loss)
I0515 01:31:59.461614 12912 sgd_solver.cpp:106] Iteration 59000, lr = 0.0005
I0515 01:32:37.445653 12912 solver.cpp:228] Iteration 59050, loss = 0.00156329
I0515 01:32:37.445783 12912 solver.cpp:244]     Train net output #0: loss = 0.00156375 (* 1 = 0.00156375 loss)
I0515 01:32:37.445801 12912 sgd_solver.cpp:106] Iteration 59050, lr = 0.0005
I0515 01:33:15.406250 12912 solver.cpp:228] Iteration 59100, loss = 0.00524677
I0515 01:33:15.406349 12912 solver.cpp:244]     Train net output #0: loss = 0.00524724 (* 1 = 0.00524724 loss)
I0515 01:33:15.406361 12912 sgd_solver.cpp:106] Iteration 59100, lr = 0.0005
I0515 01:33:53.379739 12912 solver.cpp:228] Iteration 59150, loss = 0.00347491
I0515 01:33:53.379878 12912 solver.cpp:244]     Train net output #0: loss = 0.00347537 (* 1 = 0.00347537 loss)
I0515 01:33:53.379897 12912 sgd_solver.cpp:106] Iteration 59150, lr = 0.0005
I0515 01:34:31.353782 12912 solver.cpp:228] Iteration 59200, loss = 0.00814117
I0515 01:34:31.353909 12912 solver.cpp:244]     Train net output #0: loss = 0.00814163 (* 1 = 0.00814163 loss)
I0515 01:34:31.353924 12912 sgd_solver.cpp:106] Iteration 59200, lr = 0.0005
I0515 01:35:09.319479 12912 solver.cpp:228] Iteration 59250, loss = 0.00810738
I0515 01:35:09.319612 12912 solver.cpp:244]     Train net output #0: loss = 0.00810785 (* 1 = 0.00810785 loss)
I0515 01:35:09.319628 12912 sgd_solver.cpp:106] Iteration 59250, lr = 0.0005
I0515 01:35:47.287175 12912 solver.cpp:228] Iteration 59300, loss = 0.00862252
I0515 01:35:47.287283 12912 solver.cpp:244]     Train net output #0: loss = 0.00862298 (* 1 = 0.00862298 loss)
I0515 01:35:47.287297 12912 sgd_solver.cpp:106] Iteration 59300, lr = 0.0005
I0515 01:36:25.239073 12912 solver.cpp:228] Iteration 59350, loss = 0.00632978
I0515 01:36:25.239228 12912 solver.cpp:244]     Train net output #0: loss = 0.00633024 (* 1 = 0.00633024 loss)
I0515 01:36:25.239246 12912 sgd_solver.cpp:106] Iteration 59350, lr = 0.0005
I0515 01:37:03.201311 12912 solver.cpp:228] Iteration 59400, loss = 0.00355893
I0515 01:37:03.201491 12912 solver.cpp:244]     Train net output #0: loss = 0.00355939 (* 1 = 0.00355939 loss)
I0515 01:37:03.201534 12912 sgd_solver.cpp:106] Iteration 59400, lr = 0.0005
I0515 01:37:41.166728 12912 solver.cpp:228] Iteration 59450, loss = 0.176946
I0515 01:37:41.166877 12912 solver.cpp:244]     Train net output #0: loss = 0.176947 (* 1 = 0.176947 loss)
I0515 01:37:41.166923 12912 sgd_solver.cpp:106] Iteration 59450, lr = 0.0005
I0515 01:38:19.127573 12912 solver.cpp:228] Iteration 59500, loss = 0.00923931
I0515 01:38:19.127681 12912 solver.cpp:244]     Train net output #0: loss = 0.00923979 (* 1 = 0.00923979 loss)
I0515 01:38:19.127698 12912 sgd_solver.cpp:106] Iteration 59500, lr = 0.0005
I0515 01:38:57.098767 12912 solver.cpp:228] Iteration 59550, loss = 0.0147549
I0515 01:38:57.098966 12912 solver.cpp:244]     Train net output #0: loss = 0.0147553 (* 1 = 0.0147553 loss)
I0515 01:38:57.099021 12912 sgd_solver.cpp:106] Iteration 59550, lr = 0.0005
I0515 01:39:35.079522 12912 solver.cpp:228] Iteration 59600, loss = 0.00787534
I0515 01:39:35.079634 12912 solver.cpp:244]     Train net output #0: loss = 0.00787582 (* 1 = 0.00787582 loss)
I0515 01:39:35.079653 12912 sgd_solver.cpp:106] Iteration 59600, lr = 0.0005
I0515 01:40:13.037825 12912 solver.cpp:228] Iteration 59650, loss = 0.0176311
I0515 01:40:13.038049 12912 solver.cpp:244]     Train net output #0: loss = 0.0176315 (* 1 = 0.0176315 loss)
I0515 01:40:13.038136 12912 sgd_solver.cpp:106] Iteration 59650, lr = 0.0005
I0515 01:40:50.999951 12912 solver.cpp:228] Iteration 59700, loss = 0.00857141
I0515 01:40:51.000061 12912 solver.cpp:244]     Train net output #0: loss = 0.00857186 (* 1 = 0.00857186 loss)
I0515 01:40:51.000079 12912 sgd_solver.cpp:106] Iteration 59700, lr = 0.0005
I0515 01:41:28.952236 12912 solver.cpp:228] Iteration 59750, loss = 0.00683077
I0515 01:41:28.952395 12912 solver.cpp:244]     Train net output #0: loss = 0.00683121 (* 1 = 0.00683121 loss)
I0515 01:41:28.952414 12912 sgd_solver.cpp:106] Iteration 59750, lr = 0.0005
I0515 01:42:06.944641 12912 solver.cpp:228] Iteration 59800, loss = 0.0233216
I0515 01:42:06.944839 12912 solver.cpp:244]     Train net output #0: loss = 0.023322 (* 1 = 0.023322 loss)
I0515 01:42:06.944882 12912 sgd_solver.cpp:106] Iteration 59800, lr = 0.0005
I0515 01:42:44.919010 12912 solver.cpp:228] Iteration 59850, loss = 0.00573554
I0515 01:42:44.919150 12912 solver.cpp:244]     Train net output #0: loss = 0.00573598 (* 1 = 0.00573598 loss)
I0515 01:42:44.919168 12912 sgd_solver.cpp:106] Iteration 59850, lr = 0.0005
I0515 01:43:22.898504 12912 solver.cpp:228] Iteration 59900, loss = 0.0295176
I0515 01:43:22.898605 12912 solver.cpp:244]     Train net output #0: loss = 0.0295181 (* 1 = 0.0295181 loss)
I0515 01:43:22.898623 12912 sgd_solver.cpp:106] Iteration 59900, lr = 0.0005
I0515 01:44:00.864850 12912 solver.cpp:228] Iteration 59950, loss = 0.0193584
I0515 01:44:00.864984 12912 solver.cpp:244]     Train net output #0: loss = 0.0193589 (* 1 = 0.0193589 loss)
I0515 01:44:00.865002 12912 sgd_solver.cpp:106] Iteration 59950, lr = 0.0005
I0515 01:44:38.551791 12912 solver.cpp:454] Snapshotting to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_60000.caffemodel
I0515 01:44:39.470899 12912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_60000.solverstate
I0515 01:44:39.613448 12912 solver.cpp:337] Iteration 60000, Testing net (#0)
I0515 01:44:39.613512 12912 net.cpp:685] Ignoring source layer loss
I0515 01:46:22.487529 12912 solver.cpp:404]     Test net output #0: accuracy = 0.729265
I0515 01:46:22.779844 12912 solver.cpp:228] Iteration 60000, loss = 0.010087
I0515 01:46:22.779896 12912 solver.cpp:244]     Train net output #0: loss = 0.0100875 (* 1 = 0.0100875 loss)
I0515 01:46:22.779911 12912 sgd_solver.cpp:106] Iteration 60000, lr = 0.0005
I0515 01:47:00.742059 12912 solver.cpp:228] Iteration 60050, loss = 0.00750324
I0515 01:47:00.742208 12912 solver.cpp:244]     Train net output #0: loss = 0.00750369 (* 1 = 0.00750369 loss)
I0515 01:47:00.742225 12912 sgd_solver.cpp:106] Iteration 60050, lr = 0.0005
I0515 01:47:38.728801 12912 solver.cpp:228] Iteration 60100, loss = 0.00341404
I0515 01:47:38.728901 12912 solver.cpp:244]     Train net output #0: loss = 0.0034145 (* 1 = 0.0034145 loss)
I0515 01:47:38.728914 12912 sgd_solver.cpp:106] Iteration 60100, lr = 0.0005
I0515 01:48:16.694581 12912 solver.cpp:228] Iteration 60150, loss = 0.00794135
I0515 01:48:16.694689 12912 solver.cpp:244]     Train net output #0: loss = 0.00794181 (* 1 = 0.00794181 loss)
I0515 01:48:16.694707 12912 sgd_solver.cpp:106] Iteration 60150, lr = 0.0005
I0515 01:48:54.662014 12912 solver.cpp:228] Iteration 60200, loss = 0.00295331
I0515 01:48:54.662156 12912 solver.cpp:244]     Train net output #0: loss = 0.00295377 (* 1 = 0.00295377 loss)
I0515 01:48:54.662173 12912 sgd_solver.cpp:106] Iteration 60200, lr = 0.0005
I0515 01:49:32.630323 12912 solver.cpp:228] Iteration 60250, loss = 0.00735377
I0515 01:49:32.630424 12912 solver.cpp:244]     Train net output #0: loss = 0.00735422 (* 1 = 0.00735422 loss)
I0515 01:49:32.630435 12912 sgd_solver.cpp:106] Iteration 60250, lr = 0.0005
I0515 01:50:10.601634 12912 solver.cpp:228] Iteration 60300, loss = 0.00211121
I0515 01:50:10.601749 12912 solver.cpp:244]     Train net output #0: loss = 0.00211166 (* 1 = 0.00211166 loss)
I0515 01:50:10.601766 12912 sgd_solver.cpp:106] Iteration 60300, lr = 0.0005
I0515 01:50:48.571208 12912 solver.cpp:228] Iteration 60350, loss = 0.0101996
I0515 01:50:48.571421 12912 solver.cpp:244]     Train net output #0: loss = 0.0102 (* 1 = 0.0102 loss)
I0515 01:50:48.571461 12912 sgd_solver.cpp:106] Iteration 60350, lr = 0.0005
I0515 01:51:26.549147 12912 solver.cpp:228] Iteration 60400, loss = 0.0050469
I0515 01:51:26.549342 12912 solver.cpp:244]     Train net output #0: loss = 0.00504736 (* 1 = 0.00504736 loss)
I0515 01:51:26.549382 12912 sgd_solver.cpp:106] Iteration 60400, lr = 0.0005
I0515 01:52:04.506793 12912 solver.cpp:228] Iteration 60450, loss = 0.00628208
I0515 01:52:04.506953 12912 solver.cpp:244]     Train net output #0: loss = 0.00628254 (* 1 = 0.00628254 loss)
I0515 01:52:04.506973 12912 sgd_solver.cpp:106] Iteration 60450, lr = 0.0005
I0515 01:52:42.469205 12912 solver.cpp:228] Iteration 60500, loss = 0.00680894
I0515 01:52:42.469337 12912 solver.cpp:244]     Train net output #0: loss = 0.00680941 (* 1 = 0.00680941 loss)
I0515 01:52:42.469355 12912 sgd_solver.cpp:106] Iteration 60500, lr = 0.0005
I0515 01:53:20.447824 12912 solver.cpp:228] Iteration 60550, loss = 0.0105878
I0515 01:53:20.447976 12912 solver.cpp:244]     Train net output #0: loss = 0.0105883 (* 1 = 0.0105883 loss)
I0515 01:53:20.447994 12912 sgd_solver.cpp:106] Iteration 60550, lr = 0.0005
I0515 01:53:58.418287 12912 solver.cpp:228] Iteration 60600, loss = 0.0136208
I0515 01:53:58.418464 12912 solver.cpp:244]     Train net output #0: loss = 0.0136213 (* 1 = 0.0136213 loss)
I0515 01:53:58.418501 12912 sgd_solver.cpp:106] Iteration 60600, lr = 0.0005
I0515 01:54:36.372817 12912 solver.cpp:228] Iteration 60650, loss = 0.00183852
I0515 01:54:36.372967 12912 solver.cpp:244]     Train net output #0: loss = 0.00183898 (* 1 = 0.00183898 loss)
I0515 01:54:36.372985 12912 sgd_solver.cpp:106] Iteration 60650, lr = 0.0005
I0515 01:55:14.318913 12912 solver.cpp:228] Iteration 60700, loss = 0.00596208
I0515 01:55:14.319022 12912 solver.cpp:244]     Train net output #0: loss = 0.00596254 (* 1 = 0.00596254 loss)
I0515 01:55:14.319039 12912 sgd_solver.cpp:106] Iteration 60700, lr = 0.0005
I0515 01:55:52.262789 12912 solver.cpp:228] Iteration 60750, loss = 0.00294711
I0515 01:55:52.262962 12912 solver.cpp:244]     Train net output #0: loss = 0.00294757 (* 1 = 0.00294757 loss)
I0515 01:55:52.262981 12912 sgd_solver.cpp:106] Iteration 60750, lr = 0.0005
I0515 01:56:30.213276 12912 solver.cpp:228] Iteration 60800, loss = 0.00291122
I0515 01:56:30.213454 12912 solver.cpp:244]     Train net output #0: loss = 0.00291167 (* 1 = 0.00291167 loss)
I0515 01:56:30.213472 12912 sgd_solver.cpp:106] Iteration 60800, lr = 0.0005
I0515 01:57:08.177373 12912 solver.cpp:228] Iteration 60850, loss = 0.00806368
I0515 01:57:08.177567 12912 solver.cpp:244]     Train net output #0: loss = 0.00806413 (* 1 = 0.00806413 loss)
I0515 01:57:08.177589 12912 sgd_solver.cpp:106] Iteration 60850, lr = 0.0005
I0515 01:57:46.157191 12912 solver.cpp:228] Iteration 60900, loss = 0.00210788
I0515 01:57:46.157295 12912 solver.cpp:244]     Train net output #0: loss = 0.00210834 (* 1 = 0.00210834 loss)
I0515 01:57:46.157310 12912 sgd_solver.cpp:106] Iteration 60900, lr = 0.0005
I0515 01:58:24.124119 12912 solver.cpp:228] Iteration 60950, loss = 0.0111033
I0515 01:58:24.124222 12912 solver.cpp:244]     Train net output #0: loss = 0.0111038 (* 1 = 0.0111038 loss)
I0515 01:58:24.124243 12912 sgd_solver.cpp:106] Iteration 60950, lr = 0.0005
I0515 01:59:01.808750 12912 solver.cpp:454] Snapshotting to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_61000.caffemodel
I0515 01:59:02.369212 12912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_61000.solverstate
I0515 01:59:02.464382 12912 solver.cpp:337] Iteration 61000, Testing net (#0)
I0515 01:59:02.464507 12912 net.cpp:685] Ignoring source layer loss
I0515 02:00:45.618309 12912 solver.cpp:404]     Test net output #0: accuracy = 0.769559
I0515 02:00:45.907760 12912 solver.cpp:228] Iteration 61000, loss = 0.0177624
I0515 02:00:45.907819 12912 solver.cpp:244]     Train net output #0: loss = 0.0177629 (* 1 = 0.0177629 loss)
I0515 02:00:45.907845 12912 sgd_solver.cpp:106] Iteration 61000, lr = 0.0005
I0515 02:01:23.882566 12912 solver.cpp:228] Iteration 61050, loss = 0.00265707
I0515 02:01:23.882755 12912 solver.cpp:244]     Train net output #0: loss = 0.00265752 (* 1 = 0.00265752 loss)
I0515 02:01:23.882796 12912 sgd_solver.cpp:106] Iteration 61050, lr = 0.0005
I0515 02:02:01.862588 12912 solver.cpp:228] Iteration 61100, loss = 0.00782358
I0515 02:02:01.862689 12912 solver.cpp:244]     Train net output #0: loss = 0.00782404 (* 1 = 0.00782404 loss)
I0515 02:02:01.862706 12912 sgd_solver.cpp:106] Iteration 61100, lr = 0.0005
I0515 02:02:39.844487 12912 solver.cpp:228] Iteration 61150, loss = 0.00617972
I0515 02:02:39.844595 12912 solver.cpp:244]     Train net output #0: loss = 0.00618017 (* 1 = 0.00618017 loss)
I0515 02:02:39.844612 12912 sgd_solver.cpp:106] Iteration 61150, lr = 0.0005
I0515 02:03:17.809993 12912 solver.cpp:228] Iteration 61200, loss = 0.00905751
I0515 02:03:17.810158 12912 solver.cpp:244]     Train net output #0: loss = 0.00905796 (* 1 = 0.00905796 loss)
I0515 02:03:17.810197 12912 sgd_solver.cpp:106] Iteration 61200, lr = 0.0005
I0515 02:03:55.781136 12912 solver.cpp:228] Iteration 61250, loss = 0.00379985
I0515 02:03:55.781240 12912 solver.cpp:244]     Train net output #0: loss = 0.00380031 (* 1 = 0.00380031 loss)
I0515 02:03:55.781257 12912 sgd_solver.cpp:106] Iteration 61250, lr = 0.0005
I0515 02:04:33.744015 12912 solver.cpp:228] Iteration 61300, loss = 0.0035108
I0515 02:04:33.744113 12912 solver.cpp:244]     Train net output #0: loss = 0.00351125 (* 1 = 0.00351125 loss)
I0515 02:04:33.744125 12912 sgd_solver.cpp:106] Iteration 61300, lr = 0.0005
I0515 02:05:11.693465 12912 solver.cpp:228] Iteration 61350, loss = 0.00648052
I0515 02:05:11.693567 12912 solver.cpp:244]     Train net output #0: loss = 0.00648097 (* 1 = 0.00648097 loss)
I0515 02:05:11.693583 12912 sgd_solver.cpp:106] Iteration 61350, lr = 0.0005
I0515 02:05:49.644575 12912 solver.cpp:228] Iteration 61400, loss = 0.00375501
I0515 02:05:49.644670 12912 solver.cpp:244]     Train net output #0: loss = 0.00375546 (* 1 = 0.00375546 loss)
I0515 02:05:49.644682 12912 sgd_solver.cpp:106] Iteration 61400, lr = 0.0005
I0515 02:06:27.600111 12912 solver.cpp:228] Iteration 61450, loss = 0.00306924
I0515 02:06:27.600239 12912 solver.cpp:244]     Train net output #0: loss = 0.00306969 (* 1 = 0.00306969 loss)
I0515 02:06:27.600252 12912 sgd_solver.cpp:106] Iteration 61450, lr = 0.0005
I0515 02:07:05.587952 12912 solver.cpp:228] Iteration 61500, loss = 0.00765659
I0515 02:07:05.588053 12912 solver.cpp:244]     Train net output #0: loss = 0.00765705 (* 1 = 0.00765705 loss)
I0515 02:07:05.588066 12912 sgd_solver.cpp:106] Iteration 61500, lr = 0.0005
I0515 02:07:43.545841 12912 solver.cpp:228] Iteration 61550, loss = 0.00192486
I0515 02:07:43.545975 12912 solver.cpp:244]     Train net output #0: loss = 0.00192532 (* 1 = 0.00192532 loss)
I0515 02:07:43.545994 12912 sgd_solver.cpp:106] Iteration 61550, lr = 0.0005
I0515 02:08:21.486953 12912 solver.cpp:228] Iteration 61600, loss = 0.0082939
I0515 02:08:21.487064 12912 solver.cpp:244]     Train net output #0: loss = 0.00829436 (* 1 = 0.00829436 loss)
I0515 02:08:21.487082 12912 sgd_solver.cpp:106] Iteration 61600, lr = 0.0005
I0515 02:08:59.447213 12912 solver.cpp:228] Iteration 61650, loss = 0.00144626
I0515 02:08:59.447412 12912 solver.cpp:244]     Train net output #0: loss = 0.00144672 (* 1 = 0.00144672 loss)
I0515 02:08:59.447449 12912 sgd_solver.cpp:106] Iteration 61650, lr = 0.0005
I0515 02:09:37.406467 12912 solver.cpp:228] Iteration 61700, loss = 0.00303559
I0515 02:09:37.406644 12912 solver.cpp:244]     Train net output #0: loss = 0.00303604 (* 1 = 0.00303604 loss)
I0515 02:09:37.406685 12912 sgd_solver.cpp:106] Iteration 61700, lr = 0.0005
I0515 02:10:15.350425 12912 solver.cpp:228] Iteration 61750, loss = 0.00207665
I0515 02:10:15.350558 12912 solver.cpp:244]     Train net output #0: loss = 0.00207711 (* 1 = 0.00207711 loss)
I0515 02:10:15.350572 12912 sgd_solver.cpp:106] Iteration 61750, lr = 0.0005
I0515 02:10:53.331643 12912 solver.cpp:228] Iteration 61800, loss = 0.00376442
I0515 02:10:53.331835 12912 solver.cpp:244]     Train net output #0: loss = 0.00376487 (* 1 = 0.00376487 loss)
I0515 02:10:53.331871 12912 sgd_solver.cpp:106] Iteration 61800, lr = 0.0005
I0515 02:11:31.307428 12912 solver.cpp:228] Iteration 61850, loss = 0.00780232
I0515 02:11:31.307628 12912 solver.cpp:244]     Train net output #0: loss = 0.00780277 (* 1 = 0.00780277 loss)
I0515 02:11:31.307669 12912 sgd_solver.cpp:106] Iteration 61850, lr = 0.0005
I0515 02:12:09.266614 12912 solver.cpp:228] Iteration 61900, loss = 0.0123467
I0515 02:12:09.266722 12912 solver.cpp:244]     Train net output #0: loss = 0.0123471 (* 1 = 0.0123471 loss)
I0515 02:12:09.266741 12912 sgd_solver.cpp:106] Iteration 61900, lr = 0.0005
I0515 02:12:47.240005 12912 solver.cpp:228] Iteration 61950, loss = 0.00438683
I0515 02:12:47.251832 12912 solver.cpp:244]     Train net output #0: loss = 0.00438727 (* 1 = 0.00438727 loss)
I0515 02:12:47.251906 12912 sgd_solver.cpp:106] Iteration 61950, lr = 0.0005
I0515 02:13:24.920334 12912 solver.cpp:454] Snapshotting to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_62000.caffemodel
I0515 02:13:25.456332 12912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_62000.solverstate
I0515 02:13:25.538097 12912 solver.cpp:337] Iteration 62000, Testing net (#0)
I0515 02:13:25.538148 12912 net.cpp:685] Ignoring source layer loss
I0515 02:15:08.536207 12912 solver.cpp:404]     Test net output #0: accuracy = 0.750441
I0515 02:15:08.826094 12912 solver.cpp:228] Iteration 62000, loss = 0.0139117
I0515 02:15:08.826154 12912 solver.cpp:244]     Train net output #0: loss = 0.0139121 (* 1 = 0.0139121 loss)
I0515 02:15:08.826165 12912 sgd_solver.cpp:106] Iteration 62000, lr = 0.0005
I0515 02:15:46.774873 12912 solver.cpp:228] Iteration 62050, loss = 0.0156409
I0515 02:15:46.774974 12912 solver.cpp:244]     Train net output #0: loss = 0.0156413 (* 1 = 0.0156413 loss)
I0515 02:15:46.774987 12912 sgd_solver.cpp:106] Iteration 62050, lr = 0.0005
I0515 02:16:24.745048 12912 solver.cpp:228] Iteration 62100, loss = 0.0069428
I0515 02:16:24.745224 12912 solver.cpp:244]     Train net output #0: loss = 0.00694325 (* 1 = 0.00694325 loss)
I0515 02:16:24.745244 12912 sgd_solver.cpp:106] Iteration 62100, lr = 0.0005
I0515 02:17:02.701622 12912 solver.cpp:228] Iteration 62150, loss = 0.00297633
I0515 02:17:02.701810 12912 solver.cpp:244]     Train net output #0: loss = 0.00297678 (* 1 = 0.00297678 loss)
I0515 02:17:02.701848 12912 sgd_solver.cpp:106] Iteration 62150, lr = 0.0005
I0515 02:17:40.670536 12912 solver.cpp:228] Iteration 62200, loss = 0.0057184
I0515 02:17:40.670639 12912 solver.cpp:244]     Train net output #0: loss = 0.00571884 (* 1 = 0.00571884 loss)
I0515 02:17:40.670652 12912 sgd_solver.cpp:106] Iteration 62200, lr = 0.0005
I0515 02:18:18.619236 12912 solver.cpp:228] Iteration 62250, loss = 0.00921207
I0515 02:18:18.619467 12912 solver.cpp:244]     Train net output #0: loss = 0.00921251 (* 1 = 0.00921251 loss)
I0515 02:18:18.619495 12912 sgd_solver.cpp:106] Iteration 62250, lr = 0.0005
I0515 02:18:56.570133 12912 solver.cpp:228] Iteration 62300, loss = 0.0137018
I0515 02:18:56.570246 12912 solver.cpp:244]     Train net output #0: loss = 0.0137022 (* 1 = 0.0137022 loss)
I0515 02:18:56.570266 12912 sgd_solver.cpp:106] Iteration 62300, lr = 0.0005
I0515 02:19:34.524978 12912 solver.cpp:228] Iteration 62350, loss = 0.0066554
I0515 02:19:34.525205 12912 solver.cpp:244]     Train net output #0: loss = 0.00665585 (* 1 = 0.00665585 loss)
I0515 02:19:34.525249 12912 sgd_solver.cpp:106] Iteration 62350, lr = 0.0005
I0515 02:20:12.476671 12912 solver.cpp:228] Iteration 62400, loss = 0.00311137
I0515 02:20:12.476781 12912 solver.cpp:244]     Train net output #0: loss = 0.00311181 (* 1 = 0.00311181 loss)
I0515 02:20:12.476799 12912 sgd_solver.cpp:106] Iteration 62400, lr = 0.0005
I0515 02:20:50.423239 12912 solver.cpp:228] Iteration 62450, loss = 0.00925398
I0515 02:20:50.423456 12912 solver.cpp:244]     Train net output #0: loss = 0.00925442 (* 1 = 0.00925442 loss)
I0515 02:20:50.423493 12912 sgd_solver.cpp:106] Iteration 62450, lr = 0.0005
I0515 02:21:28.379228 12912 solver.cpp:228] Iteration 62500, loss = 0.00234909
I0515 02:21:28.379359 12912 solver.cpp:244]     Train net output #0: loss = 0.00234953 (* 1 = 0.00234953 loss)
I0515 02:21:28.379371 12912 sgd_solver.cpp:106] Iteration 62500, lr = 0.0005
I0515 02:22:06.335297 12912 solver.cpp:228] Iteration 62550, loss = 0.0181291
I0515 02:22:06.335425 12912 solver.cpp:244]     Train net output #0: loss = 0.0181296 (* 1 = 0.0181296 loss)
I0515 02:22:06.335439 12912 sgd_solver.cpp:106] Iteration 62550, lr = 0.0005
I0515 02:22:44.300900 12912 solver.cpp:228] Iteration 62600, loss = 0.0021671
I0515 02:22:44.300999 12912 solver.cpp:244]     Train net output #0: loss = 0.00216754 (* 1 = 0.00216754 loss)
I0515 02:22:44.301012 12912 sgd_solver.cpp:106] Iteration 62600, lr = 0.0005
I0515 02:23:22.272313 12912 solver.cpp:228] Iteration 62650, loss = 0.00347087
I0515 02:23:22.272526 12912 solver.cpp:244]     Train net output #0: loss = 0.00347131 (* 1 = 0.00347131 loss)
I0515 02:23:22.272547 12912 sgd_solver.cpp:106] Iteration 62650, lr = 0.0005
I0515 02:24:00.218201 12912 solver.cpp:228] Iteration 62700, loss = 0.00650129
I0515 02:24:00.218308 12912 solver.cpp:244]     Train net output #0: loss = 0.00650173 (* 1 = 0.00650173 loss)
I0515 02:24:00.218327 12912 sgd_solver.cpp:106] Iteration 62700, lr = 0.0005
I0515 02:24:38.170616 12912 solver.cpp:228] Iteration 62750, loss = 0.00415074
I0515 02:24:38.171164 12912 solver.cpp:244]     Train net output #0: loss = 0.00415118 (* 1 = 0.00415118 loss)
I0515 02:24:38.171217 12912 sgd_solver.cpp:106] Iteration 62750, lr = 0.0005
I0515 02:25:16.116020 12912 solver.cpp:228] Iteration 62800, loss = 0.00832519
I0515 02:25:16.116224 12912 solver.cpp:244]     Train net output #0: loss = 0.00832563 (* 1 = 0.00832563 loss)
I0515 02:25:16.116248 12912 sgd_solver.cpp:106] Iteration 62800, lr = 0.0005
I0515 02:25:54.052103 12912 solver.cpp:228] Iteration 62850, loss = 0.00402607
I0515 02:25:54.052261 12912 solver.cpp:244]     Train net output #0: loss = 0.00402651 (* 1 = 0.00402651 loss)
I0515 02:25:54.052278 12912 sgd_solver.cpp:106] Iteration 62850, lr = 0.0005
I0515 02:26:31.994868 12912 solver.cpp:228] Iteration 62900, loss = 0.00185831
I0515 02:26:31.994981 12912 solver.cpp:244]     Train net output #0: loss = 0.00185875 (* 1 = 0.00185875 loss)
I0515 02:26:31.994994 12912 sgd_solver.cpp:106] Iteration 62900, lr = 0.0005
I0515 02:27:09.960373 12912 solver.cpp:228] Iteration 62950, loss = 0.008159
I0515 02:27:09.960467 12912 solver.cpp:244]     Train net output #0: loss = 0.00815945 (* 1 = 0.00815945 loss)
I0515 02:27:09.960480 12912 sgd_solver.cpp:106] Iteration 62950, lr = 0.0005
I0515 02:27:47.601485 12912 solver.cpp:454] Snapshotting to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_63000.caffemodel
I0515 02:27:47.802070 12912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_63000.solverstate
I0515 02:27:47.886334 12912 solver.cpp:337] Iteration 63000, Testing net (#0)
I0515 02:27:47.886404 12912 net.cpp:685] Ignoring source layer loss
I0515 02:29:30.758050 12912 solver.cpp:404]     Test net output #0: accuracy = 0.753676
I0515 02:29:31.047724 12912 solver.cpp:228] Iteration 63000, loss = 0.00933564
I0515 02:29:31.047775 12912 solver.cpp:244]     Train net output #0: loss = 0.00933609 (* 1 = 0.00933609 loss)
I0515 02:29:31.047786 12912 sgd_solver.cpp:106] Iteration 63000, lr = 0.0005
I0515 02:30:08.995117 12912 solver.cpp:228] Iteration 63050, loss = 0.00367005
I0515 02:30:08.995220 12912 solver.cpp:244]     Train net output #0: loss = 0.0036705 (* 1 = 0.0036705 loss)
I0515 02:30:08.995234 12912 sgd_solver.cpp:106] Iteration 63050, lr = 0.0005
I0515 02:30:46.957484 12912 solver.cpp:228] Iteration 63100, loss = 0.00468129
I0515 02:30:46.958070 12912 solver.cpp:244]     Train net output #0: loss = 0.00468174 (* 1 = 0.00468174 loss)
I0515 02:30:46.958127 12912 sgd_solver.cpp:106] Iteration 63100, lr = 0.0005
I0515 02:31:24.942621 12912 solver.cpp:228] Iteration 63150, loss = 0.00452675
I0515 02:31:24.942739 12912 solver.cpp:244]     Train net output #0: loss = 0.0045272 (* 1 = 0.0045272 loss)
I0515 02:31:24.942759 12912 sgd_solver.cpp:106] Iteration 63150, lr = 0.0005
I0515 02:32:02.901372 12912 solver.cpp:228] Iteration 63200, loss = 0.0045407
I0515 02:32:02.901520 12912 solver.cpp:244]     Train net output #0: loss = 0.00454115 (* 1 = 0.00454115 loss)
I0515 02:32:02.901540 12912 sgd_solver.cpp:106] Iteration 63200, lr = 0.0005
I0515 02:32:40.867171 12912 solver.cpp:228] Iteration 63250, loss = 0.00331111
I0515 02:32:40.867276 12912 solver.cpp:244]     Train net output #0: loss = 0.00331156 (* 1 = 0.00331156 loss)
I0515 02:32:40.867290 12912 sgd_solver.cpp:106] Iteration 63250, lr = 0.0005
I0515 02:33:18.843204 12912 solver.cpp:228] Iteration 63300, loss = 0.00715411
I0515 02:33:18.843421 12912 solver.cpp:244]     Train net output #0: loss = 0.00715456 (* 1 = 0.00715456 loss)
I0515 02:33:18.843483 12912 sgd_solver.cpp:106] Iteration 63300, lr = 0.0005
I0515 02:33:56.814671 12912 solver.cpp:228] Iteration 63350, loss = 0.00804103
I0515 02:33:56.814779 12912 solver.cpp:244]     Train net output #0: loss = 0.00804148 (* 1 = 0.00804148 loss)
I0515 02:33:56.814797 12912 sgd_solver.cpp:106] Iteration 63350, lr = 0.0005
I0515 02:34:34.759654 12912 solver.cpp:228] Iteration 63400, loss = 0.00355467
I0515 02:34:34.759830 12912 solver.cpp:244]     Train net output #0: loss = 0.00355512 (* 1 = 0.00355512 loss)
I0515 02:34:34.759877 12912 sgd_solver.cpp:106] Iteration 63400, lr = 0.0005
I0515 02:35:12.725710 12912 solver.cpp:228] Iteration 63450, loss = 0.0267266
I0515 02:35:12.725837 12912 solver.cpp:244]     Train net output #0: loss = 0.0267271 (* 1 = 0.0267271 loss)
I0515 02:35:12.725852 12912 sgd_solver.cpp:106] Iteration 63450, lr = 0.0005
I0515 02:35:50.676105 12912 solver.cpp:228] Iteration 63500, loss = 0.00331042
I0515 02:35:50.676205 12912 solver.cpp:244]     Train net output #0: loss = 0.00331087 (* 1 = 0.00331087 loss)
I0515 02:35:50.676223 12912 sgd_solver.cpp:106] Iteration 63500, lr = 0.0005
I0515 02:36:28.634956 12912 solver.cpp:228] Iteration 63550, loss = 0.00364911
I0515 02:36:28.635077 12912 solver.cpp:244]     Train net output #0: loss = 0.00364956 (* 1 = 0.00364956 loss)
I0515 02:36:28.635090 12912 sgd_solver.cpp:106] Iteration 63550, lr = 0.0005
I0515 02:37:06.587433 12912 solver.cpp:228] Iteration 63600, loss = 0.00286951
I0515 02:37:06.587539 12912 solver.cpp:244]     Train net output #0: loss = 0.00286996 (* 1 = 0.00286996 loss)
I0515 02:37:06.587558 12912 sgd_solver.cpp:106] Iteration 63600, lr = 0.0005
I0515 02:37:44.546725 12912 solver.cpp:228] Iteration 63650, loss = 0.00224108
I0515 02:37:44.546828 12912 solver.cpp:244]     Train net output #0: loss = 0.00224153 (* 1 = 0.00224153 loss)
I0515 02:37:44.546846 12912 sgd_solver.cpp:106] Iteration 63650, lr = 0.0005
I0515 02:38:22.505710 12912 solver.cpp:228] Iteration 63700, loss = 0.0209884
I0515 02:38:22.505841 12912 solver.cpp:244]     Train net output #0: loss = 0.0209888 (* 1 = 0.0209888 loss)
I0515 02:38:22.505853 12912 sgd_solver.cpp:106] Iteration 63700, lr = 0.0005
I0515 02:39:00.482991 12912 solver.cpp:228] Iteration 63750, loss = 0.00317561
I0515 02:39:00.483099 12912 solver.cpp:244]     Train net output #0: loss = 0.00317605 (* 1 = 0.00317605 loss)
I0515 02:39:00.483113 12912 sgd_solver.cpp:106] Iteration 63750, lr = 0.0005
I0515 02:39:38.450583 12912 solver.cpp:228] Iteration 63800, loss = 0.00338187
I0515 02:39:38.450695 12912 solver.cpp:244]     Train net output #0: loss = 0.00338231 (* 1 = 0.00338231 loss)
I0515 02:39:38.450716 12912 sgd_solver.cpp:106] Iteration 63800, lr = 0.0005
I0515 02:40:16.426223 12912 solver.cpp:228] Iteration 63850, loss = 0.0183427
I0515 02:40:16.426321 12912 solver.cpp:244]     Train net output #0: loss = 0.0183431 (* 1 = 0.0183431 loss)
I0515 02:40:16.426333 12912 sgd_solver.cpp:106] Iteration 63850, lr = 0.0005
I0515 02:40:54.404871 12912 solver.cpp:228] Iteration 63900, loss = 0.00232012
I0515 02:40:54.405012 12912 solver.cpp:244]     Train net output #0: loss = 0.00232056 (* 1 = 0.00232056 loss)
I0515 02:40:54.405030 12912 sgd_solver.cpp:106] Iteration 63900, lr = 0.0005
I0515 02:41:32.356680 12912 solver.cpp:228] Iteration 63950, loss = 0.00768112
I0515 02:41:32.356788 12912 solver.cpp:244]     Train net output #0: loss = 0.00768157 (* 1 = 0.00768157 loss)
I0515 02:41:32.356806 12912 sgd_solver.cpp:106] Iteration 63950, lr = 0.0005
I0515 02:42:10.025249 12912 solver.cpp:454] Snapshotting to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_64000.caffemodel
I0515 02:42:10.865075 12912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_64000.solverstate
I0515 02:42:11.004678 12912 solver.cpp:337] Iteration 64000, Testing net (#0)
I0515 02:42:11.004755 12912 net.cpp:685] Ignoring source layer loss
I0515 02:43:53.913725 12912 solver.cpp:404]     Test net output #0: accuracy = 0.784118
I0515 02:43:54.204498 12912 solver.cpp:228] Iteration 64000, loss = 0.00645984
I0515 02:43:54.204553 12912 solver.cpp:244]     Train net output #0: loss = 0.00646029 (* 1 = 0.00646029 loss)
I0515 02:43:54.204568 12912 sgd_solver.cpp:106] Iteration 64000, lr = 0.0005
I0515 02:44:32.154350 12912 solver.cpp:228] Iteration 64050, loss = 0.00201928
I0515 02:44:32.154471 12912 solver.cpp:244]     Train net output #0: loss = 0.00201973 (* 1 = 0.00201973 loss)
I0515 02:44:32.154489 12912 sgd_solver.cpp:106] Iteration 64050, lr = 0.0005
I0515 02:45:10.128531 12912 solver.cpp:228] Iteration 64100, loss = 0.0113324
I0515 02:45:10.128712 12912 solver.cpp:244]     Train net output #0: loss = 0.0113329 (* 1 = 0.0113329 loss)
I0515 02:45:10.128731 12912 sgd_solver.cpp:106] Iteration 64100, lr = 0.0005
I0515 02:45:48.075593 12912 solver.cpp:228] Iteration 64150, loss = 0.00419275
I0515 02:45:48.075693 12912 solver.cpp:244]     Train net output #0: loss = 0.0041932 (* 1 = 0.0041932 loss)
I0515 02:45:48.075707 12912 sgd_solver.cpp:106] Iteration 64150, lr = 0.0005
I0515 02:46:26.017446 12912 solver.cpp:228] Iteration 64200, loss = 0.00286451
I0515 02:46:26.017621 12912 solver.cpp:244]     Train net output #0: loss = 0.00286496 (* 1 = 0.00286496 loss)
I0515 02:46:26.017662 12912 sgd_solver.cpp:106] Iteration 64200, lr = 0.0005
I0515 02:47:03.977872 12912 solver.cpp:228] Iteration 64250, loss = 0.00427881
I0515 02:47:03.977987 12912 solver.cpp:244]     Train net output #0: loss = 0.00427926 (* 1 = 0.00427926 loss)
I0515 02:47:03.978004 12912 sgd_solver.cpp:106] Iteration 64250, lr = 0.0005
I0515 02:47:41.930145 12912 solver.cpp:228] Iteration 64300, loss = 0.0485963
I0515 02:47:41.930255 12912 solver.cpp:244]     Train net output #0: loss = 0.0485967 (* 1 = 0.0485967 loss)
I0515 02:47:41.930274 12912 sgd_solver.cpp:106] Iteration 64300, lr = 0.0005
I0515 02:48:19.883824 12912 solver.cpp:228] Iteration 64350, loss = 0.0132508
I0515 02:48:19.883957 12912 solver.cpp:244]     Train net output #0: loss = 0.0132513 (* 1 = 0.0132513 loss)
I0515 02:48:19.883973 12912 sgd_solver.cpp:106] Iteration 64350, lr = 0.0005
I0515 02:48:57.839545 12912 solver.cpp:228] Iteration 64400, loss = 0.00708613
I0515 02:48:57.839650 12912 solver.cpp:244]     Train net output #0: loss = 0.00708657 (* 1 = 0.00708657 loss)
I0515 02:48:57.839663 12912 sgd_solver.cpp:106] Iteration 64400, lr = 0.0005
I0515 02:49:35.804944 12912 solver.cpp:228] Iteration 64450, loss = 0.00885936
I0515 02:49:35.805217 12912 solver.cpp:244]     Train net output #0: loss = 0.00885979 (* 1 = 0.00885979 loss)
I0515 02:49:35.805259 12912 sgd_solver.cpp:106] Iteration 64450, lr = 0.0005
I0515 02:50:13.768630 12912 solver.cpp:228] Iteration 64500, loss = 0.0267889
I0515 02:50:13.768740 12912 solver.cpp:244]     Train net output #0: loss = 0.0267894 (* 1 = 0.0267894 loss)
I0515 02:50:13.768754 12912 sgd_solver.cpp:106] Iteration 64500, lr = 0.0005
I0515 02:50:51.743167 12912 solver.cpp:228] Iteration 64550, loss = 0.0271322
I0515 02:50:51.743347 12912 solver.cpp:244]     Train net output #0: loss = 0.0271327 (* 1 = 0.0271327 loss)
I0515 02:50:51.743363 12912 sgd_solver.cpp:106] Iteration 64550, lr = 0.0005
I0515 02:51:29.727460 12912 solver.cpp:228] Iteration 64600, loss = 0.00935915
I0515 02:51:29.727661 12912 solver.cpp:244]     Train net output #0: loss = 0.00935965 (* 1 = 0.00935965 loss)
I0515 02:51:29.727707 12912 sgd_solver.cpp:106] Iteration 64600, lr = 0.0005
I0515 02:52:07.686209 12912 solver.cpp:228] Iteration 64650, loss = 0.00972657
I0515 02:52:07.686321 12912 solver.cpp:244]     Train net output #0: loss = 0.00972706 (* 1 = 0.00972706 loss)
I0515 02:52:07.686334 12912 sgd_solver.cpp:106] Iteration 64650, lr = 0.0005
I0515 02:52:45.656114 12912 solver.cpp:228] Iteration 64700, loss = 0.00626104
I0515 02:52:45.656272 12912 solver.cpp:244]     Train net output #0: loss = 0.00626153 (* 1 = 0.00626153 loss)
I0515 02:52:45.656291 12912 sgd_solver.cpp:106] Iteration 64700, lr = 0.0005
I0515 02:53:23.620893 12912 solver.cpp:228] Iteration 64750, loss = 0.00496876
I0515 02:53:23.620997 12912 solver.cpp:244]     Train net output #0: loss = 0.00496924 (* 1 = 0.00496924 loss)
I0515 02:53:23.621011 12912 sgd_solver.cpp:106] Iteration 64750, lr = 0.0005
I0515 02:54:01.574261 12912 solver.cpp:228] Iteration 64800, loss = 0.0082136
I0515 02:54:01.574362 12912 solver.cpp:244]     Train net output #0: loss = 0.00821408 (* 1 = 0.00821408 loss)
I0515 02:54:01.574374 12912 sgd_solver.cpp:106] Iteration 64800, lr = 0.0005
I0515 02:54:39.521069 12912 solver.cpp:228] Iteration 64850, loss = 0.00526694
I0515 02:54:39.521170 12912 solver.cpp:244]     Train net output #0: loss = 0.00526743 (* 1 = 0.00526743 loss)
I0515 02:54:39.521183 12912 sgd_solver.cpp:106] Iteration 64850, lr = 0.0005
I0515 02:55:17.472748 12912 solver.cpp:228] Iteration 64900, loss = 0.0114169
I0515 02:55:17.472868 12912 solver.cpp:244]     Train net output #0: loss = 0.0114174 (* 1 = 0.0114174 loss)
I0515 02:55:17.472888 12912 sgd_solver.cpp:106] Iteration 64900, lr = 0.0005
I0515 02:55:55.434078 12912 solver.cpp:228] Iteration 64950, loss = 0.00703946
I0515 02:55:55.434247 12912 solver.cpp:244]     Train net output #0: loss = 0.00703996 (* 1 = 0.00703996 loss)
I0515 02:55:55.434283 12912 sgd_solver.cpp:106] Iteration 64950, lr = 0.0005
I0515 02:56:33.108147 12912 solver.cpp:454] Snapshotting to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_65000.caffemodel
I0515 02:56:33.331097 12912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_65000.solverstate
I0515 02:56:33.427608 12912 solver.cpp:337] Iteration 65000, Testing net (#0)
I0515 02:56:33.427671 12912 net.cpp:685] Ignoring source layer loss
I0515 02:58:16.232341 12912 solver.cpp:404]     Test net output #0: accuracy = 0.734265
I0515 02:58:16.532748 12912 solver.cpp:228] Iteration 65000, loss = 0.00491083
I0515 02:58:16.532821 12912 solver.cpp:244]     Train net output #0: loss = 0.00491133 (* 1 = 0.00491133 loss)
I0515 02:58:16.532835 12912 sgd_solver.cpp:106] Iteration 65000, lr = 0.0005
I0515 02:58:54.514811 12912 solver.cpp:228] Iteration 65050, loss = 0.00605384
I0515 02:58:54.514942 12912 solver.cpp:244]     Train net output #0: loss = 0.00605434 (* 1 = 0.00605434 loss)
I0515 02:58:54.514961 12912 sgd_solver.cpp:106] Iteration 65050, lr = 0.0005
I0515 02:59:32.478143 12912 solver.cpp:228] Iteration 65100, loss = 0.0104074
I0515 02:59:32.478263 12912 solver.cpp:244]     Train net output #0: loss = 0.0104079 (* 1 = 0.0104079 loss)
I0515 02:59:32.478288 12912 sgd_solver.cpp:106] Iteration 65100, lr = 0.0005
I0515 03:00:10.467231 12912 solver.cpp:228] Iteration 65150, loss = 0.00543257
I0515 03:00:10.467387 12912 solver.cpp:244]     Train net output #0: loss = 0.00543307 (* 1 = 0.00543307 loss)
I0515 03:00:10.467406 12912 sgd_solver.cpp:106] Iteration 65150, lr = 0.0005
I0515 03:00:48.436024 12912 solver.cpp:228] Iteration 65200, loss = 0.00610835
I0515 03:00:48.436159 12912 solver.cpp:244]     Train net output #0: loss = 0.00610885 (* 1 = 0.00610885 loss)
I0515 03:00:48.436178 12912 sgd_solver.cpp:106] Iteration 65200, lr = 0.0005
I0515 03:01:26.403816 12912 solver.cpp:228] Iteration 65250, loss = 0.00621574
I0515 03:01:26.403934 12912 solver.cpp:244]     Train net output #0: loss = 0.00621624 (* 1 = 0.00621624 loss)
I0515 03:01:26.403952 12912 sgd_solver.cpp:106] Iteration 65250, lr = 0.0005
I0515 03:02:04.362565 12912 solver.cpp:228] Iteration 65300, loss = 0.00492108
I0515 03:02:04.362655 12912 solver.cpp:244]     Train net output #0: loss = 0.00492158 (* 1 = 0.00492158 loss)
I0515 03:02:04.362668 12912 sgd_solver.cpp:106] Iteration 65300, lr = 0.0005
I0515 03:02:42.337029 12912 solver.cpp:228] Iteration 65350, loss = 0.00910852
I0515 03:02:42.337168 12912 solver.cpp:244]     Train net output #0: loss = 0.00910902 (* 1 = 0.00910902 loss)
I0515 03:02:42.337188 12912 sgd_solver.cpp:106] Iteration 65350, lr = 0.0005
I0515 03:03:20.299036 12912 solver.cpp:228] Iteration 65400, loss = 0.0119613
I0515 03:03:20.299173 12912 solver.cpp:244]     Train net output #0: loss = 0.0119618 (* 1 = 0.0119618 loss)
I0515 03:03:20.299190 12912 sgd_solver.cpp:106] Iteration 65400, lr = 0.0005
I0515 03:03:58.262733 12912 solver.cpp:228] Iteration 65450, loss = 0.00752704
I0515 03:03:58.262842 12912 solver.cpp:244]     Train net output #0: loss = 0.00752754 (* 1 = 0.00752754 loss)
I0515 03:03:58.262856 12912 sgd_solver.cpp:106] Iteration 65450, lr = 0.0005
I0515 03:04:36.215632 12912 solver.cpp:228] Iteration 65500, loss = 0.00729608
I0515 03:04:36.215844 12912 solver.cpp:244]     Train net output #0: loss = 0.00729658 (* 1 = 0.00729658 loss)
I0515 03:04:36.215888 12912 sgd_solver.cpp:106] Iteration 65500, lr = 0.0005
I0515 03:05:14.159939 12912 solver.cpp:228] Iteration 65550, loss = 0.0112993
I0515 03:05:14.160084 12912 solver.cpp:244]     Train net output #0: loss = 0.0112998 (* 1 = 0.0112998 loss)
I0515 03:05:14.160101 12912 sgd_solver.cpp:106] Iteration 65550, lr = 0.0005
I0515 03:05:52.145995 12912 solver.cpp:228] Iteration 65600, loss = 0.0103844
I0515 03:05:52.146153 12912 solver.cpp:244]     Train net output #0: loss = 0.0103849 (* 1 = 0.0103849 loss)
I0515 03:05:52.146170 12912 sgd_solver.cpp:106] Iteration 65600, lr = 0.0005
I0515 03:06:30.117643 12912 solver.cpp:228] Iteration 65650, loss = 0.00270714
I0515 03:06:30.117756 12912 solver.cpp:244]     Train net output #0: loss = 0.00270764 (* 1 = 0.00270764 loss)
I0515 03:06:30.117774 12912 sgd_solver.cpp:106] Iteration 65650, lr = 0.0005
I0515 03:07:08.066416 12912 solver.cpp:228] Iteration 65700, loss = 0.00625804
I0515 03:07:08.066597 12912 solver.cpp:244]     Train net output #0: loss = 0.00625854 (* 1 = 0.00625854 loss)
I0515 03:07:08.066640 12912 sgd_solver.cpp:106] Iteration 65700, lr = 0.0005
I0515 03:07:46.024739 12912 solver.cpp:228] Iteration 65750, loss = 0.00456542
I0515 03:07:46.024909 12912 solver.cpp:244]     Train net output #0: loss = 0.00456592 (* 1 = 0.00456592 loss)
I0515 03:07:46.024947 12912 sgd_solver.cpp:106] Iteration 65750, lr = 0.0005
I0515 03:08:23.985561 12912 solver.cpp:228] Iteration 65800, loss = 0.00219295
I0515 03:08:23.985669 12912 solver.cpp:244]     Train net output #0: loss = 0.00219345 (* 1 = 0.00219345 loss)
I0515 03:08:23.985688 12912 sgd_solver.cpp:106] Iteration 65800, lr = 0.0005
I0515 03:09:01.938271 12912 solver.cpp:228] Iteration 65850, loss = 0.00454562
I0515 03:09:01.938436 12912 solver.cpp:244]     Train net output #0: loss = 0.00454612 (* 1 = 0.00454612 loss)
I0515 03:09:01.938451 12912 sgd_solver.cpp:106] Iteration 65850, lr = 0.0005
I0515 03:09:39.889441 12912 solver.cpp:228] Iteration 65900, loss = 0.0026376
I0515 03:09:39.889588 12912 solver.cpp:244]     Train net output #0: loss = 0.0026381 (* 1 = 0.0026381 loss)
I0515 03:09:39.889611 12912 sgd_solver.cpp:106] Iteration 65900, lr = 0.0005
I0515 03:10:17.841832 12912 solver.cpp:228] Iteration 65950, loss = 0.00210976
I0515 03:10:17.841964 12912 solver.cpp:244]     Train net output #0: loss = 0.00211026 (* 1 = 0.00211026 loss)
I0515 03:10:17.841984 12912 sgd_solver.cpp:106] Iteration 65950, lr = 0.0005
I0515 03:10:55.508363 12912 solver.cpp:454] Snapshotting to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_66000.caffemodel
I0515 03:10:56.134495 12912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_66000.solverstate
I0515 03:10:56.276937 12912 solver.cpp:337] Iteration 66000, Testing net (#0)
I0515 03:10:56.277003 12912 net.cpp:685] Ignoring source layer loss
I0515 03:12:39.314209 12912 solver.cpp:404]     Test net output #0: accuracy = 0.744853
I0515 03:12:39.605154 12912 solver.cpp:228] Iteration 66000, loss = 0.00734322
I0515 03:12:39.605204 12912 solver.cpp:244]     Train net output #0: loss = 0.00734372 (* 1 = 0.00734372 loss)
I0515 03:12:39.605218 12912 sgd_solver.cpp:106] Iteration 66000, lr = 0.0005
I0515 03:13:17.576123 12912 solver.cpp:228] Iteration 66050, loss = 0.0928734
I0515 03:13:17.576230 12912 solver.cpp:244]     Train net output #0: loss = 0.0928739 (* 1 = 0.0928739 loss)
I0515 03:13:17.576242 12912 sgd_solver.cpp:106] Iteration 66050, lr = 0.0005
I0515 03:13:55.541121 12912 solver.cpp:228] Iteration 66100, loss = 0.0367613
I0515 03:13:55.541266 12912 solver.cpp:244]     Train net output #0: loss = 0.0367618 (* 1 = 0.0367618 loss)
I0515 03:13:55.541283 12912 sgd_solver.cpp:106] Iteration 66100, lr = 0.0005
I0515 03:14:33.503110 12912 solver.cpp:228] Iteration 66150, loss = 0.0382025
I0515 03:14:33.503217 12912 solver.cpp:244]     Train net output #0: loss = 0.038203 (* 1 = 0.038203 loss)
I0515 03:14:33.503231 12912 sgd_solver.cpp:106] Iteration 66150, lr = 0.0005
I0515 03:15:11.458261 12912 solver.cpp:228] Iteration 66200, loss = 0.0169488
I0515 03:15:11.458366 12912 solver.cpp:244]     Train net output #0: loss = 0.0169493 (* 1 = 0.0169493 loss)
I0515 03:15:11.458379 12912 sgd_solver.cpp:106] Iteration 66200, lr = 0.0005
I0515 03:15:49.423060 12912 solver.cpp:228] Iteration 66250, loss = 0.129099
I0515 03:15:49.423192 12912 solver.cpp:244]     Train net output #0: loss = 0.1291 (* 1 = 0.1291 loss)
I0515 03:15:49.423210 12912 sgd_solver.cpp:106] Iteration 66250, lr = 0.0005
I0515 03:16:27.396508 12912 solver.cpp:228] Iteration 66300, loss = 0.0191783
I0515 03:16:27.396636 12912 solver.cpp:244]     Train net output #0: loss = 0.0191787 (* 1 = 0.0191787 loss)
I0515 03:16:27.396656 12912 sgd_solver.cpp:106] Iteration 66300, lr = 0.0005
I0515 03:17:05.356796 12912 solver.cpp:228] Iteration 66350, loss = 0.0497842
I0515 03:17:05.357010 12912 solver.cpp:244]     Train net output #0: loss = 0.0497847 (* 1 = 0.0497847 loss)
I0515 03:17:05.357056 12912 sgd_solver.cpp:106] Iteration 66350, lr = 0.0005
I0515 03:17:43.326292 12912 solver.cpp:228] Iteration 66400, loss = 0.0255162
I0515 03:17:43.327042 12912 solver.cpp:244]     Train net output #0: loss = 0.0255166 (* 1 = 0.0255166 loss)
I0515 03:17:43.327064 12912 sgd_solver.cpp:106] Iteration 66400, lr = 0.0005
I0515 03:18:21.312999 12912 solver.cpp:228] Iteration 66450, loss = 0.00731845
I0515 03:18:21.313097 12912 solver.cpp:244]     Train net output #0: loss = 0.00731889 (* 1 = 0.00731889 loss)
I0515 03:18:21.313115 12912 sgd_solver.cpp:106] Iteration 66450, lr = 0.0005
I0515 03:18:59.284895 12912 solver.cpp:228] Iteration 66500, loss = 0.00265256
I0515 03:18:59.287250 12912 solver.cpp:244]     Train net output #0: loss = 0.00265301 (* 1 = 0.00265301 loss)
I0515 03:18:59.287271 12912 sgd_solver.cpp:106] Iteration 66500, lr = 0.0005
I0515 03:19:37.255877 12912 solver.cpp:228] Iteration 66550, loss = 0.00808789
I0515 03:19:37.256006 12912 solver.cpp:244]     Train net output #0: loss = 0.00808834 (* 1 = 0.00808834 loss)
I0515 03:19:37.256053 12912 sgd_solver.cpp:106] Iteration 66550, lr = 0.0005
I0515 03:20:15.224339 12912 solver.cpp:228] Iteration 66600, loss = 0.00979921
I0515 03:20:15.224462 12912 solver.cpp:244]     Train net output #0: loss = 0.00979967 (* 1 = 0.00979967 loss)
I0515 03:20:15.224474 12912 sgd_solver.cpp:106] Iteration 66600, lr = 0.0005
I0515 03:20:53.201732 12912 solver.cpp:228] Iteration 66650, loss = 0.0812641
I0515 03:20:53.201872 12912 solver.cpp:244]     Train net output #0: loss = 0.0812645 (* 1 = 0.0812645 loss)
I0515 03:20:53.201892 12912 sgd_solver.cpp:106] Iteration 66650, lr = 0.0005
I0515 03:21:31.173643 12912 solver.cpp:228] Iteration 66700, loss = 0.0534668
I0515 03:21:31.173758 12912 solver.cpp:244]     Train net output #0: loss = 0.0534672 (* 1 = 0.0534672 loss)
I0515 03:21:31.173770 12912 sgd_solver.cpp:106] Iteration 66700, lr = 0.0005
I0515 03:22:09.152359 12912 solver.cpp:228] Iteration 66750, loss = 0.0275679
I0515 03:22:09.152493 12912 solver.cpp:244]     Train net output #0: loss = 0.0275683 (* 1 = 0.0275683 loss)
I0515 03:22:09.152506 12912 sgd_solver.cpp:106] Iteration 66750, lr = 0.0005
I0515 03:22:47.119549 12912 solver.cpp:228] Iteration 66800, loss = 0.00541331
I0515 03:22:47.119690 12912 solver.cpp:244]     Train net output #0: loss = 0.00541378 (* 1 = 0.00541378 loss)
I0515 03:22:47.119707 12912 sgd_solver.cpp:106] Iteration 66800, lr = 0.0005
I0515 03:23:25.105859 12912 solver.cpp:228] Iteration 66850, loss = 0.0232647
I0515 03:23:25.106040 12912 solver.cpp:244]     Train net output #0: loss = 0.0232652 (* 1 = 0.0232652 loss)
I0515 03:23:25.106082 12912 sgd_solver.cpp:106] Iteration 66850, lr = 0.0005
I0515 03:24:03.054852 12912 solver.cpp:228] Iteration 66900, loss = 0.0036838
I0515 03:24:03.054960 12912 solver.cpp:244]     Train net output #0: loss = 0.00368426 (* 1 = 0.00368426 loss)
I0515 03:24:03.054978 12912 sgd_solver.cpp:106] Iteration 66900, lr = 0.0005
I0515 03:24:41.002437 12912 solver.cpp:228] Iteration 66950, loss = 0.00565668
I0515 03:24:41.002549 12912 solver.cpp:244]     Train net output #0: loss = 0.00565716 (* 1 = 0.00565716 loss)
I0515 03:24:41.002568 12912 sgd_solver.cpp:106] Iteration 66950, lr = 0.0005
I0515 03:25:18.671694 12912 solver.cpp:454] Snapshotting to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_67000.caffemodel
I0515 03:25:19.261188 12912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_67000.solverstate
I0515 03:25:19.356148 12912 solver.cpp:337] Iteration 67000, Testing net (#0)
I0515 03:25:19.356210 12912 net.cpp:685] Ignoring source layer loss
I0515 03:27:02.079082 12912 solver.cpp:404]     Test net output #0: accuracy = 0.642647
I0515 03:27:02.369292 12912 solver.cpp:228] Iteration 67000, loss = 0.0136276
I0515 03:27:02.369346 12912 solver.cpp:244]     Train net output #0: loss = 0.0136281 (* 1 = 0.0136281 loss)
I0515 03:27:02.369362 12912 sgd_solver.cpp:106] Iteration 67000, lr = 0.0005
I0515 03:27:40.324913 12912 solver.cpp:228] Iteration 67050, loss = 0.00488828
I0515 03:27:40.325057 12912 solver.cpp:244]     Train net output #0: loss = 0.00488875 (* 1 = 0.00488875 loss)
I0515 03:27:40.325075 12912 sgd_solver.cpp:106] Iteration 67050, lr = 0.0005
I0515 03:28:18.288236 12912 solver.cpp:228] Iteration 67100, loss = 0.0106136
I0515 03:28:18.288337 12912 solver.cpp:244]     Train net output #0: loss = 0.010614 (* 1 = 0.010614 loss)
I0515 03:28:18.288350 12912 sgd_solver.cpp:106] Iteration 67100, lr = 0.0005
I0515 03:28:56.252909 12912 solver.cpp:228] Iteration 67150, loss = 0.011597
I0515 03:28:56.253012 12912 solver.cpp:244]     Train net output #0: loss = 0.0115975 (* 1 = 0.0115975 loss)
I0515 03:28:56.253026 12912 sgd_solver.cpp:106] Iteration 67150, lr = 0.0005
I0515 03:29:34.212819 12912 solver.cpp:228] Iteration 67200, loss = 0.011359
I0515 03:29:34.212952 12912 solver.cpp:244]     Train net output #0: loss = 0.0113595 (* 1 = 0.0113595 loss)
I0515 03:29:34.212985 12912 sgd_solver.cpp:106] Iteration 67200, lr = 0.0005
I0515 03:30:12.180996 12912 solver.cpp:228] Iteration 67250, loss = 0.00527984
I0515 03:30:12.181226 12912 solver.cpp:244]     Train net output #0: loss = 0.00528031 (* 1 = 0.00528031 loss)
I0515 03:30:12.181267 12912 sgd_solver.cpp:106] Iteration 67250, lr = 0.0005
I0515 03:30:50.142928 12912 solver.cpp:228] Iteration 67300, loss = 0.0139437
I0515 03:30:50.143043 12912 solver.cpp:244]     Train net output #0: loss = 0.0139441 (* 1 = 0.0139441 loss)
I0515 03:30:50.143057 12912 sgd_solver.cpp:106] Iteration 67300, lr = 0.0005
I0515 03:31:28.106143 12912 solver.cpp:228] Iteration 67350, loss = 0.0136827
I0515 03:31:28.106287 12912 solver.cpp:244]     Train net output #0: loss = 0.0136832 (* 1 = 0.0136832 loss)
I0515 03:31:28.106305 12912 sgd_solver.cpp:106] Iteration 67350, lr = 0.0005
I0515 03:32:06.068634 12912 solver.cpp:228] Iteration 67400, loss = 0.0031646
I0515 03:32:06.068743 12912 solver.cpp:244]     Train net output #0: loss = 0.00316507 (* 1 = 0.00316507 loss)
I0515 03:32:06.068756 12912 sgd_solver.cpp:106] Iteration 67400, lr = 0.0005
I0515 03:32:44.034106 12912 solver.cpp:228] Iteration 67450, loss = 0.00254615
I0515 03:32:44.034222 12912 solver.cpp:244]     Train net output #0: loss = 0.00254663 (* 1 = 0.00254663 loss)
I0515 03:32:44.034235 12912 sgd_solver.cpp:106] Iteration 67450, lr = 0.0005
I0515 03:33:22.006343 12912 solver.cpp:228] Iteration 67500, loss = 0.0187846
I0515 03:33:22.006471 12912 solver.cpp:244]     Train net output #0: loss = 0.018785 (* 1 = 0.018785 loss)
I0515 03:33:22.006489 12912 sgd_solver.cpp:106] Iteration 67500, lr = 0.0005
I0515 03:33:59.964517 12912 solver.cpp:228] Iteration 67550, loss = 0.0073807
I0515 03:33:59.964643 12912 solver.cpp:244]     Train net output #0: loss = 0.00738118 (* 1 = 0.00738118 loss)
I0515 03:33:59.964659 12912 sgd_solver.cpp:106] Iteration 67550, lr = 0.0005
I0515 03:34:37.912817 12912 solver.cpp:228] Iteration 67600, loss = 0.00581
I0515 03:34:37.912957 12912 solver.cpp:244]     Train net output #0: loss = 0.00581047 (* 1 = 0.00581047 loss)
I0515 03:34:37.912976 12912 sgd_solver.cpp:106] Iteration 67600, lr = 0.0005
I0515 03:35:15.872158 12912 solver.cpp:228] Iteration 67650, loss = 0.0449522
I0515 03:35:15.872305 12912 solver.cpp:244]     Train net output #0: loss = 0.0449527 (* 1 = 0.0449527 loss)
I0515 03:35:15.872323 12912 sgd_solver.cpp:106] Iteration 67650, lr = 0.0005
I0515 03:35:53.817175 12912 solver.cpp:228] Iteration 67700, loss = 0.00420247
I0515 03:35:53.817298 12912 solver.cpp:244]     Train net output #0: loss = 0.00420295 (* 1 = 0.00420295 loss)
I0515 03:35:53.817312 12912 sgd_solver.cpp:106] Iteration 67700, lr = 0.0005
I0515 03:36:31.785305 12912 solver.cpp:228] Iteration 67750, loss = 0.00449397
I0515 03:36:31.785426 12912 solver.cpp:244]     Train net output #0: loss = 0.00449445 (* 1 = 0.00449445 loss)
I0515 03:36:31.785439 12912 sgd_solver.cpp:106] Iteration 67750, lr = 0.0005
I0515 03:37:09.747323 12912 solver.cpp:228] Iteration 67800, loss = 0.00720854
I0515 03:37:09.747452 12912 solver.cpp:244]     Train net output #0: loss = 0.00720902 (* 1 = 0.00720902 loss)
I0515 03:37:09.747467 12912 sgd_solver.cpp:106] Iteration 67800, lr = 0.0005
I0515 03:37:47.716217 12912 solver.cpp:228] Iteration 67850, loss = 0.0128669
I0515 03:37:47.716337 12912 solver.cpp:244]     Train net output #0: loss = 0.0128674 (* 1 = 0.0128674 loss)
I0515 03:37:47.716356 12912 sgd_solver.cpp:106] Iteration 67850, lr = 0.0005
I0515 03:38:25.690040 12912 solver.cpp:228] Iteration 67900, loss = 0.0148518
I0515 03:38:25.690156 12912 solver.cpp:244]     Train net output #0: loss = 0.0148522 (* 1 = 0.0148522 loss)
I0515 03:38:25.690171 12912 sgd_solver.cpp:106] Iteration 67900, lr = 0.0005
I0515 03:39:03.671090 12912 solver.cpp:228] Iteration 67950, loss = 0.00786402
I0515 03:39:03.671236 12912 solver.cpp:244]     Train net output #0: loss = 0.0078645 (* 1 = 0.0078645 loss)
I0515 03:39:03.671257 12912 sgd_solver.cpp:106] Iteration 67950, lr = 0.0005
I0515 03:39:41.350759 12912 solver.cpp:454] Snapshotting to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_68000.caffemodel
I0515 03:39:41.895262 12912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_68000.solverstate
I0515 03:39:41.979966 12912 solver.cpp:337] Iteration 68000, Testing net (#0)
I0515 03:39:41.980028 12912 net.cpp:685] Ignoring source layer loss
I0515 03:41:25.119765 12912 solver.cpp:404]     Test net output #0: accuracy = 0.697941
I0515 03:41:25.411202 12912 solver.cpp:228] Iteration 68000, loss = 0.00183507
I0515 03:41:25.411264 12912 solver.cpp:244]     Train net output #0: loss = 0.00183555 (* 1 = 0.00183555 loss)
I0515 03:41:25.411275 12912 sgd_solver.cpp:106] Iteration 68000, lr = 0.0005
I0515 03:42:03.383690 12912 solver.cpp:228] Iteration 68050, loss = 0.00493777
I0515 03:42:03.383795 12912 solver.cpp:244]     Train net output #0: loss = 0.00493825 (* 1 = 0.00493825 loss)
I0515 03:42:03.383808 12912 sgd_solver.cpp:106] Iteration 68050, lr = 0.0005
I0515 03:42:41.355711 12912 solver.cpp:228] Iteration 68100, loss = 0.00462269
I0515 03:42:41.355825 12912 solver.cpp:244]     Train net output #0: loss = 0.00462317 (* 1 = 0.00462317 loss)
I0515 03:42:41.355839 12912 sgd_solver.cpp:106] Iteration 68100, lr = 0.0005
I0515 03:43:19.328883 12912 solver.cpp:228] Iteration 68150, loss = 0.00128106
I0515 03:43:19.329005 12912 solver.cpp:244]     Train net output #0: loss = 0.00128154 (* 1 = 0.00128154 loss)
I0515 03:43:19.329018 12912 sgd_solver.cpp:106] Iteration 68150, lr = 0.0005
I0515 03:43:57.292747 12912 solver.cpp:228] Iteration 68200, loss = 0.0323017
I0515 03:43:57.292918 12912 solver.cpp:244]     Train net output #0: loss = 0.0323022 (* 1 = 0.0323022 loss)
I0515 03:43:57.292958 12912 sgd_solver.cpp:106] Iteration 68200, lr = 0.0005
I0515 03:44:35.257853 12912 solver.cpp:228] Iteration 68250, loss = 0.00241302
I0515 03:44:35.257966 12912 solver.cpp:244]     Train net output #0: loss = 0.0024135 (* 1 = 0.0024135 loss)
I0515 03:44:35.257985 12912 sgd_solver.cpp:106] Iteration 68250, lr = 0.0005
I0515 03:45:13.226523 12912 solver.cpp:228] Iteration 68300, loss = 0.00406484
I0515 03:45:13.226661 12912 solver.cpp:244]     Train net output #0: loss = 0.00406532 (* 1 = 0.00406532 loss)
I0515 03:45:13.226680 12912 sgd_solver.cpp:106] Iteration 68300, lr = 0.0005
I0515 03:45:51.187469 12912 solver.cpp:228] Iteration 68350, loss = 0.00570282
I0515 03:45:51.187634 12912 solver.cpp:244]     Train net output #0: loss = 0.00570331 (* 1 = 0.00570331 loss)
I0515 03:45:51.187652 12912 sgd_solver.cpp:106] Iteration 68350, lr = 0.0005
I0515 03:46:29.180608 12912 solver.cpp:228] Iteration 68400, loss = 0.00302511
I0515 03:46:29.180748 12912 solver.cpp:244]     Train net output #0: loss = 0.00302559 (* 1 = 0.00302559 loss)
I0515 03:46:29.180768 12912 sgd_solver.cpp:106] Iteration 68400, lr = 0.0005
I0515 03:47:07.139361 12912 solver.cpp:228] Iteration 68450, loss = 0.00748685
I0515 03:47:07.139485 12912 solver.cpp:244]     Train net output #0: loss = 0.00748734 (* 1 = 0.00748734 loss)
I0515 03:47:07.139511 12912 sgd_solver.cpp:106] Iteration 68450, lr = 0.0005
I0515 03:47:45.102792 12912 solver.cpp:228] Iteration 68500, loss = 0.0013789
I0515 03:47:45.102941 12912 solver.cpp:244]     Train net output #0: loss = 0.00137939 (* 1 = 0.00137939 loss)
I0515 03:47:45.102962 12912 sgd_solver.cpp:106] Iteration 68500, lr = 0.0005
I0515 03:48:23.076288 12912 solver.cpp:228] Iteration 68550, loss = 0.00434434
I0515 03:48:23.076417 12912 solver.cpp:244]     Train net output #0: loss = 0.00434483 (* 1 = 0.00434483 loss)
I0515 03:48:23.076436 12912 sgd_solver.cpp:106] Iteration 68550, lr = 0.0005
I0515 03:49:01.049363 12912 solver.cpp:228] Iteration 68600, loss = 0.00536432
I0515 03:49:01.049581 12912 solver.cpp:244]     Train net output #0: loss = 0.00536481 (* 1 = 0.00536481 loss)
I0515 03:49:01.049603 12912 sgd_solver.cpp:106] Iteration 68600, lr = 0.0005
I0515 03:49:39.005661 12912 solver.cpp:228] Iteration 68650, loss = 0.00311505
I0515 03:49:39.005787 12912 solver.cpp:244]     Train net output #0: loss = 0.00311555 (* 1 = 0.00311555 loss)
I0515 03:49:39.005805 12912 sgd_solver.cpp:106] Iteration 68650, lr = 0.0005
I0515 03:50:17.003695 12912 solver.cpp:228] Iteration 68700, loss = 0.0231877
I0515 03:50:17.003864 12912 solver.cpp:244]     Train net output #0: loss = 0.0231881 (* 1 = 0.0231881 loss)
I0515 03:50:17.003900 12912 sgd_solver.cpp:106] Iteration 68700, lr = 0.0005
I0515 03:50:54.974959 12912 solver.cpp:228] Iteration 68750, loss = 0.0036248
I0515 03:50:54.975075 12912 solver.cpp:244]     Train net output #0: loss = 0.0036253 (* 1 = 0.0036253 loss)
I0515 03:50:54.975100 12912 sgd_solver.cpp:106] Iteration 68750, lr = 0.0005
I0515 03:51:32.946842 12912 solver.cpp:228] Iteration 68800, loss = 0.00309252
I0515 03:51:32.947018 12912 solver.cpp:244]     Train net output #0: loss = 0.00309301 (* 1 = 0.00309301 loss)
I0515 03:51:32.947036 12912 sgd_solver.cpp:106] Iteration 68800, lr = 0.0005
I0515 03:52:10.939666 12912 solver.cpp:228] Iteration 68850, loss = 0.00217303
I0515 03:52:10.939823 12912 solver.cpp:244]     Train net output #0: loss = 0.00217353 (* 1 = 0.00217353 loss)
I0515 03:52:10.939838 12912 sgd_solver.cpp:106] Iteration 68850, lr = 0.0005
I0515 03:52:48.911603 12912 solver.cpp:228] Iteration 68900, loss = 0.00470375
I0515 03:52:48.911710 12912 solver.cpp:244]     Train net output #0: loss = 0.00470425 (* 1 = 0.00470425 loss)
I0515 03:52:48.911726 12912 sgd_solver.cpp:106] Iteration 68900, lr = 0.0005
I0515 03:53:26.880117 12912 solver.cpp:228] Iteration 68950, loss = 0.00386401
I0515 03:53:26.880241 12912 solver.cpp:244]     Train net output #0: loss = 0.00386452 (* 1 = 0.00386452 loss)
I0515 03:53:26.880254 12912 sgd_solver.cpp:106] Iteration 68950, lr = 0.0005
I0515 03:54:04.567008 12912 solver.cpp:454] Snapshotting to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_69000.caffemodel
I0515 03:54:05.147167 12912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_69000.solverstate
I0515 03:54:05.262425 12912 solver.cpp:337] Iteration 69000, Testing net (#0)
I0515 03:54:05.262516 12912 net.cpp:685] Ignoring source layer loss
I0515 03:55:48.221752 12912 solver.cpp:404]     Test net output #0: accuracy = 0.738529
I0515 03:55:48.514466 12912 solver.cpp:228] Iteration 69000, loss = 0.00690383
I0515 03:55:48.514520 12912 solver.cpp:244]     Train net output #0: loss = 0.00690433 (* 1 = 0.00690433 loss)
I0515 03:55:48.514531 12912 sgd_solver.cpp:106] Iteration 69000, lr = 0.0005
I0515 03:56:26.479648 12912 solver.cpp:228] Iteration 69050, loss = 0.00275712
I0515 03:56:26.479759 12912 solver.cpp:244]     Train net output #0: loss = 0.00275762 (* 1 = 0.00275762 loss)
I0515 03:56:26.479778 12912 sgd_solver.cpp:106] Iteration 69050, lr = 0.0005
I0515 03:57:04.459530 12912 solver.cpp:228] Iteration 69100, loss = 0.00392414
I0515 03:57:04.459657 12912 solver.cpp:244]     Train net output #0: loss = 0.00392465 (* 1 = 0.00392465 loss)
I0515 03:57:04.459671 12912 sgd_solver.cpp:106] Iteration 69100, lr = 0.0005
I0515 03:57:42.447993 12912 solver.cpp:228] Iteration 69150, loss = 0.0057576
I0515 03:57:42.448174 12912 solver.cpp:244]     Train net output #0: loss = 0.0057581 (* 1 = 0.0057581 loss)
I0515 03:57:42.448218 12912 sgd_solver.cpp:106] Iteration 69150, lr = 0.0005
I0515 03:58:20.417132 12912 solver.cpp:228] Iteration 69200, loss = 0.013092
I0515 03:58:20.417237 12912 solver.cpp:244]     Train net output #0: loss = 0.0130926 (* 1 = 0.0130926 loss)
I0515 03:58:20.417249 12912 sgd_solver.cpp:106] Iteration 69200, lr = 0.0005
I0515 03:58:58.386183 12912 solver.cpp:228] Iteration 69250, loss = 0.0123907
I0515 03:58:58.386337 12912 solver.cpp:244]     Train net output #0: loss = 0.0123912 (* 1 = 0.0123912 loss)
I0515 03:58:58.386355 12912 sgd_solver.cpp:106] Iteration 69250, lr = 0.0005
I0515 03:59:36.344552 12912 solver.cpp:228] Iteration 69300, loss = 0.00461965
I0515 03:59:36.344650 12912 solver.cpp:244]     Train net output #0: loss = 0.00462015 (* 1 = 0.00462015 loss)
I0515 03:59:36.344662 12912 sgd_solver.cpp:106] Iteration 69300, lr = 0.0005
I0515 04:00:14.306005 12912 solver.cpp:228] Iteration 69350, loss = 0.00317056
I0515 04:00:14.306129 12912 solver.cpp:244]     Train net output #0: loss = 0.00317106 (* 1 = 0.00317106 loss)
I0515 04:00:14.306143 12912 sgd_solver.cpp:106] Iteration 69350, lr = 0.0005
I0515 04:00:52.267371 12912 solver.cpp:228] Iteration 69400, loss = 0.0187079
I0515 04:00:52.267504 12912 solver.cpp:244]     Train net output #0: loss = 0.0187084 (* 1 = 0.0187084 loss)
I0515 04:00:52.267524 12912 sgd_solver.cpp:106] Iteration 69400, lr = 0.0005
I0515 04:01:30.234652 12912 solver.cpp:228] Iteration 69450, loss = 0.0111961
I0515 04:01:30.234777 12912 solver.cpp:244]     Train net output #0: loss = 0.0111966 (* 1 = 0.0111966 loss)
I0515 04:01:30.234791 12912 sgd_solver.cpp:106] Iteration 69450, lr = 0.0005
I0515 04:02:08.197911 12912 solver.cpp:228] Iteration 69500, loss = 0.0031122
I0515 04:02:08.198088 12912 solver.cpp:244]     Train net output #0: loss = 0.00311269 (* 1 = 0.00311269 loss)
I0515 04:02:08.198112 12912 sgd_solver.cpp:106] Iteration 69500, lr = 0.0005
I0515 04:02:46.178350 12912 solver.cpp:228] Iteration 69550, loss = 0.00447957
I0515 04:02:46.178517 12912 solver.cpp:244]     Train net output #0: loss = 0.00448007 (* 1 = 0.00448007 loss)
I0515 04:02:46.178560 12912 sgd_solver.cpp:106] Iteration 69550, lr = 0.0005
I0515 04:03:24.155699 12912 solver.cpp:228] Iteration 69600, loss = 0.00279449
I0515 04:03:24.155807 12912 solver.cpp:244]     Train net output #0: loss = 0.00279498 (* 1 = 0.00279498 loss)
I0515 04:03:24.155825 12912 sgd_solver.cpp:106] Iteration 69600, lr = 0.0005
I0515 04:04:02.124675 12912 solver.cpp:228] Iteration 69650, loss = 0.00544098
I0515 04:04:02.124789 12912 solver.cpp:244]     Train net output #0: loss = 0.00544147 (* 1 = 0.00544147 loss)
I0515 04:04:02.124802 12912 sgd_solver.cpp:106] Iteration 69650, lr = 0.0005
I0515 04:04:40.109529 12912 solver.cpp:228] Iteration 69700, loss = 0.00275111
I0515 04:04:40.109647 12912 solver.cpp:244]     Train net output #0: loss = 0.00275161 (* 1 = 0.00275161 loss)
I0515 04:04:40.109659 12912 sgd_solver.cpp:106] Iteration 69700, lr = 0.0005
I0515 04:05:18.058691 12912 solver.cpp:228] Iteration 69750, loss = 0.00579755
I0515 04:05:18.058802 12912 solver.cpp:244]     Train net output #0: loss = 0.00579804 (* 1 = 0.00579804 loss)
I0515 04:05:18.058816 12912 sgd_solver.cpp:106] Iteration 69750, lr = 0.0005
I0515 04:05:56.013730 12912 solver.cpp:228] Iteration 69800, loss = 0.00666587
I0515 04:05:56.013857 12912 solver.cpp:244]     Train net output #0: loss = 0.00666637 (* 1 = 0.00666637 loss)
I0515 04:05:56.013870 12912 sgd_solver.cpp:106] Iteration 69800, lr = 0.0005
I0515 04:06:33.988245 12912 solver.cpp:228] Iteration 69850, loss = 0.00485608
I0515 04:06:33.988349 12912 solver.cpp:244]     Train net output #0: loss = 0.00485657 (* 1 = 0.00485657 loss)
I0515 04:06:33.988363 12912 sgd_solver.cpp:106] Iteration 69850, lr = 0.0005
I0515 04:07:11.954468 12912 solver.cpp:228] Iteration 69900, loss = 0.00193592
I0515 04:07:11.954588 12912 solver.cpp:244]     Train net output #0: loss = 0.00193641 (* 1 = 0.00193641 loss)
I0515 04:07:11.954602 12912 sgd_solver.cpp:106] Iteration 69900, lr = 0.0005
I0515 04:07:49.939002 12912 solver.cpp:228] Iteration 69950, loss = 0.009647
I0515 04:07:49.939187 12912 solver.cpp:244]     Train net output #0: loss = 0.00964749 (* 1 = 0.00964749 loss)
I0515 04:07:49.939229 12912 sgd_solver.cpp:106] Iteration 69950, lr = 0.0005
I0515 04:08:27.616449 12912 solver.cpp:454] Snapshotting to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_70000.caffemodel
I0515 04:08:28.331181 12912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_70000.solverstate
I0515 04:08:28.469780 12912 solver.cpp:337] Iteration 70000, Testing net (#0)
I0515 04:08:28.469856 12912 net.cpp:685] Ignoring source layer loss
I0515 04:10:11.358438 12912 solver.cpp:404]     Test net output #0: accuracy = 0.803088
I0515 04:10:11.649092 12912 solver.cpp:228] Iteration 70000, loss = 0.00827515
I0515 04:10:11.649158 12912 solver.cpp:244]     Train net output #0: loss = 0.00827565 (* 1 = 0.00827565 loss)
I0515 04:10:11.649173 12912 sgd_solver.cpp:106] Iteration 70000, lr = 0.0005
I0515 04:10:49.608088 12912 solver.cpp:228] Iteration 70050, loss = 0.0115866
I0515 04:10:49.608194 12912 solver.cpp:244]     Train net output #0: loss = 0.0115871 (* 1 = 0.0115871 loss)
I0515 04:10:49.608207 12912 sgd_solver.cpp:106] Iteration 70050, lr = 0.0005
I0515 04:11:27.608822 12912 solver.cpp:228] Iteration 70100, loss = 0.00335864
I0515 04:11:27.608990 12912 solver.cpp:244]     Train net output #0: loss = 0.00335913 (* 1 = 0.00335913 loss)
I0515 04:11:27.609010 12912 sgd_solver.cpp:106] Iteration 70100, lr = 0.0005
I0515 04:12:05.579903 12912 solver.cpp:228] Iteration 70150, loss = 0.00193774
I0515 04:12:05.580113 12912 solver.cpp:244]     Train net output #0: loss = 0.00193823 (* 1 = 0.00193823 loss)
I0515 04:12:05.580135 12912 sgd_solver.cpp:106] Iteration 70150, lr = 0.0005
I0515 04:12:43.550089 12912 solver.cpp:228] Iteration 70200, loss = 0.00574283
I0515 04:12:43.550235 12912 solver.cpp:244]     Train net output #0: loss = 0.00574333 (* 1 = 0.00574333 loss)
I0515 04:12:43.550249 12912 sgd_solver.cpp:106] Iteration 70200, lr = 0.0005
I0515 04:13:21.520112 12912 solver.cpp:228] Iteration 70250, loss = 0.00384198
I0515 04:13:21.520278 12912 solver.cpp:244]     Train net output #0: loss = 0.00384248 (* 1 = 0.00384248 loss)
I0515 04:13:21.520298 12912 sgd_solver.cpp:106] Iteration 70250, lr = 0.0005
I0515 04:13:59.481978 12912 solver.cpp:228] Iteration 70300, loss = 0.00371351
I0515 04:13:59.482082 12912 solver.cpp:244]     Train net output #0: loss = 0.00371401 (* 1 = 0.00371401 loss)
I0515 04:13:59.482100 12912 sgd_solver.cpp:106] Iteration 70300, lr = 0.0005
I0515 04:14:37.450722 12912 solver.cpp:228] Iteration 70350, loss = 0.00260007
I0515 04:14:37.450850 12912 solver.cpp:244]     Train net output #0: loss = 0.00260056 (* 1 = 0.00260056 loss)
I0515 04:14:37.450866 12912 sgd_solver.cpp:106] Iteration 70350, lr = 0.0005
I0515 04:15:15.427906 12912 solver.cpp:228] Iteration 70400, loss = 0.00447388
I0515 04:15:15.428002 12912 solver.cpp:244]     Train net output #0: loss = 0.00447438 (* 1 = 0.00447438 loss)
I0515 04:15:15.428015 12912 sgd_solver.cpp:106] Iteration 70400, lr = 0.0005
I0515 04:15:53.397773 12912 solver.cpp:228] Iteration 70450, loss = 0.00217205
I0515 04:15:53.397896 12912 solver.cpp:244]     Train net output #0: loss = 0.00217255 (* 1 = 0.00217255 loss)
I0515 04:15:53.397912 12912 sgd_solver.cpp:106] Iteration 70450, lr = 0.0005
I0515 04:16:31.363982 12912 solver.cpp:228] Iteration 70500, loss = 0.00536803
I0515 04:16:31.364096 12912 solver.cpp:244]     Train net output #0: loss = 0.00536853 (* 1 = 0.00536853 loss)
I0515 04:16:31.364109 12912 sgd_solver.cpp:106] Iteration 70500, lr = 0.0005
I0515 04:17:09.351802 12912 solver.cpp:228] Iteration 70550, loss = 0.00247929
I0515 04:17:09.362109 12912 solver.cpp:244]     Train net output #0: loss = 0.00247979 (* 1 = 0.00247979 loss)
I0515 04:17:09.362138 12912 sgd_solver.cpp:106] Iteration 70550, lr = 0.0005
I0515 04:17:47.315328 12912 solver.cpp:228] Iteration 70600, loss = 0.00317376
I0515 04:17:47.315433 12912 solver.cpp:244]     Train net output #0: loss = 0.00317425 (* 1 = 0.00317425 loss)
I0515 04:17:47.315445 12912 sgd_solver.cpp:106] Iteration 70600, lr = 0.0005
I0515 04:18:25.288395 12912 solver.cpp:228] Iteration 70650, loss = 0.00818125
I0515 04:18:25.288570 12912 solver.cpp:244]     Train net output #0: loss = 0.00818175 (* 1 = 0.00818175 loss)
I0515 04:18:25.288589 12912 sgd_solver.cpp:106] Iteration 70650, lr = 0.0005
I0515 04:19:03.273413 12912 solver.cpp:228] Iteration 70700, loss = 0.00167956
I0515 04:19:03.273540 12912 solver.cpp:244]     Train net output #0: loss = 0.00168006 (* 1 = 0.00168006 loss)
I0515 04:19:03.273557 12912 sgd_solver.cpp:106] Iteration 70700, lr = 0.0005
I0515 04:19:41.248245 12912 solver.cpp:228] Iteration 70750, loss = 0.00877283
I0515 04:19:41.248385 12912 solver.cpp:244]     Train net output #0: loss = 0.00877333 (* 1 = 0.00877333 loss)
I0515 04:19:41.248399 12912 sgd_solver.cpp:106] Iteration 70750, lr = 0.0005
I0515 04:20:19.224947 12912 solver.cpp:228] Iteration 70800, loss = 0.027913
I0515 04:20:19.225064 12912 solver.cpp:244]     Train net output #0: loss = 0.0279135 (* 1 = 0.0279135 loss)
I0515 04:20:19.225081 12912 sgd_solver.cpp:106] Iteration 70800, lr = 0.0005
I0515 04:20:57.188076 12912 solver.cpp:228] Iteration 70850, loss = 0.0091416
I0515 04:20:57.188226 12912 solver.cpp:244]     Train net output #0: loss = 0.0091421 (* 1 = 0.0091421 loss)
I0515 04:20:57.188240 12912 sgd_solver.cpp:106] Iteration 70850, lr = 0.0005
I0515 04:21:35.125700 12912 solver.cpp:228] Iteration 70900, loss = 0.00447376
I0515 04:21:35.126113 12912 solver.cpp:244]     Train net output #0: loss = 0.00447426 (* 1 = 0.00447426 loss)
I0515 04:21:35.126152 12912 sgd_solver.cpp:106] Iteration 70900, lr = 0.0005
I0515 04:22:13.114270 12912 solver.cpp:228] Iteration 70950, loss = 0.0026377
I0515 04:22:13.114409 12912 solver.cpp:244]     Train net output #0: loss = 0.0026382 (* 1 = 0.0026382 loss)
I0515 04:22:13.114428 12912 sgd_solver.cpp:106] Iteration 70950, lr = 0.0005
I0515 04:22:50.780515 12912 solver.cpp:454] Snapshotting to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_71000.caffemodel
I0515 04:22:51.326074 12912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_71000.solverstate
I0515 04:22:51.409867 12912 solver.cpp:337] Iteration 71000, Testing net (#0)
I0515 04:22:51.409926 12912 net.cpp:685] Ignoring source layer loss
I0515 04:24:34.244799 12912 solver.cpp:404]     Test net output #0: accuracy = 0.678529
I0515 04:24:34.534828 12912 solver.cpp:228] Iteration 71000, loss = 0.00416735
I0515 04:24:34.534875 12912 solver.cpp:244]     Train net output #0: loss = 0.00416785 (* 1 = 0.00416785 loss)
I0515 04:24:34.534885 12912 sgd_solver.cpp:106] Iteration 71000, lr = 0.0005
I0515 04:25:12.496183 12912 solver.cpp:228] Iteration 71050, loss = 0.00328533
I0515 04:25:12.496364 12912 solver.cpp:244]     Train net output #0: loss = 0.00328583 (* 1 = 0.00328583 loss)
I0515 04:25:12.496405 12912 sgd_solver.cpp:106] Iteration 71050, lr = 0.0005
I0515 04:25:50.468937 12912 solver.cpp:228] Iteration 71100, loss = 0.00131794
I0515 04:25:50.469107 12912 solver.cpp:244]     Train net output #0: loss = 0.00131844 (* 1 = 0.00131844 loss)
I0515 04:25:50.469142 12912 sgd_solver.cpp:106] Iteration 71100, lr = 0.0005
I0515 04:26:28.437041 12912 solver.cpp:228] Iteration 71150, loss = 0.00387769
I0515 04:26:28.437170 12912 solver.cpp:244]     Train net output #0: loss = 0.00387819 (* 1 = 0.00387819 loss)
I0515 04:26:28.437187 12912 sgd_solver.cpp:106] Iteration 71150, lr = 0.0005
I0515 04:27:06.390097 12912 solver.cpp:228] Iteration 71200, loss = 0.00172495
I0515 04:27:06.390207 12912 solver.cpp:244]     Train net output #0: loss = 0.00172545 (* 1 = 0.00172545 loss)
I0515 04:27:06.390224 12912 sgd_solver.cpp:106] Iteration 71200, lr = 0.0005
I0515 04:27:44.359765 12912 solver.cpp:228] Iteration 71250, loss = 0.0177715
I0515 04:27:44.359925 12912 solver.cpp:244]     Train net output #0: loss = 0.017772 (* 1 = 0.017772 loss)
I0515 04:27:44.359943 12912 sgd_solver.cpp:106] Iteration 71250, lr = 0.0005
I0515 04:28:22.346123 12912 solver.cpp:228] Iteration 71300, loss = 0.00142663
I0515 04:28:22.346230 12912 solver.cpp:244]     Train net output #0: loss = 0.00142713 (* 1 = 0.00142713 loss)
I0515 04:28:22.346242 12912 sgd_solver.cpp:106] Iteration 71300, lr = 0.0005
I0515 04:29:00.310753 12912 solver.cpp:228] Iteration 71350, loss = 0.00782135
I0515 04:29:00.310907 12912 solver.cpp:244]     Train net output #0: loss = 0.00782185 (* 1 = 0.00782185 loss)
I0515 04:29:00.310951 12912 sgd_solver.cpp:106] Iteration 71350, lr = 0.0005
I0515 04:29:38.284737 12912 solver.cpp:228] Iteration 71400, loss = 0.0143787
I0515 04:29:38.284832 12912 solver.cpp:244]     Train net output #0: loss = 0.0143792 (* 1 = 0.0143792 loss)
I0515 04:29:38.284844 12912 sgd_solver.cpp:106] Iteration 71400, lr = 0.0005
I0515 04:30:16.241964 12912 solver.cpp:228] Iteration 71450, loss = 0.00170332
I0515 04:30:16.242090 12912 solver.cpp:244]     Train net output #0: loss = 0.00170383 (* 1 = 0.00170383 loss)
I0515 04:30:16.242108 12912 sgd_solver.cpp:106] Iteration 71450, lr = 0.0005
I0515 04:30:54.211871 12912 solver.cpp:228] Iteration 71500, loss = 0.00878284
I0515 04:30:54.212034 12912 solver.cpp:244]     Train net output #0: loss = 0.00878334 (* 1 = 0.00878334 loss)
I0515 04:30:54.212054 12912 sgd_solver.cpp:106] Iteration 71500, lr = 0.0005
I0515 04:31:32.190459 12912 solver.cpp:228] Iteration 71550, loss = 0.0049272
I0515 04:31:32.190594 12912 solver.cpp:244]     Train net output #0: loss = 0.0049277 (* 1 = 0.0049277 loss)
I0515 04:31:32.190613 12912 sgd_solver.cpp:106] Iteration 71550, lr = 0.0005
I0515 04:32:10.162611 12912 solver.cpp:228] Iteration 71600, loss = 0.00433667
I0515 04:32:10.162783 12912 solver.cpp:244]     Train net output #0: loss = 0.00433717 (* 1 = 0.00433717 loss)
I0515 04:32:10.162802 12912 sgd_solver.cpp:106] Iteration 71600, lr = 0.0005
I0515 04:32:48.138265 12912 solver.cpp:228] Iteration 71650, loss = 0.00654824
I0515 04:32:48.138383 12912 solver.cpp:244]     Train net output #0: loss = 0.00654874 (* 1 = 0.00654874 loss)
I0515 04:32:48.138396 12912 sgd_solver.cpp:106] Iteration 71650, lr = 0.0005
I0515 04:33:26.109809 12912 solver.cpp:228] Iteration 71700, loss = 0.0227363
I0515 04:33:26.109916 12912 solver.cpp:244]     Train net output #0: loss = 0.0227368 (* 1 = 0.0227368 loss)
I0515 04:33:26.109935 12912 sgd_solver.cpp:106] Iteration 71700, lr = 0.0005
I0515 04:34:04.061542 12912 solver.cpp:228] Iteration 71750, loss = 0.012114
I0515 04:34:04.061735 12912 solver.cpp:244]     Train net output #0: loss = 0.0121145 (* 1 = 0.0121145 loss)
I0515 04:34:04.061775 12912 sgd_solver.cpp:106] Iteration 71750, lr = 0.0005
I0515 04:34:42.030177 12912 solver.cpp:228] Iteration 71800, loss = 0.00263336
I0515 04:34:42.030279 12912 solver.cpp:244]     Train net output #0: loss = 0.00263386 (* 1 = 0.00263386 loss)
I0515 04:34:42.030292 12912 sgd_solver.cpp:106] Iteration 71800, lr = 0.0005
I0515 04:35:19.975378 12912 solver.cpp:228] Iteration 71850, loss = 0.00446638
I0515 04:35:19.975493 12912 solver.cpp:244]     Train net output #0: loss = 0.00446687 (* 1 = 0.00446687 loss)
I0515 04:35:19.975505 12912 sgd_solver.cpp:106] Iteration 71850, lr = 0.0005
I0515 04:35:57.928689 12912 solver.cpp:228] Iteration 71900, loss = 0.0075822
I0515 04:35:57.928798 12912 solver.cpp:244]     Train net output #0: loss = 0.0075827 (* 1 = 0.0075827 loss)
I0515 04:35:57.928812 12912 sgd_solver.cpp:106] Iteration 71900, lr = 0.0005
I0515 04:36:35.892377 12912 solver.cpp:228] Iteration 71950, loss = 0.00264855
I0515 04:36:35.892480 12912 solver.cpp:244]     Train net output #0: loss = 0.00264904 (* 1 = 0.00264904 loss)
I0515 04:36:35.892498 12912 sgd_solver.cpp:106] Iteration 71950, lr = 0.0005
I0515 04:37:13.559499 12912 solver.cpp:454] Snapshotting to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_72000.caffemodel
I0515 04:37:14.078302 12912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_72000.solverstate
I0515 04:37:14.169322 12912 solver.cpp:337] Iteration 72000, Testing net (#0)
I0515 04:37:14.169384 12912 net.cpp:685] Ignoring source layer loss
I0515 04:38:56.947587 12912 solver.cpp:404]     Test net output #0: accuracy = 0.753382
I0515 04:38:57.237810 12912 solver.cpp:228] Iteration 72000, loss = 0.0029076
I0515 04:38:57.237871 12912 solver.cpp:244]     Train net output #0: loss = 0.0029081 (* 1 = 0.0029081 loss)
I0515 04:38:57.237882 12912 sgd_solver.cpp:106] Iteration 72000, lr = 0.0005
I0515 04:39:35.214926 12912 solver.cpp:228] Iteration 72050, loss = 0.00469624
I0515 04:39:35.215065 12912 solver.cpp:244]     Train net output #0: loss = 0.00469674 (* 1 = 0.00469674 loss)
I0515 04:39:35.215088 12912 sgd_solver.cpp:106] Iteration 72050, lr = 0.0005
I0515 04:40:13.173166 12912 solver.cpp:228] Iteration 72100, loss = 0.00224308
I0515 04:40:13.173292 12912 solver.cpp:244]     Train net output #0: loss = 0.00224359 (* 1 = 0.00224359 loss)
I0515 04:40:13.173312 12912 sgd_solver.cpp:106] Iteration 72100, lr = 0.0005
I0515 04:40:51.125666 12912 solver.cpp:228] Iteration 72150, loss = 0.00636567
I0515 04:40:51.125788 12912 solver.cpp:244]     Train net output #0: loss = 0.00636618 (* 1 = 0.00636618 loss)
I0515 04:40:51.125804 12912 sgd_solver.cpp:106] Iteration 72150, lr = 0.0005
I0515 04:41:29.086977 12912 solver.cpp:228] Iteration 72200, loss = 0.00205388
I0515 04:41:29.087091 12912 solver.cpp:244]     Train net output #0: loss = 0.00205439 (* 1 = 0.00205439 loss)
I0515 04:41:29.087105 12912 sgd_solver.cpp:106] Iteration 72200, lr = 0.0005
I0515 04:42:07.071176 12912 solver.cpp:228] Iteration 72250, loss = 0.00311971
I0515 04:42:07.071439 12912 solver.cpp:244]     Train net output #0: loss = 0.00312021 (* 1 = 0.00312021 loss)
I0515 04:42:07.071501 12912 sgd_solver.cpp:106] Iteration 72250, lr = 0.0005
I0515 04:42:45.030992 12912 solver.cpp:228] Iteration 72300, loss = 0.0012036
I0515 04:42:45.031113 12912 solver.cpp:244]     Train net output #0: loss = 0.00120411 (* 1 = 0.00120411 loss)
I0515 04:42:45.031126 12912 sgd_solver.cpp:106] Iteration 72300, lr = 0.0005
I0515 04:43:23.000985 12912 solver.cpp:228] Iteration 72350, loss = 0.00535543
I0515 04:43:23.001091 12912 solver.cpp:244]     Train net output #0: loss = 0.00535593 (* 1 = 0.00535593 loss)
I0515 04:43:23.001108 12912 sgd_solver.cpp:106] Iteration 72350, lr = 0.0005
I0515 04:44:00.964221 12912 solver.cpp:228] Iteration 72400, loss = 0.00266161
I0515 04:44:00.964375 12912 solver.cpp:244]     Train net output #0: loss = 0.00266211 (* 1 = 0.00266211 loss)
I0515 04:44:00.964393 12912 sgd_solver.cpp:106] Iteration 72400, lr = 0.0005
I0515 04:44:38.925853 12912 solver.cpp:228] Iteration 72450, loss = 0.00513589
I0515 04:44:38.926004 12912 solver.cpp:244]     Train net output #0: loss = 0.00513638 (* 1 = 0.00513638 loss)
I0515 04:44:38.926029 12912 sgd_solver.cpp:106] Iteration 72450, lr = 0.0005
I0515 04:45:16.894589 12912 solver.cpp:228] Iteration 72500, loss = 0.0193844
I0515 04:45:16.894742 12912 solver.cpp:244]     Train net output #0: loss = 0.0193848 (* 1 = 0.0193848 loss)
I0515 04:45:16.894760 12912 sgd_solver.cpp:106] Iteration 72500, lr = 0.0005
I0515 04:45:54.860818 12912 solver.cpp:228] Iteration 72550, loss = 0.00454358
I0515 04:45:54.860934 12912 solver.cpp:244]     Train net output #0: loss = 0.00454408 (* 1 = 0.00454408 loss)
I0515 04:45:54.860951 12912 sgd_solver.cpp:106] Iteration 72550, lr = 0.0005
I0515 04:46:32.833725 12912 solver.cpp:228] Iteration 72600, loss = 0.0214183
I0515 04:46:32.833853 12912 solver.cpp:244]     Train net output #0: loss = 0.0214188 (* 1 = 0.0214188 loss)
I0515 04:46:32.833866 12912 sgd_solver.cpp:106] Iteration 72600, lr = 0.0005
I0515 04:47:10.824153 12912 solver.cpp:228] Iteration 72650, loss = 0.0327962
I0515 04:47:10.824276 12912 solver.cpp:244]     Train net output #0: loss = 0.0327967 (* 1 = 0.0327967 loss)
I0515 04:47:10.824295 12912 sgd_solver.cpp:106] Iteration 72650, lr = 0.0005
I0515 04:47:48.788450 12912 solver.cpp:228] Iteration 72700, loss = 0.00461405
I0515 04:47:48.788581 12912 solver.cpp:244]     Train net output #0: loss = 0.00461455 (* 1 = 0.00461455 loss)
I0515 04:47:48.788599 12912 sgd_solver.cpp:106] Iteration 72700, lr = 0.0005
I0515 04:48:26.732286 12912 solver.cpp:228] Iteration 72750, loss = 0.00860624
I0515 04:48:26.732400 12912 solver.cpp:244]     Train net output #0: loss = 0.00860673 (* 1 = 0.00860673 loss)
I0515 04:48:26.732419 12912 sgd_solver.cpp:106] Iteration 72750, lr = 0.0005
I0515 04:49:04.711210 12912 solver.cpp:228] Iteration 72800, loss = 0.00193521
I0515 04:49:04.711370 12912 solver.cpp:244]     Train net output #0: loss = 0.00193571 (* 1 = 0.00193571 loss)
I0515 04:49:04.711406 12912 sgd_solver.cpp:106] Iteration 72800, lr = 0.0005
I0515 04:49:42.670598 12912 solver.cpp:228] Iteration 72850, loss = 0.00310166
I0515 04:49:42.670704 12912 solver.cpp:244]     Train net output #0: loss = 0.00310216 (* 1 = 0.00310216 loss)
I0515 04:49:42.670722 12912 sgd_solver.cpp:106] Iteration 72850, lr = 0.0005
I0515 04:50:20.627646 12912 solver.cpp:228] Iteration 72900, loss = 0.00304591
I0515 04:50:20.627878 12912 solver.cpp:244]     Train net output #0: loss = 0.0030464 (* 1 = 0.0030464 loss)
I0515 04:50:20.627951 12912 sgd_solver.cpp:106] Iteration 72900, lr = 0.0005
I0515 04:50:58.602598 12912 solver.cpp:228] Iteration 72950, loss = 0.00219783
I0515 04:50:58.602756 12912 solver.cpp:244]     Train net output #0: loss = 0.00219833 (* 1 = 0.00219833 loss)
I0515 04:50:58.602769 12912 sgd_solver.cpp:106] Iteration 72950, lr = 0.0005
I0515 04:51:36.277552 12912 solver.cpp:454] Snapshotting to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_73000.caffemodel
I0515 04:51:37.094959 12912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_73000.solverstate
I0515 04:51:37.239136 12912 solver.cpp:337] Iteration 73000, Testing net (#0)
I0515 04:51:37.239213 12912 net.cpp:685] Ignoring source layer loss
I0515 04:53:20.194387 12912 solver.cpp:404]     Test net output #0: accuracy = 0.699559
I0515 04:53:20.484730 12912 solver.cpp:228] Iteration 73000, loss = 0.00763623
I0515 04:53:20.484781 12912 solver.cpp:244]     Train net output #0: loss = 0.00763673 (* 1 = 0.00763673 loss)
I0515 04:53:20.484794 12912 sgd_solver.cpp:106] Iteration 73000, lr = 0.0005
I0515 04:53:58.439483 12912 solver.cpp:228] Iteration 73050, loss = 0.00589075
I0515 04:53:58.439620 12912 solver.cpp:244]     Train net output #0: loss = 0.00589124 (* 1 = 0.00589124 loss)
I0515 04:53:58.439637 12912 sgd_solver.cpp:106] Iteration 73050, lr = 0.0005
I0515 04:54:36.408179 12912 solver.cpp:228] Iteration 73100, loss = 0.00670417
I0515 04:54:36.408318 12912 solver.cpp:244]     Train net output #0: loss = 0.00670466 (* 1 = 0.00670466 loss)
I0515 04:54:36.408339 12912 sgd_solver.cpp:106] Iteration 73100, lr = 0.0005
I0515 04:55:14.378828 12912 solver.cpp:228] Iteration 73150, loss = 0.00219758
I0515 04:55:14.379034 12912 solver.cpp:244]     Train net output #0: loss = 0.00219806 (* 1 = 0.00219806 loss)
I0515 04:55:14.379075 12912 sgd_solver.cpp:106] Iteration 73150, lr = 0.0005
I0515 04:55:52.354982 12912 solver.cpp:228] Iteration 73200, loss = 0.0138726
I0515 04:55:52.355125 12912 solver.cpp:244]     Train net output #0: loss = 0.0138731 (* 1 = 0.0138731 loss)
I0515 04:55:52.355144 12912 sgd_solver.cpp:106] Iteration 73200, lr = 0.0005
I0515 04:56:30.333561 12912 solver.cpp:228] Iteration 73250, loss = 0.00361569
I0515 04:56:30.333767 12912 solver.cpp:244]     Train net output #0: loss = 0.00361618 (* 1 = 0.00361618 loss)
I0515 04:56:30.333808 12912 sgd_solver.cpp:106] Iteration 73250, lr = 0.0005
I0515 04:57:08.293459 12912 solver.cpp:228] Iteration 73300, loss = 0.00488733
I0515 04:57:08.293623 12912 solver.cpp:244]     Train net output #0: loss = 0.00488781 (* 1 = 0.00488781 loss)
I0515 04:57:08.293649 12912 sgd_solver.cpp:106] Iteration 73300, lr = 0.0005
I0515 04:57:46.281538 12912 solver.cpp:228] Iteration 73350, loss = 0.00364615
I0515 04:57:46.281642 12912 solver.cpp:244]     Train net output #0: loss = 0.00364663 (* 1 = 0.00364663 loss)
I0515 04:57:46.281661 12912 sgd_solver.cpp:106] Iteration 73350, lr = 0.0005
I0515 04:58:24.259788 12912 solver.cpp:228] Iteration 73400, loss = 0.00451337
I0515 04:58:24.259898 12912 solver.cpp:244]     Train net output #0: loss = 0.00451385 (* 1 = 0.00451385 loss)
I0515 04:58:24.259912 12912 sgd_solver.cpp:106] Iteration 73400, lr = 0.0005
I0515 04:59:02.234617 12912 solver.cpp:228] Iteration 73450, loss = 0.00234787
I0515 04:59:02.234784 12912 solver.cpp:244]     Train net output #0: loss = 0.00234836 (* 1 = 0.00234836 loss)
I0515 04:59:02.234828 12912 sgd_solver.cpp:106] Iteration 73450, lr = 0.0005
I0515 04:59:40.212615 12912 solver.cpp:228] Iteration 73500, loss = 0.00737219
I0515 04:59:40.212724 12912 solver.cpp:244]     Train net output #0: loss = 0.00737269 (* 1 = 0.00737269 loss)
I0515 04:59:40.212743 12912 sgd_solver.cpp:106] Iteration 73500, lr = 0.0005
I0515 05:00:18.180657 12912 solver.cpp:228] Iteration 73550, loss = 0.00529311
I0515 05:00:18.180829 12912 solver.cpp:244]     Train net output #0: loss = 0.0052936 (* 1 = 0.0052936 loss)
I0515 05:00:18.180846 12912 sgd_solver.cpp:106] Iteration 73550, lr = 0.0005
I0515 05:00:56.145212 12912 solver.cpp:228] Iteration 73600, loss = 0.00588528
I0515 05:00:56.145373 12912 solver.cpp:244]     Train net output #0: loss = 0.00588578 (* 1 = 0.00588578 loss)
I0515 05:00:56.145419 12912 sgd_solver.cpp:106] Iteration 73600, lr = 0.0005
I0515 05:01:34.134192 12912 solver.cpp:228] Iteration 73650, loss = 0.00106469
I0515 05:01:34.134414 12912 solver.cpp:244]     Train net output #0: loss = 0.00106519 (* 1 = 0.00106519 loss)
I0515 05:01:34.134457 12912 sgd_solver.cpp:106] Iteration 73650, lr = 0.0005
I0515 05:02:12.111403 12912 solver.cpp:228] Iteration 73700, loss = 0.00227858
I0515 05:02:12.111523 12912 solver.cpp:244]     Train net output #0: loss = 0.00227907 (* 1 = 0.00227907 loss)
I0515 05:02:12.111542 12912 sgd_solver.cpp:106] Iteration 73700, lr = 0.0005
I0515 05:02:50.075891 12912 solver.cpp:228] Iteration 73750, loss = 0.00479704
I0515 05:02:50.076036 12912 solver.cpp:244]     Train net output #0: loss = 0.00479754 (* 1 = 0.00479754 loss)
I0515 05:02:50.076088 12912 sgd_solver.cpp:106] Iteration 73750, lr = 0.0005
I0515 05:03:28.049945 12912 solver.cpp:228] Iteration 73800, loss = 0.00106987
I0515 05:03:28.050072 12912 solver.cpp:244]     Train net output #0: loss = 0.00107036 (* 1 = 0.00107036 loss)
I0515 05:03:28.050086 12912 sgd_solver.cpp:106] Iteration 73800, lr = 0.0005
I0515 05:04:06.009441 12912 solver.cpp:228] Iteration 73850, loss = 0.0031435
I0515 05:04:06.009697 12912 solver.cpp:244]     Train net output #0: loss = 0.00314399 (* 1 = 0.00314399 loss)
I0515 05:04:06.009738 12912 sgd_solver.cpp:106] Iteration 73850, lr = 0.0005
I0515 05:04:43.969388 12912 solver.cpp:228] Iteration 73900, loss = 0.0072125
I0515 05:04:43.969537 12912 solver.cpp:244]     Train net output #0: loss = 0.007213 (* 1 = 0.007213 loss)
I0515 05:04:43.969554 12912 sgd_solver.cpp:106] Iteration 73900, lr = 0.0005
I0515 05:05:21.933941 12912 solver.cpp:228] Iteration 73950, loss = 0.00361775
I0515 05:05:21.934139 12912 solver.cpp:244]     Train net output #0: loss = 0.00361824 (* 1 = 0.00361824 loss)
I0515 05:05:21.934180 12912 sgd_solver.cpp:106] Iteration 73950, lr = 0.0005
I0515 05:05:59.597735 12912 solver.cpp:454] Snapshotting to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_74000.caffemodel
I0515 05:06:00.128741 12912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_74000.solverstate
I0515 05:06:00.214010 12912 solver.cpp:337] Iteration 74000, Testing net (#0)
I0515 05:06:00.214119 12912 net.cpp:685] Ignoring source layer loss
I0515 05:07:43.236112 12912 solver.cpp:404]     Test net output #0: accuracy = 0.791471
I0515 05:07:43.526265 12912 solver.cpp:228] Iteration 74000, loss = 0.0110236
I0515 05:07:43.526337 12912 solver.cpp:244]     Train net output #0: loss = 0.0110241 (* 1 = 0.0110241 loss)
I0515 05:07:43.526351 12912 sgd_solver.cpp:106] Iteration 74000, lr = 0.0005
I0515 05:08:21.527719 12912 solver.cpp:228] Iteration 74050, loss = 0.00848987
I0515 05:08:21.527828 12912 solver.cpp:244]     Train net output #0: loss = 0.00849037 (* 1 = 0.00849037 loss)
I0515 05:08:21.527848 12912 sgd_solver.cpp:106] Iteration 74050, lr = 0.0005
I0515 05:08:59.514065 12912 solver.cpp:228] Iteration 74100, loss = 0.0043861
I0515 05:08:59.514186 12912 solver.cpp:244]     Train net output #0: loss = 0.0043866 (* 1 = 0.0043866 loss)
I0515 05:08:59.514206 12912 sgd_solver.cpp:106] Iteration 74100, lr = 0.0005
I0515 05:09:37.483319 12912 solver.cpp:228] Iteration 74150, loss = 0.00225114
I0515 05:09:37.483427 12912 solver.cpp:244]     Train net output #0: loss = 0.00225164 (* 1 = 0.00225164 loss)
I0515 05:09:37.483444 12912 sgd_solver.cpp:106] Iteration 74150, lr = 0.0005
I0515 05:10:15.455114 12912 solver.cpp:228] Iteration 74200, loss = 0.00172169
I0515 05:10:15.455255 12912 solver.cpp:244]     Train net output #0: loss = 0.00172219 (* 1 = 0.00172219 loss)
I0515 05:10:15.455305 12912 sgd_solver.cpp:106] Iteration 74200, lr = 0.0005
I0515 05:10:53.432785 12912 solver.cpp:228] Iteration 74250, loss = 0.00158986
I0515 05:10:53.432904 12912 solver.cpp:244]     Train net output #0: loss = 0.00159036 (* 1 = 0.00159036 loss)
I0515 05:10:53.432916 12912 sgd_solver.cpp:106] Iteration 74250, lr = 0.0005
I0515 05:11:31.393141 12912 solver.cpp:228] Iteration 74300, loss = 0.00561569
I0515 05:11:31.393231 12912 solver.cpp:244]     Train net output #0: loss = 0.00561618 (* 1 = 0.00561618 loss)
I0515 05:11:31.393244 12912 sgd_solver.cpp:106] Iteration 74300, lr = 0.0005
I0515 05:12:09.374081 12912 solver.cpp:228] Iteration 74350, loss = 0.00388215
I0515 05:12:09.374299 12912 solver.cpp:244]     Train net output #0: loss = 0.00388264 (* 1 = 0.00388264 loss)
I0515 05:12:09.374337 12912 sgd_solver.cpp:106] Iteration 74350, lr = 0.0005
I0515 05:12:47.333479 12912 solver.cpp:228] Iteration 74400, loss = 0.00207271
I0515 05:12:47.333583 12912 solver.cpp:244]     Train net output #0: loss = 0.0020732 (* 1 = 0.0020732 loss)
I0515 05:12:47.333601 12912 sgd_solver.cpp:106] Iteration 74400, lr = 0.0005
I0515 05:13:25.309676 12912 solver.cpp:228] Iteration 74450, loss = 0.019276
I0515 05:13:25.309798 12912 solver.cpp:244]     Train net output #0: loss = 0.0192765 (* 1 = 0.0192765 loss)
I0515 05:13:25.309814 12912 sgd_solver.cpp:106] Iteration 74450, lr = 0.0005
I0515 05:14:03.263746 12912 solver.cpp:228] Iteration 74500, loss = 0.00377976
I0515 05:14:03.263922 12912 solver.cpp:244]     Train net output #0: loss = 0.00378026 (* 1 = 0.00378026 loss)
I0515 05:14:03.263941 12912 sgd_solver.cpp:106] Iteration 74500, lr = 0.0005
I0515 05:14:41.215704 12912 solver.cpp:228] Iteration 74550, loss = 0.00332267
I0515 05:14:41.215883 12912 solver.cpp:244]     Train net output #0: loss = 0.00332317 (* 1 = 0.00332317 loss)
I0515 05:14:41.215903 12912 sgd_solver.cpp:106] Iteration 74550, lr = 0.0005
I0515 05:15:19.160935 12912 solver.cpp:228] Iteration 74600, loss = 0.011239
I0515 05:15:19.161090 12912 solver.cpp:244]     Train net output #0: loss = 0.0112395 (* 1 = 0.0112395 loss)
I0515 05:15:19.161110 12912 sgd_solver.cpp:106] Iteration 74600, lr = 0.0005
I0515 05:15:57.143329 12912 solver.cpp:228] Iteration 74650, loss = 0.00687111
I0515 05:15:57.143435 12912 solver.cpp:244]     Train net output #0: loss = 0.00687161 (* 1 = 0.00687161 loss)
I0515 05:15:57.143453 12912 sgd_solver.cpp:106] Iteration 74650, lr = 0.0005
I0515 05:16:35.109071 12912 solver.cpp:228] Iteration 74700, loss = 0.00422421
I0515 05:16:35.109170 12912 solver.cpp:244]     Train net output #0: loss = 0.00422471 (* 1 = 0.00422471 loss)
I0515 05:16:35.109189 12912 sgd_solver.cpp:106] Iteration 74700, lr = 0.0005
I0515 05:17:13.098306 12912 solver.cpp:228] Iteration 74750, loss = 0.00107657
I0515 05:17:13.098412 12912 solver.cpp:244]     Train net output #0: loss = 0.00107707 (* 1 = 0.00107707 loss)
I0515 05:17:13.098430 12912 sgd_solver.cpp:106] Iteration 74750, lr = 0.0005
I0515 05:17:51.068820 12912 solver.cpp:228] Iteration 74800, loss = 0.0310838
I0515 05:17:51.068918 12912 solver.cpp:244]     Train net output #0: loss = 0.0310843 (* 1 = 0.0310843 loss)
I0515 05:17:51.068931 12912 sgd_solver.cpp:106] Iteration 74800, lr = 0.0005
I0515 05:18:29.053839 12912 solver.cpp:228] Iteration 74850, loss = 0.00251933
I0515 05:18:29.053941 12912 solver.cpp:244]     Train net output #0: loss = 0.00251984 (* 1 = 0.00251984 loss)
I0515 05:18:29.053953 12912 sgd_solver.cpp:106] Iteration 74850, lr = 0.0005
I0515 05:19:07.021307 12912 solver.cpp:228] Iteration 74900, loss = 0.00339475
I0515 05:19:07.021442 12912 solver.cpp:244]     Train net output #0: loss = 0.00339525 (* 1 = 0.00339525 loss)
I0515 05:19:07.021461 12912 sgd_solver.cpp:106] Iteration 74900, lr = 0.0005
I0515 05:19:44.985913 12912 solver.cpp:228] Iteration 74950, loss = 0.013244
I0515 05:19:44.986176 12912 solver.cpp:244]     Train net output #0: loss = 0.0132445 (* 1 = 0.0132445 loss)
I0515 05:19:44.986223 12912 sgd_solver.cpp:106] Iteration 74950, lr = 0.0005
I0515 05:20:22.648617 12912 solver.cpp:454] Snapshotting to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_75000.caffemodel
I0515 05:20:23.210978 12912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_75000.solverstate
I0515 05:20:23.293985 12912 solver.cpp:337] Iteration 75000, Testing net (#0)
I0515 05:20:23.294050 12912 net.cpp:685] Ignoring source layer loss
I0515 05:22:06.348335 12912 solver.cpp:404]     Test net output #0: accuracy = 0.7675
I0515 05:22:06.638856 12912 solver.cpp:228] Iteration 75000, loss = 0.00599989
I0515 05:22:06.638909 12912 solver.cpp:244]     Train net output #0: loss = 0.00600039 (* 1 = 0.00600039 loss)
I0515 05:22:06.638926 12912 sgd_solver.cpp:106] Iteration 75000, lr = 0.0005
I0515 05:22:44.625156 12912 solver.cpp:228] Iteration 75050, loss = 0.00245477
I0515 05:22:44.625275 12912 solver.cpp:244]     Train net output #0: loss = 0.00245527 (* 1 = 0.00245527 loss)
I0515 05:22:44.625289 12912 sgd_solver.cpp:106] Iteration 75050, lr = 0.0005
I0515 05:23:22.578171 12912 solver.cpp:228] Iteration 75100, loss = 0.00389392
I0515 05:23:22.578271 12912 solver.cpp:244]     Train net output #0: loss = 0.00389442 (* 1 = 0.00389442 loss)
I0515 05:23:22.578284 12912 sgd_solver.cpp:106] Iteration 75100, lr = 0.0005
I0515 05:24:00.549343 12912 solver.cpp:228] Iteration 75150, loss = 0.00302278
I0515 05:24:00.549549 12912 solver.cpp:244]     Train net output #0: loss = 0.00302329 (* 1 = 0.00302329 loss)
I0515 05:24:00.549576 12912 sgd_solver.cpp:106] Iteration 75150, lr = 0.0005
I0515 05:24:38.501386 12912 solver.cpp:228] Iteration 75200, loss = 0.00912889
I0515 05:24:38.501505 12912 solver.cpp:244]     Train net output #0: loss = 0.00912939 (* 1 = 0.00912939 loss)
I0515 05:24:38.501523 12912 sgd_solver.cpp:106] Iteration 75200, lr = 0.0005
I0515 05:25:16.467411 12912 solver.cpp:228] Iteration 75250, loss = 0.00137488
I0515 05:25:16.467568 12912 solver.cpp:244]     Train net output #0: loss = 0.00137539 (* 1 = 0.00137539 loss)
I0515 05:25:16.467587 12912 sgd_solver.cpp:106] Iteration 75250, lr = 0.0005
I0515 05:25:54.452682 12912 solver.cpp:228] Iteration 75300, loss = 0.00484389
I0515 05:25:54.452786 12912 solver.cpp:244]     Train net output #0: loss = 0.0048444 (* 1 = 0.0048444 loss)
I0515 05:25:54.452805 12912 sgd_solver.cpp:106] Iteration 75300, lr = 0.0005
I0515 05:26:32.414053 12912 solver.cpp:228] Iteration 75350, loss = 0.00461317
I0515 05:26:32.414181 12912 solver.cpp:244]     Train net output #0: loss = 0.00461367 (* 1 = 0.00461367 loss)
I0515 05:26:32.414201 12912 sgd_solver.cpp:106] Iteration 75350, lr = 0.0005
I0515 05:27:10.379643 12912 solver.cpp:228] Iteration 75400, loss = 0.00605005
I0515 05:27:10.379747 12912 solver.cpp:244]     Train net output #0: loss = 0.00605056 (* 1 = 0.00605056 loss)
I0515 05:27:10.379760 12912 sgd_solver.cpp:106] Iteration 75400, lr = 0.0005
I0515 05:27:48.349268 12912 solver.cpp:228] Iteration 75450, loss = 0.00209051
I0515 05:27:48.349405 12912 solver.cpp:244]     Train net output #0: loss = 0.00209102 (* 1 = 0.00209102 loss)
I0515 05:27:48.349423 12912 sgd_solver.cpp:106] Iteration 75450, lr = 0.0005
I0515 05:28:26.322012 12912 solver.cpp:228] Iteration 75500, loss = 0.00483845
I0515 05:28:26.322177 12912 solver.cpp:244]     Train net output #0: loss = 0.00483895 (* 1 = 0.00483895 loss)
I0515 05:28:26.322196 12912 sgd_solver.cpp:106] Iteration 75500, lr = 0.0005
I0515 05:29:04.295390 12912 solver.cpp:228] Iteration 75550, loss = 0.0164218
I0515 05:29:04.295506 12912 solver.cpp:244]     Train net output #0: loss = 0.0164223 (* 1 = 0.0164223 loss)
I0515 05:29:04.295524 12912 sgd_solver.cpp:106] Iteration 75550, lr = 0.0005
I0515 05:29:42.261348 12912 solver.cpp:228] Iteration 75600, loss = 0.00148246
I0515 05:29:42.261476 12912 solver.cpp:244]     Train net output #0: loss = 0.00148297 (* 1 = 0.00148297 loss)
I0515 05:29:42.261495 12912 sgd_solver.cpp:106] Iteration 75600, lr = 0.0005
I0515 05:30:20.238210 12912 solver.cpp:228] Iteration 75650, loss = 0.00310209
I0515 05:30:20.238355 12912 solver.cpp:244]     Train net output #0: loss = 0.0031026 (* 1 = 0.0031026 loss)
I0515 05:30:20.238373 12912 sgd_solver.cpp:106] Iteration 75650, lr = 0.0005
I0515 05:30:58.213434 12912 solver.cpp:228] Iteration 75700, loss = 0.0111523
I0515 05:30:58.213579 12912 solver.cpp:244]     Train net output #0: loss = 0.0111528 (* 1 = 0.0111528 loss)
I0515 05:30:58.213599 12912 sgd_solver.cpp:106] Iteration 75700, lr = 0.0005
I0515 05:31:36.208572 12912 solver.cpp:228] Iteration 75750, loss = 0.0125828
I0515 05:31:36.208699 12912 solver.cpp:244]     Train net output #0: loss = 0.0125834 (* 1 = 0.0125834 loss)
I0515 05:31:36.208715 12912 sgd_solver.cpp:106] Iteration 75750, lr = 0.0005
I0515 05:32:14.173929 12912 solver.cpp:228] Iteration 75800, loss = 0.00102148
I0515 05:32:14.174069 12912 solver.cpp:244]     Train net output #0: loss = 0.001022 (* 1 = 0.001022 loss)
I0515 05:32:14.174083 12912 sgd_solver.cpp:106] Iteration 75800, lr = 0.0005
I0515 05:32:52.121867 12912 solver.cpp:228] Iteration 75850, loss = 0.00249457
I0515 05:32:52.121978 12912 solver.cpp:244]     Train net output #0: loss = 0.00249509 (* 1 = 0.00249509 loss)
I0515 05:32:52.121997 12912 sgd_solver.cpp:106] Iteration 75850, lr = 0.0005
I0515 05:33:30.091850 12912 solver.cpp:228] Iteration 75900, loss = 0.0197818
I0515 05:33:30.091948 12912 solver.cpp:244]     Train net output #0: loss = 0.0197823 (* 1 = 0.0197823 loss)
I0515 05:33:30.091965 12912 sgd_solver.cpp:106] Iteration 75900, lr = 0.0005
I0515 05:34:08.045666 12912 solver.cpp:228] Iteration 75950, loss = 0.00181694
I0515 05:34:08.045796 12912 solver.cpp:244]     Train net output #0: loss = 0.00181746 (* 1 = 0.00181746 loss)
I0515 05:34:08.045814 12912 sgd_solver.cpp:106] Iteration 75950, lr = 0.0005
I0515 05:34:45.713879 12912 solver.cpp:454] Snapshotting to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_76000.caffemodel
I0515 05:34:46.456557 12912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_76000.solverstate
I0515 05:34:46.600589 12912 solver.cpp:337] Iteration 76000, Testing net (#0)
I0515 05:34:46.600656 12912 net.cpp:685] Ignoring source layer loss
I0515 05:36:29.477900 12912 solver.cpp:404]     Test net output #0: accuracy = 0.784412
I0515 05:36:29.767645 12912 solver.cpp:228] Iteration 76000, loss = 0.00808747
I0515 05:36:29.767699 12912 solver.cpp:244]     Train net output #0: loss = 0.00808798 (* 1 = 0.00808798 loss)
I0515 05:36:29.767711 12912 sgd_solver.cpp:106] Iteration 76000, lr = 0.0005
I0515 05:37:07.737560 12912 solver.cpp:228] Iteration 76050, loss = 0.00565136
I0515 05:37:07.737682 12912 solver.cpp:244]     Train net output #0: loss = 0.00565188 (* 1 = 0.00565188 loss)
I0515 05:37:07.737702 12912 sgd_solver.cpp:106] Iteration 76050, lr = 0.0005
I0515 05:37:45.715397 12912 solver.cpp:228] Iteration 76100, loss = 0.00165089
I0515 05:37:45.715523 12912 solver.cpp:244]     Train net output #0: loss = 0.00165141 (* 1 = 0.00165141 loss)
I0515 05:37:45.715539 12912 sgd_solver.cpp:106] Iteration 76100, lr = 0.0005
I0515 05:38:23.691742 12912 solver.cpp:228] Iteration 76150, loss = 0.0351178
I0515 05:38:23.691900 12912 solver.cpp:244]     Train net output #0: loss = 0.0351183 (* 1 = 0.0351183 loss)
I0515 05:38:23.691926 12912 sgd_solver.cpp:106] Iteration 76150, lr = 0.0005
I0515 05:39:01.674211 12912 solver.cpp:228] Iteration 76200, loss = 0.00767359
I0515 05:39:01.674331 12912 solver.cpp:244]     Train net output #0: loss = 0.00767411 (* 1 = 0.00767411 loss)
I0515 05:39:01.674347 12912 sgd_solver.cpp:106] Iteration 76200, lr = 0.0005
I0515 05:39:39.639948 12912 solver.cpp:228] Iteration 76250, loss = 0.0083749
I0515 05:39:39.640075 12912 solver.cpp:244]     Train net output #0: loss = 0.00837542 (* 1 = 0.00837542 loss)
I0515 05:39:39.640094 12912 sgd_solver.cpp:106] Iteration 76250, lr = 0.0005
I0515 05:40:17.638614 12912 solver.cpp:228] Iteration 76300, loss = 0.0214065
I0515 05:40:17.638736 12912 solver.cpp:244]     Train net output #0: loss = 0.0214071 (* 1 = 0.0214071 loss)
I0515 05:40:17.638758 12912 sgd_solver.cpp:106] Iteration 76300, lr = 0.0005
I0515 05:40:55.607362 12912 solver.cpp:228] Iteration 76350, loss = 0.0078599
I0515 05:40:55.607498 12912 solver.cpp:244]     Train net output #0: loss = 0.00786045 (* 1 = 0.00786045 loss)
I0515 05:40:55.607517 12912 sgd_solver.cpp:106] Iteration 76350, lr = 0.0005
I0515 05:41:33.583405 12912 solver.cpp:228] Iteration 76400, loss = 0.014543
I0515 05:41:33.583523 12912 solver.cpp:244]     Train net output #0: loss = 0.0145436 (* 1 = 0.0145436 loss)
I0515 05:41:33.583540 12912 sgd_solver.cpp:106] Iteration 76400, lr = 0.0005
I0515 05:42:11.544137 12912 solver.cpp:228] Iteration 76450, loss = 0.0264145
I0515 05:42:11.544284 12912 solver.cpp:244]     Train net output #0: loss = 0.0264151 (* 1 = 0.0264151 loss)
I0515 05:42:11.544303 12912 sgd_solver.cpp:106] Iteration 76450, lr = 0.0005
I0515 05:42:49.504209 12912 solver.cpp:228] Iteration 76500, loss = 0.0141417
I0515 05:42:49.504313 12912 solver.cpp:244]     Train net output #0: loss = 0.0141423 (* 1 = 0.0141423 loss)
I0515 05:42:49.504331 12912 sgd_solver.cpp:106] Iteration 76500, lr = 0.0005
I0515 05:43:27.464928 12912 solver.cpp:228] Iteration 76550, loss = 0.012638
I0515 05:43:27.465032 12912 solver.cpp:244]     Train net output #0: loss = 0.0126386 (* 1 = 0.0126386 loss)
I0515 05:43:27.465051 12912 sgd_solver.cpp:106] Iteration 76550, lr = 0.0005
I0515 05:44:05.417824 12912 solver.cpp:228] Iteration 76600, loss = 0.114269
I0515 05:44:05.417919 12912 solver.cpp:244]     Train net output #0: loss = 0.11427 (* 1 = 0.11427 loss)
I0515 05:44:05.417937 12912 sgd_solver.cpp:106] Iteration 76600, lr = 0.0005
I0515 05:44:43.399559 12912 solver.cpp:228] Iteration 76650, loss = 0.00362903
I0515 05:44:43.399701 12912 solver.cpp:244]     Train net output #0: loss = 0.00362961 (* 1 = 0.00362961 loss)
I0515 05:44:43.399714 12912 sgd_solver.cpp:106] Iteration 76650, lr = 0.0005
I0515 05:45:21.372318 12912 solver.cpp:228] Iteration 76700, loss = 0.0110606
I0515 05:45:21.372463 12912 solver.cpp:244]     Train net output #0: loss = 0.0110612 (* 1 = 0.0110612 loss)
I0515 05:45:21.372481 12912 sgd_solver.cpp:106] Iteration 76700, lr = 0.0005
I0515 05:45:59.343403 12912 solver.cpp:228] Iteration 76750, loss = 0.0178091
I0515 05:45:59.343513 12912 solver.cpp:244]     Train net output #0: loss = 0.0178097 (* 1 = 0.0178097 loss)
I0515 05:45:59.343533 12912 sgd_solver.cpp:106] Iteration 76750, lr = 0.0005
I0515 05:46:37.323475 12912 solver.cpp:228] Iteration 76800, loss = 0.253597
I0515 05:46:37.323582 12912 solver.cpp:244]     Train net output #0: loss = 0.253598 (* 1 = 0.253598 loss)
I0515 05:46:37.323596 12912 sgd_solver.cpp:106] Iteration 76800, lr = 0.0005
I0515 05:47:15.295251 12912 solver.cpp:228] Iteration 76850, loss = 0.010401
I0515 05:47:15.295387 12912 solver.cpp:244]     Train net output #0: loss = 0.0104016 (* 1 = 0.0104016 loss)
I0515 05:47:15.295399 12912 sgd_solver.cpp:106] Iteration 76850, lr = 0.0005
I0515 05:47:53.245447 12912 solver.cpp:228] Iteration 76900, loss = 0.0120904
I0515 05:47:53.245599 12912 solver.cpp:244]     Train net output #0: loss = 0.012091 (* 1 = 0.012091 loss)
I0515 05:47:53.245614 12912 sgd_solver.cpp:106] Iteration 76900, lr = 0.0005
I0515 05:48:31.223892 12912 solver.cpp:228] Iteration 76950, loss = 0.030039
I0515 05:48:31.224001 12912 solver.cpp:244]     Train net output #0: loss = 0.0300396 (* 1 = 0.0300396 loss)
I0515 05:48:31.224020 12912 sgd_solver.cpp:106] Iteration 76950, lr = 0.0005
I0515 05:49:08.885931 12912 solver.cpp:454] Snapshotting to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_77000.caffemodel
I0515 05:49:09.418437 12912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_77000.solverstate
I0515 05:49:09.503213 12912 solver.cpp:337] Iteration 77000, Testing net (#0)
I0515 05:49:09.503271 12912 net.cpp:685] Ignoring source layer loss
I0515 05:50:52.364970 12912 solver.cpp:404]     Test net output #0: accuracy = 0.727647
I0515 05:50:52.654983 12912 solver.cpp:228] Iteration 77000, loss = 0.0339303
I0515 05:50:52.655031 12912 solver.cpp:244]     Train net output #0: loss = 0.0339309 (* 1 = 0.0339309 loss)
I0515 05:50:52.655042 12912 sgd_solver.cpp:106] Iteration 77000, lr = 0.0005
I0515 05:51:30.640467 12912 solver.cpp:228] Iteration 77050, loss = 0.00959933
I0515 05:51:30.640645 12912 solver.cpp:244]     Train net output #0: loss = 0.00959993 (* 1 = 0.00959993 loss)
I0515 05:51:30.640686 12912 sgd_solver.cpp:106] Iteration 77050, lr = 0.0005
I0515 05:52:08.640086 12912 solver.cpp:228] Iteration 77100, loss = 0.00266334
I0515 05:52:08.640204 12912 solver.cpp:244]     Train net output #0: loss = 0.00266393 (* 1 = 0.00266393 loss)
I0515 05:52:08.640224 12912 sgd_solver.cpp:106] Iteration 77100, lr = 0.0005
I0515 05:52:46.617071 12912 solver.cpp:228] Iteration 77150, loss = 0.0187081
I0515 05:52:46.617213 12912 solver.cpp:244]     Train net output #0: loss = 0.0187087 (* 1 = 0.0187087 loss)
I0515 05:52:46.617228 12912 sgd_solver.cpp:106] Iteration 77150, lr = 0.0005
I0515 05:53:24.581969 12912 solver.cpp:228] Iteration 77200, loss = 0.00520711
I0515 05:53:24.582185 12912 solver.cpp:244]     Train net output #0: loss = 0.0052077 (* 1 = 0.0052077 loss)
I0515 05:53:24.582223 12912 sgd_solver.cpp:106] Iteration 77200, lr = 0.0005
I0515 05:54:02.534270 12912 solver.cpp:228] Iteration 77250, loss = 0.00778866
I0515 05:54:02.534370 12912 solver.cpp:244]     Train net output #0: loss = 0.00778925 (* 1 = 0.00778925 loss)
I0515 05:54:02.534389 12912 sgd_solver.cpp:106] Iteration 77250, lr = 0.0005
I0515 05:54:40.530823 12912 solver.cpp:228] Iteration 77300, loss = 0.00575254
I0515 05:54:40.530920 12912 solver.cpp:244]     Train net output #0: loss = 0.00575312 (* 1 = 0.00575312 loss)
I0515 05:54:40.530932 12912 sgd_solver.cpp:106] Iteration 77300, lr = 0.0005
I0515 05:55:18.516583 12912 solver.cpp:228] Iteration 77350, loss = 0.00732638
I0515 05:55:18.516698 12912 solver.cpp:244]     Train net output #0: loss = 0.00732697 (* 1 = 0.00732697 loss)
I0515 05:55:18.516716 12912 sgd_solver.cpp:106] Iteration 77350, lr = 0.0005
I0515 05:55:56.484688 12912 solver.cpp:228] Iteration 77400, loss = 0.00613385
I0515 05:55:56.484853 12912 solver.cpp:244]     Train net output #0: loss = 0.00613443 (* 1 = 0.00613443 loss)
I0515 05:55:56.484870 12912 sgd_solver.cpp:106] Iteration 77400, lr = 0.0005
I0515 05:56:34.462580 12912 solver.cpp:228] Iteration 77450, loss = 0.0142029
I0515 05:56:34.466167 12912 solver.cpp:244]     Train net output #0: loss = 0.0142035 (* 1 = 0.0142035 loss)
I0515 05:56:34.466222 12912 sgd_solver.cpp:106] Iteration 77450, lr = 0.0005
I0515 05:57:12.427737 12912 solver.cpp:228] Iteration 77500, loss = 0.00579128
I0515 05:57:12.427899 12912 solver.cpp:244]     Train net output #0: loss = 0.00579186 (* 1 = 0.00579186 loss)
I0515 05:57:12.427917 12912 sgd_solver.cpp:106] Iteration 77500, lr = 0.0005
I0515 05:57:50.392529 12912 solver.cpp:228] Iteration 77550, loss = 0.0038785
I0515 05:57:50.392657 12912 solver.cpp:244]     Train net output #0: loss = 0.00387908 (* 1 = 0.00387908 loss)
I0515 05:57:50.392675 12912 sgd_solver.cpp:106] Iteration 77550, lr = 0.0005
I0515 05:58:28.350693 12912 solver.cpp:228] Iteration 77600, loss = 0.00416206
I0515 05:58:28.350810 12912 solver.cpp:244]     Train net output #0: loss = 0.00416264 (* 1 = 0.00416264 loss)
I0515 05:58:28.350822 12912 sgd_solver.cpp:106] Iteration 77600, lr = 0.0005
I0515 05:59:06.336546 12912 solver.cpp:228] Iteration 77650, loss = 0.00315937
I0515 05:59:06.336670 12912 solver.cpp:244]     Train net output #0: loss = 0.00315995 (* 1 = 0.00315995 loss)
I0515 05:59:06.336688 12912 sgd_solver.cpp:106] Iteration 77650, lr = 0.0005
I0515 05:59:44.298167 12912 solver.cpp:228] Iteration 77700, loss = 0.0102297
I0515 05:59:44.298362 12912 solver.cpp:244]     Train net output #0: loss = 0.0102303 (* 1 = 0.0102303 loss)
I0515 05:59:44.298418 12912 sgd_solver.cpp:106] Iteration 77700, lr = 0.0005
I0515 06:00:22.281188 12912 solver.cpp:228] Iteration 77750, loss = 0.00265351
I0515 06:00:22.281304 12912 solver.cpp:244]     Train net output #0: loss = 0.00265409 (* 1 = 0.00265409 loss)
I0515 06:00:22.281322 12912 sgd_solver.cpp:106] Iteration 77750, lr = 0.0005
I0515 06:01:00.259990 12912 solver.cpp:228] Iteration 77800, loss = 0.00961376
I0515 06:01:00.260093 12912 solver.cpp:244]     Train net output #0: loss = 0.00961434 (* 1 = 0.00961434 loss)
I0515 06:01:00.260113 12912 sgd_solver.cpp:106] Iteration 77800, lr = 0.0005
I0515 06:01:38.250254 12912 solver.cpp:228] Iteration 77850, loss = 0.00488339
I0515 06:01:38.250360 12912 solver.cpp:244]     Train net output #0: loss = 0.00488399 (* 1 = 0.00488399 loss)
I0515 06:01:38.250376 12912 sgd_solver.cpp:106] Iteration 77850, lr = 0.0005
I0515 06:02:16.202533 12912 solver.cpp:228] Iteration 77900, loss = 0.0466282
I0515 06:02:16.202684 12912 solver.cpp:244]     Train net output #0: loss = 0.0466288 (* 1 = 0.0466288 loss)
I0515 06:02:16.202698 12912 sgd_solver.cpp:106] Iteration 77900, lr = 0.0005
I0515 06:02:54.155894 12912 solver.cpp:228] Iteration 77950, loss = 0.0798054
I0515 06:02:54.156010 12912 solver.cpp:244]     Train net output #0: loss = 0.079806 (* 1 = 0.079806 loss)
I0515 06:02:54.156024 12912 sgd_solver.cpp:106] Iteration 77950, lr = 0.0005
I0515 06:03:31.848057 12912 solver.cpp:454] Snapshotting to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_78000.caffemodel
I0515 06:03:32.386798 12912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_78000.solverstate
I0515 06:03:32.471653 12912 solver.cpp:337] Iteration 78000, Testing net (#0)
I0515 06:03:32.471726 12912 net.cpp:685] Ignoring source layer loss
I0515 06:05:15.527714 12912 solver.cpp:404]     Test net output #0: accuracy = 0.490441
I0515 06:05:15.817033 12912 solver.cpp:228] Iteration 78000, loss = 0.0601962
I0515 06:05:15.817080 12912 solver.cpp:244]     Train net output #0: loss = 0.0601968 (* 1 = 0.0601968 loss)
I0515 06:05:15.817090 12912 sgd_solver.cpp:106] Iteration 78000, lr = 0.0005
I0515 06:05:53.777258 12912 solver.cpp:228] Iteration 78050, loss = 0.0046164
I0515 06:05:53.777367 12912 solver.cpp:244]     Train net output #0: loss = 0.004617 (* 1 = 0.004617 loss)
I0515 06:05:53.777381 12912 sgd_solver.cpp:106] Iteration 78050, lr = 0.0005
I0515 06:06:31.769574 12912 solver.cpp:228] Iteration 78100, loss = 0.0072466
I0515 06:06:31.769675 12912 solver.cpp:244]     Train net output #0: loss = 0.0072472 (* 1 = 0.0072472 loss)
I0515 06:06:31.769686 12912 sgd_solver.cpp:106] Iteration 78100, lr = 0.0005
I0515 06:07:09.730407 12912 solver.cpp:228] Iteration 78150, loss = 0.00914583
I0515 06:07:09.730517 12912 solver.cpp:244]     Train net output #0: loss = 0.00914642 (* 1 = 0.00914642 loss)
I0515 06:07:09.730535 12912 sgd_solver.cpp:106] Iteration 78150, lr = 0.0005
I0515 06:07:47.694088 12912 solver.cpp:228] Iteration 78200, loss = 0.00534045
I0515 06:07:47.694210 12912 solver.cpp:244]     Train net output #0: loss = 0.00534105 (* 1 = 0.00534105 loss)
I0515 06:07:47.694228 12912 sgd_solver.cpp:106] Iteration 78200, lr = 0.0005
I0515 06:08:25.654508 12912 solver.cpp:228] Iteration 78250, loss = 0.00298214
I0515 06:08:25.654639 12912 solver.cpp:244]     Train net output #0: loss = 0.00298273 (* 1 = 0.00298273 loss)
I0515 06:08:25.654654 12912 sgd_solver.cpp:106] Iteration 78250, lr = 0.0005
I0515 06:09:03.627485 12912 solver.cpp:228] Iteration 78300, loss = 0.00590015
I0515 06:09:03.627607 12912 solver.cpp:244]     Train net output #0: loss = 0.00590074 (* 1 = 0.00590074 loss)
I0515 06:09:03.627621 12912 sgd_solver.cpp:106] Iteration 78300, lr = 0.0005
I0515 06:09:41.603248 12912 solver.cpp:228] Iteration 78350, loss = 0.00860708
I0515 06:09:41.603425 12912 solver.cpp:244]     Train net output #0: loss = 0.00860767 (* 1 = 0.00860767 loss)
I0515 06:09:41.603464 12912 sgd_solver.cpp:106] Iteration 78350, lr = 0.0005
I0515 06:10:19.590864 12912 solver.cpp:228] Iteration 78400, loss = 0.0242095
I0515 06:10:19.591030 12912 solver.cpp:244]     Train net output #0: loss = 0.0242101 (* 1 = 0.0242101 loss)
I0515 06:10:19.591071 12912 sgd_solver.cpp:106] Iteration 78400, lr = 0.0005
I0515 06:10:57.579051 12912 solver.cpp:228] Iteration 78450, loss = 0.00360702
I0515 06:10:57.579203 12912 solver.cpp:244]     Train net output #0: loss = 0.00360762 (* 1 = 0.00360762 loss)
I0515 06:10:57.579224 12912 sgd_solver.cpp:106] Iteration 78450, lr = 0.0005
I0515 06:11:35.562381 12912 solver.cpp:228] Iteration 78500, loss = 0.00243455
I0515 06:11:35.562556 12912 solver.cpp:244]     Train net output #0: loss = 0.00243514 (* 1 = 0.00243514 loss)
I0515 06:11:35.562598 12912 sgd_solver.cpp:106] Iteration 78500, lr = 0.0005
I0515 06:12:13.518118 12912 solver.cpp:228] Iteration 78550, loss = 0.00682612
I0515 06:12:13.518266 12912 solver.cpp:244]     Train net output #0: loss = 0.00682671 (* 1 = 0.00682671 loss)
I0515 06:12:13.518287 12912 sgd_solver.cpp:106] Iteration 78550, lr = 0.0005
I0515 06:12:51.474469 12912 solver.cpp:228] Iteration 78600, loss = 0.0057562
I0515 06:12:51.474599 12912 solver.cpp:244]     Train net output #0: loss = 0.00575679 (* 1 = 0.00575679 loss)
I0515 06:12:51.474617 12912 sgd_solver.cpp:106] Iteration 78600, lr = 0.0005
I0515 06:13:29.437216 12912 solver.cpp:228] Iteration 78650, loss = 0.00486828
I0515 06:13:29.437330 12912 solver.cpp:244]     Train net output #0: loss = 0.00486887 (* 1 = 0.00486887 loss)
I0515 06:13:29.437348 12912 sgd_solver.cpp:106] Iteration 78650, lr = 0.0005
I0515 06:14:07.404520 12912 solver.cpp:228] Iteration 78700, loss = 0.0049486
I0515 06:14:07.404683 12912 solver.cpp:244]     Train net output #0: loss = 0.00494919 (* 1 = 0.00494919 loss)
I0515 06:14:07.404700 12912 sgd_solver.cpp:106] Iteration 78700, lr = 0.0005
I0515 06:14:45.351109 12912 solver.cpp:228] Iteration 78750, loss = 0.00239369
I0515 06:14:45.351232 12912 solver.cpp:244]     Train net output #0: loss = 0.00239429 (* 1 = 0.00239429 loss)
I0515 06:14:45.351243 12912 sgd_solver.cpp:106] Iteration 78750, lr = 0.0005
I0515 06:15:23.298722 12912 solver.cpp:228] Iteration 78800, loss = 0.00943199
I0515 06:15:23.299020 12912 solver.cpp:244]     Train net output #0: loss = 0.00943259 (* 1 = 0.00943259 loss)
I0515 06:15:23.299065 12912 sgd_solver.cpp:106] Iteration 78800, lr = 0.0005
I0515 06:16:01.264670 12912 solver.cpp:228] Iteration 78850, loss = 0.00452029
I0515 06:16:01.264811 12912 solver.cpp:244]     Train net output #0: loss = 0.00452088 (* 1 = 0.00452088 loss)
I0515 06:16:01.264827 12912 sgd_solver.cpp:106] Iteration 78850, lr = 0.0005
I0515 06:16:39.243510 12912 solver.cpp:228] Iteration 78900, loss = 0.00362988
I0515 06:16:39.243616 12912 solver.cpp:244]     Train net output #0: loss = 0.00363047 (* 1 = 0.00363047 loss)
I0515 06:16:39.243630 12912 sgd_solver.cpp:106] Iteration 78900, lr = 0.0005
I0515 06:17:17.189865 12912 solver.cpp:228] Iteration 78950, loss = 0.00427403
I0515 06:17:17.189985 12912 solver.cpp:244]     Train net output #0: loss = 0.00427463 (* 1 = 0.00427463 loss)
I0515 06:17:17.189998 12912 sgd_solver.cpp:106] Iteration 78950, lr = 0.0005
I0515 06:17:54.866461 12912 solver.cpp:454] Snapshotting to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_79000.caffemodel
I0515 06:17:55.422443 12912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_79000.solverstate
I0515 06:17:55.506218 12912 solver.cpp:337] Iteration 79000, Testing net (#0)
I0515 06:17:55.506271 12912 net.cpp:685] Ignoring source layer loss
I0515 06:19:38.484366 12912 solver.cpp:404]     Test net output #0: accuracy = 0.720441
I0515 06:19:38.774312 12912 solver.cpp:228] Iteration 79000, loss = 0.0256221
I0515 06:19:38.774435 12912 solver.cpp:244]     Train net output #0: loss = 0.0256227 (* 1 = 0.0256227 loss)
I0515 06:19:38.774474 12912 sgd_solver.cpp:106] Iteration 79000, lr = 0.0005
I0515 06:20:16.744295 12912 solver.cpp:228] Iteration 79050, loss = 0.00705886
I0515 06:20:16.744403 12912 solver.cpp:244]     Train net output #0: loss = 0.00705945 (* 1 = 0.00705945 loss)
I0515 06:20:16.744421 12912 sgd_solver.cpp:106] Iteration 79050, lr = 0.0005
I0515 06:20:54.742312 12912 solver.cpp:228] Iteration 79100, loss = 0.00695218
I0515 06:20:54.742426 12912 solver.cpp:244]     Train net output #0: loss = 0.00695279 (* 1 = 0.00695279 loss)
I0515 06:20:54.742439 12912 sgd_solver.cpp:106] Iteration 79100, lr = 0.0005
I0515 06:21:32.728554 12912 solver.cpp:228] Iteration 79150, loss = 0.00150565
I0515 06:21:32.728665 12912 solver.cpp:244]     Train net output #0: loss = 0.00150625 (* 1 = 0.00150625 loss)
I0515 06:21:32.728678 12912 sgd_solver.cpp:106] Iteration 79150, lr = 0.0005
I0515 06:22:10.698528 12912 solver.cpp:228] Iteration 79200, loss = 0.0153977
I0515 06:22:10.698626 12912 solver.cpp:244]     Train net output #0: loss = 0.0153983 (* 1 = 0.0153983 loss)
I0515 06:22:10.698638 12912 sgd_solver.cpp:106] Iteration 79200, lr = 0.0005
I0515 06:22:48.664605 12912 solver.cpp:228] Iteration 79250, loss = 0.00762613
I0515 06:22:48.664772 12912 solver.cpp:244]     Train net output #0: loss = 0.00762675 (* 1 = 0.00762675 loss)
I0515 06:22:48.664793 12912 sgd_solver.cpp:106] Iteration 79250, lr = 0.0005
I0515 06:23:26.627152 12912 solver.cpp:228] Iteration 79300, loss = 0.00265385
I0515 06:23:26.627310 12912 solver.cpp:244]     Train net output #0: loss = 0.00265446 (* 1 = 0.00265446 loss)
I0515 06:23:26.627326 12912 sgd_solver.cpp:106] Iteration 79300, lr = 0.0005
I0515 06:24:04.587110 12912 solver.cpp:228] Iteration 79350, loss = 0.00325238
I0515 06:24:04.587219 12912 solver.cpp:244]     Train net output #0: loss = 0.00325299 (* 1 = 0.00325299 loss)
I0515 06:24:04.587237 12912 sgd_solver.cpp:106] Iteration 79350, lr = 0.0005
I0515 06:24:42.551945 12912 solver.cpp:228] Iteration 79400, loss = 0.0196017
I0515 06:24:42.552180 12912 solver.cpp:244]     Train net output #0: loss = 0.0196023 (* 1 = 0.0196023 loss)
I0515 06:24:42.552209 12912 sgd_solver.cpp:106] Iteration 79400, lr = 0.0005
I0515 06:25:20.529254 12912 solver.cpp:228] Iteration 79450, loss = 0.00348505
I0515 06:25:20.529361 12912 solver.cpp:244]     Train net output #0: loss = 0.00348565 (* 1 = 0.00348565 loss)
I0515 06:25:20.529379 12912 sgd_solver.cpp:106] Iteration 79450, lr = 0.0005
I0515 06:25:58.511343 12912 solver.cpp:228] Iteration 79500, loss = 0.0213392
I0515 06:25:58.511442 12912 solver.cpp:244]     Train net output #0: loss = 0.0213398 (* 1 = 0.0213398 loss)
I0515 06:25:58.511461 12912 sgd_solver.cpp:106] Iteration 79500, lr = 0.0005
I0515 06:26:36.485105 12912 solver.cpp:228] Iteration 79550, loss = 0.00999328
I0515 06:26:36.485255 12912 solver.cpp:244]     Train net output #0: loss = 0.00999388 (* 1 = 0.00999388 loss)
I0515 06:26:36.485275 12912 sgd_solver.cpp:106] Iteration 79550, lr = 0.0005
I0515 06:27:14.474695 12912 solver.cpp:228] Iteration 79600, loss = 0.00447078
I0515 06:27:14.474830 12912 solver.cpp:244]     Train net output #0: loss = 0.00447139 (* 1 = 0.00447139 loss)
I0515 06:27:14.474848 12912 sgd_solver.cpp:106] Iteration 79600, lr = 0.0005
I0515 06:27:52.445308 12912 solver.cpp:228] Iteration 79650, loss = 0.00787339
I0515 06:27:52.445438 12912 solver.cpp:244]     Train net output #0: loss = 0.007874 (* 1 = 0.007874 loss)
I0515 06:27:52.445454 12912 sgd_solver.cpp:106] Iteration 79650, lr = 0.0005
I0515 06:28:30.404845 12912 solver.cpp:228] Iteration 79700, loss = 0.0049605
I0515 06:28:30.404988 12912 solver.cpp:244]     Train net output #0: loss = 0.0049611 (* 1 = 0.0049611 loss)
I0515 06:28:30.405001 12912 sgd_solver.cpp:106] Iteration 79700, lr = 0.0005
I0515 06:29:08.353216 12912 solver.cpp:228] Iteration 79750, loss = 0.016677
I0515 06:29:08.353358 12912 solver.cpp:244]     Train net output #0: loss = 0.0166776 (* 1 = 0.0166776 loss)
I0515 06:29:08.353376 12912 sgd_solver.cpp:106] Iteration 79750, lr = 0.0005
I0515 06:29:46.341404 12912 solver.cpp:228] Iteration 79800, loss = 0.00139931
I0515 06:29:46.341569 12912 solver.cpp:244]     Train net output #0: loss = 0.00139991 (* 1 = 0.00139991 loss)
I0515 06:29:46.341586 12912 sgd_solver.cpp:106] Iteration 79800, lr = 0.0005
I0515 06:30:24.300838 12912 solver.cpp:228] Iteration 79850, loss = 0.0017759
I0515 06:30:24.302227 12912 solver.cpp:244]     Train net output #0: loss = 0.0017765 (* 1 = 0.0017765 loss)
I0515 06:30:24.302248 12912 sgd_solver.cpp:106] Iteration 79850, lr = 0.0005
I0515 06:31:02.273259 12912 solver.cpp:228] Iteration 79900, loss = 0.00340941
I0515 06:31:02.273368 12912 solver.cpp:244]     Train net output #0: loss = 0.00341002 (* 1 = 0.00341002 loss)
I0515 06:31:02.273382 12912 sgd_solver.cpp:106] Iteration 79900, lr = 0.0005
I0515 06:31:40.258700 12912 solver.cpp:228] Iteration 79950, loss = 0.00428383
I0515 06:31:40.258913 12912 solver.cpp:244]     Train net output #0: loss = 0.00428444 (* 1 = 0.00428444 loss)
I0515 06:31:40.258954 12912 sgd_solver.cpp:106] Iteration 79950, lr = 0.0005
I0515 06:32:17.920569 12912 solver.cpp:454] Snapshotting to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_80000.caffemodel
I0515 06:32:18.475673 12912 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /data1/shiv/ModelA/Training/fulls2_tr_iter_80000.solverstate
I0515 06:32:18.781582 12912 solver.cpp:317] Iteration 80000, loss = 0.00234014
I0515 06:32:18.781630 12912 solver.cpp:337] Iteration 80000, Testing net (#0)
I0515 06:32:18.781667 12912 net.cpp:685] Ignoring source layer loss
I0515 06:34:01.800400 12912 solver.cpp:404]     Test net output #0: accuracy = 0.783382
I0515 06:34:01.800518 12912 solver.cpp:322] Optimization Done.
I0515 06:34:01.801568 12912 caffe.cpp:222] Optimization Done.
